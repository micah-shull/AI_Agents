{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNoi1sZiBWCWMdL1ZX7zFEs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/000_Agent_Design_Foundations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🤖 What is an AI Agent?\n",
        "\n",
        "An **AI agent** is a system that can:\n",
        "\n",
        "> **Perceive its environment, make decisions, and take actions to achieve a goal — often with some level of autonomy.**\n",
        "\n",
        "It can range from something very simple (like a chatbot that answers your questions) to something very advanced (like a personal assistant that books appointments, sends emails, or even writes code for you).\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 The Core Components of an AI Agent\n",
        "\n",
        "1. **Perception** – Gathers input (text, voice, data, etc.)\n",
        "2. **Reasoning** – Decides what to do based on the input\n",
        "3. **Action** – Responds or performs tasks\n",
        "4. **Memory** (optional but valuable) – Remembers past interactions\n",
        "5. **Tool Use** (advanced) – Uses APIs, calculators, web search, or file systems\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 Why Are AI Agents Valuable?\n",
        "\n",
        "AI agents **save time, scale expertise, and automate tasks** that would otherwise require human attention.\n",
        "\n",
        "### They're valuable because they can:\n",
        "- Work 24/7\n",
        "- Handle repetitive tasks with no fatigue\n",
        "- Provide consistent answers\n",
        "- Scale customer support, marketing, scheduling, etc.\n",
        "- Make data-driven decisions instantly\n",
        "- Interface with other systems (APIs, documents, databases)\n",
        "\n",
        "---\n",
        "\n",
        "## 🔥 Real-World Use Cases\n",
        "\n",
        "| Use Case                    | Example                                                                 |\n",
        "|----------------------------|-------------------------------------------------------------------------|\n",
        "| 💬 Chatbots                | Answer customer questions (e.g., banking, e-commerce)                   |\n",
        "| 📅 Virtual Assistants      | Schedule meetings, send emails (e.g., x.ai, Siri, Google Assistant)     |\n",
        "| 📊 Data Agents             | Analyze spreadsheets, create reports, generate insights                 |\n",
        "| 🕸️ Web Agents             | Search the web, extract data, summarize articles                        |\n",
        "| 🧪 Research Agents         | Read papers, summarize findings, write citations                        |\n",
        "| 🛠️ Tool-Using Agents      | Use calculators, access APIs, write or edit code                        |\n",
        "| 📦 RPA (Robotic Process Automation) | Handle invoice processing, HR onboarding, finance ops          |\n",
        "| 🎮 Game Agents             | Play or assist in video games (e.g., bots that learn by playing)         |\n",
        "\n",
        "---\n",
        "\n",
        "## 🤝 AI Agent vs Chatbot vs Assistant\n",
        "\n",
        "| Term         | What it Means                                                                 |\n",
        "|--------------|--------------------------------------------------------------------------------|\n",
        "| **Chatbot**  | Conversational tool, usually rules-based or LLM-based                         |\n",
        "| **Assistant**| Smarter chatbot — more memory, maybe tools or goals                           |\n",
        "| **Agent**    | More autonomous, goal-oriented, tool-using, adaptable                         |\n",
        "\n",
        "A chatbot is **a type of agent**, but an agent can do **much more** than just chat.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Example of an AI Agent in Action\n",
        "\n",
        "Let’s say you build a **\"Marketing Assistant\"** agent. It could:\n",
        "1. Accept a product description\n",
        "2. Search for trending keywords\n",
        "3. Generate a blog post\n",
        "4. Create social media posts\n",
        "5. Schedule them via API\n",
        "6. Email a report to your team\n",
        "\n",
        "That’s a full workflow automated by an agent — not just a conversation.\n",
        "\n",
        "\n",
        "## Agents are systems that independently accomplish tasks on your behalf.\n",
        "\n",
        "An **agent** is a system that performs multi-step tasks on your behalf using an LLM. Unlike traditional automation or simple chatbots, agents can:\n",
        "- **Independently manage workflows**\n",
        "- **Make decisions**, detect when a task is complete, and handle errors or unexpected conditions\n",
        "- **Use tools dynamically** to gather data and take action\n",
        "- Operate within **guardrails** to ensure safe and predictable behavior\n",
        "\n",
        "> 🧠 **Key Idea**: Agents don’t just assist—they act *on your behalf* with autonomy.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 When Should You Build an Agent?\n",
        "Agents shine in workflows where traditional automation struggles:\n",
        "1. **Complex Decision-Making**: Context-aware tasks like refund approvals.\n",
        "2. **Hard-to-Maintain Rules**: Situations with complicated, brittle rule systems (e.g., security reviews).\n",
        "3. **Unstructured Data**: Tasks involving language understanding, document analysis, or conversational input (e.g., insurance claims).\n",
        "\n",
        "Before building, ask: *Is the workflow too ambiguous, dynamic, or context-rich for rule-based automation?*\n",
        "\n",
        "> ✅ If yes — an agent may be the better solution.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dWOP--J1GTkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 🧠 Agent Design Foundations\n",
        "\n",
        "In its most essential form, an **AI agent** consists of three core components:\n",
        "\n",
        "### 🔹 1. Model (The Agent’s Brain)\n",
        "- This is the LLM (Large Language Model) that powers the agent’s **reasoning and decision-making**.\n",
        "- It interprets user input, selects actions, and can even guide tool usage.\n",
        "- In our case, we’re using Hugging Face’s `flan-t5-base` model for its balance of size, speed, and instruction-following ability.\n",
        "\n",
        "### 🔹 2. Tools (The Agent’s Hands)\n",
        "- Tools are **functions or external APIs** the agent can call to take real-world action.\n",
        "- Examples in our notebook:\n",
        "  - `get_weather()`\n",
        "  - `save_note()`\n",
        "  - `search_faq()`\n",
        "- In production systems, tools could connect to databases, send emails, generate reports, or control devices.\n",
        "\n",
        "### 🔹 3. Instructions (The Agent’s Personality and Guardrails)\n",
        "- These are **explicit prompts or guidelines** that define how the agent should behave.\n",
        "- They help steer the model’s responses, ensuring consistency, safety, and task alignment.\n",
        "- Example: We instructed the model to *only use tools* for weather, notes, and FAQ — and to *politely decline off-topic questions*.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Model Selection Principles\n",
        "\n",
        "Choosing the right model is key to building a smart, fast, and cost-effective agent. The PDF recommends the following approach:\n",
        "\n",
        "### ✅ Best Practices for Model Selection\n",
        "\n",
        "1. **Start with the most capable model** available to build your prototype.\n",
        "   - This helps you measure the *ideal behavior* without performance issues.\n",
        "2. **Evaluate your agent’s performance** (accuracy, reliability, tool selection).\n",
        "3. **Replace with smaller or cheaper models** only if they maintain acceptable performance.\n",
        "   - Example: A small model might work fine for tool selection, but fail at nuanced decision-making.\n",
        "\n",
        "### ⚖️ Tradeoffs to Consider\n",
        "\n",
        "| Task Type | Model Recommendation |\n",
        "|-----------|----------------------|\n",
        "| Simple classification, intent detection | Small, fast models (`flan-t5-small`, `distilbert`) |\n",
        "| General instruction-following | Mid-size models (`flan-t5-base`, `mistral`) |\n",
        "| Complex reasoning, judgment, summarization | Large models (`mistral-7b`, `llama2-13b`, GPT-4) |\n",
        "\n",
        "> **Key Idea**: Don't over-engineer early. Start strong, then optimize later.\n",
        "\n"
      ],
      "metadata": {
        "id": "cBFCWUBVKsLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s walk through this first block *not just as code*, but as your **first real lesson in agent thinking**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Agent Lab 1 – Setup & Core Concepts\n",
        "\n",
        "This setup lays the foundation for how agents work. Let’s unpack each piece from a learning perspective:\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 1. `transformers` Pipeline\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "model_name = \"google/flan-t5-base\"\n",
        "llm = pipeline(\"text2text-generation\", model=model_name)\n",
        "```\n",
        "\n",
        "> **🧠 Key Concept: The Model = Your Agent’s Brain**\n",
        "\n",
        "- You're loading a small Hugging Face model that can follow instructions.\n",
        "- In agent design, this is the **reasoning engine** — it reads input and decides what to do.\n",
        "- We’re using a *pipeline* to simplify everything: tokenization, model inference, and decoding are wrapped into one step.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 2. Defining Tools\n",
        "\n",
        "```python\n",
        "def get_weather(city=\"Gainesville\"):\n",
        "    return f\"The weather in {city} is sunny with a high of 82°F.\"\n",
        "\n",
        "def save_note(note):\n",
        "    return f\"Note saved: {note}\"\n",
        "```\n",
        "\n",
        "> **🧠 Key Concept: Tools = How Your Agent Takes Action**\n",
        "\n",
        "- Tools are like the agent’s “hands” — they interact with the world.\n",
        "- In real agents, these could be APIs, databases, or browser actions.\n",
        "- Here, we mock tools for simplicity so you can focus on **tool selection** and logic.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 3. Tool Registry\n",
        "\n",
        "```python\n",
        "tools = {\n",
        "    \"get_weather\": get_weather,\n",
        "    \"save_note\": save_note\n",
        "}\n",
        "```\n",
        "\n",
        "> **🧠 Key Concept: A Tool Registry = Your Agent’s Toolbox**\n",
        "\n",
        "- This lets the agent look up and call tools by name.\n",
        "- Later, you’ll use this to simulate decision-making: the agent will choose a tool like a command from a menu.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Learning Takeaways So Far\n",
        "\n",
        "| Concept | Meaning | How It Maps to Agents |\n",
        "|--------|---------|------------------------|\n",
        "| **LLM Model** | Reasoning engine | Makes decisions and interprets user input |\n",
        "| **Tool** | Action function | Executes steps on behalf of user |\n",
        "| **Tool Registry** | Dictionary of tools | Lets the agent find and call tools dynamically |\n"
      ],
      "metadata": {
        "id": "JW63Yz61OLaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7afRY2TNkDb",
        "outputId": "30a6a6f4-82b9-4f2b-876a-906148214a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💡 Why the Pipeline Is So Powerful\n",
        "\n",
        "The `pipeline()` function from Hugging Face abstracts away **all the gritty, low-level details** of how transformers actually work under the hood:\n",
        "\n",
        "| Step | Without Pipeline | With `pipeline()` |\n",
        "|------|------------------|-------------------|\n",
        "| **Tokenization** | You'd manually load a tokenizer, tokenize input | ✅ Done for you |\n",
        "| **Model Inference** | You’d load a model, pass tokenized input, manage tensors | ✅ Done for you |\n",
        "| **Decoding** | You’d convert output IDs back into readable text | ✅ Done for you |\n",
        "| **Task-Specific Behavior** | You’d need custom logic (e.g., for text2text, QA, etc.) | ✅ Handled by pipeline type |\n",
        "\n"
      ],
      "metadata": {
        "id": "GNFkgUA5O7RU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 🤖 Chatbot vs 🧠 Agent\n",
        "\n",
        "| Aspect | **Chatbot** | **Agent** |\n",
        "|--------|-------------|-----------|\n",
        "| 🗣️ **Goal** | Answer a question or have a conversation | Complete a *task* on your behalf |\n",
        "| 🧠 **Thinking** | Responds to input, usually single-turn or narrow | Maintains state, evaluates, makes decisions |\n",
        "| 🛠️ **Tools** | Usually none — answers from memory (model weights) | Has tools and APIs it can **use** |\n",
        "| 🔁 **Action** | Mostly text replies | Takes **actions** like retrieving data, saving info, sending messages |\n",
        "| ⚙️ **Autonomy** | You drive the flow | The **agent drives the workflow** — you just provide the goal |\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 You Said It Perfectly:\n",
        "> *“An agent has tools at its disposal to take in information and take action based on that information* — it’s a **reasoning engine with hands**.\"\n",
        "\n",
        "- **Input**: “Can you save this note?”\n",
        "- **Agent thinks**: Is this a save_note task? What’s the note content?\n",
        "- **Agent acts**: Calls `save_note(note=\"Remember to review the guide\")`\n",
        "- **Agent responds**: “Note saved: Remember to review the guide”\n",
        "\n",
        "And it can repeat this process across multiple steps, adapting as it goes.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 That’s What Makes Agents So Powerful:\n",
        "They’re not just “talkers” — they’re **doers**.\n",
        "\n",
        "This is what makes them suited for:\n",
        "- Customer support automation\n",
        "- Internal tools and ops agents\n",
        "- Personal assistants\n",
        "- Data analyzers\n",
        "- Code committers\n",
        "- Forecasting bots (😉 like yours!)\n",
        "\n"
      ],
      "metadata": {
        "id": "xNdLaEVfQP9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 Agent Lesson: **Model Selection = Picking the Right Brain for the Job**\n",
        "\n",
        "### 🔍 Why Model Selection Matters\n",
        "\n",
        "Every agent has a **goal** — and the model is its **thinking engine**. But not all brains are built the same.\n",
        "\n",
        "| Goal | Best Model Type | Why |\n",
        "|------|------------------|-----|\n",
        "| Simple lookups / intent detection | Small model (e.g., `distilbert`, `flan-t5-small`) | Fast, cheap, low latency |\n",
        "| Answering questions or following instructions | Medium model (e.g., `flan-t5-base`, `mistral-7b`) | Good balance of performance and cost |\n",
        "| Complex reasoning, judgment, summarization | Larger model (e.g., `mistral-7b-instruct`, `llama2-13b`) | Stronger reasoning skills |\n",
        "| Multimodal tasks (e.g., vision + text) | Specialized model (e.g., `llava`, `gemini`, `gpt-4o`) | Different inputs or formats |\n",
        "\n",
        "> ✅ Lesson: **Not all agent steps need a big model.** You might use:\n",
        "- A small model for tool selection\n",
        "- A medium model for planning\n",
        "- A large model only when needed for complex judgment\n",
        "\n",
        "---\n",
        "\n",
        "### 🛠️ In Practice\n",
        "Here’s what agent builders usually do:\n",
        "1. Prototype with a strong general model (like `flan-t5-base` or `gpt-4`)\n",
        "2. Measure performance\n",
        "3. Optimize: replace with smaller models where possible (to cut cost, increase speed)\n",
        "\n",
        "> Think of it like hiring employees — you don’t need a rocket scientist to answer phone calls, but you might want one to design the rocket.\n",
        "\n"
      ],
      "metadata": {
        "id": "_QVXBcQ8RVHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a small instruction-following model\n",
        "model_name = \"google/flan-t5-base\"\n",
        "llm = pipeline(\"text2text-generation\", model=model_name)\n",
        "\n",
        "# Simple tools\n",
        "def get_weather(city=\"Gainesville\"):\n",
        "    return f\"The weather in {city} is sunny with a high of 82°F.\"\n",
        "\n",
        "def save_note(note):\n",
        "    return f\"Note saved: {note}\"\n",
        "\n",
        "# Tool dictionary\n",
        "tools = {\n",
        "    \"get_weather\": get_weather,\n",
        "    \"save_note\": save_note\n",
        "}\n"
      ],
      "metadata": {
        "id": "DCgP5drLgigQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 Agent Lab 2 – Run Loop\n",
        "\n",
        "Let’s break it down clearly and make sure you’re learning the *right lessons*, not just what the code does.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔁 Agent Run Loop — Line-by-Line, Lesson-by-Lesson\n",
        "\n",
        "Here’s the loop again in chunks — I’ll walk you through both **how it works** and **what you should take away as a future agent builder**.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 Step 1: Ask the model to choose a tool\n",
        "\n",
        "```python\n",
        "tool_prompt = f\"\"\"\n",
        "You are a helpful assistant. Choose the right tool for this request:\n",
        "\n",
        "Available tools:\n",
        "- get_weather\n",
        "- save_note\n",
        "\n",
        "Instructions:\n",
        "- Return ONLY the name of the tool to use.\n",
        "- If the request is to save something, use 'save_note'.\n",
        "- If the request is about weather, use 'get_weather'.\n",
        "\n",
        "User request: {user_input}\n",
        "Tool:\n",
        "\"\"\"\n",
        "tool_response = llm(tool_prompt, max_new_tokens=10)[0]['generated_text'].strip()\n",
        "```\n",
        "\n",
        "> 🧠 **Key Lesson: Prompt engineering powers decision-making.**\n",
        "\n",
        "- You’re giving the model a **clear menu of choices**.\n",
        "- You're being specific: *\"Return ONLY the name of the tool.\"*\n",
        "- You’re *delegating responsibility* to the model — and it’s doing lightweight reasoning.\n",
        "\n",
        "**As an agent builder, this is your job:**  \n",
        "➡️ Design prompts that help the model **interpret intent** and **choose the right action**.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 Step 2: Execute the tool\n",
        "\n",
        "```python\n",
        "if tool_response == \"get_weather\":\n",
        "    result = tools[\"get_weather\"]()\n",
        "elif tool_response == \"save_note\":\n",
        "    note_content = user_input.replace(\"save\", \"\").strip()\n",
        "    result = tools[\"save_note\"](note_content)\n",
        "else:\n",
        "    result = f\"Sorry, I don't know how to handle: {tool_response}\"\n",
        "```\n",
        "\n",
        "> 🧠 **Key Lesson: Tools make the agent *do something* beyond just chatting.**\n",
        "\n",
        "- This is the agent’s “action step” — the model says “use this tool,” and you let it call that tool.\n",
        "- You're **routing control dynamically** based on LLM output — that's the core of agent behavior.\n",
        "- Right now we’re doing simple string replacement — later we’ll do full parsing or use models to extract inputs.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔹 Step 3: Return the result\n",
        "\n",
        "```python\n",
        "return result\n",
        "```\n",
        "\n",
        "> 🧠 **Key Lesson: Agents *complete* tasks, not just answer questions.**\n",
        "\n",
        "This isn’t a back-and-forth chat — this is “you asked → I thought → I acted → here’s the result.”\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 What You Should Be Learning\n",
        "\n",
        "Here are the **top takeaways** from this first agent:\n",
        "\n",
        "| 🧠 Concept | 💬 What It Means | 🚀 Why It Matters |\n",
        "|-----------|------------------|-------------------|\n",
        "| **Prompt = agent’s instruction** | Your prompt is the agent’s \"brain script\" | Agents act how you tell them |\n",
        "| **LLM = decision maker** | Model decides which tool to use | LLM ≠ answer machine — it’s a planner |\n",
        "| **Tools = execution layer** | Real work gets done here | Agents don’t just talk — they *do* things |\n",
        "| **Loop = workflow engine** | Think → Act → Respond | The basis of any single- or multi-agent system |\n",
        "| **Simple routing = powerful logic** | If model says \"get_weather\", call that tool | Dynamic behavior from static code |\n",
        "\n"
      ],
      "metadata": {
        "id": "xI6EgW_-RhSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_run(user_input):\n",
        "    # Step 1: Ask the model what tool to use\n",
        "    tool_prompt = f\"\"\"\n",
        "    You are a helpful assistant. Choose the right tool for this request:\n",
        "\n",
        "    Available tools:\n",
        "    - get_weather\n",
        "    - save_note\n",
        "\n",
        "    Instructions:\n",
        "    - Return ONLY the name of the tool to use.\n",
        "    - If the request is to save something, use 'save_note'.\n",
        "    - If the request is about weather, use 'get_weather'.\n",
        "\n",
        "    User request: {user_input}\n",
        "    Tool:\n",
        "    \"\"\"\n",
        "    tool_response = llm(tool_prompt, max_new_tokens=10)[0]['generated_text'].strip()\n",
        "\n",
        "    # Step 2: Use the tool (very basic input handling for now)\n",
        "    if tool_response == \"get_weather\":\n",
        "        result = tools[\"get_weather\"]()\n",
        "    elif tool_response == \"save_note\":\n",
        "        # Just use the whole input as the note for now\n",
        "        note_content = user_input.replace(\"save\", \"\").strip()\n",
        "        result = tools[\"save_note\"](note_content)\n",
        "    else:\n",
        "        result = f\"Sorry, I don't know how to handle: {tool_response}\"\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "U9LkTISaRiB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Weather\n",
        "print(agent_run(\"What's the weather today?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7GvpfqgR8c6",
        "outputId": "e5992c87-91a1-4709-cc62-6610f4db5efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Gainesville is sunny with a high of 82°F.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Save a note\n",
        "print(agent_run(\"Can you save 'pick up milk'?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjyZtlUJR_0A",
        "outputId": "52397796-eedf-478f-8af2-34f88a2b1a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note saved: Can you  'pick up milk'?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 🛠️ Agent Upgrade Path\n",
        "\n",
        "### ✅ Step 1: Add a New Tool — `search_faq`\n",
        "We'll simulate a FAQ search tool that \"retrieves\" an answer from a predefined list.\n",
        "\n",
        "### ⏭ Coming Next:\n",
        "2. Handle edge cases (e.g., unrecognized tool, unclear input)  \n",
        "3. Let the user choose a tool manually if auto-selection fails  \n",
        "4. Add memory so the agent can handle multi-turn chats  \n",
        "5. Build guardrails and instructions into your agent (e.g., stop bad inputs, enforce safety)"
      ],
      "metadata": {
        "id": "QH4r5fhmVKWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔧 Step 1: Add a New Tool (`search_faq`)"
      ],
      "metadata": {
        "id": "BCAwhls-Vdj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FAQ database (mocked)\n",
        "faq_db = {\n",
        "    \"return policy\": \"You can return any item within 30 days with a receipt.\",\n",
        "    \"shipping time\": \"Standard shipping takes 5-7 business days.\",\n",
        "    \"support hours\": \"We offer support Monday to Friday, 9am to 5pm EST.\"\n",
        "}\n",
        "\n",
        "# New tool\n",
        "def search_faq(query):\n",
        "    for key in faq_db:\n",
        "        if key in query.lower():\n",
        "            return faq_db[key]\n",
        "    return \"Sorry, I couldn't find an answer to that question.\"\n",
        "\n",
        "# Add it to the tool registry\n",
        "tools[\"search_faq\"] = search_faq"
      ],
      "metadata": {
        "id": "eEK8NDeOVT0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. Update the prompt used in `agent_run()"
      ],
      "metadata": {
        "id": "qwN54FBjVp3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_run(user_input):\n",
        "    # 🧠 Prompt to ask the LLM which tool to use, now including 'search_faq'\n",
        "    tool_prompt = f\"\"\"\n",
        "    You are a helpful assistant. Choose the right tool for this request:\n",
        "\n",
        "    Available tools:\n",
        "    - get_weather\n",
        "    - save_note\n",
        "    - search_faq  # 🆕 New FAQ tool added\n",
        "\n",
        "    Instructions:\n",
        "    - If the request is to save something, use 'save_note'.\n",
        "    - If the request is about weather, use 'get_weather'.\n",
        "    - If the request is asking a general FAQ (like return policy, shipping, support), use 'search_faq'.\n",
        "\n",
        "    User request: {user_input}\n",
        "    Tool:\n",
        "    \"\"\"\n",
        "\n",
        "    # 🧠 Ask the LLM to decide which tool to use based on user input\n",
        "    tool_response = llm(tool_prompt, max_new_tokens=10)[0]['generated_text'].strip()\n",
        "\n",
        "    # 🛠 Route the decision to the correct tool function\n",
        "    if tool_response == \"get_weather\":\n",
        "        result = tools[\"get_weather\"]()\n",
        "\n",
        "    elif tool_response == \"save_note\":\n",
        "        # ✏️ Extract the note from the input and call save_note\n",
        "        note_content = user_input.replace(\"save\", \"\").strip()\n",
        "        result = tools[\"save_note\"](note_content)\n",
        "\n",
        "    elif tool_response == \"search_faq\":\n",
        "        # 🔍 NEW: Route to the FAQ tool using user input as a search query\n",
        "        result = tools[\"search_faq\"](user_input)\n",
        "\n",
        "    else:\n",
        "        # 🚫 Unknown tool or unrecognized response\n",
        "        result = f\"Sorry, I don't know how to handle: {tool_response}\"\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "4Ic981v7VTwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_run(\"What’s your return policy?\"),'\\n')\n",
        "print(agent_run(\"How long does shipping take?\"),'\\n')\n",
        "print(agent_run(\"What's the weather today?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7038n-SVTp8",
        "outputId": "ef975b31-9afd-4092-b02f-ddeb757667a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You can return any item within 30 days with a receipt. \n",
            "\n",
            "Sorry, I couldn't find an answer to that question. \n",
            "\n",
            "The weather in Gainesville is sunny with a high of 82°F.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👏 That's a win! You now have a working agent that can reason about different requests and call the right tool — even gracefully handle unanswerable FAQs. Let’s level it up.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Agent Lab 3 - Add Edge-Case Handling\n",
        "\n",
        "### 🧠 Why This Matters:\n",
        "Agents don’t live in perfect worlds. Real users:\n",
        "- Type typos\n",
        "- Ask weird or unrelated things\n",
        "- Confuse the model\n",
        "- Trigger tool names that don’t exist\n",
        "\n",
        "You need to **protect your agent from making mistakes** by handling:\n",
        "1. Unrecognized tool names\n",
        "2. Empty or unclear model responses\n",
        "3. Completely off-topic questions\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Let’s Add Some Basic Guarding\n",
        "\n",
        "\n",
        "## 🧠 What You’re Learning\n",
        "\n",
        "| 💡 Lesson | Why It Matters |\n",
        "|----------|----------------|\n",
        "| Validate LLM output | Models aren’t always predictable — verify before acting |\n",
        "| Normalize input | Always `strip()` and `lower()` before matching |\n",
        "| Fallbacks = good UX | Clear errors prevent confusion and make agents feel smarter |\n",
        "| Agents need protection | Just like apps need try/except — agents need guardrails |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WLzewML3YSH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_run(user_input):\n",
        "    # Prompt with available tools and instructions\n",
        "    tool_prompt = f\"\"\"\n",
        "    You are a helpful assistant. Choose the right tool for this request:\n",
        "\n",
        "    Available tools:\n",
        "    - get_weather\n",
        "    - save_note\n",
        "    - search_faq\n",
        "\n",
        "    Instructions:\n",
        "    - If the request is to save something, use 'save_note'.\n",
        "    - If the request is about weather, use 'get_weather'.\n",
        "    - If the request is asking a general FAQ (like return policy, shipping, support), use 'search_faq'.\n",
        "\n",
        "    User request: {user_input}\n",
        "    Tool:\n",
        "    \"\"\"\n",
        "    tool_response_raw = llm(tool_prompt, max_new_tokens=10)[0]['generated_text'].strip()\n",
        "\n",
        "    # Clean and normalize the response\n",
        "    tool_response = tool_response_raw.lower().strip()\n",
        "\n",
        "    # 🚧 EDGE CASE #1: Empty model response\n",
        "    if not tool_response:\n",
        "        return \"Hmm, I couldn't understand your request. Could you rephrase it?\"\n",
        "\n",
        "    # 🚧 EDGE CASE #2: Tool not in registry\n",
        "    if tool_response not in tools:\n",
        "        return f\"Sorry, I don’t recognize the tool: '{tool_response}'. Please try again with a clearer request.\"\n",
        "\n",
        "    # Main tool logic\n",
        "    if tool_response == \"get_weather\":\n",
        "        result = tools[\"get_weather\"]()\n",
        "\n",
        "    elif tool_response == \"save_note\":\n",
        "        note_content = user_input.replace(\"save\", \"\").strip()\n",
        "        result = tools[\"save_note\"](note_content)\n",
        "\n",
        "    elif tool_response == \"search_faq\":\n",
        "        result = tools[\"search_faq\"](user_input)\n",
        "\n",
        "    else:\n",
        "        result = \"Unexpected error. Something went wrong.\"\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "JKCaRQ6fYrfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_run(\"Tell me about your elephant policy\"))  # Should trigger fallback\n",
        "print(agent_run(\"\"))  # Empty input\n",
        "print(agent_run(\"save this for later\"))  # Should work\n",
        "print(agent_run(\"What's the status of my package\"))  # Uncovered edge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeZPcWibVTnm",
        "outputId": "7dfcd852-dae1-4c3e-c04d-c28a55533a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I couldn't find an answer to that question.\n",
            "Sorry, I couldn't find an answer to that question.\n",
            "Note saved: this for later\n",
            "Sorry, I couldn't find an answer to that question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You’ve just touched on one of the **central design tensions in building AI agents**:  \n",
        "\n",
        "> 🧠 **Where should logic be hardcoded vs. delegated to the LLM?**\n",
        "\n",
        "This is **the art of agent design** — knowing when to let the model reason freely, and when to box it in with clear instructions or rules.\n",
        "\n",
        "Let’s explore this in depth.\n",
        "\n",
        "---\n",
        "\n",
        "## 🤔 Hardcoded Logic vs. LLM Reasoning\n",
        "\n",
        "| 🎯 Purpose | 🧱 Hardcoded Logic | 🤖 LLM Reasoning |\n",
        "|------------|------------------|------------------|\n",
        "| Safety & predictability | ✅ Always preferred | ❌ Can hallucinate |\n",
        "| Common edge cases | ✅ Efficient | ❌ Overkill |\n",
        "| Flexible understanding | ❌ Brittle / rigid | ✅ Great at interpreting nuance |\n",
        "| User-specific nuance | ❌ Needs code for every case | ✅ Adapts from prompt context |\n",
        "| Open-ended tasks | ❌ Impossible to enumerate | ✅ Natural fit for LLM |\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 Rule of Thumb:\n",
        "> ✨ **Use hardcoding for structure, guardrails, and system safety. Let the LLM handle fuzzy human reasoning, edge-case interpretation, and natural language understanding.**\n",
        "\n",
        "---\n",
        "\n",
        "## 🛡️ Guardrails: You’re *Exactly* Right\n",
        "\n",
        "Instead of hardcoding rejections, you can guide the LLM with instructions like:\n",
        "\n",
        "> “If the user asks questions beyond the scope of this agent, politely remind them that this assistant is focused on {subject} and steer them back.”\n",
        "\n",
        "This lives in your **prompt**, and works beautifully in most cases — especially when the topic is defined (e.g., customer service, weather agent, product FAQ, forecasting bot, etc.).\n",
        "\n",
        "### ✅ Example Prompt Addition\n",
        "\n",
        "Add this to the top of your tool-picking prompt:\n",
        "\n",
        "```text\n",
        "IMPORTANT: This assistant only handles weather, notes, and FAQs.\n",
        "If a user asks something outside that scope, politely respond:\n",
        "\"I'm here to help with weather updates, notes, or common questions. Could you ask something related to that?\"\n",
        "```\n",
        "\n",
        "Now the LLM might return:\n",
        "> `\"I'm here to help with FAQs, weather, or saving notes — can I help with one of those?\"`\n",
        "\n",
        "Instead of:\n",
        "> `\"Answering your question about quantum physics...\"`\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 So to answer your question directly:\n",
        "Yes — we **can and should** use high-quality system-level instructions like the one you suggested. It’s not “hardcoding,” it’s **soft-guiding** the model toward safe and relevant behavior.\n",
        "\n"
      ],
      "metadata": {
        "id": "6woe9zGTeaYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agent_run(user_input):\n",
        "    # Prompt with available tools and instructions\n",
        "    tool_prompt = f\"\"\"\n",
        "    You are a helpful assistant that can only handle the following tools:\n",
        "\n",
        "    Available tools:\n",
        "    - get_weather: For answering questions about the weather.\n",
        "    - save_note: For saving user notes or reminders.\n",
        "    - search_faq: For answering common questions about return policy, shipping, or support hours.\n",
        "\n",
        "    IMPORTANT RULES:\n",
        "    - If the user request is unrelated to these tools, politely respond with:\n",
        "      \"I'm here to help with weather updates, saving notes, or answering common customer questions. Could you ask something related to that?\"\n",
        "    - Otherwise, return ONLY the name of the tool you will use: get_weather, save_note, or search_faq.\n",
        "    - DO NOT return full sentences or descriptions — just the tool name.\n",
        "\n",
        "    User request: {user_input}\n",
        "    Your response:\n",
        "    \"\"\"\n",
        "\n",
        "    tool_response = llm(tool_prompt, max_new_tokens=50)[0]['generated_text'].strip()\n",
        "\n",
        "    # EDGE CASE: Empty or unclear response\n",
        "    # if not tool_response:\n",
        "    #     return \"Hmm, I couldn't understand your request. Could you rephrase it?\"\n",
        "\n",
        "    # Normalize and extract tool name if embedded in a sentence\n",
        "    tool_response_cleaned = tool_response.lower().strip()\n",
        "\n",
        "    # Try to extract a known tool name from the model's response\n",
        "    matched_tool = next((name for name in tools if name in tool_response_cleaned), None)\n",
        "\n",
        "    if not matched_tool:\n",
        "        return tool_response  # Let the model respond naturally if no tool was matched\n",
        "\n",
        "    # Handle polite redirect messages directly\n",
        "    if matched_tool == \"get_weather\":\n",
        "        return tools[\"get_weather\"]()\n",
        "\n",
        "    elif matched_tool == \"save_note\":\n",
        "        note_content = user_input.replace(\"save\", \"\").strip()\n",
        "        return tools[\"save_note\"](note_content)\n",
        "\n",
        "    elif matched_tool == \"search_faq\":\n",
        "        return tools[\"search_faq\"](user_input)\n",
        "\n",
        "    else:\n",
        "        return \"Unexpected error. Something went wrong.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "sy62H5qUe36W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🔧 1. **The Problem: The LLM wasn't returning clean tool names**\n",
        "\n",
        "You told it:  \n",
        "> “Return ONLY the tool name”  \n",
        "But it replied:\n",
        "> `\"get_weather: For answering questions about the weather.\"`\n",
        "\n",
        "**Why?**  \n",
        "LLMs like `flan-t5-base` were trained to be helpful and verbose. They often **ignore strict formatting** — especially small models — even when your prompt begs them not to.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ 2. **The Fix: We added post-processing logic to catch tool names**\n",
        "\n",
        "```python\n",
        "# Extract tool name from model output (even if it includes extra text)\n",
        "matched_tool = next((name for name in tools if name in tool_response.lower()), None)\n",
        "```\n",
        "\n",
        "This line:\n",
        "- Loops through your tool names: `\"get_weather\"`, `\"save_note\"`, `\"search_faq\"`\n",
        "- Checks if any of them appear inside the model's output string\n",
        "- Selects the **first match it finds**\n",
        "\n",
        "This allows us to **handle fuzzy LLM output gracefully**, even when it's verbose.\n",
        "\n",
        "#### Example:\n",
        "If the model says:\n",
        "```text\n",
        "\"get_weather: For answering questions about the weather.\"\n",
        "```\n",
        "Your logic still says:\n",
        "```python\n",
        "→ matched_tool = \"get_weather\"\n",
        "→ run tools[\"get_weather\"]()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 Why This Matters\n",
        "\n",
        "This is one of the most important agent design patterns:\n",
        "\n",
        "> **LLMs don’t return clean values — you interpret their intent.**\n",
        "\n",
        "This is exactly what real agents do in production:\n",
        "- Use patterns to match tool names\n",
        "- Post-process output\n",
        "- Fall back to defaults if nothing matches\n",
        "- Sometimes log the full output for debugging\n",
        "\n",
        "---\n",
        "\n",
        "### 💬 Bonus Fix: Polite redirect\n",
        "\n",
        "When **no valid tool is matched**, you let the model speak freely:\n",
        "\n",
        "```python\n",
        "if not matched_tool:\n",
        "    return tool_response  # Let it respond naturally if no tool matched\n",
        "```\n",
        "\n",
        "This lets the model **return your fallback message**, like:\n",
        "> “I'm here to help with weather updates, saving notes, or answering common customer questions.”\n",
        "\n",
        "You didn’t hardcode that — the **model decided to say it**, thanks to your prompt. That's soft guardrails in action.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Bottom Line\n",
        "\n",
        "| What You Did | What You Learned |\n",
        "|--------------|------------------|\n",
        "| Matched fuzzy model output | LLMs = not APIs, they’re probabilistic |\n",
        "| Soft-guarded off-topic questions | Prompt + polite fallback = graceful UX |\n",
        "| Combined logic + language | Agents live at the boundary of code and conversation |\n",
        "\n"
      ],
      "metadata": {
        "id": "G5wU_jstwiJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ In-scope:\n",
        "print(agent_run(\"What's the weather today?\"))\n",
        "print(agent_run(\"Can you save 'pick up groceries'?\"))\n",
        "print(agent_run(\"What’s your return policy?\"))\n",
        "# ❌ Out-of-scope:\n",
        "print(agent_run(\"Can you write me a Python function?\"))\n",
        "print(agent_run(\"What’s the meaning of life?\"))\n",
        "print(agent_run(\"Should I break up with my boyfriend?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK6_fAg_fHjs",
        "outputId": "15ce9b08-0726-4dbd-98fe-971263b20edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weather in Gainesville is sunny with a high of 82°F.\n",
            "Note saved: Can you  'pick up groceries'?\n",
            "You can return any item within 30 days with a receipt.\n",
            "If the user request is unrelated to these tools, politely respond with: \"I'm here to help with weather updates, saving notes, or answering common customer questions. Could you ask something related to that?\"\n",
            "The weather in Gainesville is sunny with a high of 82°F.\n",
            "Sorry, I couldn't find an answer to that question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G1rB_9yfJ4I",
        "outputId": "3d519c0b-57f1-4a8a-b7e2-24a7ea789097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get_weather: For answering questions about the weather.\n",
            "get_weather: For answering questions about the weather.\n",
            "get_weather: For answering questions about the weather.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove Widgets"
      ],
      "metadata": {
        "id": "npGKwWCEMTcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "notebook_path = \"/content/drive/My Drive/AI AGENTS/000_Agent_Design_Foundations.ipynb\"\n",
        "\n",
        "# Load the notebook JSON\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "# 1. Remove widgets from notebook-level metadata\n",
        "if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "    del nb[\"metadata\"][\"widgets\"]\n",
        "    print(\"✅ Removed notebook-level 'widgets' metadata.\")\n",
        "\n",
        "# 2. Remove widgets from each cell's metadata\n",
        "for i, cell in enumerate(nb.get(\"cells\", [])):\n",
        "    if \"metadata\" in cell and \"widgets\" in cell[\"metadata\"]:\n",
        "        del cell[\"metadata\"][\"widgets\"]\n",
        "        print(f\"✅ Removed 'widgets' from cell {i}\")\n",
        "\n",
        "# Save the cleaned notebook\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"✅ Notebook deeply cleaned. Try uploading to GitHub again.\")"
      ],
      "metadata": {
        "id": "YxVvj7UfNZwB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}