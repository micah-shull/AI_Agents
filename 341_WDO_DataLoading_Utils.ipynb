{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnYsXfuxEmLtTaJniBhMPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/341_WDO_DataLoading_Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Workforce Development Orchestrator — Data Loading & Lookup Utilities\n",
        "\n",
        "This module is responsible for **bringing structured, trusted data into the agent** and preparing it for fast, deterministic analysis. It follows a strict design principle:\n",
        "\n",
        "> **Utilities implement logic. Nodes orchestrate behavior.**\n",
        "\n",
        "As a result, this code is:\n",
        "\n",
        "* Independently testable\n",
        "* Easy to reason about\n",
        "* Reusable across agents and workflows\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Controlled Data Ingestion\n",
        "\n",
        "The `load_json_file` function acts as the **single gatekeeper** for all data entering the system.\n",
        "\n",
        "### What This Function Guarantees\n",
        "\n",
        "* Data is valid JSON\n",
        "* Data is consistently returned as a list\n",
        "* File and parsing errors are surfaced immediately\n",
        "\n",
        "This prevents subtle downstream failures where:\n",
        "\n",
        "* A malformed file silently loads partial data\n",
        "* A single-object JSON breaks list-based logic\n",
        "* Errors appear deep in the analysis instead of at ingestion\n",
        "\n",
        "From a business perspective, this ensures the agent never reasons over **unknown or corrupted inputs**.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Explicit Loaders for Each Dataset\n",
        "\n",
        "Each dataset (employees, roles, tasks, skills, automation signals, etc.) has its own dedicated loader.\n",
        "\n",
        "This design choice is intentional:\n",
        "\n",
        "* Filenames are explicit\n",
        "* Dataset responsibility is clear\n",
        "* Each loader can be mocked or tested independently\n",
        "\n",
        "If leadership ever asks:\n",
        "\n",
        "> “What data does this system depend on?”\n",
        "\n",
        "The answer is immediate and inspectable.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Lookups as a Performance and Clarity Strategy\n",
        "\n",
        "Once raw data is loaded, the utilities build **lookup dictionaries** that map IDs to full records.\n",
        "\n",
        "Examples:\n",
        "\n",
        "* `role_id → role`\n",
        "* `task_id → task`\n",
        "* `employee_id → employee`\n",
        "\n",
        "This avoids:\n",
        "\n",
        "* Repeated list scanning\n",
        "* Implicit joins\n",
        "* Hidden computational cost\n",
        "\n",
        "Instead, the agent operates on **O(1) access patterns**, making execution predictable and efficient.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Relationship Maps Make Organizational Structure Explicit\n",
        "\n",
        "The `build_tasks_by_role` and `build_employees_by_role` utilities encode **organizational structure** directly into state.\n",
        "\n",
        "This enables:\n",
        "\n",
        "* Role-level automation analysis\n",
        "* Role-based reskilling strategies\n",
        "* Team-level reporting\n",
        "\n",
        "Importantly, these mappings are **derived**, not hard-coded, which keeps the system adaptable as the organization changes.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Defensive, Transparent Design\n",
        "\n",
        "Several subtle design choices improve trust and maintainability:\n",
        "\n",
        "* Missing role IDs are safely ignored rather than crashing execution\n",
        "* No mutation of input data\n",
        "* No hidden defaults or inference\n",
        "\n",
        "The system always operates on **what is explicitly present**.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Design Matters for Trust and ROI\n",
        "\n",
        "This data layer ensures that:\n",
        "\n",
        "* All downstream analytics are grounded in verified inputs\n",
        "* Errors are caught early and explained clearly\n",
        "* Performance remains stable as data grows\n",
        "* Changes to data do not require changes to orchestration logic\n",
        "\n",
        "For leaders, this means:\n",
        "\n",
        "* Fewer surprises\n",
        "* Easier audits\n",
        "* Higher confidence in outputs\n",
        "\n",
        "For developers, it means:\n",
        "\n",
        "* Clean boundaries\n",
        "* Low coupling\n",
        "* Easy extensibility\n",
        "\n",
        "---\n",
        "\n",
        "## Architectural Takeaway\n",
        "\n",
        "This module quietly does something very important:\n",
        "\n",
        "It **turns raw files into structured organizational knowledge** that the agent can reason over safely.\n",
        "\n",
        "That’s the difference between a demo agent and a system designed to support real workforce decisions.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wy4EbfKr5Cf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading utilities for Workforce Development Orchestrator"
      ],
      "metadata": {
        "id": "Vc_3Blho4r0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84ZdO8XJ4QBt"
      },
      "outputs": [],
      "source": [
        "\"\"\"Data loading utilities for Workforce Development Orchestrator\n",
        "\n",
        "Following the pattern: Utilities implement, nodes orchestrate.\n",
        "These utilities are independently testable.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "\n",
        "def load_json_file(file_path: Path) -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load JSON data from file\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        return data if isinstance(data, list) else [data]\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(f\"Invalid JSON in {file_path}: {e}\")\n",
        "\n",
        "\n",
        "def load_employees(data_dir: Path, filename: str = \"employees.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load employees data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_roles(data_dir: Path, filename: str = \"roles.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load roles data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_tasks(data_dir: Path, filename: str = \"tasks.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load tasks data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_skills(data_dir: Path, filename: str = \"skills.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load skills data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_automation_signals(data_dir: Path, filename: str = \"automation_signals.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load automation signals data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_skill_gaps(data_dir: Path, filename: str = \"skills_gaps.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load skill gaps data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_learning_paths(data_dir: Path, filename: str = \"learning_paths.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load learning paths data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_role_evolution(data_dir: Path, filename: str = \"role_evolution.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Load role evolution data\"\"\"\n",
        "    file_path = data_dir / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def build_roles_lookup(roles: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Build lookup dictionary: role_id -> role dict\"\"\"\n",
        "    return {role[\"role_id\"]: role for role in roles}\n",
        "\n",
        "\n",
        "def build_tasks_lookup(tasks: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Build lookup dictionary: task_id -> task dict\"\"\"\n",
        "    return {task[\"task_id\"]: task for task in tasks}\n",
        "\n",
        "\n",
        "def build_skills_lookup(skills: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Build lookup dictionary: skill_id -> skill dict\"\"\"\n",
        "    return {skill[\"skill_id\"]: skill for skill in skills}\n",
        "\n",
        "\n",
        "def build_employees_lookup(employees: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"Build lookup dictionary: employee_id -> employee dict\"\"\"\n",
        "    return {emp[\"employee_id\"]: emp for emp in employees}\n",
        "\n",
        "\n",
        "def build_tasks_by_role(tasks: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"Build lookup dictionary: role_id -> list of tasks\"\"\"\n",
        "    tasks_by_role: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for task in tasks:\n",
        "        role_id = task.get(\"role_id\")\n",
        "        if role_id:\n",
        "            if role_id not in tasks_by_role:\n",
        "                tasks_by_role[role_id] = []\n",
        "            tasks_by_role[role_id].append(task)\n",
        "    return tasks_by_role\n",
        "\n",
        "\n",
        "def build_employees_by_role(employees: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"Build lookup dictionary: role_id -> list of employees\"\"\"\n",
        "    employees_by_role: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for emp in employees:\n",
        "        role_id = emp.get(\"role_id\")\n",
        "        if role_id:\n",
        "            if role_id not in employees_by_role:\n",
        "                employees_by_role[role_id] = []\n",
        "            employees_by_role[role_id].append(emp)\n",
        "    return employees_by_role\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test data loading utilities for Workforce Development Orchestrator"
      ],
      "metadata": {
        "id": "xXN_noKa4pwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Test data loading utilities for Workforce Development Orchestrator\n",
        "\n",
        "Testing Phase 2: Data Loading Utilities\n",
        "Following the pattern: Test utilities before building nodes\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "from agents.workforce_development_orchestrator.utilities.data_loading import (\n",
        "    load_employees,\n",
        "    load_roles,\n",
        "    load_tasks,\n",
        "    load_skills,\n",
        "    load_automation_signals,\n",
        "    load_skill_gaps,\n",
        "    load_learning_paths,\n",
        "    load_role_evolution,\n",
        "    build_roles_lookup,\n",
        "    build_tasks_lookup,\n",
        "    build_skills_lookup,\n",
        "    build_employees_lookup,\n",
        "    build_tasks_by_role,\n",
        "    build_employees_by_role\n",
        ")\n",
        "\n",
        "\n",
        "def test_load_employees():\n",
        "    \"\"\"Test loading employees data\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    employees = load_employees(data_dir)\n",
        "\n",
        "    assert len(employees) > 0\n",
        "    assert \"employee_id\" in employees[0]\n",
        "    assert \"name\" in employees[0]\n",
        "    assert \"role_id\" in employees[0]\n",
        "\n",
        "    print(\"✅ test_load_employees: PASSED\")\n",
        "\n",
        "\n",
        "def test_load_roles():\n",
        "    \"\"\"Test loading roles data\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    roles = load_roles(data_dir)\n",
        "\n",
        "    assert len(roles) > 0\n",
        "    assert \"role_id\" in roles[0]\n",
        "    assert \"role_name\" in roles[0]\n",
        "    assert \"required_skills\" in roles[0]\n",
        "\n",
        "    print(\"✅ test_load_roles: PASSED\")\n",
        "\n",
        "\n",
        "def test_load_tasks():\n",
        "    \"\"\"Test loading tasks data\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    tasks = load_tasks(data_dir)\n",
        "\n",
        "    assert len(tasks) > 0\n",
        "    assert \"task_id\" in tasks[0]\n",
        "    assert \"task_name\" in tasks[0]\n",
        "    assert \"automation_risk_score\" in tasks[0]\n",
        "\n",
        "    print(\"✅ test_load_tasks: PASSED\")\n",
        "\n",
        "\n",
        "def test_load_skills():\n",
        "    \"\"\"Test loading skills data\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    skills = load_skills(data_dir)\n",
        "\n",
        "    assert len(skills) > 0\n",
        "    assert \"skill_id\" in skills[0]\n",
        "    assert \"skill_name\" in skills[0]\n",
        "    assert \"skill_type\" in skills[0]\n",
        "\n",
        "    print(\"✅ test_load_skills: PASSED\")\n",
        "\n",
        "\n",
        "def test_load_all_data_files():\n",
        "    \"\"\"Test loading all data files\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "\n",
        "    employees = load_employees(data_dir)\n",
        "    roles = load_roles(data_dir)\n",
        "    tasks = load_tasks(data_dir)\n",
        "    skills = load_skills(data_dir)\n",
        "    automation_signals = load_automation_signals(data_dir)\n",
        "    skill_gaps = load_skill_gaps(data_dir)\n",
        "    learning_paths = load_learning_paths(data_dir)\n",
        "    role_evolution = load_role_evolution(data_dir)\n",
        "\n",
        "    assert len(employees) == 10\n",
        "    assert len(roles) == 5\n",
        "    assert len(tasks) == 15\n",
        "    assert len(skills) == 12\n",
        "\n",
        "    print(\"✅ test_load_all_data_files: PASSED\")\n",
        "\n",
        "\n",
        "def test_build_roles_lookup():\n",
        "    \"\"\"Test building roles lookup\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    roles = load_roles(data_dir)\n",
        "    lookup = build_roles_lookup(roles)\n",
        "\n",
        "    assert \"R001\" in lookup\n",
        "    assert lookup[\"R001\"][\"role_name\"] == \"HR Coordinator\"\n",
        "\n",
        "    print(\"✅ test_build_roles_lookup: PASSED\")\n",
        "\n",
        "\n",
        "def test_build_tasks_lookup():\n",
        "    \"\"\"Test building tasks lookup\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    tasks = load_tasks(data_dir)\n",
        "    lookup = build_tasks_lookup(tasks)\n",
        "\n",
        "    assert \"T001\" in lookup\n",
        "    assert lookup[\"T001\"][\"task_name\"] == \"Maintain employee records\"\n",
        "\n",
        "    print(\"✅ test_build_tasks_lookup: PASSED\")\n",
        "\n",
        "\n",
        "def test_build_skills_lookup():\n",
        "    \"\"\"Test building skills lookup\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    skills = load_skills(data_dir)\n",
        "    lookup = build_skills_lookup(skills)\n",
        "\n",
        "    assert \"data_entry\" in lookup\n",
        "    assert lookup[\"data_entry\"][\"skill_name\"] == \"Data Entry\"\n",
        "\n",
        "    print(\"✅ test_build_skills_lookup: PASSED\")\n",
        "\n",
        "\n",
        "def test_build_employees_lookup():\n",
        "    \"\"\"Test building employees lookup\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    employees = load_employees(data_dir)\n",
        "    lookup = build_employees_lookup(employees)\n",
        "\n",
        "    assert \"E001\" in lookup\n",
        "    assert lookup[\"E001\"][\"name\"] == \"Sarah Chen\"\n",
        "\n",
        "    print(\"✅ test_build_employees_lookup: PASSED\")\n",
        "\n",
        "\n",
        "def test_build_tasks_by_role():\n",
        "    \"\"\"Test building tasks by role\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    tasks = load_tasks(data_dir)\n",
        "    tasks_by_role = build_tasks_by_role(tasks)\n",
        "\n",
        "    assert \"R001\" in tasks_by_role\n",
        "    assert len(tasks_by_role[\"R001\"]) == 3  # R001 has 3 tasks\n",
        "\n",
        "    print(\"✅ test_build_tasks_by_role: PASSED\")\n",
        "\n",
        "\n",
        "def test_build_employees_by_role():\n",
        "    \"\"\"Test building employees by role\"\"\"\n",
        "    data_dir = Path(\"agents/data\")\n",
        "    employees = load_employees(data_dir)\n",
        "    employees_by_role = build_employees_by_role(employees)\n",
        "\n",
        "    assert \"R001\" in employees_by_role\n",
        "    assert len(employees_by_role[\"R001\"]) == 2  # R001 has 2 employees\n",
        "\n",
        "    print(\"✅ test_build_employees_by_role: PASSED\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Testing Data Loading Utilities (Phase 2)\")\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "    test_load_employees()\n",
        "    test_load_roles()\n",
        "    test_load_tasks()\n",
        "    test_load_skills()\n",
        "    test_load_all_data_files()\n",
        "    test_build_roles_lookup()\n",
        "    test_build_tasks_lookup()\n",
        "    test_build_skills_lookup()\n",
        "    test_build_employees_lookup()\n",
        "    test_build_tasks_by_role()\n",
        "    test_build_employees_by_role()\n",
        "\n",
        "    print()\n",
        "    print(\"=\" * 60)\n",
        "    print(\"✅ All data loading utility tests passed!\")\n",
        "    print(\"=\" * 60)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xi2rRS_y4ne0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_008_Workforce_Development_Orchestrator % python3 test_data_loading_utilities.py\n",
        "============================================================\n",
        "Testing Data Loading Utilities (Phase 2)\n",
        "============================================================\n",
        "\n",
        "✅ test_load_employees: PASSED\n",
        "✅ test_load_roles: PASSED\n",
        "✅ test_load_tasks: PASSED\n",
        "✅ test_load_skills: PASSED\n",
        "✅ test_load_all_data_files: PASSED\n",
        "✅ test_build_roles_lookup: PASSED\n",
        "✅ test_build_tasks_lookup: PASSED\n",
        "✅ test_build_skills_lookup: PASSED\n",
        "✅ test_build_employees_lookup: PASSED\n",
        "✅ test_build_tasks_by_role: PASSED\n",
        "✅ test_build_employees_by_role: PASSED\n",
        "\n",
        "============================================================\n",
        "✅ All data loading utility tests passed!\n",
        "============================================================\n"
      ],
      "metadata": {
        "id": "AVyJoyoi5WDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workforce Development Orchestrator — Data Loading Node Code"
      ],
      "metadata": {
        "id": "fmR4thab6cWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loading_node(\n",
        "    state: WorkforceDevelopmentOrchestratorState,\n",
        "    config: WorkforceDevelopmentOrchestratorConfig\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Data Loading Node: Orchestrate loading all workforce data.\n",
        "\n",
        "    Loads employees, roles, tasks, skills, and related data from JSON files,\n",
        "    then builds lookup dictionaries for fast access.\n",
        "    \"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    data_dir = Path(config.data_dir)\n",
        "\n",
        "    if not data_dir.exists():\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: Data directory not found: {data_dir}\"]\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        # Load all data files\n",
        "        employees = load_employees(data_dir, config.employees_file)\n",
        "        roles = load_roles(data_dir, config.roles_file)\n",
        "        tasks = load_tasks(data_dir, config.tasks_file)\n",
        "        skills = load_skills(data_dir, config.skills_file)\n",
        "        automation_signals = load_automation_signals(data_dir, config.automation_signals_file)\n",
        "        skill_gaps = load_skill_gaps(data_dir, config.skill_gaps_file)\n",
        "        learning_paths = load_learning_paths(data_dir, config.learning_paths_file)\n",
        "        role_evolution = load_role_evolution(data_dir, config.role_evolution_file)\n",
        "\n",
        "        # Build lookup dictionaries for fast access\n",
        "        roles_lookup = build_roles_lookup(roles)\n",
        "        tasks_lookup = build_tasks_lookup(tasks)\n",
        "        skills_lookup = build_skills_lookup(skills)\n",
        "        employees_lookup = build_employees_lookup(employees)\n",
        "        tasks_by_role = build_tasks_by_role(tasks)\n",
        "        employees_by_role = build_employees_by_role(employees)\n",
        "\n",
        "        return {\n",
        "            \"employees\": employees,\n",
        "            \"roles\": roles,\n",
        "            \"tasks\": tasks,\n",
        "            \"skills\": skills,\n",
        "            \"automation_signals\": automation_signals,\n",
        "            \"skill_gaps\": skill_gaps,\n",
        "            \"learning_paths\": learning_paths,\n",
        "            \"role_evolution\": role_evolution,\n",
        "            \"roles_lookup\": roles_lookup,\n",
        "            \"tasks_lookup\": tasks_lookup,\n",
        "            \"skills_lookup\": skills_lookup,\n",
        "            \"employees_lookup\": employees_lookup,\n",
        "            \"tasks_by_role\": tasks_by_role,\n",
        "            \"employees_by_role\": employees_by_role,\n",
        "            \"errors\": errors\n",
        "        }\n",
        "    except FileNotFoundError as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: {str(e)}\"]\n",
        "        }\n",
        "    except ValueError as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: {str(e)}\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: Unexpected error: {str(e)}\"]\n",
        "        }"
      ],
      "metadata": {
        "id": "2fVq0s0P5v67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Workforce Development Orchestrator — Data Loading Node\n",
        "\n",
        "The `data_loading_node` is the **foundation node** of the Workforce Development Orchestrator. Its responsibility is simple but critical:\n",
        "\n",
        "> **Safely transform raw workforce data into a structured, reliable state the agent can trust.**\n",
        "\n",
        "Every downstream analysis — automation risk, skill gaps, learning paths, role evolution — depends on this step being correct, complete, and auditable.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Why This Node Exists\n",
        "\n",
        "Rather than allowing each analytical component to load data independently, this node centralizes **all data ingestion** into a single, controlled step.\n",
        "\n",
        "This design:\n",
        "\n",
        "* Eliminates duplication\n",
        "* Prevents inconsistent views of data\n",
        "* Creates a single source of truth for the entire run\n",
        "\n",
        "If something goes wrong here, the system fails early — before misleading insights are generated.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Configuration-Driven, Not Hard-Coded\n",
        "\n",
        "The node relies entirely on the `WorkforceDevelopmentOrchestratorConfig` for file locations and names.\n",
        "\n",
        "This ensures:\n",
        "\n",
        "* Environments can change without code changes\n",
        "* Data sources can be swapped safely\n",
        "* Executives can understand *where the data comes from*\n",
        "\n",
        "This is a small but powerful step toward operational trust.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Explicit Data Coverage\n",
        "\n",
        "The node loads **every dataset required by the agent** in one place:\n",
        "\n",
        "* Employees\n",
        "* Roles\n",
        "* Tasks\n",
        "* Skills\n",
        "* Automation signals\n",
        "* Skill gaps\n",
        "* Learning paths\n",
        "* Role evolution scenarios\n",
        "\n",
        "Nothing is implicit. Nothing is assumed.\n",
        "\n",
        "This makes it immediately clear:\n",
        "\n",
        "* What data the agent depends on\n",
        "* What would break if a dataset were missing\n",
        "* What needs to be updated as the organization evolves\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Performance and Determinism Through Lookups\n",
        "\n",
        "After loading raw data, the node builds **lookup and relationship maps**:\n",
        "\n",
        "* Direct ID lookups (roles, tasks, skills, employees)\n",
        "* Role-to-task mappings\n",
        "* Role-to-employee mappings\n",
        "\n",
        "These structures are deliberately created *once* and reused everywhere else.\n",
        "\n",
        "From a business standpoint, this ensures:\n",
        "\n",
        "* Predictable execution time\n",
        "* No hidden computation costs\n",
        "* No inconsistent joins during analysis\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Defensive Error Handling\n",
        "\n",
        "The node treats errors as first-class outputs.\n",
        "\n",
        "### Key behaviors:\n",
        "\n",
        "* Missing data directories are detected immediately\n",
        "* File and parsing errors are captured and contextualized\n",
        "* Unexpected failures are surfaced without crashing the agent\n",
        "\n",
        "Importantly, errors are **accumulated**, not overwritten. This allows:\n",
        "\n",
        "* Partial execution where appropriate\n",
        "* Clear diagnostics at the end of a run\n",
        "* Easier debugging and post-mortems\n",
        "\n",
        "This is critical for long-running or enterprise-facing agents.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Thin Node, Strong Utilities\n",
        "\n",
        "Notice what this node does *not* do:\n",
        "\n",
        "* It does not parse JSON directly\n",
        "* It does not build data structures inline\n",
        "* It does not embed business logic\n",
        "\n",
        "Instead, it delegates to utilities that are:\n",
        "\n",
        "* Independently tested\n",
        "* Reusable\n",
        "* Easier to reason about\n",
        "\n",
        "The fact that all utilities passed tests before this node was built is exactly the right workflow. This keeps orchestration clean and logic trustworthy.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Node Builds Confidence\n",
        "\n",
        "From an executive or stakeholder perspective, this node guarantees:\n",
        "\n",
        "* The agent reasons only over verified inputs\n",
        "* Failures are visible and explainable\n",
        "* Outputs are grounded in consistent data\n",
        "* Changes to data are controlled and auditable\n",
        "\n",
        "From a system design perspective, this node establishes a **stable base layer** that allows every other component to focus on *analysis*, not *data hygiene*.\n",
        "\n",
        "---\n",
        "\n",
        "## Architectural Takeaway\n",
        "\n",
        "This node does something deceptively important:\n",
        "\n",
        "It draws a clear line between **data reality** and **agent intelligence**.\n",
        "\n",
        "Everything beyond this point is interpretation and recommendation — but only because this node ensures the underlying facts are solid.\n",
        "\n"
      ],
      "metadata": {
        "id": "gLQP3ggJ6WBS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdUi2MV96ZED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}