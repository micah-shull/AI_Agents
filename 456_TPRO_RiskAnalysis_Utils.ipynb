{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ88toOkIZPHNEJW0NrreM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/456_TPRO_RiskAnalysis_Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Why This Makes the Agent Better Than Most LLM-Based Systems\n",
        "\n",
        "Most agents:\n",
        "\n",
        "* collapse signals into a score immediately\n",
        "* hide reasoning in prompts\n",
        "* mix explanation and decision\n",
        "* lose audit trails\n",
        "\n",
        "Your system:\n",
        "\n",
        "* builds a case\n",
        "* records the case\n",
        "* then decides *later*\n",
        "\n",
        "Thatâ€™s why itâ€™s trustworthy.\n",
        "\n",
        "---\n",
        "\n",
        "# Risk Analysis Node â€” Structured Reasoning Without Scoring\n",
        "\n",
        "## What This Node Does (High-Level)\n",
        "\n",
        "The `risk_analysis_node` is where the orchestrator **builds understanding** â€” but deliberately **does not decide yet**.\n",
        "\n",
        "Its job is to:\n",
        "\n",
        "* collect evidence\n",
        "* analyze risk dimensions independently\n",
        "* preserve structure\n",
        "* identify *why* a vendor might be risky\n",
        "\n",
        "This separation is critical:\n",
        "ðŸ‘‰ **analysis first, judgment later**\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Why This Node Exists as Its Own Phase\n",
        "\n",
        "In real risk teams, analysis and scoring are separate steps.\n",
        "\n",
        "This node mirrors that reality by:\n",
        "\n",
        "* avoiding thresholds\n",
        "* avoiding aggregation\n",
        "* avoiding escalation logic\n",
        "* avoiding business decisions\n",
        "\n",
        "Instead, it creates a **fact pattern** per vendor.\n",
        "\n",
        "That design choice dramatically improves:\n",
        "\n",
        "* explainability\n",
        "* auditability\n",
        "* testability\n",
        "* future model evolution\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Dependency Injection via Utilities (Excellent Choice)\n",
        "\n",
        "```python\n",
        "from agents.third_party_risk_orchestrator.utilities.risk_analysis import (\n",
        "    analyze_control_compliance,\n",
        "    analyze_external_signals,\n",
        "    analyze_performance_metrics,\n",
        "    detect_risk_drift,\n",
        "    identify_risk_drivers\n",
        ")\n",
        "```\n",
        "\n",
        "This is *textbook orchestration*.\n",
        "\n",
        "The node:\n",
        "\n",
        "* coordinates\n",
        "* sequences\n",
        "* aggregates\n",
        "\n",
        "The utilities:\n",
        "\n",
        "* compute\n",
        "* specialize\n",
        "* remain testable in isolation\n",
        "\n",
        "This prevents:\n",
        "\n",
        "* monolithic logic\n",
        "* hidden coupling\n",
        "* untestable reasoning\n",
        "\n",
        "It also lets you improve any analysis dimension without touching orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Defensive State Access (Quietly Very Important)\n",
        "\n",
        "```python\n",
        "third_parties = state.get(\"third_parties\", [])\n",
        "...\n",
        "risk_domain_lookup = state.get(\"risk_domain_lookup\", {})\n",
        "```\n",
        "\n",
        "You never assume the state is perfect.\n",
        "\n",
        "This allows:\n",
        "\n",
        "* graceful failure\n",
        "* partial testing\n",
        "* future node reuse\n",
        "* clearer error messages\n",
        "\n",
        "Combined with early exits, this avoids cascading failures later in scoring.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Explicit Precondition Enforcement\n",
        "\n",
        "```python\n",
        "if not third_parties:\n",
        "    return {\n",
        "        \"errors\": errors + [\"risk_analysis_node: third_parties required\"]\n",
        "    }\n",
        "```\n",
        "\n",
        "This is not a guard clause â€” itâ€™s a **quality gate**.\n",
        "\n",
        "Youâ€™re enforcing:\n",
        "\n",
        "> â€œNo analysis without vendors.â€\n",
        "\n",
        "That may seem obvious, but many systems fail here and produce empty or misleading outputs.\n",
        "\n",
        "Youâ€™ve chosen correctness over convenience.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Vendor-by-Vendor Isolation (Critical for Accountability)\n",
        "\n",
        "```python\n",
        "for vendor in third_parties:\n",
        "```\n",
        "\n",
        "Each vendor is analyzed **independently**.\n",
        "\n",
        "Why this matters:\n",
        "\n",
        "* failures donâ€™t contaminate other vendors\n",
        "* explanations stay scoped\n",
        "* future parallelization is trivial\n",
        "* drift detection stays clean\n",
        "\n",
        "This design also makes it easy to answer:\n",
        "\n",
        "> â€œWhy is *this* vendor risky?â€\n",
        "\n",
        "without cross-talk.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Dimension-by-Dimension Analysis (No Cross-Pollution)\n",
        "\n",
        "For each vendor, you run **five distinct analyses**:\n",
        "\n",
        "### 1ï¸âƒ£ Control Compliance\n",
        "\n",
        "```python\n",
        "analyze_control_compliance(...)\n",
        "```\n",
        "\n",
        "Evaluates:\n",
        "\n",
        "* required controls per domain\n",
        "* evidence status\n",
        "* confidence gaps\n",
        "\n",
        "This answers:\n",
        "\n",
        "> â€œIs the vendor meeting expected safeguards?â€\n",
        "\n",
        "---\n",
        "\n",
        "### 2ï¸âƒ£ External Signals\n",
        "\n",
        "```python\n",
        "analyze_external_signals(...)\n",
        "```\n",
        "\n",
        "Evaluates:\n",
        "\n",
        "* incidents\n",
        "* regulatory actions\n",
        "* negative media\n",
        "* severity and recency\n",
        "\n",
        "This answers:\n",
        "\n",
        "> â€œIs the outside world telling us something changed?â€\n",
        "\n",
        "---\n",
        "\n",
        "### 3ï¸âƒ£ Performance Metrics\n",
        "\n",
        "```python\n",
        "analyze_performance_metrics(...)\n",
        "```\n",
        "\n",
        "Evaluates:\n",
        "\n",
        "* SLA compliance\n",
        "* incident frequency\n",
        "* responsiveness\n",
        "* satisfaction\n",
        "\n",
        "This answers:\n",
        "\n",
        "> â€œIs the vendor operationally reliable?â€\n",
        "\n",
        "---\n",
        "\n",
        "### 4ï¸âƒ£ Risk Drift Detection (Major Differentiator)\n",
        "\n",
        "```python\n",
        "detect_risk_drift(...)\n",
        "```\n",
        "\n",
        "This compares **past vs present**.\n",
        "\n",
        "It answers:\n",
        "\n",
        "> â€œIs risk increasing, decreasing, or stable â€” and why?â€\n",
        "\n",
        "Most agents *donâ€™t model time*.\n",
        "You explicitly do.\n",
        "\n",
        "---\n",
        "\n",
        "### 5ï¸âƒ£ Risk Driver Identification (Narrative Layer)\n",
        "\n",
        "```python\n",
        "identify_risk_drivers(...)\n",
        "```\n",
        "\n",
        "This is where structure becomes explanation.\n",
        "\n",
        "Instead of raw metrics, you generate **human-readable drivers**:\n",
        "\n",
        "* â€œExpired SOC2â€\n",
        "* â€œRecent high-severity incidentâ€\n",
        "* â€œRepeated SLA breachesâ€\n",
        "\n",
        "This is the bridge between:\n",
        "\n",
        "* data\n",
        "* decision\n",
        "* executive communication\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Clean Aggregation Without Scoring\n",
        "\n",
        "```python\n",
        "vendor_risk_analysis[vendor_id] = {\n",
        "    ...\n",
        "}\n",
        "```\n",
        "\n",
        "Notice whatâ€™s missing:\n",
        "\n",
        "* no scores\n",
        "* no thresholds\n",
        "* no labels\n",
        "* no escalation flags\n",
        "\n",
        "This is intentional and *very good*.\n",
        "\n",
        "You are preserving **raw analytical signal**, not collapsing it prematurely.\n",
        "\n",
        "That makes downstream scoring:\n",
        "\n",
        "* testable\n",
        "* adjustable\n",
        "* explainable\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Drift Stored Separately (Subtle but Smart)\n",
        "\n",
        "```python\n",
        "risk_drift_detection[vendor_id] = drift_info\n",
        "```\n",
        "\n",
        "Drift is not mixed into current analysis.\n",
        "\n",
        "Why that matters:\n",
        "\n",
        "* avoids double counting\n",
        "* allows independent KPI tracking\n",
        "* supports early warning dashboards\n",
        "* keeps historical reasoning intact\n",
        "\n",
        "This separation is rare and excellent.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Failure Handling Philosophy\n",
        "\n",
        "```python\n",
        "except Exception as e:\n",
        "    return {\n",
        "        \"errors\": errors + [f\"risk_analysis_node: Unexpected error - {str(e)}\"]\n",
        "    }\n",
        "```\n",
        "\n",
        "You do not:\n",
        "\n",
        "* crash silently\n",
        "* partially return results\n",
        "* hide the failure\n",
        "\n",
        "You fail *explicitly* and *traceably*.\n",
        "\n",
        "Thatâ€™s exactly what you want in a risk system.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Why This Node Is High Quality\n",
        "\n",
        "This node:\n",
        "\n",
        "* reasons without deciding\n",
        "* structures without summarizing\n",
        "* isolates concerns\n",
        "* preserves evidence\n",
        "* enables explanation later\n",
        "\n",
        "In other words, it behaves like a **risk analyst**, not a judge.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I2lLevPkLU2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9enBntZIv2_"
      },
      "outputs": [],
      "source": [
        "\"\"\"Risk analysis utilities for Third-Party Risk Orchestrator\n",
        "\n",
        "This module contains utilities to analyze risk across all dimensions:\n",
        "- Control compliance analysis\n",
        "- External signals analysis\n",
        "- Performance metrics analysis\n",
        "- Risk drift detection\n",
        "- Risk driver identification\n",
        "\n",
        "All utilities are pure functions, independently testable.\n",
        "\n",
        "Following MVP-first approach: Rule-based analysis, no LLM dependencies.\n",
        "\"\"\"\n",
        "\n",
        "from typing import List, Dict, Any, Optional\n",
        "from datetime import datetime, date\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def analyze_control_compliance(\n",
        "    vendor_id: str,\n",
        "    vendor_controls: List[Dict[str, Any]],\n",
        "    risk_domains: List[Dict[str, Any]],\n",
        "    risk_domain_lookup: Dict[str, Dict[str, Any]]\n",
        ") -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Analyze control compliance for a vendor across all risk domains.\n",
        "\n",
        "    Args:\n",
        "        vendor_id: Vendor to analyze\n",
        "        vendor_controls: All vendor controls\n",
        "        risk_domains: All risk domain definitions\n",
        "        risk_domain_lookup: Fast lookup for risk domains\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping risk_domain to compliance analysis\n",
        "        Structure:\n",
        "        {\n",
        "            \"Information Security\": {\n",
        "                \"status\": \"partial\" | \"active\" | \"expired\" | \"missing\",\n",
        "                \"score\": 0-100,\n",
        "                \"controls_analyzed\": 2,\n",
        "                \"controls_active\": 1,\n",
        "                \"controls_expired\": 1,\n",
        "                \"controls_partial\": 0,\n",
        "                \"controls_missing\": 1,\n",
        "                \"missing_controls\": [\"SOC2\"],\n",
        "                \"required_controls\": [\"SOC2\", \"Encryption\", \"Access Controls\"],\n",
        "                \"controls_detail\": [...]\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Filter controls for this vendor\n",
        "    vendor_control_list = [c for c in vendor_controls if c.get(\"vendor_id\") == vendor_id]\n",
        "\n",
        "    # Group controls by risk domain\n",
        "    domain_controls = defaultdict(list)\n",
        "    for control in vendor_control_list:\n",
        "        domain = control.get(\"risk_domain\")\n",
        "        if domain:\n",
        "            domain_controls[domain].append(control)\n",
        "\n",
        "    # Analyze each risk domain\n",
        "    domain_analysis = {}\n",
        "\n",
        "    for domain_def in risk_domains:\n",
        "        domain_name = domain_def.get(\"risk_domain\")\n",
        "        required_controls = domain_def.get(\"required_controls\", [])\n",
        "        domain_control_list = domain_controls.get(domain_name, [])\n",
        "\n",
        "        # Count control statuses\n",
        "        controls_active = sum(1 for c in domain_control_list if c.get(\"status\") == \"active\")\n",
        "        controls_expired = sum(1 for c in domain_control_list if c.get(\"status\") == \"expired\")\n",
        "        controls_partial = sum(1 for c in domain_control_list if c.get(\"status\") == \"partial\")\n",
        "\n",
        "        # Find which required controls are present\n",
        "        present_controls = {c.get(\"control\") for c in domain_control_list}\n",
        "        missing_controls = [c for c in required_controls if c not in present_controls]\n",
        "\n",
        "        # Calculate compliance score\n",
        "        # Active = 100%, Partial = 50%, Expired = 0%, Missing = 0%\n",
        "        total_required = len(required_controls)\n",
        "        if total_required == 0:\n",
        "            score = 100.0\n",
        "        else:\n",
        "            score = (\n",
        "                (controls_active * 100.0) +\n",
        "                (controls_partial * 50.0) +\n",
        "                (controls_expired * 0.0)\n",
        "            ) / total_required\n",
        "\n",
        "        # Determine overall status\n",
        "        if controls_expired > 0 or len(missing_controls) > 0:\n",
        "            if controls_active > 0 or controls_partial > 0:\n",
        "                status = \"partial\"\n",
        "            else:\n",
        "                status = \"missing\"\n",
        "        elif controls_partial > 0:\n",
        "            status = \"partial\"\n",
        "        elif controls_active == total_required and len(missing_controls) == 0:\n",
        "            status = \"active\"\n",
        "        else:\n",
        "            status = \"partial\"\n",
        "\n",
        "        domain_analysis[domain_name] = {\n",
        "            \"status\": status,\n",
        "            \"score\": round(score, 2),\n",
        "            \"controls_analyzed\": len(domain_control_list),\n",
        "            \"controls_active\": controls_active,\n",
        "            \"controls_expired\": controls_expired,\n",
        "            \"controls_partial\": controls_partial,\n",
        "            \"controls_missing\": len(missing_controls),\n",
        "            \"missing_controls\": missing_controls,\n",
        "            \"required_controls\": required_controls,\n",
        "            \"controls_detail\": domain_control_list\n",
        "        }\n",
        "\n",
        "    return domain_analysis\n",
        "\n",
        "\n",
        "def analyze_external_signals(\n",
        "    vendor_id: str,\n",
        "    external_signals: List[Dict[str, Any]]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Analyze external risk signals for a vendor.\n",
        "\n",
        "    Args:\n",
        "        vendor_id: Vendor to analyze\n",
        "        external_signals: All external signals\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with signal analysis\n",
        "        Structure:\n",
        "        {\n",
        "            \"total_signals\": 2,\n",
        "            \"high_severity_count\": 1,\n",
        "            \"medium_severity_count\": 1,\n",
        "            \"low_severity_count\": 0,\n",
        "            \"signal_types\": {\n",
        "                \"security_incident\": 1,\n",
        "                \"regulatory_notice\": 1\n",
        "            },\n",
        "            \"recent_signals\": [...],  # Signals from last 30 days\n",
        "            \"high_priority_signals\": [...],  # High severity signals\n",
        "            \"signal_impact_score\": 0-100  # Weighted impact score\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Filter signals for this vendor\n",
        "    vendor_signals = [s for s in external_signals if s.get(\"vendor_id\") == vendor_id]\n",
        "\n",
        "    if not vendor_signals:\n",
        "        return {\n",
        "            \"total_signals\": 0,\n",
        "            \"high_severity_count\": 0,\n",
        "            \"medium_severity_count\": 0,\n",
        "            \"low_severity_count\": 0,\n",
        "            \"signal_types\": {},\n",
        "            \"recent_signals\": [],\n",
        "            \"high_priority_signals\": [],\n",
        "            \"signal_impact_score\": 0.0\n",
        "        }\n",
        "\n",
        "    # Count by severity\n",
        "    high_count = sum(1 for s in vendor_signals if s.get(\"severity\") == \"high\")\n",
        "    medium_count = sum(1 for s in vendor_signals if s.get(\"severity\") == \"medium\")\n",
        "    low_count = sum(1 for s in vendor_signals if s.get(\"severity\") == \"low\")\n",
        "\n",
        "    # Count by type\n",
        "    signal_types = defaultdict(int)\n",
        "    for signal in vendor_signals:\n",
        "        signal_type = signal.get(\"signal_type\", \"unknown\")\n",
        "        signal_types[signal_type] += 1\n",
        "\n",
        "    # Find recent signals (last 30 days)\n",
        "    today = date.today()\n",
        "    recent_signals = []\n",
        "    for signal in vendor_signals:\n",
        "        detected_date_str = signal.get(\"detected_date\")\n",
        "        if detected_date_str:\n",
        "            try:\n",
        "                detected_date = datetime.fromisoformat(detected_date_str).date()\n",
        "                days_ago = (today - detected_date).days\n",
        "                if days_ago <= 30:\n",
        "                    recent_signals.append(signal)\n",
        "            except (ValueError, TypeError):\n",
        "                pass\n",
        "\n",
        "    # Find high priority signals (high severity)\n",
        "    high_priority_signals = [s for s in vendor_signals if s.get(\"severity\") == \"high\"]\n",
        "\n",
        "    # Calculate impact score (weighted by severity and recency)\n",
        "    # High = 100, Medium = 50, Low = 25\n",
        "    # Recent (<=30 days) = 1.5x multiplier\n",
        "    impact_score = 0.0\n",
        "    for signal in vendor_signals:\n",
        "        severity = signal.get(\"severity\", \"low\")\n",
        "        base_score = {\"high\": 100.0, \"medium\": 50.0, \"low\": 25.0}.get(severity, 0.0)\n",
        "\n",
        "        # Check if recent\n",
        "        detected_date_str = signal.get(\"detected_date\")\n",
        "        is_recent = False\n",
        "        if detected_date_str:\n",
        "            try:\n",
        "                detected_date = datetime.fromisoformat(detected_date_str).date()\n",
        "                days_ago = (today - detected_date).days\n",
        "                is_recent = days_ago <= 30\n",
        "            except (ValueError, TypeError):\n",
        "                pass\n",
        "\n",
        "        multiplier = 1.5 if is_recent else 1.0\n",
        "        impact_score += base_score * multiplier\n",
        "\n",
        "    # Normalize to 0-100 scale (assuming max 5 signals)\n",
        "    max_possible_score = 5 * 100.0 * 1.5  # 5 high-severity recent signals\n",
        "    normalized_score = min(100.0, (impact_score / max_possible_score) * 100.0) if max_possible_score > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        \"total_signals\": len(vendor_signals),\n",
        "        \"high_severity_count\": high_count,\n",
        "        \"medium_severity_count\": medium_count,\n",
        "        \"low_severity_count\": low_count,\n",
        "        \"signal_types\": dict(signal_types),\n",
        "        \"recent_signals\": recent_signals,\n",
        "        \"high_priority_signals\": high_priority_signals,\n",
        "        \"signal_impact_score\": round(normalized_score, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_performance_metrics(\n",
        "    vendor_id: str,\n",
        "    vendor_performance: List[Dict[str, Any]]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Analyze vendor performance metrics.\n",
        "\n",
        "    Args:\n",
        "        vendor_id: Vendor to analyze\n",
        "        vendor_performance: All vendor performance data\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with performance analysis\n",
        "        Structure:\n",
        "        {\n",
        "            \"sla_compliance\": 0.89,\n",
        "            \"sla_status\": \"below_threshold\" | \"meets_threshold\" | \"exceeds_threshold\",\n",
        "            \"incident_count\": 4,\n",
        "            \"incident_status\": \"elevated\" | \"normal\" | \"low\",\n",
        "            \"response_time_avg_hours\": 5.6,\n",
        "            \"response_time_status\": \"slow\" | \"acceptable\" | \"fast\",\n",
        "            \"customer_satisfaction_score\": 3.4,\n",
        "            \"satisfaction_status\": \"low\" | \"medium\" | \"high\",\n",
        "            \"performance_score\": 0-100,\n",
        "            \"performance_issues\": [...]\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Find performance data for this vendor\n",
        "    perf_data = next(\n",
        "        (p for p in vendor_performance if p.get(\"vendor_id\") == vendor_id),\n",
        "        None\n",
        "    )\n",
        "\n",
        "    if not perf_data:\n",
        "        return {\n",
        "            \"sla_compliance\": None,\n",
        "            \"sla_status\": \"no_data\",\n",
        "            \"incident_count\": None,\n",
        "            \"incident_status\": \"no_data\",\n",
        "            \"response_time_avg_hours\": None,\n",
        "            \"response_time_status\": \"no_data\",\n",
        "            \"customer_satisfaction_score\": None,\n",
        "            \"satisfaction_status\": \"no_data\",\n",
        "            \"performance_score\": 0.0,\n",
        "            \"performance_issues\": []\n",
        "        }\n",
        "\n",
        "    sla_compliance = perf_data.get(\"sla_compliance\")\n",
        "    incident_count = perf_data.get(\"incident_count\")\n",
        "    response_time = perf_data.get(\"response_time_avg_hours\")\n",
        "    satisfaction = perf_data.get(\"customer_satisfaction_score\")\n",
        "\n",
        "    performance_issues = []\n",
        "\n",
        "    # Analyze SLA compliance\n",
        "    sla_status = \"no_data\"\n",
        "    if sla_compliance is not None:\n",
        "        if sla_compliance >= 0.95:\n",
        "            sla_status = \"exceeds_threshold\"\n",
        "        elif sla_compliance >= 0.90:\n",
        "            sla_status = \"meets_threshold\"\n",
        "        else:\n",
        "            sla_status = \"below_threshold\"\n",
        "            performance_issues.append(f\"SLA compliance below threshold: {sla_compliance:.2%}\")\n",
        "\n",
        "    # Analyze incident count\n",
        "    incident_status = \"no_data\"\n",
        "    if incident_count is not None:\n",
        "        if incident_count >= 5:\n",
        "            incident_status = \"elevated\"\n",
        "            performance_issues.append(f\"Elevated incident count: {incident_count}\")\n",
        "        elif incident_count >= 2:\n",
        "            incident_status = \"normal\"\n",
        "        else:\n",
        "            incident_status = \"low\"\n",
        "\n",
        "    # Analyze response time\n",
        "    response_time_status = \"no_data\"\n",
        "    if response_time is not None:\n",
        "        if response_time > 6.0:\n",
        "            response_time_status = \"slow\"\n",
        "            performance_issues.append(f\"Slow response time: {response_time:.1f} hours\")\n",
        "        elif response_time > 4.0:\n",
        "            response_time_status = \"acceptable\"\n",
        "        else:\n",
        "            response_time_status = \"fast\"\n",
        "\n",
        "    # Analyze customer satisfaction\n",
        "    satisfaction_status = \"no_data\"\n",
        "    if satisfaction is not None:\n",
        "        if satisfaction >= 4.0:\n",
        "            satisfaction_status = \"high\"\n",
        "        elif satisfaction >= 3.0:\n",
        "            satisfaction_status = \"medium\"\n",
        "        else:\n",
        "            satisfaction_status = \"low\"\n",
        "            performance_issues.append(f\"Low customer satisfaction: {satisfaction:.1f}/5.0\")\n",
        "\n",
        "    # Calculate overall performance score (0-100)\n",
        "    # Weighted: SLA 40%, Satisfaction 30%, Response Time 20%, Incidents 10%\n",
        "    performance_score = 0.0\n",
        "    components = 0\n",
        "\n",
        "    if sla_compliance is not None:\n",
        "        performance_score += sla_compliance * 100.0 * 0.40\n",
        "        components += 0.40\n",
        "\n",
        "    if satisfaction is not None:\n",
        "        # Convert 1-5 scale to 0-100\n",
        "        satisfaction_normalized = (satisfaction / 5.0) * 100.0\n",
        "        performance_score += satisfaction_normalized * 0.30\n",
        "        components += 0.30\n",
        "\n",
        "    if response_time is not None:\n",
        "        # Invert: faster is better (6 hours = 0, 0 hours = 100)\n",
        "        response_time_normalized = max(0.0, min(100.0, (6.0 - response_time) / 6.0 * 100.0))\n",
        "        performance_score += response_time_normalized * 0.20\n",
        "        components += 0.20\n",
        "\n",
        "    if incident_count is not None:\n",
        "        # Invert: fewer incidents is better (5+ = 0, 0 = 100)\n",
        "        incident_normalized = max(0.0, min(100.0, (5.0 - incident_count) / 5.0 * 100.0))\n",
        "        performance_score += incident_normalized * 0.10\n",
        "        components += 0.10\n",
        "\n",
        "    # Normalize by components present\n",
        "    if components > 0:\n",
        "        performance_score = performance_score / components\n",
        "    else:\n",
        "        performance_score = 0.0\n",
        "\n",
        "    return {\n",
        "        \"sla_compliance\": sla_compliance,\n",
        "        \"sla_status\": sla_status,\n",
        "        \"incident_count\": incident_count,\n",
        "        \"incident_status\": incident_status,\n",
        "        \"response_time_avg_hours\": response_time,\n",
        "        \"response_time_status\": response_time_status,\n",
        "        \"customer_satisfaction_score\": satisfaction,\n",
        "        \"satisfaction_status\": satisfaction_status,\n",
        "        \"performance_score\": round(performance_score, 2),\n",
        "        \"performance_issues\": performance_issues\n",
        "    }\n",
        "\n",
        "\n",
        "def detect_risk_drift(\n",
        "    vendor_id: str,\n",
        "    assessment_history: List[Dict[str, Any]],\n",
        "    current_date: Optional[str] = None\n",
        ") -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Detect risk drift by comparing current assessment to historical baseline.\n",
        "\n",
        "    Args:\n",
        "        vendor_id: Vendor to analyze\n",
        "        assessment_history: All historical assessments\n",
        "        current_date: Current assessment date (ISO format, defaults to today)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with drift analysis, or None if no history\n",
        "        Structure:\n",
        "        {\n",
        "            \"vendor_id\": \"VEND_001\",\n",
        "            \"previous_score\": 42,\n",
        "            \"current_score\": None,  # Will be set during scoring phase\n",
        "            \"score_delta\": None,\n",
        "            \"drift_direction\": \"increasing\" | \"decreasing\" | \"stable\" | \"unknown\",\n",
        "            \"previous_assessment_date\": \"2025-10-01\",\n",
        "            \"previous_risk_level\": \"medium\",\n",
        "            \"previous_trigger\": \"scheduled_review\",\n",
        "            \"drift_trigger\": \"external_signal\" | \"scheduled_review\" | None\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Filter history for this vendor\n",
        "    vendor_history = [\n",
        "        h for h in assessment_history\n",
        "        if h.get(\"vendor_id\") == vendor_id\n",
        "    ]\n",
        "\n",
        "    if not vendor_history:\n",
        "        return None\n",
        "\n",
        "    # Sort by date (most recent first)\n",
        "    vendor_history.sort(\n",
        "        key=lambda x: x.get(\"assessment_date\", \"\"),\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    # Get most recent historical assessment\n",
        "    most_recent = vendor_history[0]\n",
        "\n",
        "    previous_score = most_recent.get(\"risk_score\")\n",
        "    previous_date = most_recent.get(\"assessment_date\")\n",
        "    previous_level = most_recent.get(\"risk_level\")\n",
        "    previous_trigger = most_recent.get(\"trigger\")\n",
        "\n",
        "    # Check if there's a more recent signal-triggered assessment\n",
        "    signal_triggered = None\n",
        "    for assessment in vendor_history:\n",
        "        if assessment.get(\"trigger\") == \"external_signal\":\n",
        "            signal_triggered = assessment\n",
        "            break\n",
        "\n",
        "    # Use signal-triggered if it's more recent\n",
        "    if signal_triggered:\n",
        "        signal_date = signal_triggered.get(\"assessment_date\", \"\")\n",
        "        if signal_date > previous_date:\n",
        "            previous_score = signal_triggered.get(\"risk_score\")\n",
        "            previous_date = signal_date\n",
        "            previous_level = signal_triggered.get(\"risk_level\")\n",
        "            previous_trigger = signal_triggered.get(\"trigger\")\n",
        "\n",
        "    return {\n",
        "        \"vendor_id\": vendor_id,\n",
        "        \"previous_score\": previous_score,\n",
        "        \"current_score\": None,  # Will be set during scoring\n",
        "        \"score_delta\": None,  # Will be calculated during scoring\n",
        "        \"drift_direction\": \"unknown\",  # Will be determined during scoring\n",
        "        \"previous_assessment_date\": previous_date,\n",
        "        \"previous_risk_level\": previous_level,\n",
        "        \"previous_trigger\": previous_trigger,\n",
        "        \"drift_trigger\": previous_trigger\n",
        "    }\n",
        "\n",
        "\n",
        "def identify_risk_drivers(\n",
        "    vendor_id: str,\n",
        "    control_analysis: Dict[str, Dict[str, Any]],\n",
        "    signal_analysis: Dict[str, Any],\n",
        "    performance_analysis: Dict[str, Any],\n",
        "    vendor_data: Dict[str, Any]\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Identify primary risk drivers by aggregating all analysis findings.\n",
        "\n",
        "    Args:\n",
        "        vendor_id: Vendor ID\n",
        "        control_analysis: Control compliance analysis\n",
        "        signal_analysis: External signal analysis\n",
        "        performance_analysis: Performance metrics analysis\n",
        "        vendor_data: Vendor metadata\n",
        "\n",
        "    Returns:\n",
        "        List of risk driver descriptions, prioritized by severity\n",
        "    \"\"\"\n",
        "    drivers = []\n",
        "\n",
        "    # Control-related drivers\n",
        "    for domain_name, domain_data in control_analysis.items():\n",
        "        status = domain_data.get(\"status\")\n",
        "        missing_controls = domain_data.get(\"missing_controls\", [])\n",
        "        expired_controls = [\n",
        "            c.get(\"control\") for c in domain_data.get(\"controls_detail\", [])\n",
        "            if c.get(\"status\") == \"expired\"\n",
        "        ]\n",
        "\n",
        "        if expired_controls:\n",
        "            for control in expired_controls:\n",
        "                drivers.append(f\"Expired {control} in {domain_name}\")\n",
        "\n",
        "        if missing_controls:\n",
        "            for control in missing_controls:\n",
        "                drivers.append(f\"Missing {control} in {domain_name}\")\n",
        "\n",
        "        if status == \"partial\" and not expired_controls and not missing_controls:\n",
        "            drivers.append(f\"Partial compliance in {domain_name}\")\n",
        "\n",
        "    # Signal-related drivers\n",
        "    high_priority_signals = signal_analysis.get(\"high_priority_signals\", [])\n",
        "    for signal in high_priority_signals:\n",
        "        signal_type = signal.get(\"signal_type\", \"unknown\")\n",
        "        severity = signal.get(\"severity\", \"unknown\")\n",
        "        drivers.append(f\"Recent {severity}-severity {signal_type.replace('_', ' ')}\")\n",
        "\n",
        "    # Performance-related drivers\n",
        "    performance_issues = performance_analysis.get(\"performance_issues\", [])\n",
        "    drivers.extend(performance_issues)\n",
        "\n",
        "    # Contract lifecycle drivers\n",
        "    contract_status = vendor_data.get(\"contract_status\")\n",
        "    if contract_status == \"renewal_pending\":\n",
        "        drivers.append(\"Contract renewal pending - requires review\")\n",
        "    elif contract_status == \"onboarding\":\n",
        "        drivers.append(\"Vendor onboarding in progress - incomplete assessment\")\n",
        "\n",
        "    # Criticality-based drivers\n",
        "    criticality = vendor_data.get(\"criticality\")\n",
        "    if criticality == \"high\":\n",
        "        # High criticality vendors get extra scrutiny\n",
        "        if len(drivers) > 0:\n",
        "            drivers.append(\"High criticality vendor requires enhanced monitoring\")\n",
        "\n",
        "    return drivers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node"
      ],
      "metadata": {
        "id": "izHC5oDEJAns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def risk_analysis_node(state: ThirdPartyRiskOrchestratorState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Risk Analysis Node: Orchestrate analyzing risk across all dimensions.\n",
        "\n",
        "    Analyzes each vendor across:\n",
        "    - Control compliance per risk domain\n",
        "    - External risk signals\n",
        "    - Performance metrics\n",
        "    - Risk drift detection\n",
        "    - Risk driver identification\n",
        "    \"\"\"\n",
        "    from agents.third_party_risk_orchestrator.utilities.risk_analysis import (\n",
        "        analyze_control_compliance,\n",
        "        analyze_external_signals,\n",
        "        analyze_performance_metrics,\n",
        "        detect_risk_drift,\n",
        "        identify_risk_drivers\n",
        "    )\n",
        "\n",
        "    errors = state.get(\"errors\", [])\n",
        "    third_parties = state.get(\"third_parties\", [])\n",
        "    vendor_controls = state.get(\"vendor_controls\", [])\n",
        "    external_signals = state.get(\"external_signals\", [])\n",
        "    vendor_performance = state.get(\"vendor_performance\", [])\n",
        "    assessment_history = state.get(\"assessment_history\", [])\n",
        "    risk_domains = state.get(\"risk_domains\", [])\n",
        "    risk_domain_lookup = state.get(\"risk_domain_lookup\", {})\n",
        "    vendor_lookup = state.get(\"vendor_lookup\", {})\n",
        "\n",
        "    if not third_parties:\n",
        "        return {\n",
        "            \"errors\": errors + [\"risk_analysis_node: third_parties required\"]\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        vendor_risk_analysis = {}\n",
        "        risk_drift_detection = {}\n",
        "\n",
        "        # Analyze each vendor\n",
        "        for vendor in third_parties:\n",
        "            vendor_id = vendor.get(\"vendor_id\")\n",
        "            if not vendor_id:\n",
        "                continue\n",
        "\n",
        "            # Analyze control compliance\n",
        "            control_analysis = analyze_control_compliance(\n",
        "                vendor_id,\n",
        "                vendor_controls,\n",
        "                risk_domains,\n",
        "                risk_domain_lookup\n",
        "            )\n",
        "\n",
        "            # Analyze external signals\n",
        "            signal_analysis = analyze_external_signals(\n",
        "                vendor_id,\n",
        "                external_signals\n",
        "            )\n",
        "\n",
        "            # Analyze performance metrics\n",
        "            performance_analysis = analyze_performance_metrics(\n",
        "                vendor_id,\n",
        "                vendor_performance\n",
        "            )\n",
        "\n",
        "            # Detect risk drift\n",
        "            drift_info = detect_risk_drift(\n",
        "                vendor_id,\n",
        "                assessment_history\n",
        "            )\n",
        "            if drift_info:\n",
        "                risk_drift_detection[vendor_id] = drift_info\n",
        "\n",
        "            # Identify risk drivers\n",
        "            vendor_data = vendor_lookup.get(vendor_id, {})\n",
        "            risk_drivers = identify_risk_drivers(\n",
        "                vendor_id,\n",
        "                control_analysis,\n",
        "                signal_analysis,\n",
        "                performance_analysis,\n",
        "                vendor_data\n",
        "            )\n",
        "\n",
        "            # Combine all analysis\n",
        "            vendor_risk_analysis[vendor_id] = {\n",
        "                \"vendor_id\": vendor_id,\n",
        "                \"control_compliance\": control_analysis,\n",
        "                \"external_signals\": signal_analysis,\n",
        "                \"performance_metrics\": performance_analysis,\n",
        "                \"risk_drivers\": risk_drivers\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            \"vendor_risk_analysis\": vendor_risk_analysis,\n",
        "            \"risk_drift_detection\": risk_drift_detection,\n",
        "            \"errors\": errors\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"risk_analysis_node: Unexpected error - {str(e)}\"]\n",
        "        }"
      ],
      "metadata": {
        "id": "_cw4sl_fJBWP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}