{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN21nf9Kj3BwULBQ1qGR9d7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/106_TxtSummarizerAgent_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# What the scaffold already covers (✅)\n",
        "\n",
        "* **Result envelope** (uniform `ok/err`) and structured errors with hints.\n",
        "* **ActionContext** as the DI “backpack” (memory, config, deps).\n",
        "* **Tool registry** + **JSON-ish schemas** + basic validation.\n",
        "* **Environment** that validates → DI injects underscore deps → executes → logs.\n",
        "* **Minimal tools** (`create_plan`, `track_progress`, `terminate`) to demo the loop.\n",
        "* **Deterministic orchestrator** (`ScriptedAgent`) with stop conditions.\n",
        "* **Progress logging** helpers.\n",
        "\n",
        "# What’s still missing (⚠️)\n",
        "\n",
        "These map to your Recipe, Handbook, and Particulars:\n",
        "\n",
        "1. **Message Plan & Function-Calling driver**\n",
        "\n",
        "   * No explicit **system/user prompt plan** or **one-tool-per-step** function-calling driver (the scaffold uses a FakeLLM + scripted loop).\n",
        "\n",
        "2. **Capabilities layer (hooks)**\n",
        "\n",
        "   * No `PlanFirst/Retry/ProgressTracking` hook system in the scaffold version (you had those in another code path).\n",
        "\n",
        "3. **Environment contracts**\n",
        "\n",
        "   * Missing explicit **path whitelist, filename policy, truncation caps**, and **determinism rules**; result envelope doesn’t yet include your canonical `{\"tool_executed\": ...}` fields.\n",
        "\n",
        "4. **Memory policy**\n",
        "\n",
        "   * No codified **window size / item shape / coercion** policy—right now it’s an ad-hoc scratch store.\n",
        "\n",
        "5. **Logging triad**\n",
        "\n",
        "   * We log progress, but not the canonical **Prompt → Decision ← Result ←** trace that speeds debugging.\n",
        "\n",
        "6. **Testing & acceptance**\n",
        "\n",
        "   * No unit/integration test stubs or **acceptance checklist** wired into the repo.\n",
        "\n",
        "7. **Risks & guardrails**\n",
        "\n",
        "   * Lacking the explicit early choices (encoding policy, naming convention, big-file plan) your checklist expects.\n",
        "\n",
        "8. **GAME labeling**\n",
        "\n",
        "   * G/A/M/E are present in spirit, but not **named/isolated** as such for clarity (e.g., a short `GAME.md` or comments).\n",
        "\n",
        "# Minimal patch plan to make it “complete”\n",
        "\n",
        "Prioritized (fastest wins first):\n",
        "\n",
        "1. **Add Message Plan + Driver**\n",
        "\n",
        "   * Provide a `build_messages(goal, memory, tools)` and a `FunctionCallingAgent` that enforces **exactly one tool** per step (with a safe fallback).\n",
        "\n",
        "2. **Capability hooks**\n",
        "\n",
        "   * Add a tiny `Capability` base with `on_before_model/on_after_tool/...` and implement **PlanFirst** + **RetryBackoff** + **ProgressTracking** as opt-in.\n",
        "\n",
        "3. **Environment contracts**\n",
        "\n",
        "   * Configure **`path_whitelist`, `filename_policy`, `truncation_cap_chars`**; normalize results to include `tool_executed` fields alongside `ok/err`.\n",
        "\n",
        "4. **Memory policy**\n",
        "\n",
        "   * Store messages as `{role, content}` with a **window of N** and coercion of dicts → strings, per your particulars.\n",
        "\n",
        "5. **Logging triad**\n",
        "\n",
        "   * Add a small logger to print/store **Prompt → Decision ← Result ←** each step (redact secrets).\n",
        "\n",
        "6. **Tests & acceptance**\n",
        "\n",
        "   * Ship a `tests/` folder with: tool unit tests, a one-file E2E smoke, and a function-calling sanity case; include your acceptance items as asserts.\n",
        "\n",
        "7. **Risks & early choices**\n",
        "\n",
        "   * Add a `config.py` block with **encoding `errors='replace'`**, naming `verb_object_context`, and a note to add `read_chunk` in v2 for large files.\n",
        "\n",
        "8. **GAME docstring**\n",
        "\n",
        "   * Annotate the scaffold’s top: **Goals, Actions, Memory, Environment** mapping for quick orientation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rBC7hkAvAOT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "If you're training or guiding an LLM to **build agents that follow best practices**, you’ll get **better, more reliable results** by providing a **minimal, structured scaffold** + **annotated best-practice notes**, **not** the entire final code dump.\n",
        "\n",
        "---\n",
        "\n",
        "## 🆚 Full Code Example vs. Scaffold\n",
        "\n",
        "| Option                       | Pros                                                                                                                      | Cons                                                                                                                          |\n",
        "| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **✅ Scaffold (Best Choice)** | - Easier to digest<br>- Encourages generalization<br>- Explicitly highlights required parts<br>- Makes structure reusable | - Requires initial design work<br>- May leave out edge-case handling unless included                                          |\n",
        "| Full Final Code              | - Shows everything<br>- Demonstrates edge cases, polish, advanced tricks                                                  | - Overwhelming to parse<br>- Easy to overfit to one format<br>- LLM may copy rather than reason<br>- Harder to debug or adapt |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ What a Strong Scaffold Should Include\n",
        "\n",
        "Design your scaffold as **modular blocks**, with:\n",
        "\n",
        "* 📌 *Section Headers*\n",
        "* 📄 *Docstrings or brief comments*\n",
        "* 🧱 *Minimal code that illustrates the structure*\n",
        "* 💡 *Optional: prompts or slots where an LLM can \"fill in the logic\"*\n",
        "\n",
        "Here’s an example **scaffold block** for tools:\n",
        "\n",
        "```python\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ TOOLS: Example Tool                                                          ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "def my_tool(ctx, some_input, _fs):\n",
        "    \"\"\"Describe what this tool does clearly and briefly.\"\"\"\n",
        "    # Use ctx.memory.get(...) if needed\n",
        "    # Use _fs.open, _fs.path, etc. if file operations are required\n",
        "    ...\n",
        "    return ok(message=\"Success\", result=...)\n",
        "```\n",
        "\n",
        "This is *much easier* for an LLM to reason over and replicate.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Bonus: Give a Summary “Schema” for Agent Design\n",
        "\n",
        "At the top of your scaffold, you can define the **agent layout** like this:\n",
        "\n",
        "```python\n",
        "\"\"\"\n",
        "AGENT TEMPLATE OVERVIEW\n",
        "\n",
        "Sections:\n",
        "1. Utilities (ok/err, RealFS, ScratchMemory)\n",
        "2. LLM Wrapper\n",
        "3. Context (ActionContext)\n",
        "4. Tools (create_plan, etc.)\n",
        "5. Tool Registry\n",
        "6. Execution Environment\n",
        "7. Setup + Config\n",
        "8. Scripted Agent Steps\n",
        "9. Run Agent\n",
        "10. (Optional) Pretty Printing or Logging\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "Then populate each section with the minimal viable code.\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Ideal Workflow for Teaching LLMs to Build Agents\n",
        "\n",
        "1. **Provide the scaffold with placeholders + examples**\n",
        "2. Give it a **concrete goal** (like \"extract tasks from meeting transcript\")\n",
        "3. Let it fill in the steps/tools\n",
        "4. Optionally, give it access to or summarize relevant tool interfaces\n",
        "5. Evaluate output for structure, completeness, and alignment with the scaffold\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 Final Recommendation\n",
        "\n",
        "Use your excellent, complete codebase (like Agent ZERO) as **a reference** for:\n",
        "\n",
        "* Best-practice examples\n",
        "* Error handling\n",
        "* How to do dependency injection\n",
        "* Progress logging\n",
        "\n",
        "**But use a scaffold** as the **primary input** when prompting LLMs to build agents. You'll get more reliable, generalized, and easier-to-debug agents that way.\n",
        "\n"
      ],
      "metadata": {
        "id": "qurRQ00PeDMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ✅ Scaffolded Template Version (With Best Practices & Comments)\n",
        "\n",
        "This is your **foundation** section: install dependencies, set up imports, and initialize core environment variables. The goal is **simplicity, portability, and modularity** — especially for Jupyter or Colab environments.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ LLM-Friendly Prompt Summary (Optional)\n",
        "\n",
        "To pair this scaffold with LLM prompting, you can define a high-level description like:\n",
        "\n",
        "```\n",
        "This is the base setup section for agent design. It:\n",
        "- Installs required libraries (only if notebook-based)\n",
        "- Loads environment variables for secure config\n",
        "- Initializes the OpenAI client\n",
        "- Defines standard success/failure envelope functions (used across tools)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Key Design Best Practices to Teach LLMs\n",
        "\n",
        "| Concept                     | Why It’s Used                                                          |\n",
        "| --------------------------- | ---------------------------------------------------------------------- |\n",
        "| `.env` loading              | Keeps API keys secure & separate from code                             |\n",
        "| `ok` / `err` envelope       | Ensures **uniform** communication across tools, environment, and agent |\n",
        "| Type-safe envelope          | Enables easier LLM reasoning and less ambiguous responses              |\n",
        "| Reusable scaffold structure | Makes the design easy to replicate and extend                          |\n"
      ],
      "metadata": {
        "id": "r0pOs4cDehl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ SETUP: Notebook Environment (Optional)                                       ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "# For Colab or Notebook use only. Use pip install if dependencies are not pre-installed.\n",
        "!pip install -q openai python-dotenv\n",
        "\n",
        "\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ IMPORTS                                                                      ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "# Standard Library\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import inspect\n",
        "import textwrap\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, Optional\n",
        "\n",
        "# External Libraries\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ OPENAI CLIENT SETUP                                                          ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "# Load secrets from .env — avoid hardcoding API keys!\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found. Please check your .env file.\")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ STANDARD RESULT ENVELOPE                                                     ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "# These functions define a common \"contract\" between tools and agent logic.\n",
        "\n",
        "def ok(**data):\n",
        "    \"\"\"\n",
        "    Return a successful result in standardized format.\n",
        "    This helps agents reason about output consistently.\n",
        "    \"\"\"\n",
        "    return {\"ok\": True, **data}\n",
        "\n",
        "def err(msg, hint=None, retryable=False, **extra):\n",
        "    \"\"\"\n",
        "    Return a failure result with optional hints and retryable flag.\n",
        "    Ensures consistent structure for error handling and debugging.\n",
        "    \"\"\"\n",
        "    out = {\"ok\": False, \"error\": msg, \"retryable\": retryable}\n",
        "    if hint:\n",
        "        out[\"hint\"] = hint\n",
        "    if extra:\n",
        "        out.update(extra)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "Mdf_HIB7eIGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a **compact but powerful abstraction**. It allows tools to use a **pluggable filesystem interface** — meaning tools can interact with files **without caring if it's local, in-memory, or mocked**.\n",
        "\n",
        "Let’s break it down and reformat it into a **best-practice scaffold** for LLM or team reuse:\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Purpose of This Block\n",
        "\n",
        "The `RealFS` adapter allows for **dependency injection** of filesystem logic. This makes your agent:\n",
        "\n",
        "* **Testable** (swap with in-memory or mock file system)\n",
        "* **Flexible** (swap with cloud storage if needed)\n",
        "* **Clean** (avoids direct `os.*` or `open()` calls in tool logic)\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Key Concepts to Emphasize in an LLM Prompt\n",
        "\n",
        "| Concept                       | Explanation                                                                                                          |\n",
        "| ----------------------------- | -------------------------------------------------------------------------------------------------------------------- |\n",
        "| **DI (Dependency Injection)** | The adapter is passed into tools via `ctx.deps`, giving tools indirect access to file operations                     |\n",
        "| **Pluggability**              | You can replace `RealFS` with an in-memory or cloud version for testing or other environments                        |\n",
        "| **Underscore convention**     | Naming injected tools like `_fs` helps the agent automatically wire dependencies using the `Environment` class logic |\n",
        "| **Isolation**                 | Keeps your business logic (tools) free from hardcoded `os` or `open()` calls                                         |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Example LLM Prompt Description\n",
        "\n",
        "```\n",
        "This adapter allows tools to interact with files in a consistent and testable way. Instead of hardcoding `os.path`, `os.makedirs`, or `open()`, they access these via `_fs`, which is injected into the tool by the Environment system.\n",
        "\n",
        "In production, this is `RealFS`. In tests, it can be mocked. This makes the tools modular and decoupled from specific IO implementations.\n",
        "```\n"
      ],
      "metadata": {
        "id": "BD97kUYwe8EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ FILESYSTEM ADAPTER (for underscore-DI: _fs)                                  ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "\n",
        "import builtins  # Ensure builtins.open is available (not overridden)\n",
        "\n",
        "class RealFS:\n",
        "    \"\"\"\n",
        "    A pluggable filesystem adapter.\n",
        "    Enables tools to work with files via dependency injection (_fs),\n",
        "    allowing flexibility for testing or alternate storage layers.\n",
        "    \"\"\"\n",
        "    path = os.path               # Standard path operations (e.g., join, exists)\n",
        "    makedirs = staticmethod(os.makedirs)  # Create directories\n",
        "    open = staticmethod(builtins.open)    # File open (read/write)\n"
      ],
      "metadata": {
        "id": "f9Hv2bOzefVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a foundational section, and it sets the stage for **agent autonomy, traceability, and flexibility**. Let's break it down and then reframe it into your **\"best-practice scaffold\"** version for reuse or prompting.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Purpose of This Block\n",
        "\n",
        "This section introduces:\n",
        "\n",
        "* **`ScratchMemory`**: A simple key-value store for agent state across steps.\n",
        "* **`ActionContext`**: The core carrier of agent state, dependencies, config, and LLM access.\n",
        "* **Progress tracking**: Centralized logging of each step’s status (success, failure, in progress).\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Key Design Lessons to Focus On\n",
        "\n",
        "| Feature            | Why It Matters                                                                                           |\n",
        "| ------------------ | -------------------------------------------------------------------------------------------------------- |\n",
        "| `ScratchMemory`    | Keeps tool outputs lightweight and self-contained (no global state or complex storage)                   |\n",
        "| `ActionContext`    | A central hub for memory, configuration, injected dependencies, and progress tracking                    |\n",
        "| `track_progress()` | Enables visibility, debugging, and safe retries                                                          |\n",
        "| `deps` bag         | Allows for easy injection of services like `_fs`, `_clock`, etc. via underscore-based parameter matching |\n",
        "| ✅ Decoupled        | No step depends on a global or hidden state — everything is passed or injected cleanly                   |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Example Prompt Fragment for LLM\n",
        "\n",
        "> Each agent step has access to a shared `ActionContext`, which includes:\n",
        ">\n",
        "> * a memory store for reading/writing key-value pairs across steps\n",
        "> * a config dictionary for runtime settings (e.g. folders, model names)\n",
        "> * injected dependencies like `_fs` (filesystem) or `_clock`\n",
        "> * progress tracking for debugging, retries, and reporting\n",
        "\n"
      ],
      "metadata": {
        "id": "cLr3aJfVfPBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ MEMORY & CONTEXT                                                             ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "\n",
        "import time\n",
        "\n",
        "class ScratchMemory:\n",
        "    \"\"\"\n",
        "    Minimal in-memory key/value store for agent state.\n",
        "    Enables steps to share information and persist outputs.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "\n",
        "    def get(self, key, default=None):\n",
        "        return self.store.get(key, default)\n",
        "\n",
        "    def set(self, key, value):\n",
        "        self.store[key] = value\n",
        "\n",
        "# ── Valid progress states for tracking tool execution ──────────────────────────\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "\n",
        "class ActionContext:\n",
        "    \"\"\"\n",
        "    Agent context object — shared across all tools and steps.\n",
        "\n",
        "    Attributes:\n",
        "    - memory:   scratchpad state (shared step-to-step)\n",
        "    - llm:      LLM wrapper for completions\n",
        "    - config:   runtime config like folder paths or model names\n",
        "    - deps:     injectable dependencies (_fs, _clock, etc.)\n",
        "\n",
        "    Also handles centralized progress logging and status checks.\n",
        "    \"\"\"\n",
        "    def __init__(self, memory, llm, config=None, deps=None):\n",
        "        self.memory = memory\n",
        "        self.llm = llm\n",
        "        self.config = config or {}\n",
        "        self.deps = deps or {}\n",
        "\n",
        "    # ── Progress tracking: step lifecycle states ───────────────────────────────\n",
        "    def track_progress(self, step, status, note=\"\"):\n",
        "        if status not in VALID_STATUSES:\n",
        "            raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "        log = self.memory.get(\"progress_log\", [])\n",
        "        log.append({\n",
        "            \"step\": step,\n",
        "            \"status\": status,\n",
        "            \"note\": note,\n",
        "            \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        })\n",
        "        self.memory.set(\"progress_log\", log)\n",
        "\n",
        "    def print_progress(self):\n",
        "        log = self.memory.get(\"progress_log\", [])\n",
        "        print(\"\\n📊 Progress Log:\")\n",
        "        for e in log:\n",
        "            t = f\" ({e.get('time')})\" if e.get(\"time\") else \"\"\n",
        "            note = f\" — {e['note']}\" if e['note'] else \"\"\n",
        "            print(f\"- [{e['status']}] {e['step']}{t}{note}\")\n",
        "\n",
        "    def last_completed_step(self):\n",
        "        log = self.memory.get(\"progress_log\", [])\n",
        "        for e in reversed(log):\n",
        "            if e.get(\"status\") == \"completed\":\n",
        "                return e.get(\"step\")\n",
        "        return None\n",
        "\n",
        "    def first_error(self):\n",
        "        log = self.memory.get(\"progress_log\", [])\n",
        "        for e in log:\n",
        "            if e.get(\"status\") == \"error\":\n",
        "                return e\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "A42TkWh-efTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is compact but **strategically very important**, because it abstracts how the LLM is used. Here's how to break it down and reframe it for your **ideal agent scaffold** or a reusable LLM agent pattern.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Purpose of This Block\n",
        "\n",
        "The `OpenAILLM` wrapper serves to:\n",
        "\n",
        "* Abstract the direct usage of the OpenAI client.\n",
        "* Simplify LLM usage for tool writers (no need to know the API).\n",
        "* Enable future extensibility (e.g., prompt formatting, multi-message chat, tool-calling, logging, retries).\n",
        "\n",
        "\n",
        "\n",
        "## 🎯 Key Concepts to Emphasize\n",
        "\n",
        "| Feature              | Why It Matters                                                                                   |\n",
        "| -------------------- | ------------------------------------------------------------------------------------------------ |\n",
        "| **Encapsulation**    | All OpenAI-specific behavior is confined to this one class. Changes are isolated here.           |\n",
        "| **Simplified API**   | Tools can just call `ctx.llm.complete(prompt)` without worrying about models or message formats. |\n",
        "| **Default handling** | Allows global settings (like temperature) to be overridden per-call.                             |\n",
        "| **Extensibility**    | You could later support system messages, retries, tool-calling, streaming, etc. in one place.    |\n",
        "\n",
        "---\n",
        "\n",
        "## 🧱 Scaffold Prompt Fragment (for LLM-based generation)\n",
        "\n",
        "> Use an `LLM` wrapper class to abstract LLM calls behind a `.complete(prompt)` method. This ensures tools don’t depend on OpenAI-specific APIs and allows consistent behavior (e.g., default temperature, centralized error handling, logging, etc.).\n"
      ],
      "metadata": {
        "id": "6PdDCFiHfgtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ LLM WRAPPER                                                                 ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "\n",
        "class OpenAILLM:\n",
        "    \"\"\"\n",
        "    Wrapper for OpenAI chat models.\n",
        "    Provides a simplified `.complete(prompt)` interface for agent tools.\n",
        "    \"\"\"\n",
        "    def __init__(self, client, model=\"gpt-4o-mini\", temperature=0.2):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def complete(self, prompt: str, **kwargs) -> str:\n",
        "        \"\"\"\n",
        "        Send a simple prompt to the model and return the reply text.\n",
        "        Optional override: temperature, etc.\n",
        "        \"\"\"\n",
        "        temp = kwargs.get(\"temperature\", self.temperature)\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=temp,\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"LLM call failed: {type(e).__name__}: {e}\")\n"
      ],
      "metadata": {
        "id": "-Yym0xxIefQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a **core tool** in the agent lifecycle — it turns an abstract goal into an actionable plan. It’s simple, yet rich with smart design choices.\n",
        "\n",
        "Let’s walk through how to **optimize, document, and scaffold** this tool for your reusable agent pattern.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Purpose of `create_plan`\n",
        "\n",
        "* Converts a **goal** into a **step-by-step plan** using an LLM.\n",
        "* Uses regex + normalization to **parse unstructured LLM output** robustly.\n",
        "* Saves result in `ctx.memory[\"plan\"]` for downstream use.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Key Concepts to Highlight\n",
        "\n",
        "| Feature                | Why It's Important                                   |\n",
        "| ---------------------- | ---------------------------------------------------- |\n",
        "| **LLM planning**       | Decouples high-level intent from low-level execution |\n",
        "| **Regex parsing**      | Handles varied LLM output formats gracefully         |\n",
        "| **Step deduplication** | Avoids clutter from repeated steps                   |\n",
        "| **Memory injection**   | Plan becomes reusable state for agent or UI          |\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 Suggested Prompt Fragment (for LLM templates)\n",
        "\n",
        "> Given a `goal`, use the LLM to generate a **numbered list of concrete steps**. Prefer numbered format, but fallback to bullets. Parse and clean the output. Save in `ctx.memory[\"plan\"]`.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔄 Optional Enhancements\n",
        "\n",
        "* **Few-shot prompt** (to guide format).\n",
        "* **Support for hierarchical plans** (e.g. subtasks).\n",
        "* **Save raw LLM output** alongside parsed version for debugging.\n",
        "* **Store step descriptions + metadata** (like estimated effort or type).\n"
      ],
      "metadata": {
        "id": "oJchGX6LfuUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ TOOL: create_plan                                                           ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "def create_plan(ctx):\n",
        "    \"\"\"\n",
        "    Converts a high-level goal into a step-by-step plan using the LLM.\n",
        "    Saves the plan in ctx.memory['plan'] for future steps.\n",
        "    \"\"\"\n",
        "    goal = ctx.memory.get(\"goal\")\n",
        "    if not goal:\n",
        "        return err(\"No goal provided (memory key 'goal' missing).\",\n",
        "                   hint=\"Set ctx.memory['goal'] before calling create_plan\")\n",
        "\n",
        "    prompt = f\"\"\"You are an expert task planner.\n",
        "\n",
        "Given the goal below, break it into a short numbered list of clear, concrete steps.\n",
        "\n",
        "Goal: {goal}\n",
        "\n",
        "Respond ONLY with a numbered list. One step per line. No extra explanation.\"\"\"\n",
        "\n",
        "    raw = ctx.llm.complete(prompt).strip()\n",
        "\n",
        "    # Prefer numbered format (e.g. 1. ..., 2) ...)\n",
        "    numbered = re.findall(r'^\\s*(?:\\d+[\\).\\s-]+)\\s*(.+)$', raw, flags=re.M)\n",
        "\n",
        "    if numbered:\n",
        "        steps = numbered\n",
        "    else:\n",
        "        # Fallback: bullets (-, *, •)\n",
        "        bullets = re.findall(r'^\\s*[-*•]\\s+(.+)$', raw, flags=re.M)\n",
        "        steps = bullets if bullets else [ln.strip() for ln in raw.splitlines() if ln.strip()]\n",
        "\n",
        "    # Normalize and deduplicate steps\n",
        "    clean_steps = []\n",
        "    seen = set()\n",
        "    for step in steps:\n",
        "        norm = re.sub(r'\\s+', ' ', step).strip(' .')\n",
        "        if norm and norm.lower() not in seen:\n",
        "            seen.add(norm.lower())\n",
        "            clean_steps.append(norm)\n",
        "\n",
        "    if not clean_steps:\n",
        "        return err(\"Planner returned no usable steps.\",\n",
        "                   hint=\"Try refining the goal or loosening parsing rules\")\n",
        "\n",
        "    ctx.memory.set(\"plan\", clean_steps)\n",
        "    return ok(message=\"Plan created from goal.\", steps=clean_steps)\n",
        "\n",
        "def read_txt_file(ctx, file_name):\n",
        "    \"\"\"\n",
        "    Reads a .txt file from the configured input folder.\n",
        "    Stores raw text and filename in memory.\n",
        "    \"\"\"\n",
        "    base = os.path.abspath(ctx.config.get(\"input_folder\", \"\"))\n",
        "    path = os.path.abspath(os.path.join(base, file_name))\n",
        "\n",
        "    if not base or not path.startswith(base + os.sep):\n",
        "        return err(\"Path traversal blocked.\", retryable=False)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        return err(f\"File not found: {path}\",\n",
        "                   hint=\"Call list_txt_files to see available files\",\n",
        "                   retryable=True)\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    ctx.memory.set(\"file_name\", file_name)\n",
        "    ctx.memory.set(\"raw_text\", text)\n",
        "    return ok(message=\"File read successfully.\", length=len(text))\n",
        "\n",
        "def list_txt_files(ctx):\n",
        "    \"\"\"\n",
        "    Lists all .txt files in the input folder.\n",
        "    Useful for UI or just-in-time user hints.\n",
        "    \"\"\"\n",
        "    base = ctx.config.get(\"input_folder\")\n",
        "    if not base:\n",
        "        return err(\"No input_folder in config.\", hint=\"Set ctx.config['input_folder']\")\n",
        "    if not os.path.isdir(base):\n",
        "        return err(f\"Input folder not found: {base}\", retryable=False)\n",
        "\n",
        "    files = sorted(f for f in os.listdir(base) if f.endswith(\".txt\"))\n",
        "    ctx.memory.set(\"available_txt_files\", files)\n",
        "    return ok(message=f\"Found {len(files)} .txt files.\", files=files, count=len(files))\n",
        "\n",
        "def generate_summary_prompt(ctx, max_len=None):\n",
        "    \"\"\"\n",
        "    Builds a prompt to summarize the raw input text.\n",
        "    Truncates if over limit, stores prompt + stats in memory.\n",
        "    \"\"\"\n",
        "    text = ctx.memory.get(\"raw_text\")\n",
        "    if not text:\n",
        "        return err(\"No raw text found in memory.\",\n",
        "                   hint=\"Run read_txt_file before generate_summary_prompt\")\n",
        "\n",
        "    if max_len is None:\n",
        "        max_len = ctx.config.get(\"summary_max_chars\", 2000)\n",
        "\n",
        "    short_text = text[:max_len]\n",
        "    truncated = len(text) > max_len\n",
        "\n",
        "    ctx.memory.set(\"was_truncated\", truncated)\n",
        "    ctx.memory.set(\"source_length\", len(text))\n",
        "    ctx.memory.set(\"used_length\", len(short_text))\n",
        "\n",
        "    prompt = f\"\"\"You are an expert technical writer.\n",
        "\n",
        "Summarize the following content into a set of clear, concise bullet points:\n",
        "\\\"\\\"\\\"{short_text}\\\"\\\"\\\"\n",
        "\n",
        "Summary:\"\"\"\n",
        "    ctx.memory.set(\"summary_prompt\", prompt)\n",
        "\n",
        "    return ok(message=\"Summary prompt created.\",\n",
        "              truncated=truncated, used=len(short_text), total=len(text),\n",
        "              prompt_preview=prompt[:600])\n",
        "\n",
        "def summarize(ctx):\n",
        "    \"\"\"\n",
        "    Calls LLM with the prompt generated in memory to produce the summary.\n",
        "    \"\"\"\n",
        "    prompt = ctx.memory.get(\"summary_prompt\")\n",
        "    if not prompt:\n",
        "        return err(\"No summary prompt found in memory.\",\n",
        "                   hint=\"Run generate_summary_prompt before summarize\")\n",
        "\n",
        "    response = ctx.llm.complete(prompt)\n",
        "    ctx.memory.set(\"summary\", response)\n",
        "\n",
        "    return ok(message=\"Summary completed.\", summary_preview=response[:1000])\n",
        "\n",
        "def save_summary(ctx, out_name=None, _fs=os):\n",
        "    \"\"\"\n",
        "    Saves the summary from memory to a text file in output_folder.\n",
        "    Uses DI to enable testing or alt filesystems via _fs.\n",
        "    \"\"\"\n",
        "    summary = ctx.memory.get(\"summary\")\n",
        "    if not summary:\n",
        "        return err(\"No summary in memory.\",\n",
        "                   hint=\"Run summarize before save_summary\")\n",
        "\n",
        "    out_dir = ctx.config.get(\"output_folder\")\n",
        "    if not out_dir:\n",
        "        return err(\"No output_folder in config.\",\n",
        "                   hint=\"Set ctx.config['output_folder']\")\n",
        "\n",
        "    _fs.makedirs(out_dir, exist_ok=True)\n",
        "    src = ctx.memory.get(\"file_name\", \"summary\")\n",
        "    root, _ = os.path.splitext(os.path.basename(src))\n",
        "    base = out_name or f\"{root}_summary.txt\"\n",
        "    path = _fs.path.join(out_dir, base)\n",
        "\n",
        "    with _fs.open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    ctx.memory.set(\"summary_path\", path)\n",
        "    return ok(message=\"Summary saved.\", path=path)\n"
      ],
      "metadata": {
        "id": "ws_OGA4yefFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the **Tool Registry** is a lightweight but powerful layer for managing your tools systematically. Here's how to present this block as part of your reusable agent-building scaffold.\n",
        "\n",
        "---\n",
        "\n",
        "# 🧰 **TOOL REGISTRY — TYPES & REGISTRATION**\n",
        "\n",
        "### ✅ Purpose:\n",
        "\n",
        "* Collect all tools in one place.\n",
        "* Enable tools to be accessed **by name**.\n",
        "* Support metadata for schema validation and documentation.\n",
        "* Serve as the **single source of truth** for what's available to the agent.\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 `ToolDef` — Tool Metadata Definition\n",
        "\n",
        "\n",
        "### Why `@dataclass`?\n",
        "\n",
        "* Cleaner syntax than manual `__init__`\n",
        "* Automatically gives you `__repr__`, `__eq__`, etc.\n",
        "* Keeps tool declarations short and readable\n",
        "\n",
        "\n",
        "\n",
        "### What to Focus On:\n",
        "\n",
        "* `.register(...)` accepts `ToolDef` objects, allowing structured metadata.\n",
        "* `.get(...)` allows safe lookup and guards against typos/missing tools.\n",
        "* You can use `.list()` to inspect what’s registered — useful for agents that self-reflect or auto-plan.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Why This Abstraction Matters\n",
        "\n",
        "Without a registry:\n",
        "\n",
        "* You’d hardcode tool access (e.g., `tools[\"summarize\"](...)`)\n",
        "* You’d need to manually manage function-to-name mapping\n",
        "* You’d lose out on schema validation and doc introspection\n",
        "\n",
        "With it:\n",
        "\n",
        "* Tools are modular and discoverable\n",
        "* Execution is name-driven (great for LLMs!)\n",
        "* You can enforce input validation automatically in the `Environment`\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Best Practice\n",
        "\n",
        "At the end of your tool definitions, register them like this:\n",
        "\n",
        "```python\n",
        "registry = ToolRegistry()\n",
        "\n",
        "registry.register(ToolDef(name=\"read_txt_file\", func=read_txt_file, description=\"Reads a .txt file.\"))\n",
        "registry.register(ToolDef(name=\"summarize\", func=summarize, description=\"Summarizes a prompt in memory.\"))\n",
        "# ...and so on\n",
        "```\n",
        "\n",
        "You can also use decorators later to register tools more concisely (if desired), but this explicit version is ideal for scaffold clarity.\n",
        "\n"
      ],
      "metadata": {
        "id": "GtZUz-MUgVlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ToolDef:\n",
        "    name: str                  # Unique name for calling the tool\n",
        "    func: Callable             # Actual function to execute\n",
        "    description: str = \"\"      # Optional human-readable help\n",
        "    schema: dict | None = None # Optional JSON Schema for validation\n",
        "    returns: dict | None = None# Optional return schema for metadata\n",
        "\n",
        "class ToolRegistry:\n",
        "    def __init__(self):\n",
        "        self._tools = {}\n",
        "\n",
        "    def register(self, tool: ToolDef):\n",
        "        self._tools[tool.name] = tool\n",
        "\n",
        "    def get(self, name: str) -> ToolDef:\n",
        "        if name not in self._tools:\n",
        "            raise KeyError(f\"Unknown tool: {name}\")\n",
        "        return self._tools[name]\n",
        "\n",
        "    def list(self):\n",
        "        return list(self._tools.keys())\n"
      ],
      "metadata": {
        "id": "MdKziudTee1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section shows how to **register each tool** into the `ToolRegistry` using `ToolDef` entries. This is the **key interface** between your tools and the runtime environment.\n",
        "\n",
        "Here's how to document and present this block in a reusable and readable template:\n",
        "\n",
        "---\n",
        "\n",
        "# 🛠️ **BUILD REGISTRY — Registering All Tools**\n",
        "\n",
        "This section makes your tools **discoverable** and **runnable** by name, with optional schema validation and output structure hints.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔧 Registry Setup\n",
        "\n",
        "```python\n",
        "registry = ToolRegistry()\n",
        "```\n",
        "\n",
        "This initializes a fresh registry object that you'll populate with tools.\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 Tool Registration Pattern\n",
        "\n",
        "Each tool is registered via:\n",
        "\n",
        "```python\n",
        "registry.register(ToolDef(\n",
        "    name,                  # Unique string name\n",
        "    function,              # Python callable\n",
        "    description,           # Optional human description\n",
        "    schema=...,            # JSON-like input validation (optional)\n",
        "    returns=...            # Output format metadata (optional)\n",
        "))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Input Schema: `schema=...`\n",
        "\n",
        "This uses a simplified JSON Schema format to:\n",
        "\n",
        "* Enforce required fields\n",
        "* Check types (`string`, `integer`, etc.)\n",
        "* (Optional) Set bounds, defaults, or documentation\n",
        "\n",
        "If your tool accepts no kwargs, just pass:\n",
        "\n",
        "```python\n",
        "schema={ \"type\": \"object\", \"properties\": {}, \"required\": [] }\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📤 Output Metadata: `returns=...`\n",
        "\n",
        "Optional, but useful if:\n",
        "\n",
        "* You want downstream tools/agents to reason about outputs\n",
        "* You're building tooling/UIs on top of the agent\n",
        "* You want extra validation or documentation\n",
        "\n",
        "---\n",
        "\n",
        "## 🔄 Best Practices\n",
        "\n",
        "* Register tools right after defining them, or group in this section\n",
        "* Always include `description` — helps with reflection / agent introspection\n",
        "* Use `schema` for safe runtime execution and better debugging\n",
        "* Output `returns` are optional, but help with interface clarity\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OgArnMGvgoYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registry.register(ToolDef(\n",
        "    \"create_plan\",\n",
        "    create_plan,\n",
        "    \"Create a plan from goal\",\n",
        "    schema={ \"type\": \"object\", \"properties\": {}, \"required\": [] },\n",
        "    returns={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"message\": { \"type\": \"string\" },\n",
        "            \"steps\":   { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n",
        "        },\n",
        "        \"required\": [\"message\", \"steps\"]\n",
        "    }\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"read_txt_file\", read_txt_file, \"Read a .txt file from input_folder\",\n",
        "  schema={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "    \"required\": [\"file_name\"]\n",
        "  },\n",
        "  returns={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"message\": {\"type\": \"string\"}, \"length\": {\"type\": \"integer\"}},\n",
        "    \"required\": [\"message\"]\n",
        "  },\n",
        "))\n"
      ],
      "metadata": {
        "id": "U9e2zfGIeIDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is one of the most *pivotal* sections of your agent framework. It defines how tools are validated, invoked, and monitored.\n",
        "\n",
        "Here’s how to structure it for clarity and reusability in your \"ideal agent\" scaffold:\n",
        "\n",
        "---\n",
        "\n",
        "# ⚙️ ENVIRONMENT: Validation, Dependency Injection, and Execution\n",
        "\n",
        "This is the **runtime engine** that:\n",
        "\n",
        "* Validates inputs before calling tools\n",
        "* Injects required dependencies\n",
        "* Calls the tool functions safely\n",
        "* Logs status at every step\n",
        "* Normalizes results for agent consumption\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ `_validate(schema, kwargs)`\n",
        "\n",
        "```python\n",
        "def _validate(schema, kwargs):\n",
        "    ...\n",
        "```\n",
        "\n",
        "A lightweight JSON-schema-style validator for tool arguments.\n",
        "\n",
        "### ✨ What it does:\n",
        "\n",
        "* Ensures all `\"required\"` keys are present\n",
        "* Checks `type` (string, integer, number, boolean)\n",
        "* Skips validation if `schema` is None\n",
        "\n",
        "Use this if your tools need some basic input validation without full JSON Schema overhead.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 `Environment` Class\n",
        "\n",
        "```python\n",
        "class Environment:\n",
        "    def __init__(self, ctx: ActionContext, registry: ToolRegistry):\n",
        "        ...\n",
        "```\n",
        "\n",
        "The Environment encapsulates **tool orchestration logic**, working like a middleware + DI system.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔁 `run(tool_name, **kwargs)` — The Heart of It All\n",
        "\n",
        "This is the method you call to run a tool by name. Here’s what happens:\n",
        "\n",
        "---\n",
        "\n",
        "### 1️⃣ **Schema Validation**\n",
        "\n",
        "```python\n",
        "v_err = _validate(tool.schema, kwargs)\n",
        "```\n",
        "\n",
        "Rejects the call early if input is invalid — avoids wasted LLM or I/O calls.\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ **Dependency Injection (DI)**\n",
        "\n",
        "```python\n",
        "for pname, param in sig.parameters.items():\n",
        "    ...\n",
        "```\n",
        "\n",
        "Auto-injects:\n",
        "\n",
        "* `ctx` if requested\n",
        "* Any param like `_fs`, `_clock`, `_logger` from `ctx.deps`\n",
        "* Uses `kwargs` for the rest\n",
        "\n",
        "🔧 Tools just declare what they need — the environment wires them up.\n",
        "\n",
        "---\n",
        "\n",
        "### 3️⃣ **Tool Execution + Error Handling**\n",
        "\n",
        "```python\n",
        "try:\n",
        "    result = fn(**call_args)\n",
        "except Exception as e:\n",
        "    ...\n",
        "```\n",
        "\n",
        "* Errors are normalized into `err(...)` envelopes\n",
        "* Agent won’t crash — can inspect and recover\n",
        "\n",
        "---\n",
        "\n",
        "### 4️⃣ **Result Normalization**\n",
        "\n",
        "```python\n",
        "if isinstance(result, dict):\n",
        "    ...\n",
        "```\n",
        "\n",
        "Ensures the tool output is always:\n",
        "\n",
        "```python\n",
        "{ \"ok\": True/False, ... }\n",
        "```\n",
        "\n",
        "That means:\n",
        "\n",
        "* Errors are standardized\n",
        "* Successes are trackable\n",
        "* Agents can reason about output consistently\n",
        "\n",
        "---\n",
        "\n",
        "### 🧠 Why This Block Is Crucial\n",
        "\n",
        "* It's where tools become “callable-by-name” services\n",
        "* Shields tools from bad inputs or missing deps\n",
        "* Ensures clean logs and error surfaces\n",
        "* Makes building, debugging, and evolving tools a lot easier\n",
        "\n",
        "---\n",
        "\n",
        "### 📦 Example Use:\n",
        "\n",
        "```python\n",
        "env = Environment(ctx, registry)\n",
        "result = env.run(\"read_txt_file\", file_name=\"README.md\")\n",
        "```\n",
        "\n",
        "Just like calling an API, but with validation, logging, and DI done for you.\n",
        "\n"
      ],
      "metadata": {
        "id": "lmT-q3eeiAZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ ENVIRONMENT — Validation, DI, Execution (Generic Scaffold)                   ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "import inspect\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "# --- Minimal JSON-schema-ish validator for tool kwargs -------------------------\n",
        "_JSON_TYPES = {\n",
        "    \"string\": str,\n",
        "    \"integer\": int,\n",
        "    \"number\": (int, float),\n",
        "    \"boolean\": bool,\n",
        "    # extend as needed: \"array\": list, \"object\": dict ...\n",
        "}\n",
        "\n",
        "def validate_args(schema: Optional[Dict[str, Any]], kwargs: Dict[str, Any]) -> Optional[str]:\n",
        "    \"\"\"Return None if valid, else an error message.\"\"\"\n",
        "    if not schema:\n",
        "        return None\n",
        "    # required keys\n",
        "    missing = [k for k in schema.get(\"required\", []) if k not in kwargs]\n",
        "    if missing:\n",
        "        return f\"Missing required: {missing}\"\n",
        "    # type checks\n",
        "    props = schema.get(\"properties\") or {}\n",
        "    for key, spec in props.items():\n",
        "        if key in kwargs and \"type\" in spec:\n",
        "            py_t = _JSON_TYPES.get(spec[\"type\"])\n",
        "            if py_t and not isinstance(kwargs[key], py_t):\n",
        "                return f\"Bad type for '{key}': expected {spec['type']}\"\n",
        "    return None\n",
        "\n",
        "\n",
        "class Environment:\n",
        "    \"\"\"\n",
        "    Runs tools by name with:\n",
        "      - input validation (schema)\n",
        "      - dependency injection (ctx + underscore deps, e.g., _fs -> ctx.deps['fs'])\n",
        "      - centralized progress logging via ctx.track_progress(...)\n",
        "      - standardized results (ensures {'ok': True/False, ...})\n",
        "    \"\"\"\n",
        "    def __init__(self, ctx, registry):\n",
        "        self.ctx = ctx\n",
        "        self.registry = registry\n",
        "\n",
        "    def run(self, tool_name: str, **kwargs) -> Dict[str, Any]:\n",
        "        # Lookup\n",
        "        tool = self.registry.get(tool_name)\n",
        "        fn = tool.func\n",
        "        sig = inspect.signature(fn)\n",
        "\n",
        "        # 1) Validate input BEFORE execution\n",
        "        v_err = validate_args(tool.schema, kwargs)\n",
        "        if v_err:\n",
        "            self._log(tool.name, \"error\", v_err)\n",
        "            return {\"ok\": False, \"error\": v_err, \"retryable\": True}\n",
        "\n",
        "        # 2) Build call args with auto-DI\n",
        "        call = {}\n",
        "        for pname, param in sig.parameters.items():\n",
        "            if pname == \"ctx\":\n",
        "                call[pname] = self.ctx\n",
        "            elif pname.startswith(\"_\"):  # underscore dep → ctx.deps['name']\n",
        "                dep_name = pname[1:]\n",
        "                if dep_name not in self.ctx.deps:\n",
        "                    msg = f\"Missing dep '{dep_name}' for tool '{tool_name}'\"\n",
        "                    self._log(tool.name, \"error\", msg)\n",
        "                    return {\"ok\": False, \"error\": msg}\n",
        "                call[pname] = self.ctx.deps[dep_name]\n",
        "            else:\n",
        "                if pname in kwargs:\n",
        "                    call[pname] = kwargs[pname]\n",
        "                elif param.default is not inspect._empty:\n",
        "                    # optional arg with default → let function use its default\n",
        "                    pass\n",
        "                else:\n",
        "                    msg = f\"Missing required arg '{pname}' for tool '{tool_name}'\"\n",
        "                    self._log(tool.name, \"error\", msg)\n",
        "                    return {\"ok\": False, \"error\": msg, \"retryable\": True}\n",
        "\n",
        "        # 3) Execute with logging + exception capture\n",
        "        self._log(tool.name, \"started\", note=str(kwargs)[:180])\n",
        "        try:\n",
        "            result = fn(**call)\n",
        "        except Exception as e:\n",
        "            msg = f\"{type(e).__name__}: {e}\"\n",
        "            self._log(tool.name, \"error\", msg)\n",
        "            return {\"ok\": False, \"error\": msg}\n",
        "\n",
        "        # 4) Normalize result shape + final log\n",
        "        if isinstance(result, dict):\n",
        "            if result.get(\"ok\") is False:\n",
        "                # tool already returned an error envelope\n",
        "                self._log(tool.name, \"error\", note=str(result.get(\"error\", \"\"))[:180])\n",
        "                return result\n",
        "            if \"ok\" not in result and \"error\" in result:\n",
        "                # back-compat for dicts that signal error without ok flag\n",
        "                self._log(tool.name, \"error\", note=str(result[\"error\"])[:180])\n",
        "                return {\"ok\": False, **result}\n",
        "            # success path\n",
        "            out = result if \"ok\" in result else {\"ok\": True, **result}\n",
        "            self._log(tool.name, \"completed\", note=str(out.get(\"message\", \"\"))[:180])\n",
        "            return out\n",
        "\n",
        "        # Non-dict success: wrap it\n",
        "        self._log(tool.name, \"completed\")\n",
        "        return {\"ok\": True, \"result\": result}\n",
        "\n",
        "    # --- helper: centralized progress logging -----------------------------------\n",
        "    def _log(self, step: str, status: str, note: str = \"\") -> None:\n",
        "        # If ctx has track_progress, use it; otherwise no-op\n",
        "        logger = getattr(self.ctx, \"track_progress\", None)\n",
        "        if callable(logger):\n",
        "            logger(step, status, note)\n"
      ],
      "metadata": {
        "id": "CUCLWrbdeIBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ SCRIPTED AGENT — Fixed Pipeline Runner (Generic Scaffold)                    ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "from typing import Iterable, Tuple, Dict, Any, Optional\n",
        "\n",
        "class ScriptedAgent:\n",
        "    \"\"\"\n",
        "    Executes a predetermined sequence of (tool_name, kwargs) steps\n",
        "    using the provided Environment.\n",
        "    \"\"\"\n",
        "    def __init__(self, env, steps: Iterable[Tuple[str, Dict[str, Any]]]):\n",
        "        self.env = env\n",
        "        self.steps = list(steps)\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        max_calls: Optional[int] = None,\n",
        "        stop_on_error: bool = True,\n",
        "    ) -> Dict[str, Any]:\n",
        "        calls = 0\n",
        "        for name, kwargs in self.steps:\n",
        "            if max_calls is not None and calls >= max_calls:\n",
        "                return {\"final\": f\"stopped: max_calls={max_calls}\"}\n",
        "\n",
        "            result = self.env.run(name, **(kwargs or {}))\n",
        "            calls += 1\n",
        "\n",
        "            # Optional: attach last_result to context for inspection\n",
        "            if hasattr(self.env, \"ctx\"):\n",
        "                self.env.ctx.memory.set(\"last_result\", result)\n",
        "\n",
        "            if stop_on_error and isinstance(result, dict) and result.get(\"ok\") is False:\n",
        "                out = {\"final\": f\"stopped at {name}: {result.get('error', 'unknown error')}\"}\n",
        "                if \"hint\" in result:  # surface recovery tips\n",
        "                    out[\"hint\"] = result[\"hint\"]\n",
        "                return out\n",
        "\n",
        "        return {\"final\": \"done\"}\n",
        "\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ SETUP & CONFIG                                                               ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "\n",
        "# Memory: simple scratchpad shared across steps\n",
        "memory = ScratchMemory()\n",
        "memory.set(\"goal\", \"Summarize the content of a text file.\")  # ← customize per run\n",
        "\n",
        "# Runtime configuration knobs\n",
        "config = {\n",
        "    \"input_folder\": \"/content/files\",     # where input .txt files live\n",
        "    \"output_folder\": \"/content/output\",   # where outputs are written\n",
        "    # \"summary_max_chars\": 2400,          # optional truncation limit\n",
        "    # \"model\": \"gpt-4o-mini\",\n",
        "    # \"temperature\": 0.2,\n",
        "}\n",
        "\n",
        "# LLM wrapper: single source of truth for model + defaults\n",
        "llm = OpenAILLM(\n",
        "    client=client,\n",
        "    model=config.get(\"model\", \"gpt-4o-mini\"),\n",
        "    temperature=config.get(\"temperature\", 0.2),\n",
        ")\n",
        "\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ CONTEXT & ENVIRONMENT                                                        ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "# Create context with DI bag pre-populated (fs adapter, clock if you want later)\n",
        "ctx = ActionContext(\n",
        "    memory=memory,\n",
        "    llm=llm,\n",
        "    config=config,\n",
        "    deps={\"fs\": RealFS}  # add more: {\"fs\": RealFS, \"clock\": time, \"uid\": uuid}\n",
        ")\n",
        "\n",
        "# Guardrails: ensure folders exist\n",
        "os.makedirs(ctx.config[\"input_folder\"], exist_ok=True)\n",
        "os.makedirs(ctx.config[\"output_folder\"], exist_ok=True)\n",
        "ctx.track_progress(\"setup\", \"completed\", \"goal + config injected\")\n",
        "\n",
        "# Build runtime (validation + underscore-DI + centralized logging)\n",
        "env = Environment(ctx, registry)\n",
        "\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ AGENT STEPS (SCRIPTED PIPELINE)                                              ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "file_name = \"004_AGENT_Tools.txt\"  # ← customize per run\n",
        "steps = [\n",
        "    (\"create_plan\", {}),\n",
        "    (\"read_txt_file\", {\"file_name\": file_name}),\n",
        "    (\"generate_summary_prompt\", {}),  # or {\"max_len\": 2400}\n",
        "    (\"summarize\", {}),\n",
        "    (\"save_summary\", {}),\n",
        "]\n",
        "\n",
        "# ╔══════════════════════════════════════════════════════════════════════════════╗\n",
        "# ║ RUN AGENT                                                                    ║\n",
        "# ╚══════════════════════════════════════════════════════════════════════════════╝\n",
        "agent = ScriptedAgent(env, steps)\n",
        "final = agent.run(max_calls=10)  # guard against runaway loops\n",
        "print(\"Agent result:\", final.get(\"final\", \"<no final>\"))\n",
        "if \"hint\" in final:\n",
        "    print(\"💡 Hint:\", final[\"hint\"])\n"
      ],
      "metadata": {
        "id": "R9o4dakseH-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s turn your intent into a clear **definition of done**, a **review checklist**, and a **plan** for the doc so we can objectively say “yup, this hits the mark.”\n",
        "\n",
        "---\n",
        "\n",
        "# 🎯 Success Criteria (Definition of Done)\n",
        "\n",
        "## 1) Outcomes the scaffold must enable\n",
        "\n",
        "* **Reusability:** New agents can be created by swapping goals/tools without refactoring core layers.\n",
        "* **LLM-legibility:** An LLM can read the doc and produce a working agent that follows the same patterns.\n",
        "* **Safety & reliability:** Inputs validated, errors standardized, no path traversal, guardrails in place.\n",
        "* **Observability:** Progress logging and inspectable state (memory/outputs).\n",
        "* **Testability:** Core pieces (tools, env, llm wrapper) are easy to unit test with fakes/mocks.\n",
        "* **Pluggability:** Filesystem + other deps are injected (underscore-DI) and swappable.\n",
        "* **Minimalism:** No vendor lock-in beyond a thin LLM wrapper; simple default memory.\n",
        "\n",
        "## 2) Measurable acceptance tests\n",
        "\n",
        "* **Boot test:** Running the scaffold with the provided steps completes with `{\"final\":\"done\"}` and saves an artifact (e.g., summary file).\n",
        "* **Swap test:** Replace `read_txt_file` with a trivial mock tool; pipeline still completes without code changes elsewhere.\n",
        "* **DI test:** Swap `RealFS` with an in-memory FS; `save_summary` still works.\n",
        "* **Schema test:** Intentionally call a tool with a missing required arg; environment returns `{\"ok\": False, \"error\": \"Missing required: [...]\"}` and logs `error`.\n",
        "* **Error envelope test:** Raise an exception inside a tool; environment returns `{\"ok\": False, \"error\": \"ExceptionType: ...\"}` and logs `error`.\n",
        "* **Plan test:** Use `create_plan` to produce steps, map to tools, and run a dynamic pipeline.\n",
        "* **LLM wrapper swap test (optional):** Inject a `DummyLLM.complete()` that returns canned text; pipeline still runs.\n",
        "* **Token guard test (optional):** Long input is truncated per config; metadata (`was_truncated`) is recorded.\n",
        "\n",
        "---\n",
        "\n",
        "# 📋 Review Checklist (Benchmark During Doc Review)\n",
        "\n",
        "## Structure & Readability\n",
        "\n",
        "* [ ] Clear **section headers** for each block (setup, wrappers, memory/context, tools, registry, env, agent runner).\n",
        "* [ ] Each block has a **1–3 sentence docstring** explaining purpose and how an LLM should use it.\n",
        "* [ ] Minimal, self-contained code samples per block (no cross-file mysteries).\n",
        "* [ ] Naming conventions consistent: underscore-DI params (`_fs`), `ctx.memory`, `ok/err`.\n",
        "\n",
        "## Contracts & APIs\n",
        "\n",
        "* [ ] `ok(**data)` / `err(msg, hint=None, retryable=False, **extra)` used everywhere.\n",
        "* [ ] Tool inputs have simple **JSON-schema-ish** validation.\n",
        "* [ ] **Dependency Injection** via underscore params is explained and demonstrated.\n",
        "* [ ] **LLM wrapper** exposes a single `.complete(prompt, **overrides)` entry point.\n",
        "\n",
        "## Safety & Guardrails\n",
        "\n",
        "* [ ] Filesystem uses **path traversal check** and whitelisted base paths.\n",
        "* [ ] Long-text **truncation** is configurable.\n",
        "* [ ] Exceptions are caught and normalized to `err(...)`.\n",
        "* [ ] `max_calls` in runner prevents runaway loops.\n",
        "\n",
        "## Observability\n",
        "\n",
        "* [ ] `track_progress(step, status, note)` logs `started/completed/error`.\n",
        "* [ ] Pretty-prints (or a quick reporter) show **plan**, **prompt**, **summary**, **artifact path**, and **progress log**.\n",
        "\n",
        "## Pluggability & Testing\n",
        "\n",
        "* [ ] Filesystem adapter (`RealFS`) used via DI; easy to swap.\n",
        "* [ ] Memory is a thin interface (`get/set`) so you can replace it later.\n",
        "* [ ] LLM wrapper isolated so providers/models can be swapped without touching tools.\n",
        "\n",
        "## LLM-Readability (Promptability)\n",
        "\n",
        "* [ ] Each section includes a **brief prompt fragment** that explains how to extend it.\n",
        "* [ ] Tools show **input→memory→output** clearly so an LLM can chain them.\n",
        "* [ ] A tiny **example pipeline** is included and runnable.\n",
        "\n",
        "---\n",
        "\n",
        "# 🗺️ Document Plan (Table of Contents)\n",
        "\n",
        "1. **Purpose & Philosophy**\n",
        "\n",
        "   * What this scaffold is for; when to use; design principles (predictability, DI, minimalism).\n",
        "\n",
        "2. **Quickstart (5 minutes)**\n",
        "\n",
        "   * Copy/paste block to run a minimal pipeline end-to-end (uses DummyLLM if needed).\n",
        "\n",
        "3. **Core Contracts**\n",
        "\n",
        "   * `ok/err` result envelopes (why + examples)\n",
        "   * `VALID_STATUSES` & `track_progress` (why + examples)\n",
        "\n",
        "4. **Runtime Building Blocks**\n",
        "\n",
        "   * `ScratchMemory` (short-term state)\n",
        "   * Filesystem Adapter (`RealFS`, underscore-DI rationale)\n",
        "   * LLM Wrapper (single `.complete` method; how to swap)\n",
        "\n",
        "5. **Tools**\n",
        "\n",
        "   * Planning tool (`create_plan`)\n",
        "   * I/O tools (`list_txt_files`, `read_txt_file`)\n",
        "   * Summarization tools (`generate_summary_prompt`, `summarize`)\n",
        "   * Output tool (`save_summary`)\n",
        "   * Pattern to add new tools (template function + registry entry)\n",
        "\n",
        "6. **Tool Registry**\n",
        "\n",
        "   * `ToolDef`, `ToolRegistry`, and **schema/returns** usage\n",
        "   * Example registrations + how to list/query tools\n",
        "\n",
        "7. **Environment (Validation + DI + Execution)**\n",
        "\n",
        "   * Arg validation (mini-schema)\n",
        "   * Auto-DI rules (underscore-prefixed params)\n",
        "   * Result normalization & error capture\n",
        "   * Centralized logging calls\n",
        "\n",
        "8. **Agents**\n",
        "\n",
        "   * `ScriptedAgent` (fixed pipeline)\n",
        "   * Optional: **dynamic pipeline** from `create_plan` mapping\n",
        "\n",
        "9. **Configuration & Setup**\n",
        "\n",
        "   * `.env` loading, config dict, folder guardrails\n",
        "   * Seeding `memory[\"goal\"]`\n",
        "\n",
        "10. **Observability & Debugging**\n",
        "\n",
        "    * Pretty prints, progress snapshots, common failure modes\n",
        "\n",
        "11. **Testing & Swapping**\n",
        "\n",
        "    * DummyLLM, InMemoryFS example, unit test nubs\n",
        "\n",
        "12. **Appendix**\n",
        "\n",
        "    * Prompt fragments for each section\n",
        "    * Common extensions (retry policy, token counting, JSON outputs)\n",
        "    * Anti-goals (what *not* to include in the scaffold)\n",
        "\n",
        "---\n",
        "\n",
        "# ✅ Review Rubric (Score 0–2 per line)\n",
        "\n",
        "* **Clarity:** Can a new reader understand each section’s purpose in ≤ 10 seconds?\n",
        "* **Cohesion:** Do sections interlock without hidden dependencies?\n",
        "* **Executability:** Can the minimal pipeline run without editing code?\n",
        "* **Safety:** Are common failure modes prevented or standardized?\n",
        "* **Extensibility:** Is it obvious where to add a new tool or swap a dependency?\n",
        "* **LLM Promptability:** Could an LLM extend each section given the examples?\n",
        "\n",
        "(12–14 = excellent, 9–11 = good, 6–8 = needs work, <6 = rework)\n",
        "\n",
        "---\n",
        "\n",
        "# 🧪 Quick Smoke Tests (copy/paste while reviewing)\n",
        "\n",
        "* **Happy path:**\n",
        "\n",
        "  * Set `goal`, run fixed steps → summary saved, progress shows all steps completed.\n",
        "* **Missing arg:**\n",
        "\n",
        "  * Call `env.run(\"read_txt_file\")` with no `file_name` → `ok=False` + helpful error.\n",
        "* **Bad type:**\n",
        "\n",
        "  * Call `env.run(\"generate_summary_prompt\", max_len=\"100\")` → type error from validator.\n",
        "* **DI missing:**\n",
        "\n",
        "  * Remove `\"fs\"` from `deps` and run `save_summary` → `ok=False`, “Missing dep 'fs'…”.\n",
        "* **LLM swap:**\n",
        "\n",
        "  * Inject `DummyLLM` that returns static text; summarization still works.\n",
        "\n",
        "---\n",
        "\n",
        "# 🚫 Anti-Goals (keep these out of the scaffold)\n",
        "\n",
        "* Vendor-specific features beyond the wrapper (e.g., advanced function-calling tied to one API).\n",
        "* Hidden globals or side effects inside tools.\n",
        "* Complex persistence layers (DBs, vectors) in the base — those are extensions.\n",
        "* Overly clever metaprogramming; prefer explicit code a model can follow.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7N-YgEqs6T8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s hold up the scaffold against the **checklist we made earlier** and see how it performs. Here’s the breakdown:\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Checklist vs. Scaffold Review\n",
        "\n",
        "### 1. **Section Headers**\n",
        "\n",
        "* **Expectation:** Clear, consistent section headers with purpose.\n",
        "* **Scaffold:** ✅ Uses big ASCII box headers (`# ╔══ ... ╗`) for each major block: setup, imports, memory, tools, registry, environment, steps, run, etc.\n",
        "* **Verdict:** **Meets expectation.**\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Docstrings / Comments**\n",
        "\n",
        "* **Expectation:** Each section should explain purpose; functions/classes should have docstrings.\n",
        "* **Scaffold:** ✅ Provides docstrings for utilities, `RealFS`, `ScratchMemory`, `ActionContext`, `OpenAILLM`, and all tools (`create_plan`, `summarize`, etc.).\n",
        "  – Even includes rationale for DI (`_fs`), logging, and error envelopes.\n",
        "* **Verdict:** **Exceeds expectation** (very thorough explanations).\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Minimal but Complete Code**\n",
        "\n",
        "* **Expectation:** Show structure + best practices without overwhelming detail.\n",
        "* **Scaffold:** ✅ Achieves modular balance — each part is lean but functional:\n",
        "  – `Environment` validates, injects, logs.\n",
        "  – Tools are simplified but usable.\n",
        "  – Setup/config is lightweight.\n",
        "* **Verdict:** **Meets expectation.**\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Optional Prompts / Fill-in Slots**\n",
        "\n",
        "* **Expectation:** Leave flexibility where LLMs or developers can “fill in” details.\n",
        "* **Scaffold:** ✅ Provides placeholders:\n",
        "  – `goal` is user-customizable.\n",
        "  – `steps` pipeline can be modified.\n",
        "  – Config has optional fields (e.g., `summary_max_chars`).\n",
        "  – Tools are generic enough to be swapped out.\n",
        "* **Verdict:** **Meets expectation.**\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Workflow Alignment**\n",
        "\n",
        "* **Expectation:** Supports the “ideal workflow” (scaffold → goal → steps → execution).\n",
        "* **Scaffold:** ✅ Mirrors workflow exactly:\n",
        "\n",
        "  1. Define scaffold.\n",
        "  2. Set `goal`.\n",
        "  3. Generate steps (`create_plan`).\n",
        "  4. Run scripted pipeline.\n",
        "  5. Log + debug with consistent envelopes.\n",
        "* **Verdict:** **Meets expectation.**\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Error Handling**\n",
        "\n",
        "* **Expectation:** Standardized error envelopes; consistent agent behavior.\n",
        "* **Scaffold:** ✅ `ok(...)` and `err(...)` at top; environment normalizes errors.\n",
        "* **Verdict:** **Strong compliance.**\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Dependency Injection (DI)**\n",
        "\n",
        "* **Expectation:** Flexible injection for filesystem, clocks, etc.\n",
        "* **Scaffold:** ✅ Uses underscore DI (`_fs`, `ctx.deps`).\n",
        "* **Verdict:** **Meets expectation.**\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Progress Logging**\n",
        "\n",
        "* **Expectation:** Centralized, easy to query.\n",
        "* **Scaffold:** ✅ `ctx.track_progress`, `print_progress`.\n",
        "* **Verdict:** **Meets expectation.**\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Modularity**\n",
        "\n",
        "* **Expectation:** Independent, swappable blocks.\n",
        "* **Scaffold:** ✅ Tools, registry, environment, and agent are all decoupled.\n",
        "* **Verdict:** **Meets expectation.**\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Pretty Printing / Visualization**\n",
        "\n",
        "* **Expectation:** Optional, not required.\n",
        "* **Scaffold:** ⚠️ Minimal — has `print_progress`, but lacks richer pretty-print snapshots (plan preview, text preview, summary preview like in Agent ZERO).\n",
        "* **Verdict:** **Slightly below expectation.** (But this might be intentional for a generalized scaffold.)\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 Overall Score\n",
        "\n",
        "* **9 / 10 checklist items fully satisfied**\n",
        "* Only gap: **Optional “pretty print”/reporting utilities** aren’t as rich as in Agent ZERO.\n",
        "\n",
        "---\n",
        "\n",
        "✅ **Conclusion:**\n",
        "Your scaffold **meets the blueprint criteria almost perfectly**.\n",
        "It’s clean, modular, teaches best practices, and is flexible for an LLM to extend.\n",
        "\n",
        "⚠️ The only thing you might add (optional) is a **“reporting/inspection block”** at the end (Plan preview, Summary preview, Saved path), since that’s very useful when debugging or teaching an LLM to “show its work.”\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1UjMZ3bm7ETG"
      }
    }
  ]
}