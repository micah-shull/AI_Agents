{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMRu8a7KWCKO5EG4OxRGIBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/146_B2B_Sales_Agent_Claude_Langchain_04_Orchestrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL9mSnuCDaIP"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "LangChain Orchestrator - Manages multi-agent sales pipeline workflow using LangChain\n",
        "\n",
        "This orchestrator demonstrates:\n",
        "- LangChain workflow management\n",
        "- Agent coordination and data flow\n",
        "- Error handling and retry logic\n",
        "- State management and monitoring\n",
        "- Integration with LangChain tools and chains\n",
        "\"\"\"\n",
        "\n",
        "import logging\n",
        "import time\n",
        "from typing import Dict, List, Optional, Any\n",
        "from datetime import datetime\n",
        "from langchain.schema import BaseOutputParser\n",
        "from langchain_models import (\n",
        "    WorkflowState, WorkflowStep, WorkflowStatus, AgentStatus,\n",
        "    CompanyInfo, AnalysisResult, PersonalizationResult\n",
        ")\n",
        "from langchain_research_agent import LangChainResearchAgent\n",
        "from langchain_analysis_agent import LangChainAnalysisAgent\n",
        "from langchain_personalization_agent import LangChainPersonalizationAgent\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LangChainSalesOrchestrator:\n",
        "    \"\"\"\n",
        "    LangChain Sales Orchestrator that manages the complete sales research pipeline\n",
        "\n",
        "    This orchestrator demonstrates:\n",
        "    - LangChain workflow management\n",
        "    - Agent coordination and data flow\n",
        "    - Error handling and retry logic\n",
        "    - State management across agents\n",
        "    - Monitoring and logging\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, orchestrator_id: str = \"langchain_sales_orchestrator\", use_mock: bool = True):\n",
        "        self.orchestrator_id = orchestrator_id\n",
        "        self.logger = logging.getLogger(f\"{__name__}.{orchestrator_id}\")\n",
        "        self.use_mock = use_mock\n",
        "\n",
        "        # Initialize LangChain agents\n",
        "        self.research_agent = LangChainResearchAgent()\n",
        "        self.analysis_agent = LangChainAnalysisAgent(use_mock=use_mock)\n",
        "        self.personalization_agent = LangChainPersonalizationAgent(use_mock=use_mock)\n",
        "\n",
        "        # Workflow configuration\n",
        "        self.workflow_steps = [\n",
        "            {\n",
        "                \"step_id\": \"research\",\n",
        "                \"agent_name\": \"langchain_research_agent\",\n",
        "                \"description\": \"Research company information using LangChain tools\"\n",
        "            },\n",
        "            {\n",
        "                \"step_id\": \"analysis\",\n",
        "                \"agent_name\": \"langchain_analysis_agent\",\n",
        "                \"description\": \"Analyze pain points and opportunities using LangChain LLM chains\"\n",
        "            },\n",
        "            {\n",
        "                \"step_id\": \"personalization\",\n",
        "                \"agent_name\": \"langchain_personalization_agent\",\n",
        "                \"description\": \"Create personalized outreach messages using LangChain templates\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Active workflows\n",
        "        self.active_workflows: Dict[str, WorkflowState] = {}\n",
        "\n",
        "        self.logger.info(f\"LangChain Sales Orchestrator initialized with {len(self.workflow_steps)} steps\")\n",
        "\n",
        "    def execute_sales_pipeline(self, company_name: str, sender_name: str = \"Sales Professional\") -> WorkflowState:\n",
        "        \"\"\"\n",
        "        Execute the complete sales research pipeline using LangChain\n",
        "\n",
        "        Args:\n",
        "            company_name: Name of the company to research\n",
        "            sender_name: Name of the person sending outreach\n",
        "\n",
        "        Returns:\n",
        "            WorkflowState with complete execution results\n",
        "        \"\"\"\n",
        "        workflow_id = f\"langchain_workflow_{int(time.time())}_{company_name.replace(' ', '_')}\"\n",
        "\n",
        "        self.logger.info(f\"Starting LangChain sales pipeline for {company_name} (Workflow ID: {workflow_id})\")\n",
        "\n",
        "        # Initialize workflow state\n",
        "        workflow_state = WorkflowState(\n",
        "            workflow_id=workflow_id,\n",
        "            company_name=company_name,\n",
        "            status=WorkflowStatus.IN_PROGRESS,\n",
        "            start_time=datetime.now().isoformat()\n",
        "        )\n",
        "\n",
        "        # Initialize workflow steps\n",
        "        for step_config in self.workflow_steps:\n",
        "            step = WorkflowStep(\n",
        "                step_id=step_config[\"step_id\"],\n",
        "                agent_name=step_config[\"agent_name\"]\n",
        "            )\n",
        "            workflow_state.steps.append(step)\n",
        "\n",
        "        # Store active workflow\n",
        "        self.active_workflows[workflow_id] = workflow_state\n",
        "\n",
        "        try:\n",
        "            # Execute workflow steps\n",
        "            self._execute_workflow_steps(workflow_state, sender_name)\n",
        "\n",
        "            # Mark workflow as completed\n",
        "            workflow_state.status = WorkflowStatus.COMPLETED\n",
        "            workflow_state.end_time = datetime.now().isoformat()\n",
        "\n",
        "            self.logger.info(f\"LangChain sales pipeline completed for {company_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle workflow failure\n",
        "            workflow_state.status = WorkflowStatus.FAILED\n",
        "            workflow_state.end_time = datetime.now().isoformat()\n",
        "            workflow_state.error_message = str(e)\n",
        "\n",
        "            self.logger.error(f\"LangChain sales pipeline failed for {company_name}: {str(e)}\")\n",
        "\n",
        "        return workflow_state\n",
        "\n",
        "    def _execute_workflow_steps(self, workflow_state: WorkflowState, sender_name: str):\n",
        "        \"\"\"Execute all workflow steps in sequence using LangChain agents\"\"\"\n",
        "\n",
        "        # Step 1: Research Company using LangChain tools\n",
        "        self._execute_research_step(workflow_state)\n",
        "\n",
        "        # Check if research succeeded\n",
        "        if workflow_state.steps[0].status == AgentStatus.FAILED:\n",
        "            raise Exception(f\"LangChain research step failed: {workflow_state.steps[0].error_message}\")\n",
        "\n",
        "        # Step 2: Analyze Company using LangChain LLM chains\n",
        "        self._execute_analysis_step(workflow_state)\n",
        "\n",
        "        # Check if analysis succeeded\n",
        "        if workflow_state.steps[1].status == AgentStatus.FAILED:\n",
        "            raise Exception(f\"LangChain analysis step failed: {workflow_state.steps[1].error_message}\")\n",
        "\n",
        "        # Step 3: Personalize Outreach using LangChain templates\n",
        "        self._execute_personalization_step(workflow_state, sender_name)\n",
        "\n",
        "        # Check if personalization succeeded\n",
        "        if workflow_state.steps[2].status == AgentStatus.FAILED:\n",
        "            raise Exception(f\"LangChain personalization step failed: {workflow_state.steps[2].error_message}\")\n",
        "\n",
        "    def _execute_research_step(self, workflow_state: WorkflowState):\n",
        "        \"\"\"Execute the research step using LangChain tools\"\"\"\n",
        "        step = workflow_state.steps[0]\n",
        "        step.status = AgentStatus.RUNNING\n",
        "        step.start_time = datetime.now().isoformat()\n",
        "\n",
        "        self.logger.info(f\"Executing LangChain research step for {workflow_state.company_name}\")\n",
        "\n",
        "        try:\n",
        "            # Execute LangChain research agent\n",
        "            company_info = self.research_agent.research_company(workflow_state.company_name)\n",
        "\n",
        "            if company_info:\n",
        "                step.status = AgentStatus.COMPLETED\n",
        "                step.output_data = {\n",
        "                    \"company_info\": company_info.model_dump(),\n",
        "                    \"success\": True,\n",
        "                    \"framework\": \"langchain\"\n",
        "                }\n",
        "                self.logger.info(f\"LangChain research completed for {workflow_state.company_name}\")\n",
        "            else:\n",
        "                step.status = AgentStatus.FAILED\n",
        "                step.error_message = f\"No information found for {workflow_state.company_name}\"\n",
        "                self.logger.warning(f\"LangChain research failed for {workflow_state.company_name}: No information found\")\n",
        "\n",
        "        except Exception as e:\n",
        "            step.status = AgentStatus.FAILED\n",
        "            step.error_message = str(e)\n",
        "            self.logger.error(f\"LangChain research step failed: {str(e)}\")\n",
        "\n",
        "        step.end_time = datetime.now().isoformat()\n",
        "\n",
        "    def _execute_analysis_step(self, workflow_state: WorkflowState):\n",
        "        \"\"\"Execute the analysis step using LangChain LLM chains\"\"\"\n",
        "        step = workflow_state.steps[1]\n",
        "        step.status = AgentStatus.RUNNING\n",
        "        step.start_time = datetime.now().isoformat()\n",
        "\n",
        "        self.logger.info(f\"Executing LangChain analysis step for {workflow_state.company_name}\")\n",
        "\n",
        "        try:\n",
        "            # Get company info from previous step\n",
        "            company_info_data = workflow_state.steps[0].output_data[\"company_info\"]\n",
        "            company_info = CompanyInfo.model_validate(company_info_data)\n",
        "\n",
        "            # Execute LangChain analysis agent\n",
        "            analysis_result = self.analysis_agent.analyze_company(company_info)\n",
        "\n",
        "            step.status = AgentStatus.COMPLETED\n",
        "            step.output_data = {\n",
        "                \"analysis_result\": analysis_result.model_dump(),\n",
        "                \"success\": True,\n",
        "                \"framework\": \"langchain\"\n",
        "            }\n",
        "            self.logger.info(f\"LangChain analysis completed for {workflow_state.company_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            step.status = AgentStatus.FAILED\n",
        "            step.error_message = str(e)\n",
        "            self.logger.error(f\"LangChain analysis step failed: {str(e)}\")\n",
        "\n",
        "        step.end_time = datetime.now().isoformat()\n",
        "\n",
        "    def _execute_personalization_step(self, workflow_state: WorkflowState, sender_name: str):\n",
        "        \"\"\"Execute the personalization step using LangChain templates\"\"\"\n",
        "        step = workflow_state.steps[2]\n",
        "        step.status = AgentStatus.RUNNING\n",
        "        step.start_time = datetime.now().isoformat()\n",
        "\n",
        "        self.logger.info(f\"Executing LangChain personalization step for {workflow_state.company_name}\")\n",
        "\n",
        "        try:\n",
        "            # Get data from previous steps\n",
        "            company_info_data = workflow_state.steps[0].output_data[\"company_info\"]\n",
        "            analysis_result_data = workflow_state.steps[1].output_data[\"analysis_result\"]\n",
        "\n",
        "            company_info = CompanyInfo.model_validate(company_info_data)\n",
        "            analysis_result = AnalysisResult.model_validate(analysis_result_data)\n",
        "\n",
        "            # Execute LangChain personalization agent\n",
        "            personalization_result = self.personalization_agent.personalize_outreach(\n",
        "                company_info, analysis_result, sender_name\n",
        "            )\n",
        "\n",
        "            step.status = AgentStatus.COMPLETED\n",
        "            step.output_data = {\n",
        "                \"personalization_result\": personalization_result.model_dump(),\n",
        "                \"success\": True,\n",
        "                \"framework\": \"langchain\"\n",
        "            }\n",
        "            self.logger.info(f\"LangChain personalization completed for {workflow_state.company_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            step.status = AgentStatus.FAILED\n",
        "            step.error_message = str(e)\n",
        "            self.logger.error(f\"LangChain personalization step failed: {str(e)}\")\n",
        "\n",
        "        step.end_time = datetime.now().isoformat()\n",
        "\n",
        "    def get_workflow_status(self, workflow_id: str) -> Optional[WorkflowState]:\n",
        "        \"\"\"Get status of a specific workflow\"\"\"\n",
        "        return self.active_workflows.get(workflow_id)\n",
        "\n",
        "    def get_all_workflows(self) -> Dict[str, WorkflowState]:\n",
        "        \"\"\"Get all active workflows\"\"\"\n",
        "        return self.active_workflows.copy()\n",
        "\n",
        "    def retry_failed_step(self, workflow_id: str, step_id: str) -> bool:\n",
        "        \"\"\"Retry a failed workflow step\"\"\"\n",
        "        if workflow_id not in self.active_workflows:\n",
        "            return False\n",
        "\n",
        "        workflow_state = self.active_workflows[workflow_id]\n",
        "\n",
        "        # Find the step\n",
        "        step = next((s for s in workflow_state.steps if s.step_id == step_id), None)\n",
        "        if not step:\n",
        "            return False\n",
        "\n",
        "        # Check retry limits\n",
        "        if step.retry_count >= step.max_retries:\n",
        "            self.logger.warning(f\"Step {step_id} has exceeded max retries\")\n",
        "            return False\n",
        "\n",
        "        # Increment retry count\n",
        "        step.retry_count += 1\n",
        "        step.status = AgentStatus.RETRYING\n",
        "\n",
        "        self.logger.info(f\"Retrying LangChain step {step_id} (attempt {step.retry_count})\")\n",
        "\n",
        "        # Retry the step based on step type\n",
        "        try:\n",
        "            if step_id == \"research\":\n",
        "                self._execute_research_step(workflow_state)\n",
        "            elif step_id == \"analysis\":\n",
        "                self._execute_analysis_step(workflow_state)\n",
        "            elif step_id == \"personalization\":\n",
        "                self._execute_personalization_step(workflow_state, \"Sales Professional\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"LangChain retry failed for step {step_id}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_orchestrator_status(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get orchestrator status and metrics\"\"\"\n",
        "        total_workflows = len(self.active_workflows)\n",
        "        completed_workflows = len([w for w in self.active_workflows.values() if w.status == WorkflowStatus.COMPLETED])\n",
        "        failed_workflows = len([w for w in self.active_workflows.values() if w.status == WorkflowStatus.FAILED])\n",
        "\n",
        "        return {\n",
        "            \"orchestrator_id\": self.orchestrator_id,\n",
        "            \"status\": \"ready\",\n",
        "            \"framework\": \"langchain\",\n",
        "            \"use_mock\": self.use_mock,\n",
        "            \"total_workflows\": total_workflows,\n",
        "            \"completed_workflows\": completed_workflows,\n",
        "            \"failed_workflows\": failed_workflows,\n",
        "            \"success_rate\": completed_workflows / total_workflows if total_workflows > 0 else 0,\n",
        "            \"workflow_steps\": len(self.workflow_steps),\n",
        "            \"active_agents\": [\n",
        "                self.research_agent.get_status(),\n",
        "                self.analysis_agent.get_status(),\n",
        "                self.personalization_agent.get_status()\n",
        "            ]\n",
        "        }\n",
        "\n",
        "# Example usage and testing\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== LangChain Sales Orchestrator Demo ===\\n\")\n",
        "\n",
        "    # Create orchestrator\n",
        "    orchestrator = LangChainSalesOrchestrator(use_mock=True)\n",
        "\n",
        "    # Execute sales pipeline\n",
        "    workflow_state = orchestrator.execute_sales_pipeline(\"Acme Corporation\", \"John Smith\")\n",
        "\n",
        "    print(f\"Workflow ID: {workflow_state.workflow_id}\")\n",
        "    print(f\"Company: {workflow_state.company_name}\")\n",
        "    print(f\"Status: {workflow_state.status}\")\n",
        "    print(f\"Start Time: {workflow_state.start_time}\")\n",
        "    print(f\"End Time: {workflow_state.end_time}\")\n",
        "\n",
        "    if workflow_state.error_message:\n",
        "        print(f\"Error: {workflow_state.error_message}\")\n",
        "\n",
        "    print(f\"\\nWorkflow Steps:\")\n",
        "    for i, step in enumerate(workflow_state.steps, 1):\n",
        "        print(f\"  {i}. {step.step_id.upper()}\")\n",
        "        print(f\"     Status: {step.status}\")\n",
        "        print(f\"     Agent: {step.agent_name}\")\n",
        "        if step.start_time and step.end_time:\n",
        "            start_dt = datetime.fromisoformat(step.start_time)\n",
        "            end_dt = datetime.fromisoformat(step.end_time)\n",
        "            duration = (end_dt - start_dt).total_seconds()\n",
        "            print(f\"     Duration: {duration:.2f}s\")\n",
        "        if step.error_message:\n",
        "            print(f\"     Error: {step.error_message}\")\n",
        "        if step.output_data and step.output_data.get(\"success\"):\n",
        "            print(f\"     Success: {step.output_data['success']}\")\n",
        "            print(f\"     Framework: {step.output_data.get('framework', 'N/A')}\")\n",
        "\n",
        "    # Show final results if successful\n",
        "    if workflow_state.status == WorkflowStatus.COMPLETED:\n",
        "        personalization_data = workflow_state.steps[2].output_data[\"personalization_result\"]\n",
        "        personalization_result = PersonalizationResult.model_validate(personalization_data)\n",
        "\n",
        "        print(f\"\\n=== Final Results ===\")\n",
        "        print(f\"Strategy: {personalization_result.personalization_strategy}\")\n",
        "        print(f\"Messages Created: {len(personalization_result.messages)}\")\n",
        "        print(f\"Recommended Sequence: {', '.join(personalization_result.recommended_sequence)}\")\n",
        "\n",
        "        print(f\"\\nSample Email Message:\")\n",
        "        email_msg = next((msg for msg in personalization_result.messages if msg[\"channel\"] == \"email\"), None)\n",
        "        if email_msg:\n",
        "            print(f\"Subject: {email_msg['subject']}\")\n",
        "            print(f\"Body Preview: {email_msg['body'][:200]}...\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Show orchestrator status\n",
        "    status = orchestrator.get_orchestrator_status()\n",
        "    print(f\"LangChain Orchestrator Status:\")\n",
        "    for key, value in status.items():\n",
        "        if key == \"active_agents\":\n",
        "            print(f\"  {key}:\")\n",
        "            for agent in value:\n",
        "                print(f\"    - {agent['agent_id']}: {agent['status']} ({agent['framework']})\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we‚Äôre at the **LangChain Orchestrator**, here‚Äôs a breakdown of how it improves over the original orchestrator, why it matters, and what you should focus on learning:\n",
        "\n",
        "---\n",
        "\n",
        "## üîë Improvements LangChain Brings\n",
        "\n",
        "### 1. **Unified Framework Across Agents**\n",
        "\n",
        "* The orchestrator coordinates `LangChainResearchAgent`, `LangChainAnalysisAgent`, and `LangChainPersonalizationAgent` ‚Äî all built on the same LangChain abstractions.\n",
        "* This means each step shares a **common interface** (schemas, `LLMChain`, templates), so the orchestrator just plugs them together.\n",
        "* In the original, each agent had bespoke logic; here, everything is normalized.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Structured State & Monitoring**\n",
        "\n",
        "* Uses `WorkflowState`, `WorkflowStep`, `WorkflowStatus`, and `AgentStatus` models from your `langchain_models.py`.\n",
        "* Every run produces a **structured log**: start/end time, retries, error messages, outputs.\n",
        "* This is invaluable for debugging, analytics, and plugging into LangSmith observability.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Error Handling & Retry Logic**\n",
        "\n",
        "* Each step is wrapped in try/except with its own `FAILED` status and error message.\n",
        "* Steps can be retried with backoff (`retry_failed_step`) instead of re-running the entire workflow.\n",
        "* Original code had linear \"all-or-nothing\" execution ‚Äî now you get granular fault tolerance.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Composable Pipelines**\n",
        "\n",
        "* Workflow steps are defined as configs (`workflow_steps`) instead of hardcoding.\n",
        "* Easy to add new agents: e.g. a `ValidationAgent` or `SummaryAgent` without rewriting core logic.\n",
        "* Makes this feel more like a *pipeline engine* than just procedural glue code.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **LangChain Tool/Chain Integration**\n",
        "\n",
        "* Because it‚Äôs in the LangChain ecosystem, you can slot in:\n",
        "\n",
        "  * Tools (search, APIs, calculators).\n",
        "  * Advanced Chains (multi-step LLM reasoning).\n",
        "  * Observability with LangSmith.\n",
        "* The original was Python-only orchestration; here you inherit a growing ecosystem.\n",
        "\n",
        "---\n",
        "\n",
        "## üìà Why This Is ‚ÄúBetter Overall‚Äù\n",
        "\n",
        "* **Scalability** ‚Üí Add/replace agents easily.\n",
        "* **Reliability** ‚Üí Step-by-step retries, structured states.\n",
        "* **Observability** ‚Üí Built for integration with monitoring tools.\n",
        "* **Maintainability** ‚Üí Agents use standardized patterns (`LLMChain`, prompt templates, Pydantic models).\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ What You Should Learn & Focus On\n",
        "\n",
        "1. **LangChain Core Concepts**\n",
        "\n",
        "   * `PromptTemplate`, `LLMChain`, `RunnableSequence`.\n",
        "   * How inputs/outputs flow through chains.\n",
        "\n",
        "2. **Structured Outputs**\n",
        "\n",
        "   * Using Pydantic models for safe parsing & validation (you‚Äôre already doing this really well).\n",
        "\n",
        "3. **Workflow Orchestration Patterns**\n",
        "\n",
        "   * Sequencing steps vs. running in parallel.\n",
        "   * Retry strategies, checkpoints, and human-in-the-loop workflows.\n",
        "\n",
        "4. **Observability with LangSmith**\n",
        "\n",
        "   * Tracing what happened at each step.\n",
        "   * Capturing errors and metrics (latency, token usage).\n",
        "\n",
        "5. **Extensibility**\n",
        "\n",
        "   * Adding new step types (e.g. enrichment agents, summarizers).\n",
        "   * Modularizing so the orchestrator becomes your **sales pipeline OS**.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **In short**: the original orchestrator was like a hardcoded script.\n",
        "The LangChain orchestrator is a **workflow engine** with monitoring, retry logic, and ecosystem integration.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rS-IqhcCD-2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `__init__` block is the **foundation** of your LangChain orchestrator. Let‚Äôs unpack it section by section and see what‚Äôs going on, and more importantly, *why* it matters for orchestrator design.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 1. Orchestrator Metadata\n",
        "\n",
        "```python\n",
        "def __init__(self, orchestrator_id: str = \"langchain_sales_orchestrator\", use_mock: bool = True):\n",
        "    self.orchestrator_id = orchestrator_id\n",
        "    self.logger = logging.getLogger(f\"{__name__}.{orchestrator_id}\")\n",
        "    self.use_mock = use_mock\n",
        "```\n",
        "\n",
        "* **`orchestrator_id`** ‚Üí Gives this orchestrator instance a unique name (handy when running multiple orchestrators in parallel).\n",
        "* **Logger** ‚Üí Creates a namespaced logger (`langchain_orchestrator.langchain_sales_orchestrator`) so you can track logs per orchestrator instance. This is critical for observability.\n",
        "* **`use_mock` flag** ‚Üí Controls whether downstream agents run in \"mock mode\" (no LLM/API calls, just demo data). This makes testing fast, cheap, and safe.\n",
        "\n",
        "**Takeaway:** Always initialize your orchestrator with metadata and toggles for environment (mock vs. production). This is the difference between code that‚Äôs ‚Äúhacky‚Äù vs. production-ready.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 2. Agent Initialization\n",
        "\n",
        "```python\n",
        "# Initialize LangChain agents\n",
        "self.research_agent = LangChainResearchAgent()\n",
        "self.analysis_agent = LangChainAnalysisAgent(use_mock=use_mock)\n",
        "self.personalization_agent = LangChainPersonalizationAgent(use_mock=use_mock)\n",
        "```\n",
        "\n",
        "* Each agent is instantiated here, and you see the **mock flag propagated downstream**.\n",
        "* This makes the orchestrator the *owner* of agents ‚Äî it manages their lifecycle, config, and dependencies.\n",
        "* Note how different agents may or may not care about `use_mock`:\n",
        "\n",
        "  * ResearchAgent = structured API lookups (mock vs. real).\n",
        "  * AnalysisAgent & PersonalizationAgent = LLMs (mock avoids tokens).\n",
        "\n",
        "**Takeaway:** The orchestrator is the \"manager\" that spins up all its worker agents, passing down the right config.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 3. Workflow Configuration\n",
        "\n",
        "```python\n",
        "# Workflow configuration\n",
        "self.workflow_steps = [\n",
        "    {\n",
        "        \"step_id\": \"research\",\n",
        "        \"agent_name\": \"langchain_research_agent\",\n",
        "        \"description\": \"Research company information using LangChain tools\"\n",
        "    },\n",
        "    {\n",
        "        \"step_id\": \"analysis\",\n",
        "        \"agent_name\": \"langchain_analysis_agent\",\n",
        "        \"description\": \"Analyze pain points and opportunities using LangChain LLM chains\"\n",
        "    },\n",
        "    {\n",
        "        \"step_id\": \"personalization\",\n",
        "        \"agent_name\": \"langchain_personalization_agent\",\n",
        "        \"description\": \"Create personalized outreach messages using LangChain templates\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "* This list is basically the **pipeline recipe**.\n",
        "* Instead of hardcoding calls like `self.research_agent.run(); self.analysis_agent.run()`, you store step configs here.\n",
        "* Makes the workflow **declarative**: you can log, reorder, or even dynamically swap steps later.\n",
        "* Each step is self-describing with `step_id`, `agent_name`, and `description`.\n",
        "\n",
        "**Takeaway:** This is the first step toward *pipeline as data* (think YAML workflows, Airflow DAGs, etc.). It‚Äôs what lets your orchestrator scale.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 4. Workflow State Tracking\n",
        "\n",
        "```python\n",
        "# Active workflows\n",
        "self.active_workflows: Dict[str, WorkflowState] = {}\n",
        "```\n",
        "\n",
        "* This dictionary tracks all currently running workflows.\n",
        "* Keys = workflow IDs (unique per run).\n",
        "* Values = `WorkflowState` dataclasses (which include status, steps, errors, etc.).\n",
        "* Lets you run multiple companies in parallel and still know which workflow is at what stage.\n",
        "\n",
        "**Takeaway:** This is *stateful orchestration*. Without this, you‚Äôd only ever run one workflow at a time.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 5. Logging Initialization\n",
        "\n",
        "```python\n",
        "self.logger.info(f\"LangChain Sales Orchestrator initialized with {len(self.workflow_steps)} steps\")\n",
        "```\n",
        "\n",
        "* Provides an immediate sanity check in logs when the orchestrator is bootstrapped.\n",
        "* Tells you how many steps are configured ‚Äî a subtle but useful observability feature.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ What You Should Focus On Learning Here\n",
        "\n",
        "1. **Initialization patterns** ‚Üí Always design your orchestrator to be flexible (mock vs prod).\n",
        "2. **Agent lifecycle** ‚Üí Orchestrator owns and configures all agents.\n",
        "3. **Declarative workflows** ‚Üí Move away from hardcoded logic toward config-driven steps.\n",
        "4. **State management** ‚Üí Track multiple workflows and their progress.\n",
        "5. **Logging** ‚Üí Build observability from the ground up.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ In short: this init block is setting up the orchestrator as a **pipeline engine**, not just a script.\n",
        "It‚Äôs like going from ‚Äúa chef following a recipe in their head‚Äù ‚Üí ‚Äúa kitchen that has recipes pinned to the wall, cooks assigned, and a manager tracking every dish.‚Äù\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GPMARiVgK-rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üü¶ 1. Expanding the Pipeline (Scalability)\n",
        "\n",
        "Yes ‚Äî you can add more agents by **appending new step configs** to `self.workflow_steps`.\n",
        "For example:\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"step_id\": \"validation\",\n",
        "    \"agent_name\": \"langchain_validation_agent\",\n",
        "    \"description\": \"Validate analysis results against internal CRM data\"\n",
        "},\n",
        "{\n",
        "    \"step_id\": \"summary\",\n",
        "    \"agent_name\": \"langchain_summary_agent\",\n",
        "    \"description\": \"Summarize workflow results for human review\"\n",
        "}\n",
        "```\n",
        "\n",
        "The orchestrator doesn‚Äôt care what the agent *does* ‚Äî it just knows:\n",
        "\n",
        "* *Step ID*: unique tag\n",
        "* *Agent*: who to call\n",
        "* *Description*: logging/observability\n",
        "\n",
        "Because of this, the orchestrator can ‚Äúscale‚Äù from 3 steps ‚Üí 5 steps ‚Üí 20 steps without rewriting core logic.\n",
        "\n",
        "That‚Äôs scalability in **workflow design**. üöÄ\n",
        "\n",
        "---\n",
        "\n",
        "## üü¶ 2. What Does ‚ÄúPipeline as Data‚Äù Mean?\n",
        "\n",
        "Normally, pipelines are *hardcoded* in Python like:\n",
        "\n",
        "```python\n",
        "research_result = research_agent.run(company)\n",
        "analysis_result = analysis_agent.run(research_result)\n",
        "personalization_result = personalization_agent.run(analysis_result)\n",
        "```\n",
        "\n",
        "That‚Äôs brittle. If you want to add a validation step, you edit the code.\n",
        "\n",
        "Instead, you define your pipeline in **data form** (like your `workflow_steps` list).\n",
        "The orchestrator *reads* this config and runs steps accordingly.\n",
        "This makes pipelines more flexible and maintainable.\n",
        "\n",
        "---\n",
        "\n",
        "## üü¶ 3. YAML & Airflow (Quick Primer)\n",
        "\n",
        "These are **tools/paradigms** used in industry for pipeline orchestration:\n",
        "\n",
        "* **YAML**\n",
        "\n",
        "  * A human-friendly configuration file format.\n",
        "\n",
        "  * Instead of writing workflow steps in Python, you might define them in a `.yaml` file.\n",
        "\n",
        "  * Example:\n",
        "\n",
        "    ```yaml\n",
        "    workflow:\n",
        "      - step_id: research\n",
        "        agent: langchain_research_agent\n",
        "      - step_id: analysis\n",
        "        agent: langchain_analysis_agent\n",
        "      - step_id: personalization\n",
        "        agent: langchain_personalization_agent\n",
        "    ```\n",
        "\n",
        "  * Your orchestrator loads this YAML and builds the workflow dynamically.\n",
        "\n",
        "* **Airflow** (Apache Airflow)\n",
        "\n",
        "  * A production-grade **workflow orchestrator** used by data teams.\n",
        "  * Lets you define workflows as DAGs (Directed Acyclic Graphs) and schedule them.\n",
        "  * Example use: ‚ÄúRun ETL pipeline at 8am daily, retry failed steps 3 times.‚Äù\n",
        "  * Your orchestrator is a **mini-Airflow** specialized for sales pipelines.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Takeaway\n",
        "\n",
        "* Adding more agents = scalability of functionality.\n",
        "* Storing workflow steps in configs (like YAML) = scalability of configuration.\n",
        "* Tools like **Airflow** are industry examples of orchestrators that do this at massive scale.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EASjAivtLZ46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "That **YAML file** you wrote could *completely replace* the hardcoded Python list of workflow steps.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Why This Works\n",
        "\n",
        "Right now in Python you have:\n",
        "\n",
        "```python\n",
        "self.workflow_steps = [\n",
        "    {\n",
        "        \"step_id\": \"research\",\n",
        "        \"agent_name\": \"langchain_research_agent\",\n",
        "        \"description\": \"Research company information using LangChain tools\"\n",
        "    },\n",
        "    {\n",
        "        \"step_id\": \"analysis\",\n",
        "        \"agent_name\": \"langchain_analysis_agent\",\n",
        "        \"description\": \"Analyze pain points and opportunities using LangChain LLM chains\"\n",
        "    },\n",
        "    {\n",
        "        \"step_id\": \"personalization\",\n",
        "        \"agent_name\": \"langchain_personalization_agent\",\n",
        "        \"description\": \"Create personalized outreach messages using LangChain templates\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "That‚Äôs basically a **list of dictionaries**. YAML is just a **human-readable way of writing the same structure**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Your YAML Version\n",
        "\n",
        "```yaml\n",
        "workflow:\n",
        "  - step_id: research\n",
        "    agent: langchain_research_agent\n",
        "  - step_id: analysis\n",
        "    agent: langchain_analysis_agent\n",
        "  - step_id: personalization\n",
        "    agent: langchain_personalization_agent\n",
        "```\n",
        "\n",
        "When you load this YAML in Python:\n",
        "\n",
        "```python\n",
        "import yaml\n",
        "\n",
        "with open(\"workflow.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "self.workflow_steps = config[\"workflow\"]\n",
        "```\n",
        "\n",
        "üëâ Now `self.workflow_steps` is the **same list of dicts**, but loaded from a file instead of being hardcoded.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Adding New Steps\n",
        "\n",
        "If you want to expand the pipeline later (like your validation + summary example), you‚Äôd just edit the YAML:\n",
        "\n",
        "```yaml\n",
        "workflow:\n",
        "  - step_id: research\n",
        "    agent: langchain_research_agent\n",
        "  - step_id: analysis\n",
        "    agent: langchain_analysis_agent\n",
        "  - step_id: personalization\n",
        "    agent: langchain_personalization_agent\n",
        "  - step_id: validation\n",
        "    agent: langchain_validation_agent\n",
        "  - step_id: summary\n",
        "    agent: langchain_summary_agent\n",
        "```\n",
        "\n",
        "No Python code changes needed. The orchestrator will automatically run the new steps.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Why This Matters\n",
        "\n",
        "* **Human-readable:** Non-engineers (sales ops, analysts) can change workflows.\n",
        "* **Dynamic:** You can swap agents or re-order steps without touching code.\n",
        "* **Scalable:** Same orchestrator can run many workflows, just by pointing to different YAML configs.\n",
        "\n",
        "This is exactly what I meant earlier by **‚Äúpipeline as data.‚Äù**\n",
        "\n"
      ],
      "metadata": {
        "id": "D8DYY6wJLzYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "With **YAML-driven workflows**, your orchestrator becomes a **generic execution engine**, and the *pipeline itself* becomes just data. That gives you a few superpowers:\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Benefits of YAML Workflows\n",
        "\n",
        "1. **Modularity** ‚Üí Add/remove agents without touching code.\n",
        "\n",
        "   * New step? Just drop it into the YAML.\n",
        "   * Retire a step? Delete it from YAML.\n",
        "2. **Non-engineer friendly** ‚Üí Ops, analysts, or even business users can tweak workflows without editing Python.\n",
        "3. **Reusability** ‚Üí One orchestrator can run many different pipelines, just swap configs.\n",
        "\n",
        "   * Example: `sales_pipeline.yaml` vs. `customer_success_pipeline.yaml`.\n",
        "4. **Versioning** ‚Üí Workflows are just files, so you can track them in Git.\n",
        "\n",
        "   * ‚ÄúWhat did our pipeline look like last quarter?‚Äù ‚Üí Just check the YAML history.\n",
        "5. **Scalability** ‚Üí If you want 50 steps, YAML stays readable. Code would get messy.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Example\n",
        "\n",
        "Here‚Äôs a mini YAML:\n",
        "\n",
        "```yaml\n",
        "workflow:\n",
        "  - step_id: research\n",
        "    agent: langchain_research_agent\n",
        "  - step_id: analysis\n",
        "    agent: langchain_analysis_agent\n",
        "  - step_id: personalization\n",
        "    agent: langchain_personalization_agent\n",
        "  - step_id: summary\n",
        "    agent: langchain_summary_agent\n",
        "```\n",
        "\n",
        "And here‚Äôs how your orchestrator could load it:\n",
        "\n",
        "```python\n",
        "import yaml\n",
        "\n",
        "class SalesOrchestrator:\n",
        "    def __init__(self, workflow_file: str):\n",
        "        with open(workflow_file, \"r\") as f:\n",
        "            config = yaml.safe_load(f)\n",
        "        self.workflow_steps = config[\"workflow\"]\n",
        "\n",
        "    def run(self):\n",
        "        for step in self.workflow_steps:\n",
        "            print(f\"Running step {step['step_id']} with agent {step['agent']}\")\n",
        "```\n",
        "\n",
        "Run it:\n",
        "\n",
        "```python\n",
        "orchestrator = SalesOrchestrator(\"workflow.yaml\")\n",
        "orchestrator.run()\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "```\n",
        "Running step research with agent langchain_research_agent\n",
        "Running step analysis with agent langchain_analysis_agent\n",
        "Running step personalization with agent langchain_personalization_agent\n",
        "Running step summary with agent langchain_summary_agent\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Big Picture\n",
        "\n",
        "* **Today:** Your orchestrator is tightly coupled to its steps.\n",
        "* **Tomorrow:** The orchestrator is a **flexible engine**, and the pipeline is a **config file**.\n",
        "\n",
        "That‚Äôs the leap from *scripts* ‚Üí *systems*.\n"
      ],
      "metadata": {
        "id": "LYSt45r1MXG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You‚Äôre noticing that your **pipeline logic** (like `execute_sales_pipeline`) is doing a lot, and asking: *should this live inside the orchestrator, or be modularized into smaller blocks?*\n",
        "\n",
        "Let‚Äôs break it down.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ What This Block Does\n",
        "\n",
        "Your `execute_sales_pipeline` method:\n",
        "\n",
        "1. **Creates a unique workflow ID** (traceability).\n",
        "2. **Initializes workflow state** (`WorkflowState` + steps).\n",
        "3. **Stores it in active\\_workflows** (so multiple runs can co-exist).\n",
        "4. **Runs the steps** via `_execute_workflow_steps`.\n",
        "5. **Updates status** to COMPLETED or FAILED.\n",
        "6. **Returns the structured state**.\n",
        "\n",
        "This is essentially a **pipeline runner** ‚Äî a high-level controller for one workflow execution.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Two Ways to Organize This\n",
        "\n",
        "### Option 1 ‚Äî Keep Inside the Orchestrator (Current)\n",
        "\n",
        "* ‚úÖ Cohesion: Orchestrator both *manages workflows* and *executes them*.\n",
        "* ‚úÖ Easy to understand: All pipeline logic is in one place.\n",
        "* ‚ùå Can get bulky if you add more pipelines (e.g. sales, onboarding, support).\n",
        "\n",
        "---\n",
        "\n",
        "### Option 2 ‚Äî Modularize into Separate Script / Module\n",
        "\n",
        "You could store these kinds of blocks as **modular pipeline runners** in a separate file, e.g. `pipelines.py`:\n",
        "\n",
        "```python\n",
        "# pipelines.py\n",
        "def run_sales_pipeline(orchestrator, company_name, sender_name=\"Sales Professional\"):\n",
        "    return orchestrator._run_pipeline(\n",
        "        pipeline_name=\"sales\",\n",
        "        company_name=company_name,\n",
        "        sender_name=sender_name\n",
        "    )\n",
        "```\n",
        "\n",
        "Or even make **Pipeline classes**:\n",
        "\n",
        "```python\n",
        "# pipelines/sales_pipeline.py\n",
        "class SalesPipeline:\n",
        "    def __init__(self, orchestrator):\n",
        "        self.orchestrator = orchestrator\n",
        "    \n",
        "    def run(self, company_name, sender_name=\"Sales Professional\"):\n",
        "        return self.orchestrator.execute_pipeline(\"sales\", company_name, sender_name)\n",
        "```\n",
        "\n",
        "Then in your orchestrator:\n",
        "\n",
        "```python\n",
        "from pipelines.sales_pipeline import SalesPipeline\n",
        "\n",
        "sales_pipeline = SalesPipeline(orchestrator)\n",
        "state = sales_pipeline.run(\"Acme Corp\")\n",
        "```\n",
        "\n",
        "* ‚úÖ Cleaner orchestrator: it just manages agents & states.\n",
        "* ‚úÖ Pipelines are pluggable: add `MarketingPipeline`, `SupportPipeline`, etc.\n",
        "* ‚úÖ Easier testing: you can unit-test each pipeline separately.\n",
        "* ‚ùå Adds indirection (a beginner might need to jump across files to see the full picture).\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Which Is Better?\n",
        "\n",
        "* If your **goal is learning orchestration** ‚Üí keep inside the orchestrator for now (Option 1). Easier to see the big picture.\n",
        "* If your **goal is modular systems at scale** ‚Üí move to Option 2. Treat pipelines as **first-class objects** that can be defined outside the orchestrator.\n",
        "\n",
        "That‚Äôs what big systems (like **Airflow DAGs**, or LangChain `RunnableSequences`) do ‚Äî pipelines are *data/config*, not hardcoded in one place.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Takeaway\n",
        "\n",
        "Yes ‚Äî these blocks could be moved into separate scripts as **modular pipeline runners**. That‚Äôs a more scalable approach if you plan to support multiple pipelines or let others define workflows.\n",
        "\n",
        "But for your current sales agent (learning phase), keeping them inside the orchestrator is fine.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BFT0FXDRNALp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üü¶ What the Rest of the Code Is\n",
        "\n",
        "1. **Operational functions** ‚Üí `_execute_workflow_steps` and friends.\n",
        "\n",
        "   * These are the ‚Äúengine room‚Äù functions: actually loop through steps, call the right agent, pass data along.\n",
        "   * Think: *do the work*.\n",
        "\n",
        "2. **Error handling** ‚Üí the `try/except` block in your `execute_sales_pipeline`.\n",
        "\n",
        "   * Ensures a workflow doesn‚Äôt crash the whole orchestrator.\n",
        "   * Updates `workflow_state` with `FAILED` status + error message.\n",
        "   * Logs the error cleanly for observability.\n",
        "\n",
        "3. **Logging** ‚Üí `self.logger.info(...)`, `self.logger.error(...)`.\n",
        "\n",
        "   * Critical for observability.\n",
        "   * Lets you trace what happened, when, and why.\n",
        "   * In production, you‚Äôd often forward these logs to a monitoring platform (Datadog, ELK, LangSmith).\n",
        "\n",
        "---\n",
        "\n",
        "## üü¶ Last Thoughts Before Moving On\n",
        "\n",
        "* **You‚Äôre basically building a mini-Airflow.**\n",
        "\n",
        "  * Each step = task.\n",
        "  * `workflow_state` = DAG state.\n",
        "  * Logging/error handling = Airflow UI + retry logic.\n",
        "\n",
        "* **Don‚Äôt underestimate logging.** It‚Äôs not just ‚Äúfor debugging.‚Äù\n",
        "\n",
        "  * It‚Äôs your *audit trail*.\n",
        "  * If a client asks ‚ÄúWhy did we reach out with this message?‚Äù ‚Üí you have a full trace.\n",
        "\n",
        "* **Future upgrade path**\n",
        "\n",
        "  * YAML config for pipeline definitions.\n",
        "  * Parallel execution (not just sequential).\n",
        "  * Retry policies per step (retry `research` twice, but fail fast on `personalization`).\n",
        "\n",
        "---\n",
        "\n",
        "üéØ Takeaway:\n",
        "Right now, your orchestrator is **operationally solid**: it executes, handles errors, and logs. That‚Äôs exactly what you need before layering on more advanced features like YAML configs or LangSmith observability.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zd7cI2-FNlJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ChuxS0abEELJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}