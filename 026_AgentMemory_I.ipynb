{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyML8ct+nfhipmHwPqJGfJM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/026_AgentMemory_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸ§  Key Lessons from the Memory + Feedback Agent\n",
        "\n",
        "### 1. **Agent Memory Must Be Explicitly Managed**\n",
        "\n",
        "* Agents donâ€™t â€œrememberâ€ unless you **manually append** previous messages (`{\"role\": \"user\"}`, `{\"role\": \"assistant\"}`) to the `messages` list.\n",
        "* This is how the LLM gets **context** of what happened before â€” just like a chat history.\n",
        "* Use `memory.extend([...])` to grow the context gradually and intentionally.\n",
        "\n",
        "> âœ… *Memory is not automatic. It is your responsibility to build and manage it.*\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Feedback Loops Enable Iteration**\n",
        "\n",
        "* Instead of just accepting the LLMâ€™s first summary, the agent pauses and allows for:\n",
        "\n",
        "  * ðŸ‘¤ User feedback (â€œmake this more conciseâ€)\n",
        "  * ðŸ” LLM revision based on that feedback\n",
        "* You built an **interactive revision loop** where the user stays in control.\n",
        "\n",
        "> âœ… *Agents arenâ€™t static â€” they improve through feedback.*\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Stateful Agents Are More Powerful**\n",
        "\n",
        "* Because you stored memory and summaries:\n",
        "\n",
        "  * You could retain what documents were seen\n",
        "  * You could later use those summaries to write reports, generate comparisons, etc.\n",
        "\n",
        "> âœ… *Stateful design enables more intelligent, compound workflows.*\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Structured, Concise Prompts Yield Better Results**\n",
        "\n",
        "* By building prompts that clearly define:\n",
        "\n",
        "  * The system role (e.g., summarizer)\n",
        "  * The task (e.g., â€œsummarize this docâ€)\n",
        "  * The content (`content` block)\n",
        "* You made the LLM **more predictable and accurate**.\n",
        "\n",
        "> âœ… *Prompt quality directly affects agent performance.*\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Clear Feedback = Better LLM Revisions**\n",
        "\n",
        "* Your feedback (â€œmake it more succinct and use markdownâ€) was:\n",
        "\n",
        "  * Direct\n",
        "  * Structured\n",
        "  * Easy for the LLM to interpret and act on\n",
        "* The revised outputs were significantly better as a result.\n",
        "\n",
        "> âœ… *LLMs are excellent rewriters â€” when given good instructions.*\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ’¾ Knowledge to Retain Going Forward\n",
        "\n",
        "| Concept                     | Why It Matters                                                        |\n",
        "| --------------------------- | --------------------------------------------------------------------- |\n",
        "| **Memory Management**       | Enables agents to work across multiple steps or documents.            |\n",
        "| **Structured Prompts**      | Improve output consistency and allow for easier parsing.              |\n",
        "| **Feedback Loops**          | Unlock the ability to refine, correct, and improve LLM output.        |\n",
        "| **Explicit State Tracking** | Crucial for planning, revisiting, or chaining agent tasks.            |\n",
        "| **Agent Design Pattern**    | Agents orchestrate tools, respond to feedback, and build upon memory. |\n",
        "\n"
      ],
      "metadata": {
        "id": "Cb3KG8RruFqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR8hDyBisESE",
        "outputId": "855e7a06-b6bd-4fc9-a768-b15548340392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/765.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU dotenv openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# ðŸ”¹ Step 1: Imports and Setup\n",
        "source_dir = \"/content/docs_folder\"\n",
        "\n",
        "# Make sure the directory exists\n",
        "if not os.path.exists(source_dir):\n",
        "    raise FileNotFoundError(f\"ðŸ“ Directory not found: {source_dir}\")\n",
        "\n",
        "# List and build full file paths\n",
        "file_list = [\n",
        "    os.path.join(source_dir, f)\n",
        "    for f in os.listdir(source_dir)\n",
        "    if os.path.isfile(os.path.join(source_dir, f))\n",
        "]\n",
        "\n",
        "# Display the found files\n",
        "print(\"ðŸ“‚ Files found:\")\n",
        "for file in file_list:\n",
        "    print(\"  -\", file)\n",
        "\n",
        "# ðŸ”¹ Step 2: Utility to Read File Preview\n",
        "def read_file(path, max_chars=1500):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()[:max_chars]\n",
        "\n",
        "# ðŸ”¹ Step 3: Prompt Builder\n",
        "def build_summary_prompt(content):\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful assistant who summarizes lecture notes clearly and concisely.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Please summarize the following document:\\n\\n{content}\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "# ðŸ”¹ Step 4: LLM Call\n",
        "def generate_response(messages, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# ðŸ”¹ Step 5: Summary + Feedback Loop\n",
        "memory = []\n",
        "summaries = []\n",
        "\n",
        "for i, file_path in enumerate(file_list):\n",
        "    filename = os.path.basename(file_path)\n",
        "    content = read_file(file_path)\n",
        "\n",
        "    print(f\"\\nðŸ“„ Document {i+1}/{len(file_list)}: {filename}\")\n",
        "\n",
        "    # Start a new summary conversation\n",
        "    messages = memory + build_summary_prompt(content)\n",
        "    summary = generate_response(messages)\n",
        "\n",
        "    print(\"\\nðŸ§  Summary:\\n\")\n",
        "    print(textwrap.fill(summary, width=80))\n",
        "\n",
        "    while True:\n",
        "        feedback = input(\"\\nðŸ’¬ Feedback (or 'next' / 'stop'): \").strip().lower()\n",
        "\n",
        "        if feedback == \"next\":\n",
        "            memory.extend([\n",
        "                {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "                {\"role\": \"assistant\", \"content\": summary}\n",
        "            ])\n",
        "            summaries.append({\"file\": filename, \"summary\": summary})\n",
        "            break\n",
        "\n",
        "        elif feedback == \"stop\":\n",
        "            print(\"\\nðŸ‘‹ Stopping summary loop.\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            messages.append({\"role\": \"user\", \"content\": feedback})\n",
        "            summary = generate_response(messages)\n",
        "            print(\"\\nðŸ” Updated Summary:\\n\")\n",
        "            print(textwrap.fill(summary, width=80))\n",
        "\n",
        "    if feedback == \"stop\":\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0-YZl7Qt8xG",
        "outputId": "b12b344d-9382-4166-b678-3585d442ed40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“„ Document 1/5: 004_AGENT_Tools.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "The document discusses the importance of describing tools to an AI agent in an\n",
            "agentic AI system. It gives an example of automating documentation for Python\n",
            "code by scanning Python files in a src/ directory and generating documentation\n",
            "files in a docs/ directory. The importance of defining tools clearly with\n",
            "naming, parameters, and structured metadata is emphasized. It outlines steps to\n",
            "define tools with structured metadata in Python and using JSON schema to define\n",
            "parameters effectively for AI systems.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): next\n",
            "\n",
            "ðŸ“„ Document 2/5: 001_PArse_the Response.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "The document discusses the process of parsing a response generated by an AI\n",
            "language model (LLM) to extract the intended action and its parameters. The\n",
            "response is expected to follow a predefined structure, typically in JSON format\n",
            "within a markdown code block, for clear parsing and execution. The code snippet\n",
            "provided demonstrates how to parse the response and extract the action\n",
            "information, returning a structured action dictionary. This parsing step is\n",
            "crucial to ensure the response is actionable and includes examples of structured\n",
            "output for tool_name and arguments.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): next\n",
            "\n",
            "ðŸ“„ Document 3/5: 003_gent Feedback and Memory.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "The document discusses the importance of updating an agent's memory after\n",
            "executing an action in an interaction. The agent's memory records user requests,\n",
            "actions performed, and their outcomes, enabling the agent to retain context for\n",
            "making informed decisions in future interactions. The code snippet provided\n",
            "demonstrates how to update the memory with the LLM's response and the result of\n",
            "the executed action. This process allows the agent to refine its behavior\n",
            "dynamically as the memory grows and track the status of its work. The final step\n",
            "in each iteration is to decide whether to continue or terminate based on the\n",
            "action executed and the task's state.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): stop\n",
            "\n",
            "ðŸ‘‹ Stopping summary loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸ§  What Youâ€™re Learning About Agent Memory\n",
        "\n",
        "### 1. **Memory Lives Outside the Loop**\n",
        "\n",
        "```python\n",
        "memory = []\n",
        "```\n",
        "\n",
        "* Memory starts empty and grows across files.\n",
        "* This mirrors how an agent would accumulate experience or context over a session.\n",
        "* If you restarted this cell, all memory would reset â€” itâ€™s up to *you* to persist it if needed (e.g. to disk).\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **The Agent's Brain = memory + prompt**\n",
        "\n",
        "```python\n",
        "messages = memory + build_summary_prompt(content)\n",
        "```\n",
        "\n",
        "* The current prompt is combined with all prior memory to form the **complete input** for the LLM.\n",
        "* This simulates how a human thinks: \"Given everything I already know, hereâ€™s what I now need to respond to.\"\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **The Agent Responds to You**\n",
        "\n",
        "```python\n",
        "feedback = input(\"ðŸ’¬ Feedback...\")\n",
        "```\n",
        "\n",
        "* Your feedback becomes the *new prompt* for the next round.\n",
        "* The model treats that feedback as if it's part of an ongoing chat â€” which it is.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Memory Grows After Every Action**\n",
        "\n",
        "```python\n",
        "memory.extend([\n",
        "    {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "    {\"role\": \"assistant\", \"content\": summary}\n",
        "])\n",
        "```\n",
        "\n",
        "* You store both the user's task and the model's output as the **basis for future reasoning.**\n",
        "* This is crucial â€” the agent canâ€™t remember what it did unless you **manually store it**.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **You (the user) Control the Loop**\n",
        "\n",
        "```python\n",
        "if feedback == \"stop\":\n",
        "    break\n",
        "```\n",
        "\n",
        "* You decide when the session ends.\n",
        "* This is the earliest version of **agent control flow**, and it will later become programmatic (â€œterminateâ€ tool, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© Key Mental Model:\n",
        "\n",
        "> You're building a **rolling conversation transcript** that the model uses to make smarter decisions as it goes.\n",
        "\n",
        "Itâ€™s not unlike a court reporter: everything said gets recorded, and later responses are judged in the context of the full record.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary: Why This Code Is Important\n",
        "\n",
        "| Concept                      | What It Teaches                 |\n",
        "| ---------------------------- | ------------------------------- |\n",
        "| `memory = []`                | You own the agentâ€™s memory      |\n",
        "| `messages = memory + prompt` | Context = memory + task         |\n",
        "| `extend()` after each step   | Memory grows as the agent works |\n",
        "| Feedback inside loop         | The agent iterates and improves |\n",
        "| Exit condition               | Agents need boundaries          |\n",
        "\n"
      ],
      "metadata": {
        "id": "S8hjQ7nVwlQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Understanding the difference between `.append()` and `.extend()` is **key to managing memory correctly** in agent workflows.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Difference Between `append()` vs `extend()`\n",
        "\n",
        "| Method     | What It Does                                                                 |\n",
        "| ---------- | ---------------------------------------------------------------------------- |\n",
        "| `append()` | Adds **a single object** to the end of a list.                               |\n",
        "| `extend()` | Adds **each item from another iterable (like a list)** to the original list. |\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Let's look at what happens in your code:\n",
        "\n",
        "```python\n",
        "memory.extend([\n",
        "    {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "    {\"role\": \"assistant\", \"content\": summary}\n",
        "])\n",
        "```\n",
        "\n",
        "This adds **two new dictionary entries** (chat turns) to `memory`. After execution, `memory` will contain:\n",
        "\n",
        "```python\n",
        "[\n",
        "    ...  # all previous chat turns\n",
        "    {\"role\": \"user\", \"content\": \"Summarize document: file_01.txt\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"This doc explains memory in LLM agents...\"}\n",
        "]\n",
        "```\n",
        "\n",
        "âœ… Thatâ€™s exactly what we want: **two new turns in the conversation**.\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ What would go wrong with `append()`?\n",
        "\n",
        "If you used `.append()` here:\n",
        "\n",
        "```python\n",
        "memory.append([\n",
        "    {\"role\": \"user\", \"content\": \"...\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"...\"}\n",
        "])\n",
        "```\n",
        "\n",
        "Your `memory` list would now contain:\n",
        "\n",
        "```python\n",
        "[\n",
        "    ...,\n",
        "    [  # a nested list\n",
        "        {\"role\": \"user\", ...},\n",
        "        {\"role\": \"assistant\", ...}\n",
        "    ]\n",
        "]\n",
        "```\n",
        "\n",
        "ðŸ‘Ž That breaks the format. The `messages` list must be **flat**, not nested. The OpenAI API expects a list of dictionaries, not a list of lists.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Why You Use `append()` for `summaries`\n",
        "\n",
        "```python\n",
        "summaries.append({\"file\": filename, \"summary\": summary})\n",
        "```\n",
        "\n",
        "* In this case, you are adding **one dictionary** to the list of summaries.\n",
        "* So `.append()` is correct â€” you're not trying to merge multiple items in.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Rule of Thumb:\n",
        "\n",
        "| Use this...              | When you...                                        |\n",
        "| ------------------------ | -------------------------------------------------- |\n",
        "| `append(item)`           | Want to add **a single object** to the list        |\n",
        "| `extend([item1, item2])` | Want to add **multiple objects** from another list |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XlnV9XFixsSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX2asMuHv4hO",
        "outputId": "1baeb5b2-9a91-4f58-a7c0-c11d4188494b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user', 'content': 'Summarize document: 004_AGENT_Tools.txt'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'The document discusses the importance of describing tools to an AI agent in an agentic AI system. It gives an example of automating documentation for Python code by scanning Python files in a src/ directory and generating documentation files in a docs/ directory. The importance of defining tools clearly with naming, parameters, and structured metadata is emphasized. It outlines steps to define tools with structured metadata in Python and using JSON schema to define parameters effectively for AI systems.'},\n",
              " {'role': 'user', 'content': 'Summarize document: 001_PArse_the Response.txt'},\n",
              " {'role': 'assistant',\n",
              "  'content': 'The document discusses the process of parsing a response generated by an AI language model (LLM) to extract the intended action and its parameters. The response is expected to follow a predefined structure, typically in JSON format within a markdown code block, for clear parsing and execution. The code snippet provided demonstrates how to parse the response and extract the action information, returning a structured action dictionary. This parsing step is crucial to ensure the response is actionable and includes examples of structured output for tool_name and arguments.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(textwrap.fill(summary, width=80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xO6tKSNv5Xq",
        "outputId": "b31b6ac9-3dbc-4820-cea1-4c398d9e822c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The document discusses the importance of updating an agent's memory after\n",
            "executing an action in an interaction. The agent's memory records user requests,\n",
            "actions performed, and their outcomes, enabling the agent to retain context for\n",
            "making informed decisions in future interactions. The code snippet provided\n",
            "demonstrates how to update the memory with the LLM's response and the result of\n",
            "the executed action. This process allows the agent to refine its behavior\n",
            "dynamically as the memory grows and track the status of its work. The final step\n",
            "in each iteration is to decide whether to continue or terminate based on the\n",
            "action executed and the task's state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Youâ€™re seeing a mismatch between:\n",
        "\n",
        "* What **was summarized** âœ…\n",
        "* What got **stored in memory** ðŸ§ \n",
        "* And what got **added to the summaries list** ðŸ“„\n",
        "\n",
        "Letâ€™s break it down and debug what happened.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” Whatâ€™s the Problem?\n",
        "\n",
        "You summarized **3 files**, but only **2 got stored in memory** and only **1 made it into `summaries`**.\n",
        "\n",
        "Hereâ€™s why:\n",
        "\n",
        "### âœ… This block adds to memory and summaries:\n",
        "\n",
        "```python\n",
        "if feedback == \"next\":\n",
        "    memory.extend([\n",
        "        {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "        {\"role\": \"assistant\", \"content\": summary}\n",
        "    ])\n",
        "    summaries.append({\"file\": filename, \"summary\": summary})\n",
        "    break\n",
        "```\n",
        "\n",
        "### âŒ But this block does *not* store anything:\n",
        "\n",
        "```python\n",
        "elif feedback == \"stop\":\n",
        "    print(\"\\nðŸ‘‹ Stopping summary loop.\")\n",
        "    break\n",
        "```\n",
        "\n",
        "So when you hit `\"stop\"` on the **third document**, the loop exited before saving it to memory or summaries.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… How to Fix It\n",
        "\n",
        "You want to save the third summary **before** exiting when `\"stop\"` is triggered.\n",
        "\n",
        "Hereâ€™s the fix:\n",
        "\n",
        "```python\n",
        "elif feedback == \"stop\":\n",
        "    # âœ… Save the summary before breaking\n",
        "    memory.extend([\n",
        "        {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "        {\"role\": \"assistant\", \"content\": summary}\n",
        "    ])\n",
        "    summaries.append({\"file\": filename, \"summary\": summary})\n",
        "    \n",
        "    print(\"\\nðŸ‘‹ Stopping summary loop.\")\n",
        "    break\n",
        "```\n",
        "\n",
        "This way, the **current summary is preserved** before terminating the loop.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary of What You Learned\n",
        "\n",
        "| Issue               | Why It Happened         | How to Fix                                     |\n",
        "| ------------------- | ----------------------- | ---------------------------------------------- |\n",
        "| 3rd summary missing | `\"stop\"` breaks early   | Add `.extend()` and `.append()` before `break` |\n",
        "| Memory skipped      | Same reason â€” no update | Must persist state before exit                 |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r1D814dPzwUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# ðŸ”¹ Step 1: Imports and Setup\n",
        "source_dir = \"/content/docs_folder\"\n",
        "\n",
        "# Make sure the directory exists\n",
        "if not os.path.exists(source_dir):\n",
        "    raise FileNotFoundError(f\"ðŸ“ Directory not found: {source_dir}\")\n",
        "\n",
        "# List and build full file paths\n",
        "file_list = [\n",
        "    os.path.join(source_dir, f)\n",
        "    for f in os.listdir(source_dir)\n",
        "    if os.path.isfile(os.path.join(source_dir, f))\n",
        "]\n",
        "\n",
        "# Display the found files\n",
        "print(\"ðŸ“‚ Files found:\")\n",
        "for file in file_list:\n",
        "    print(\"  -\", file)\n",
        "\n",
        "# ðŸ”¹ Step 2: Utility to Read File Preview\n",
        "def read_file(path, max_chars=1500):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()[:max_chars]\n",
        "\n",
        "# ðŸ”¹ Step 3: Prompt Builder\n",
        "def build_summary_prompt(content):\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a helpful assistant who summarizes lecture notes clearly and concisely.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Please summarize the following document:\\n\\n{content}\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "# ðŸ”¹ Step 4: LLM Call\n",
        "def generate_response(messages, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# ðŸ”¹ Step 5: Summary + Feedback Loop\n",
        "memory = []\n",
        "summaries = []\n",
        "\n",
        "for i, file_path in enumerate(file_list):\n",
        "    filename = os.path.basename(file_path)\n",
        "    content = read_file(file_path)\n",
        "\n",
        "    print(f\"\\nðŸ“„ Document {i+1}/{len(file_list)}: {filename}\")\n",
        "\n",
        "    # Start a new summary conversation\n",
        "    messages = memory + build_summary_prompt(content)\n",
        "    summary = generate_response(messages)\n",
        "\n",
        "    print(\"\\nðŸ§  Summary:\\n\")\n",
        "    print(textwrap.fill(summary, width=80))\n",
        "\n",
        "    while True:\n",
        "        feedback = input(\"\\nðŸ’¬ Feedback (or 'next' / 'stop'): \").strip().lower()\n",
        "\n",
        "        if feedback == \"next\":\n",
        "            memory.extend([\n",
        "                {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "                {\"role\": \"assistant\", \"content\": summary}\n",
        "            ])\n",
        "            summaries.append({\"file\": filename, \"summary\": summary})\n",
        "            break\n",
        "\n",
        "        elif feedback == \"stop\":\n",
        "            # âœ… Save the summary before breaking\n",
        "            memory.extend([\n",
        "                {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "                {\"role\": \"assistant\", \"content\": summary}\n",
        "            ])\n",
        "            summaries.append({\"file\": filename, \"summary\": summary})\n",
        "\n",
        "            print(\"\\nðŸ‘‹ Stopping summary loop.\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            messages.append({\"role\": \"user\", \"content\": feedback})\n",
        "            summary = generate_response(messages)\n",
        "            print(\"\\nðŸ” Updated Summary:\\n\")\n",
        "            print(textwrap.fill(summary, width=80))\n",
        "\n",
        "    if feedback == \"stop\":\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4e9UTKHwVRB",
        "outputId": "eacfb2f4-99d3-4ad4-948d-b5edb08dd5a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Files found:\n",
            "  - /content/docs_folder/004_AGENT_Tools.txt\n",
            "  - /content/docs_folder/001_PArse_the Response.txt\n",
            "  - /content/docs_folder/003_gent Feedback and Memory.txt\n",
            "  - /content/docs_folder/000_Prompting for Agents -GAIL.txt\n",
            "  - /content/docs_folder/002_Execute_the_Action.txt\n",
            "\n",
            "ðŸ“„ Document 1/5: 004_AGENT_Tools.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "The document discusses the importance of defining tools for an agentic AI system\n",
            "and emphasizes the need for clear naming, parameters, and structured metadata.\n",
            "An example is provided for automating documentation for Python code by listing\n",
            "files, reading file content, and writing documentation files. The importance of\n",
            "clearly defining tools to enable effective use by the AI agent is highlighted.\n",
            "The document also introduces steps to defining tools with structured metadata in\n",
            "Python and using JSON schema to define parameters.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): next\n",
            "\n",
            "ðŸ“„ Document 2/5: 001_PArse_the Response.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "The document outlines the process of parsing the response generated by the LLM\n",
            "(Language Model) to extract the intended action and its parameters in a\n",
            "structured manner. It explains how the response, typically in a predefined\n",
            "format like JSON within a markdown code block, is parsed to locate the action\n",
            "markers and extract the relevant content. The provided Python code snippet\n",
            "demonstrates the parsing process and handling cases where the response does not\n",
            "contain a valid action block. The parsing step is crucial for providing a\n",
            "structured action dictionary that includes the tool name and arguments, enabling\n",
            "the agent to effectively process and execute the identified action.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): next\n",
            "\n",
            "ðŸ“„ Document 3/5: 003_gent Feedback and Memory.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "The document discusses the importance of updating the agent's memory after\n",
            "executing an action. The memory serves as a record of interactions, including\n",
            "user requests, actions taken, and their outcomes. By appending information to\n",
            "the memory, the agent can retain context and make more informed decisions in\n",
            "future iterations. The document explains how the memory is updated with the\n",
            "LLM's response and the result of the executed action. It also highlights the\n",
            "roles of the assistant and the user in capturing structured responses and\n",
            "feedback, respectively. By maintaining a history of interactions, the agent can\n",
            "refine its behaviors dynamically as the memory grows. The document concludes by\n",
            "mentioning the final step of deciding whether to continue or terminate based on\n",
            "the executed action and the task's state.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): stop\n",
            "\n",
            "ðŸ‘‹ Stopping summary loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Print the Final Agent Memory\n",
        "\n",
        "print(\"\\nðŸ§  Final Agent Memory:\")\n",
        "for i, msg in enumerate(memory):\n",
        "    role = msg[\"role\"]\n",
        "    content = textwrap.fill(msg[\"content\"], width=80)\n",
        "    print(f\"\\n{i+1:02d}. {role.upper()}:\\n{content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M47IP-sK0cj3",
        "outputId": "a61d0f04-99ee-42ad-c91c-2e55b7873f56"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§  Final Agent Memory:\n",
            "\n",
            "01. USER:\n",
            "Summarize document: 004_AGENT_Tools.txt\n",
            "\n",
            "02. ASSISTANT:\n",
            "The document discusses the importance of defining tools for an agentic AI system\n",
            "and emphasizes the need for clear naming, parameters, and structured metadata.\n",
            "An example is provided for automating documentation for Python code by listing\n",
            "files, reading file content, and writing documentation files. The importance of\n",
            "clearly defining tools to enable effective use by the AI agent is highlighted.\n",
            "The document also introduces steps to defining tools with structured metadata in\n",
            "Python and using JSON schema to define parameters.\n",
            "\n",
            "03. USER:\n",
            "Summarize document: 001_PArse_the Response.txt\n",
            "\n",
            "04. ASSISTANT:\n",
            "The document outlines the process of parsing the response generated by the LLM\n",
            "(Language Model) to extract the intended action and its parameters in a\n",
            "structured manner. It explains how the response, typically in a predefined\n",
            "format like JSON within a markdown code block, is parsed to locate the action\n",
            "markers and extract the relevant content. The provided Python code snippet\n",
            "demonstrates the parsing process and handling cases where the response does not\n",
            "contain a valid action block. The parsing step is crucial for providing a\n",
            "structured action dictionary that includes the tool name and arguments, enabling\n",
            "the agent to effectively process and execute the identified action.\n",
            "\n",
            "05. USER:\n",
            "Summarize document: 003_gent Feedback and Memory.txt\n",
            "\n",
            "06. ASSISTANT:\n",
            "The document discusses the importance of updating the agent's memory after\n",
            "executing an action. The memory serves as a record of interactions, including\n",
            "user requests, actions taken, and their outcomes. By appending information to\n",
            "the memory, the agent can retain context and make more informed decisions in\n",
            "future iterations. The document explains how the memory is updated with the\n",
            "LLM's response and the result of the executed action. It also highlights the\n",
            "roles of the assistant and the user in capturing structured responses and\n",
            "feedback, respectively. By maintaining a history of interactions, the agent can\n",
            "refine its behaviors dynamically as the memory grows. The document concludes by\n",
            "mentioning the final step of deciding whether to continue or terminate based on\n",
            "the executed action and the task's state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Print All Summaries\n",
        "\n",
        "print(\"\\nðŸ“š All Summaries:\")\n",
        "for i, summary_obj in enumerate(summaries):\n",
        "    filename = summary_obj[\"file\"]\n",
        "    summary = textwrap.fill(summary_obj[\"summary\"], width=80)\n",
        "\n",
        "    print(f\"\\n{i+1:02d}. ðŸ“„ {filename}:\\n{summary}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYbRSQpK0Zfc",
        "outputId": "984290da-9ec6-4d77-b657-84a57fd18fb1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“š All Summaries:\n",
            "\n",
            "01. ðŸ“„ 004_AGENT_Tools.txt:\n",
            "The document discusses the importance of defining tools for an agentic AI system\n",
            "and emphasizes the need for clear naming, parameters, and structured metadata.\n",
            "An example is provided for automating documentation for Python code by listing\n",
            "files, reading file content, and writing documentation files. The importance of\n",
            "clearly defining tools to enable effective use by the AI agent is highlighted.\n",
            "The document also introduces steps to defining tools with structured metadata in\n",
            "Python and using JSON schema to define parameters.\n",
            "\n",
            "02. ðŸ“„ 001_PArse_the Response.txt:\n",
            "The document outlines the process of parsing the response generated by the LLM\n",
            "(Language Model) to extract the intended action and its parameters in a\n",
            "structured manner. It explains how the response, typically in a predefined\n",
            "format like JSON within a markdown code block, is parsed to locate the action\n",
            "markers and extract the relevant content. The provided Python code snippet\n",
            "demonstrates the parsing process and handling cases where the response does not\n",
            "contain a valid action block. The parsing step is crucial for providing a\n",
            "structured action dictionary that includes the tool name and arguments, enabling\n",
            "the agent to effectively process and execute the identified action.\n",
            "\n",
            "03. ðŸ“„ 003_gent Feedback and Memory.txt:\n",
            "The document discusses the importance of updating the agent's memory after\n",
            "executing an action. The memory serves as a record of interactions, including\n",
            "user requests, actions taken, and their outcomes. By appending information to\n",
            "the memory, the agent can retain context and make more informed decisions in\n",
            "future iterations. The document explains how the memory is updated with the\n",
            "LLM's response and the result of the executed action. It also highlights the\n",
            "roles of the assistant and the user in capturing structured responses and\n",
            "feedback, respectively. By maintaining a history of interactions, the agent can\n",
            "refine its behaviors dynamically as the memory grows. The document concludes by\n",
            "mentioning the final step of deciding whether to continue or terminate based on\n",
            "the executed action and the task's state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Revise the Summaries"
      ],
      "metadata": {
        "id": "0J5fSg8F0-vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ”¹ Step 5: Summary + Feedback Loop\n",
        "memory = []\n",
        "summaries = []\n",
        "\n",
        "for i, file_path in enumerate(file_list):\n",
        "    filename = os.path.basename(file_path)\n",
        "    content = read_file(file_path)\n",
        "\n",
        "    print(f\"\\nðŸ“„ Document {i+1}/{len(file_list)}: {filename}\")\n",
        "\n",
        "    # Start a new summary conversation\n",
        "    messages = memory + build_summary_prompt(content)\n",
        "    summary = generate_response(messages)\n",
        "\n",
        "    print(\"\\nðŸ§  Summary:\\n\")\n",
        "    print(textwrap.fill(summary, width=80))\n",
        "\n",
        "    while True:\n",
        "        feedback = input(\"\\nðŸ’¬ Feedback (or 'next' / 'stop'): \").strip().lower()\n",
        "\n",
        "        if feedback == \"next\":\n",
        "            memory.extend([\n",
        "                {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "                {\"role\": \"assistant\", \"content\": summary}\n",
        "            ])\n",
        "            summaries.append({\"file\": filename, \"summary\": summary})\n",
        "            break\n",
        "\n",
        "        elif feedback == \"stop\":\n",
        "            # âœ… Save the summary before breaking\n",
        "            memory.extend([\n",
        "                {\"role\": \"user\", \"content\": f\"Summarize document: {filename}\"},\n",
        "                {\"role\": \"assistant\", \"content\": summary}\n",
        "            ])\n",
        "            summaries.append({\"file\": filename, \"summary\": summary})\n",
        "\n",
        "            print(\"\\nðŸ‘‹ Stopping summary loop.\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            messages.append({\"role\": \"user\", \"content\": feedback})\n",
        "            summary = generate_response(messages)\n",
        "            print(\"\\nðŸ” Updated Summary:\\n\")\n",
        "            print(textwrap.fill(summary, width=80))\n",
        "\n",
        "    if feedback == \"stop\":\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcGYWq_E02E2",
        "outputId": "44464118-d91c-48ad-bd03-728b1b03e097"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“„ Document 1/5: 004_AGENT_Tools.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "The document discusses the importance of effectively describing tools to an AI\n",
            "agent for successful interaction. It provides an example of automating\n",
            "documentation for Python code and emphasizes the need for clear tool\n",
            "definitions, including naming, parameters, and structured metadata. It outlines\n",
            "steps for defining tools, such as creating a basic function in Python and using\n",
            "JSON Schema to define parameters. The goal is to ensure that the AI agent\n",
            "understands how to utilize the tools provided effectively.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): Can you make this more succint and ues bullet points and markdown?\n",
            "\n",
            "ðŸ” Updated Summary:\n",
            "\n",
            "- **AI-Agent Tool Descriptions and Naming**:   - Explains the importance of\n",
            "defining tools for an AI agent.   - Emphasizes the significance of naming,\n",
            "parameters, and structured metadata. - **Example: Automating Documentation for\n",
            "Python Code**:   - Illustrates a scenario where an AI agent generates\n",
            "documentation for Python files.   - Lists necessary functions such as listing\n",
            "and reading files, and writing documentation. - **Step 1: Defining a Tool with\n",
            "Structured Metadata**:   - Suggests a basic Python code snippet for listing\n",
            "Python files in a directory.   - Indicates the necessity for a more structured\n",
            "description for AI understanding. - **Step 2: Using JSON Schema to Define\n",
            "Parameters**:   - Describes the utilization of JSON Schema to define tool\n",
            "parameters succinctly.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): next\n",
            "\n",
            "ðŸ“„ Document 2/5: 001_PArse_the Response.txt\n",
            "\n",
            "ðŸ§  Summary:\n",
            "\n",
            "Summary: The document discusses the importance of parsing the response generated\n",
            "by an LLM (Large Language Model) to extract the intended action and parameters\n",
            "in a structured manner. It explains the process of locating and extracting the\n",
            "action block enclosed within action markers, typically in a JSON format within a\n",
            "markdown code block. A Python function `parse_action` is provided to parse the\n",
            "response into a structured action dictionary, verifying the presence of\n",
            "essential fields like \"tool_name\" and \"args.\" If the response is not in a valid\n",
            "format, an error message is returned. The parsed output includes the tool name\n",
            "and its arguments, enabling the agent to identify and execute the intended\n",
            "action accurately.\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): Can you make this more succint and ues bullet points and markdown?\n",
            "\n",
            "ðŸ” Updated Summary:\n",
            "\n",
            "- **Parsing the Response**:   - Extract the intended action and parameters from\n",
            "the LLM's output.   - Response should follow a predefined structure, like JSON\n",
            "in a markdown code block.   - Use action markers to locate and extract content\n",
            "for parsing.  - **Code Function to Parse Action**:   - Function\n",
            "`parse_action(response: str) -> Dict` extracts structured action dictionary.   -\n",
            "Attempts to extract the action content and parse it as JSON.   - If valid\n",
            "`tool_name` and `args` are present, returns the response JSON.   - Otherwise,\n",
            "defaults to an error message for invalid or missing JSON response.  -\n",
            "**Structured Output**:   - Parsed output includes `tool_name` and `args` for\n",
            "actionable information.   - Example output:     ```json     {\n",
            "\"tool_name\": \"list_files\",         \"args\": {}     }     ```\n",
            "\n",
            "ðŸ’¬ Feedback (or 'next' / 'stop'): stop\n",
            "\n",
            "ðŸ‘‹ Stopping summary loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Print the Final Agent Memory\n",
        "\n",
        "print(\"\\nðŸ§  Final Agent Memory:\")\n",
        "for i, msg in enumerate(memory):\n",
        "    role = msg[\"role\"]\n",
        "    content = textwrap.fill(msg[\"content\"], width=80)\n",
        "    print(f\"\\n{i+1:02d}. {role.upper()}:\\n{content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZgU_sdm09Lj",
        "outputId": "77de5920-1c6b-49b5-e019-21c49911fac7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§  Final Agent Memory:\n",
            "\n",
            "01. USER:\n",
            "Summarize document: 004_AGENT_Tools.txt\n",
            "\n",
            "02. ASSISTANT:\n",
            "- **AI-Agent Tool Descriptions and Naming**:   - Explains the importance of\n",
            "defining tools for an AI agent.   - Emphasizes the significance of naming,\n",
            "parameters, and structured metadata. - **Example: Automating Documentation for\n",
            "Python Code**:   - Illustrates a scenario where an AI agent generates\n",
            "documentation for Python files.   - Lists necessary functions such as listing\n",
            "and reading files, and writing documentation. - **Step 1: Defining a Tool with\n",
            "Structured Metadata**:   - Suggests a basic Python code snippet for listing\n",
            "Python files in a directory.   - Indicates the necessity for a more structured\n",
            "description for AI understanding. - **Step 2: Using JSON Schema to Define\n",
            "Parameters**:   - Describes the utilization of JSON Schema to define tool\n",
            "parameters succinctly.\n",
            "\n",
            "03. USER:\n",
            "Summarize document: 001_PArse_the Response.txt\n",
            "\n",
            "04. ASSISTANT:\n",
            "- **Parsing the Response**:   - Extract the intended action and parameters from\n",
            "the LLM's output.   - Response should follow a predefined structure, like JSON\n",
            "in a markdown code block.   - Use action markers to locate and extract content\n",
            "for parsing.  - **Code Function to Parse Action**:   - Function\n",
            "`parse_action(response: str) -> Dict` extracts structured action dictionary.   -\n",
            "Attempts to extract the action content and parse it as JSON.   - If valid\n",
            "`tool_name` and `args` are present, returns the response JSON.   - Otherwise,\n",
            "defaults to an error message for invalid or missing JSON response.  -\n",
            "**Structured Output**:   - Parsed output includes `tool_name` and `args` for\n",
            "actionable information.   - Example output:     ```json     {\n",
            "\"tool_name\": \"list_files\",         \"args\": {}     }     ```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Print All Summaries\n",
        "\n",
        "print(\"\\nðŸ“š All Summaries:\")\n",
        "for i, summary_obj in enumerate(summaries):\n",
        "    filename = summary_obj[\"file\"]\n",
        "    summary = textwrap.fill(summary_obj[\"summary\"], width=80)\n",
        "\n",
        "    print(f\"\\n{i+1:02d}. ðŸ“„ {filename}:\\n{summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHIL1Hfi09pg",
        "outputId": "7fdd2450-f898-4335-cff9-3966f73861c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“š All Summaries:\n",
            "\n",
            "01. ðŸ“„ 004_AGENT_Tools.txt:\n",
            "- **AI-Agent Tool Descriptions and Naming**:   - Explains the importance of\n",
            "defining tools for an AI agent.   - Emphasizes the significance of naming,\n",
            "parameters, and structured metadata. - **Example: Automating Documentation for\n",
            "Python Code**:   - Illustrates a scenario where an AI agent generates\n",
            "documentation for Python files.   - Lists necessary functions such as listing\n",
            "and reading files, and writing documentation. - **Step 1: Defining a Tool with\n",
            "Structured Metadata**:   - Suggests a basic Python code snippet for listing\n",
            "Python files in a directory.   - Indicates the necessity for a more structured\n",
            "description for AI understanding. - **Step 2: Using JSON Schema to Define\n",
            "Parameters**:   - Describes the utilization of JSON Schema to define tool\n",
            "parameters succinctly.\n",
            "\n",
            "02. ðŸ“„ 001_PArse_the Response.txt:\n",
            "- **Parsing the Response**:   - Extract the intended action and parameters from\n",
            "the LLM's output.   - Response should follow a predefined structure, like JSON\n",
            "in a markdown code block.   - Use action markers to locate and extract content\n",
            "for parsing.  - **Code Function to Parse Action**:   - Function\n",
            "`parse_action(response: str) -> Dict` extracts structured action dictionary.   -\n",
            "Attempts to extract the action content and parse it as JSON.   - If valid\n",
            "`tool_name` and `args` are present, returns the response JSON.   - Otherwise,\n",
            "defaults to an error message for invalid or missing JSON response.  -\n",
            "**Structured Output**:   - Parsed output includes `tool_name` and `args` for\n",
            "actionable information.   - Example output:     ```json     {\n",
            "\"tool_name\": \"list_files\",         \"args\": {}     }     ```\n"
          ]
        }
      ]
    }
  ]
}