{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMP4lfzPpYGvzx5aj3GRkuI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/024_ParseResponse_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† **What‚Äôs the next level of parsing?**\n",
        "\n",
        "### ‚ûï Add complexity to the return structure:\n",
        "\n",
        "* Multiple actions\n",
        "* Conditional steps\n",
        "* Multi-tool reasoning\n",
        "\n",
        "This simulates real-world agent orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "## üî• Recommended Next Step:\n",
        "\n",
        "# **üß© Multi-Tool Planner Agent**\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Agent Goal:\n",
        "\n",
        "You give a natural language task like:\n",
        "\n",
        "> ‚ÄúSummarize each file in docs\\_folder and then move it into a topic folder.‚Äù\n",
        "\n",
        "The LLM returns **a list of structured steps**, like:\n",
        "\n",
        "````markdown\n",
        "```action\n",
        "[\n",
        "  {\n",
        "    \"tool_name\": \"summarize_file\",\n",
        "    \"args\": { \"filename\": \"lecture_01.txt\" }\n",
        "  },\n",
        "  {\n",
        "    \"tool_name\": \"move_file\",\n",
        "    \"args\": {\n",
        "      \"filename\": \"lecture_01.txt\",\n",
        "      \"target_folder\": \"Memory_Management\"\n",
        "    }\n",
        "  }\n",
        "]\n",
        "````\n",
        "\n",
        "\n",
        "\n",
        "### ‚úÖ What you‚Äôll build:\n",
        "- LLM returns a list of actions (instead of one)\n",
        "- You parse it with `json.loads()` into a **list of dicts**\n",
        "- You loop through each step and execute the corresponding tool (summarize, move, rename, tag‚Ä¶)\n",
        "\n",
        "---\n",
        "\n",
        "## üí° What this teaches you:\n",
        "\n",
        "| Concept | Why it matters |\n",
        "|--------|----------------|\n",
        "| ‚úÖ Multi-step reasoning | Required for real planning agents |\n",
        "| ‚úÖ Tool orchestration | Foundation of LangChain / OpenAgents style design |\n",
        "| ‚úÖ Dynamic routing | Agent decides what function to run |\n",
        "| ‚úÖ Multi-action parsing | Real-world LLMs often return batches of actions |\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Tools You'll Simulate\n",
        "\n",
        "| Tool | Args |\n",
        "|------|------|\n",
        "| `summarize_file` | `filename: str` |\n",
        "| `move_file` | `filename: str`, `target_folder: str` |\n",
        "| `tag_file` (optional) | `filename: str`, `tag: str` |\n",
        "\n",
        "---\n",
        "\n",
        "Would you like to:\n",
        "- Dive into this new **Multi-Action Planner Agent**, step by step?\n",
        "- Start with a **prompt + parser**?\n",
        "- Or do you want me to generate the full agent scaffold for you first?\n",
        "\n"
      ],
      "metadata": {
        "id": "m-NnvLK-Sswa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO0cRXcqNPYR",
        "outputId": "1966f5c4-cc41-48fc-d007-dac1233a2f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/765.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m757.8/765.0 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU dotenv openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "source_dir = \"/content/docs_folder\"\n",
        "\n",
        "# Make sure the directory exists\n",
        "if not os.path.exists(source_dir):\n",
        "    raise FileNotFoundError(f\"üìÅ Directory not found: {source_dir}\")\n",
        "\n",
        "# List and build full file paths\n",
        "file_list = [\n",
        "    os.path.join(source_dir, f)\n",
        "    for f in os.listdir(source_dir)\n",
        "    if os.path.isfile(os.path.join(source_dir, f))\n",
        "]\n",
        "\n",
        "# Display the found files\n",
        "print(\"üìÇ Files found:\")\n",
        "for file in file_list:\n",
        "    print(\"  -\", file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylHl6sdMNUGv",
        "outputId": "dc968f19-76bf-4fbd-8d74-5491f1ed09fb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Files found:\n",
            "  - /content/docs_folder/001_PArse_the Response.txt\n",
            "  - /content/docs_folder/006_Agent Loop with Function Calling.txt\n",
            "  - /content/docs_folder/000_Prompting for Agents -GAIL.txt\n",
            "  - /content/docs_folder/002_Execute_the_Action.txt\n",
            "  - /content/docs_folder/005_Using Function Calling Capabilities with LLMs.txt\n",
            "  - /content/docs_folder/003_gent Feedback and Memory.txt\n",
            "  - /content/docs_folder/004_AGENT_Tools.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß© Step-by-Step Plan"
      ],
      "metadata": {
        "id": "eLNp2JpZTWTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the multi action prompt\n",
        "def build_multi_action_prompt(file_list):\n",
        "    file_names = [os.path.basename(f) for f in file_list]\n",
        "    file_list_str = \"\\n\".join(f\"- {name}\" for name in file_names)\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an agent planner that creates a list of tool-based actions.\\n\"\n",
        "        \"You always respond with a JSON list of tool invocations inside a markdown code block, like this:\\n\\n\"\n",
        "        \"```action\\n\"\n",
        "        \"[\\n\"\n",
        "        \"  {\\n\"\n",
        "        \"    \\\"tool_name\\\": \\\"summarize_file\\\",\\n\"\n",
        "        \"    \\\"args\\\": { \\\"filename\\\": \\\"lecture_01.txt\\\" }\\n\"\n",
        "        \"  },\\n\"\n",
        "        \"  {\\n\"\n",
        "        \"    \\\"tool_name\\\": \\\"move_file\\\",\\n\"\n",
        "        \"    \\\"args\\\": { \\\"filename\\\": \\\"lecture_01.txt\\\", \\\"target_folder\\\": \\\"Memory_Management\\\" }\\n\"\n",
        "        \"  }\\n\"\n",
        "        \"]\\n\"\n",
        "        \"```\\n\\n\"\n",
        "        \"Available tools:\\n\"\n",
        "        \"- summarize_file: takes {\\\"filename\\\": str}\\n\"\n",
        "        \"- move_file: takes {\\\"filename\\\": str, \\\"target_folder\\\": str}\"\n",
        "    )\n",
        "\n",
        "    user_prompt = (\n",
        "        f\"I want to summarize and organize the following files:\\n\\n{file_list_str}\\n\\n\"\n",
        "        \"Please create an ordered list of tool actions that I should perform.\"\n",
        "    )\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "\n",
        "def generate_response(messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        max_tokens=700\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "messages = build_multi_action_prompt(file_list)\n",
        "llm_output = generate_response(messages)\n",
        "\n",
        "print(\"ü§ñ LLM Response:\\n\")\n",
        "print(llm_output)\n",
        "\n",
        "\n",
        "# üì¶ Parse the Markdown Block\n",
        "def extract_markdown_block(text: str, tag: str = \"action\") -> str:\n",
        "    pattern = rf\"```{tag}\\s*(.*?)```\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    else:\n",
        "        raise ValueError(f\"Missing markdown block with tag '{tag}'\")\n",
        "\n",
        "# ‚úÖ Load it into a Python list\n",
        "def parse_multi_action_plan(llm_response):\n",
        "    try:\n",
        "        json_block = extract_markdown_block(llm_response, tag=\"action\")\n",
        "        return json.loads(json_block)\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Failed to parse multi-action plan:\", e)\n",
        "        return []\n",
        "\n",
        "# Agent Executes Each Action\n",
        "def simulate_tool(tool_name, args):\n",
        "    if tool_name == \"summarize_file\":\n",
        "        print(f\"üìù Summarizing: {args['filename']}\")\n",
        "    elif tool_name == \"move_file\":\n",
        "        print(f\"üìÇ Moving '{args['filename']}' ‚Üí '{args['target_folder']}'\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Unknown tool: {tool_name}\")\n",
        "\n",
        "plan = parse_multi_action_plan(generate_response(build_multi_action_prompt(file_list)))\n",
        "\n",
        "print(\"\\nüõ†Ô∏è Executing agent plan...\\n\")\n",
        "for step in plan:\n",
        "    simulate_tool(step[\"tool_name\"], step[\"args\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GWUAzlWNUDg",
        "outputId": "7921009b-09f7-48cc-e593-a78b9a53c40c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ LLM Response:\n",
            "\n",
            "```action\n",
            "[\n",
            "  {\n",
            "    \"tool_name\": \"summarize_file\",\n",
            "    \"args\": { \"filename\": \"000_Prompting for Agents -GAIL.txt\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"summarize_file\",\n",
            "    \"args\": { \"filename\": \"001_PArse_the Response.txt\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"summarize_file\",\n",
            "    \"args\": { \"filename\": \"002_Execute_the_Action.txt\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"summarize_file\",\n",
            "    \"args\": { \"filename\": \"003_gent Feedback and Memory.txt\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"summarize_file\",\n",
            "    \"args\": { \"filename\": \"004_AGENT_Tools.txt\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"summarize_file\",\n",
            "    \"args\": { \"filename\": \"005_Using Function Calling Capabilities with LLMs.txt\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"summarize_file\",\n",
            "    \"args\": { \"filename\": \"006_Agent Loop with Function Calling.txt\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"move_file\",\n",
            "    \"args\": { \"filename\": \"000_Prompting for Agents -GAIL.txt\", \"target_folder\": \"Organized_Summaries\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"move_file\",\n",
            "    \"args\": { \"filename\": \"001_PArse_the Response.txt\", \"target_folder\": \"Organized_Summaries\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"move_file\",\n",
            "    \"args\": { \"filename\": \"002_Execute_the_Action.txt\", \"target_folder\": \"Organized_Summaries\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"move_file\",\n",
            "    \"args\": { \"filename\": \"003_gent Feedback and Memory.txt\", \"target_folder\": \"Organized_Summaries\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"move_file\",\n",
            "    \"args\": { \"filename\": \"004_AGENT_Tools.txt\", \"target_folder\": \"Organized_Summaries\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"move_file\",\n",
            "    \"args\": { \"filename\": \"005_Using Function Calling Capabilities with LLMs.txt\", \"target_folder\": \"Organized_Summaries\" }\n",
            "  },\n",
            "  {\n",
            "    \"tool_name\": \"move_file\",\n",
            "    \"args\": { \"filename\": \"006_Agent Loop with Function Calling.txt\", \"target_folder\": \"Organized_Summaries\" }\n",
            "  }\n",
            "]\n",
            "```\n",
            "\n",
            "üõ†Ô∏è Executing agent plan...\n",
            "\n",
            "üìù Summarizing: 000_Prompting for Agents -GAIL.txt\n",
            "üìù Summarizing: 001_PArse_the Response.txt\n",
            "üìù Summarizing: 002_Execute_the_Action.txt\n",
            "üìù Summarizing: 003_gent Feedback and Memory.txt\n",
            "üìù Summarizing: 004_AGENT_Tools.txt\n",
            "üìù Summarizing: 005_Using Function Calling Capabilities with LLMs.txt\n",
            "üìù Summarizing: 006_Agent Loop with Function Calling.txt\n",
            "üìÇ Moving '000_Prompting for Agents -GAIL.txt' ‚Üí 'Summaries'\n",
            "üìÇ Moving '001_PArse_the Response.txt' ‚Üí 'Summaries'\n",
            "üìÇ Moving '002_Execute_the_Action.txt' ‚Üí 'Summaries'\n",
            "üìÇ Moving '003_gent Feedback and Memory.txt' ‚Üí 'Summaries'\n",
            "üìÇ Moving '004_AGENT_Tools.txt' ‚Üí 'Summaries'\n",
            "üìÇ Moving '005_Using Function Calling Capabilities with LLMs.txt' ‚Üí 'Summaries'\n",
            "üìÇ Moving '006_Agent Loop with Function Calling.txt' ‚Üí 'Summaries'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß© Why Is the Output Inside Triple Backticks?\n",
        "\n",
        "This:\n",
        "\n",
        "````python\n",
        "\"```action\\n\"\n",
        "\"[\\n\"\n",
        "\"  {...},\\n\"\n",
        "\"  {...}\\n\"\n",
        "\"]\\n\"\n",
        "\"```\\n\"\n",
        "````\n",
        "\n",
        "...is a **Markdown code block**, and it's used **on purpose** to:\n",
        "\n",
        "### ‚úÖ 1. Make the Output **Easy to Parse**\n",
        "\n",
        "By putting the JSON inside:\n",
        "\n",
        "````markdown\n",
        "```action\n",
        "[\n",
        "  { \"tool_name\": ..., \"args\": {...} },\n",
        "  ...\n",
        "]\n",
        "```\n",
        "````\n",
        "\n",
        "‚Ä¶we can use **regex** to reliably extract it later:\n",
        "\n",
        "````python\n",
        "pattern = r\"```action\\s*(.*?)```\"\n",
        "````\n",
        "\n",
        "This ensures we can **locate and isolate** the JSON from other surrounding LLM content (like extra commentary, formatting, etc).\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ 2. Prevent the LLM from Adding Confusing Output\n",
        "\n",
        "LLMs sometimes add:\n",
        "\n",
        "* Explanations: \"Here‚Äôs your requested JSON:\"\n",
        "* Markdown formatting\n",
        "* Apologies or extra text\n",
        "\n",
        "Putting the plan in a ` ```action ` block tells the LLM:\n",
        "\n",
        "> ‚ÄúOnly include tool instructions in *this* block. Everything else goes outside.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ 3. Allow Multiple Blocks in One Output\n",
        "\n",
        "You might later use:\n",
        "\n",
        "* ` ```query ` for a search\n",
        "* ` ```plan ` for high-level strategy\n",
        "* ` ```action ` for tool execution\n",
        "\n",
        "This lets you extract **only the part you care about**, using tags.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Why the Word `\"action\"`?\n",
        "\n",
        "It's a **custom tag**.\n",
        "\n",
        "You could use any tag (like `\"json\"`, `\"plan\"`, `\"result\"`), but by calling it `\"action\"`, you're signaling:\n",
        "\n",
        "> ‚ÄúThis block contains a list of tool-based steps the agent should take.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Summary\n",
        "\n",
        "| Purpose                          | Benefit                              |\n",
        "| -------------------------------- | ------------------------------------ |\n",
        "| ‚úÖ Wrap in \\`\\`\\`action           | Lets you extract only the tool plan  |\n",
        "| üß† Use markdown code block       | Keeps JSON clean and separate        |\n",
        "| üßπ Parse cleanly with regex      | No guessing or extra formatting      |\n",
        "| üß± Supports multi-block messages | Easy to separate structured sections |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aD40CaKcccEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The ` ```action ` block acts like a **labelled container** or **named index**, so that later in your agent pipeline you can say:\n",
        "\n",
        "> ‚ÄúHey, go find the part of the message that contains the **action plan** ‚Äî and only that part.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üîñ Analogy\n",
        "\n",
        "Think of the LLM‚Äôs output as a full document. Inside it, you're marking sections like this:\n",
        "\n",
        "````\n",
        "Here‚Äôs what I want to do:\n",
        "\n",
        "```action\n",
        "[ { \"tool_name\": ..., \"args\": {...} } ]\n",
        "````\n",
        "\n",
        "Here‚Äôs why I‚Äôm doing it:\n",
        "\n",
        "```reasoning\n",
        "I want to group similar files together to help the user find them faster.\n",
        "```\n",
        "\n",
        "````\n",
        "\n",
        "Now you can write extractors like:\n",
        "\n",
        "```python\n",
        "extract_markdown_block(response, tag=\"action\")\n",
        "extract_markdown_block(response, tag=\"reasoning\")\n",
        "````\n",
        "\n",
        "Each tag gives you **structured access** to different parts of the LLM‚Äôs reasoning or output.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Benefits\n",
        "\n",
        "| Concept                                    | Benefit                                               |\n",
        "| ------------------------------------------ | ----------------------------------------------------- |\n",
        "| üîñ Tags like `action`, `reasoning`, `plan` | Create a schema for multi-step agent logic            |\n",
        "| üßº Markdown code block                     | Keeps JSON clean and parseable                        |\n",
        "| üìç Acts like a labeled container           | You can always find it later with a regex             |\n",
        "| üß† Reliable LLM parsing                    | Avoids accidental formatting errors, stray text, etc. |\n",
        "\n"
      ],
      "metadata": {
        "id": "qyw0DoYNc2w8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß∞ `\"Available tools\"` Section ‚Äî Why It's Included\n",
        "\n",
        "This part:\n",
        "\n",
        "```python\n",
        "\"Available tools:\\n\"\n",
        "\"- summarize_file: takes {\\\"filename\\\": str}\\n\"\n",
        "\"- move_file: takes {\\\"filename\\\": str, \\\"target_folder\\\": str}\"\n",
        "```\n",
        "\n",
        "...is a **reference guide** for the LLM. You're giving it a **tool schema** ‚Äî like API documentation ‚Äî so it knows:\n",
        "\n",
        "* What tools it can choose from\n",
        "* What arguments are required for each tool\n",
        "* The correct structure and spelling for the tool names and arguments\n",
        "\n",
        "---\n",
        "\n",
        "## ü§ñ Why Does the LLM Need This?\n",
        "\n",
        "LLMs are good at language but **don‚Äôt know what tools your agent supports** unless you tell them.\n",
        "\n",
        "So this section does two things:\n",
        "\n",
        "| Purpose                         | How                                                         |\n",
        "| ------------------------------- | ----------------------------------------------------------- |\n",
        "| üõ†Ô∏è Defines the ‚Äúmenu‚Äù of tools | Gives the names and argument shapes                         |\n",
        "| üîê Prevents hallucination       | Keeps LLM from inventing tools like `\"summarize_and_email\"` |\n",
        "\n",
        "You‚Äôre saying:\n",
        "\n",
        "> ‚ÄúHey LLM, you can ONLY use `summarize_file` and `move_file`, and here‚Äôs exactly how they work.‚Äù\n",
        "\n",
        "This guides the LLM to produce output like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"move_file\",\n",
        "  \"args\": {\n",
        "    \"filename\": \"001.txt\",\n",
        "    \"target_folder\": \"Summaries\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† It's Like an API Spec\n",
        "\n",
        "Think of it like this:\n",
        "\n",
        "* `\"Available tools\"` = **OpenAPI schema**\n",
        "* `\"tool_name\"` + `\"args\"` = **API call**\n",
        "* LLM = **caller**\n",
        "* Your agent = **executor**\n",
        "\n",
        "So you're giving it a **safe, structured list** to work from.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Could You Leave It Out?\n",
        "\n",
        "Technically yes, but:\n",
        "\n",
        "* LLM might guess wrong tool names\n",
        "* Or add invalid arguments\n",
        "* Or format the JSON incorrectly\n",
        "\n",
        "üí° Including `\"Available tools\"` boosts **reliability** and **correct formatting** by a lot ‚Äî especially when the tool list grows.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Summary\n",
        "\n",
        "| Element                  | Purpose                                  |\n",
        "| ------------------------ | ---------------------------------------- |\n",
        "| `\"action\"` tag           | Marks the output section to extract      |\n",
        "| `\"Available tools\"`      | Informs the LLM how to respond correctly |\n",
        "| `\"tool_name\"` + `\"args\"` | Defines a single action to take          |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zJcBA6kfduMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> ü§ñ **LLMs are powerful at language, but imprecise by default. Agents require precision.**\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Why Parsing Is Hard Without Structure\n",
        "\n",
        "LLMs are trained to write like this:\n",
        "\n",
        "> \"Sure! To summarize `lecture_01.txt`, I suggest moving it to the folder `Summaries`. Let me know if you'd like help renaming it.\"\n",
        "\n",
        "That‚Äôs natural language ‚Äî great for humans, **terrible for machines**.\n",
        "\n",
        "Now imagine trying to extract:\n",
        "\n",
        "* What file to summarize\n",
        "* What folder to move it to\n",
        "* What order those should happen in\n",
        "\n",
        "üß† You‚Äôd need complex NLP parsing logic‚Ä¶ and still risk breaking.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Why the Structured Format Fixes That\n",
        "\n",
        "By enforcing:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"move_file\",\n",
        "  \"args\": {\n",
        "    \"filename\": \"lecture_01.txt\",\n",
        "    \"target_folder\": \"Summaries\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "...inside a markdown block like:\n",
        "\n",
        "````\n",
        "```action\n",
        "[ ... ]\n",
        "````\n",
        "\n",
        "You‚Äôre telling the LLM:\n",
        "\n",
        "- ‚ÄúDon‚Äôt talk.‚Äù\n",
        "- ‚ÄúDon‚Äôt explain.‚Äù\n",
        "- ‚ÄúJust give me machine-readable instructions.‚Äù\n",
        "\n",
        "That‚Äôs **exactly** what enables reliable, automated parsing.\n",
        "\n",
        "---\n",
        "\n",
        "## üí• Without the `\"Available tools\"` List...\n",
        "\n",
        "The LLM might return:\n",
        "- `\"moveFile\"` instead of `\"move_file\"`\n",
        "- `\"folder\": \"Summaries\"` instead of `\"target_folder\"`\n",
        "- Or invent a tool like `\"summarize_and_move\"`\n",
        "\n",
        "Parsing would fail, or your agent might break or do the wrong thing.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† So Yes, You're Spot On:\n",
        "\n",
        "| Design Element | Why It Matters |\n",
        "|----------------|----------------|\n",
        "| ‚úÖ Parsing | Lets your agent *act* on the LLM‚Äôs output |\n",
        "| üö´ English prose | Looks pretty, but not actionable |\n",
        "| ‚úÖ Structured JSON in markdown | Cleanly extractable and reliable |\n",
        "| ‚úÖ Explicit tool schema | Prevents LLM hallucinations or misuse |\n",
        "| üö´ Leaving it to the LLM‚Äôs guess | Breaks reliability and makes agents flaky |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kGe-zDfjeTUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† Step-by-Step: What Each Function Does\n",
        "\n",
        "---\n",
        "\n",
        "### 1. ‚úÖ `extract_markdown_block(text, tag=\"action\")`\n",
        "\n",
        "This function:\n",
        "\n",
        "* Searches the LLM response for a **markdown block** like:\n",
        "\n",
        "  ````\n",
        "  ```action\n",
        "  { ... JSON ... }\n",
        "  ````\n",
        "\n",
        "  ```\n",
        "  ```\n",
        "* It extracts only the part between the backticks, using the `tag` (`action`) to target the correct block.\n",
        "\n",
        "üîç **Why?** LLMs often wrap structured data in markdown so you can parse it out cleanly without extra fluff.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. ‚úÖ `parse_multi_action_plan(llm_response)`\n",
        "\n",
        "This function:\n",
        "\n",
        "* Uses `extract_markdown_block()` to isolate the structured block.\n",
        "* Then runs `json.loads()` to convert it from **JSON text ‚Üí Python data structure** (a list of dicts).\n",
        "\n",
        "üì• Input:\n",
        "LLM output (as raw string)\n",
        "\n",
        "üì§ Output:\n",
        "\n",
        "```python\n",
        "[\n",
        "  {\"tool_name\": \"summarize_file\", \"args\": {\"filename\": \"file1.txt\"}},\n",
        "  {\"tool_name\": \"move_file\", \"args\": {\"filename\": \"file1.txt\", \"target_folder\": \"Summaries\"}}\n",
        "]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. ‚úÖ `simulate_tool(tool_name, args)`\n",
        "\n",
        "This is your **agent's executor.**\n",
        "\n",
        "Right now it's just simulating real behavior:\n",
        "\n",
        "| Tool               | Simulated Action                                |\n",
        "| ------------------ | ----------------------------------------------- |\n",
        "| `\"summarize_file\"` | Prints `üìù Summarizing: filename.txt`           |\n",
        "| `\"move_file\"`      | Prints `üìÇ Moving 'filename' ‚Üí 'target_folder'` |\n",
        "| unknown            | Prints warning: unknown tool                    |\n",
        "\n",
        "Later, you could replace these print statements with:\n",
        "\n",
        "* Real summarization using OpenAI\n",
        "* Real file moving via `shutil.move()`\n",
        "* Web scraping, emailing, database calls ‚Äî anything!\n",
        "\n",
        "---\n",
        "\n",
        "### 4. ‚úÖ Looping Through the Plan\n",
        "\n",
        "This is the **agent loop**:\n",
        "\n",
        "```python\n",
        "for step in plan:\n",
        "    simulate_tool(step[\"tool_name\"], step[\"args\"])\n",
        "```\n",
        "\n",
        "Each step in the plan is:\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"tool_name\": \"move_file\",\n",
        "  \"args\": {\n",
        "    \"filename\": \"lecture_01.txt\",\n",
        "    \"target_folder\": \"Memory\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "So the loop says:\n",
        "\n",
        "> ‚ÄúTool = `move_file`, args = `{filename: ..., target_folder: ...}` ‚Äî now go run that.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Agent Logic Summary\n",
        "\n",
        "```python\n",
        "LLM ‚ûú markdown block ‚ûú parsed JSON ‚ûú tool name + args ‚ûú tool execution\n",
        "```\n",
        "\n",
        "The LLM **thinks**.\n",
        "Your Python code **does**.\n",
        "\n"
      ],
      "metadata": {
        "id": "Yr8XyX8bba7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agents can get expensive surprisingly fast**, especially when:\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è LLM Agents Cost Risks\n",
        "\n",
        "| Risk                                     | What It Means                                                       |\n",
        "| ---------------------------------------- | ------------------------------------------------------------------- |\n",
        "| üßæ **Long prompts**                      | Big file lists, long context, detailed instructions                 |\n",
        "| üì§ **Large outputs**                     | Structured responses (JSON, plans, chains) can be verbose           |\n",
        "| üîÅ **Multiple LLM calls per agent loop** | If your agent plans, checks, reasons, executes‚Ä¶ that adds up fast   |\n",
        "| ü™ú **Recursive reasoning**               | Agents calling agents (e.g., one LLM interprets another's response) |\n",
        "| üß† **Stateful conversations**            | Chat history gets long = big context every time                     |\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Real Token Cost Breakdown (Estimates)\n",
        "\n",
        "| Action                                   | Token Cost                 |\n",
        "| ---------------------------------------- | -------------------------- |\n",
        "| 10 filenames listed in prompt            | \\~150‚Äì200 tokens           |\n",
        "| Structured plan per file                 | \\~40‚Äì100 tokens per action |\n",
        "| 10 files with 2 actions each             | \\~800‚Äì2000+ tokens         |\n",
        "| One agent loop with planning + execution | \\~2‚Äì4k tokens total        |\n",
        "| One detailed summarization per file      | 500‚Äì1500 tokens each       |\n",
        "\n",
        "So if you‚Äôre summarizing + organizing 10‚Äì20 files in a planner loop‚Ä¶\n",
        "üëâ You're easily at **20,000‚Äì40,000 tokens** just for one session.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Key Insight\n",
        "\n",
        "> **Simple apps are cheap. Agents are powerful ‚Äî but power has a price.**\n",
        "\n",
        "Agents bring more:\n",
        "\n",
        "* Flexibility\n",
        "* Reasoning\n",
        "* Control flow\n",
        "* Autonomy\n",
        "  ‚Ä¶but those advantages come at the cost of **longer prompts**, **richer output**, and **multi-turn processing**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Cost Management Tips\n",
        "\n",
        "| Strategy                                          | Result                             |\n",
        "| ------------------------------------------------- | ---------------------------------- |\n",
        "| üîπ Use `gpt-3.5-turbo` for general planning       | 90% of the time it's ‚Äúgood enough‚Äù |\n",
        "| üîπ Log token usage per run (`usage.total_tokens`) | Monitor & alert on large jobs      |\n",
        "| üîπ Save and reuse plans                           | Only re-call LLM if inputs change  |\n",
        "| üîπ Use local code for filtering, clustering       | Let LLM do only what Python can't  |\n",
        "| üîπ Use batching or a queueing system              | Avoid massive prompts in one go    |\n",
        "\n",
        "\n",
        "## ü§î So Why Was It More Expensive?\n",
        "\n",
        "Likely because of:\n",
        "\n",
        "### 1. **Prompt Size**\n",
        "\n",
        "* If you have many files, the `file_list_str` is long.\n",
        "* More input tokens = higher cost.\n",
        "\n",
        "### 2. **LLM Output Size**\n",
        "\n",
        "* The model returns a JSON list of actions, which can be long if there are lots of files.\n",
        "* More output tokens = higher cost.\n",
        "\n",
        "### 3. **Model Choice**\n",
        "\n",
        "* Even `gpt-4o-mini` is more expensive than `gpt-3.5-turbo`, though it's faster and smarter.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Ways to Save on Cost\n",
        "\n",
        "| Strategy                     | How                                                                      |\n",
        "| ---------------------------- | ------------------------------------------------------------------------ |\n",
        "| üßπ **Summarize fewer files** | Only pass a subset of files                                              |\n",
        "| üîÑ **Batch the LLM calls**   | Break files into chunks of 5‚Äì10                                          |\n",
        "| ‚ö° **Use a cheaper model**    | Switch to `gpt-3.5-turbo` if accuracy is acceptable                      |\n",
        "| üß† **Preprocess locally**    | Use local Python (e.g., keywords) to cluster/group files before LLM call |\n",
        "| üìâ **Log & cache results**   | Save plans so you don‚Äôt re-query the LLM for the same files repeatedly   |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Optional Optimization\n",
        "\n",
        "You could break this into a batching loop like:\n",
        "\n",
        "```python\n",
        "from math import ceil\n",
        "\n",
        "batch_size = 5\n",
        "batches = [file_list[i:i + batch_size] for i in range(0, len(file_list), batch_size)]\n",
        "\n",
        "all_steps = []\n",
        "\n",
        "for batch in batches:\n",
        "    messages = build_multi_action_prompt(batch)\n",
        "    llm_output = generate_response(messages)\n",
        "    plan = parse_multi_action_plan(llm_output)\n",
        "    all_steps.extend(plan)\n",
        "```\n",
        "\n",
        "This breaks up big prompts and avoids a huge single LLM call ‚Äî which helps with:\n",
        "\n",
        "* Cost\n",
        "* Speed\n",
        "* Token limit risks\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Bottom Line\n",
        "\n",
        "* ‚úÖ You're doing the right thing so far (1 call total).\n",
        "* üß† As scale grows, batching and optimization matter.\n",
        "* üí∞ You‚Äôre building cost-aware, production-capable agents ‚Äî huge milestone!\n",
        "\n"
      ],
      "metadata": {
        "id": "79ZJHeCFYeL0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1xpKm_aNUAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}