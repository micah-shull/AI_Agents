{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7J0CcWcQPxwyyFWj4E/ae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/499_EPOv2_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test suite is where your agent proves it can **move from awareness to controlled action without losing safety**. I’ll explain it as a **workflow-level verification of judgment readiness**, not as test mechanics.\n",
        "\n",
        "---\n",
        "\n",
        "# Phase 3.2 Tests — Portfolio Analysis Node Explained\n",
        "\n",
        "## What These Tests Are Really Verifying\n",
        "\n",
        "By the time these tests run, your agent already has:\n",
        "\n",
        "* a declared goal\n",
        "* a fixed execution plan\n",
        "* fully loaded and indexed data\n",
        "* portfolio-level reasoning logic\n",
        "\n",
        "These tests verify that the **orchestration layer correctly applies that reasoning** under real workflow conditions.\n",
        "\n",
        "In short, they answer:\n",
        "\n",
        "> “Does the agent know *when* portfolio analysis should run, *when it should not*, and *what to do if prerequisites are missing*?”\n",
        "\n",
        "That’s orchestration maturity.\n",
        "\n",
        "---\n",
        "\n",
        "## Test 1: Portfolio-Wide Analysis Executes Correctly\n",
        "\n",
        "### `test_portfolio_analysis_node_portfolio_wide`\n",
        "\n",
        "**What this validates**\n",
        "\n",
        "* The node runs only after goal → plan → data loading\n",
        "* Portfolio analysis executes successfully\n",
        "* All experiments are analyzed\n",
        "* Portfolio summary reflects reality\n",
        "* No errors are introduced\n",
        "\n",
        "**Why this matters**\n",
        "This test proves the **happy path** works end-to-end:\n",
        "\n",
        "* intent is clear\n",
        "* data is present\n",
        "* reasoning is applied\n",
        "* results are structured\n",
        "\n",
        "This is the moment where the agent stops being preparatory and starts being *operational*.\n",
        "\n",
        "---\n",
        "\n",
        "## Test 2: Single-Experiment Mode Is Explicitly Respected\n",
        "\n",
        "### `test_portfolio_analysis_node_single_experiment`\n",
        "\n",
        "This is a **guardrail test**, not a convenience test.\n",
        "\n",
        "**What this validates**\n",
        "\n",
        "* Portfolio analysis is skipped when scope is `single_experiment`\n",
        "* The node does not partially execute\n",
        "* No fake summaries are generated\n",
        "* No errors are raised\n",
        "\n",
        "**Why this matters**\n",
        "This prevents a very subtle but dangerous failure mode:\n",
        "\n",
        "> Running portfolio logic when only one experiment was requested.\n",
        "\n",
        "Your agent:\n",
        "\n",
        "* does not guess\n",
        "* does not “kind of run”\n",
        "* does not leak cross-experiment logic\n",
        "\n",
        "This is **scope enforcement**, not branching convenience.\n",
        "\n",
        "---\n",
        "\n",
        "## Test 3: Missing Data Causes a Hard, Explainable Stop\n",
        "\n",
        "### `test_portfolio_analysis_node_missing_data`\n",
        "\n",
        "This is one of the most important tests in the file.\n",
        "\n",
        "**What this validates**\n",
        "\n",
        "* The node refuses to run without `portfolio_lookup`\n",
        "* The agent detects execution-order violations\n",
        "* The error message is explicit and actionable\n",
        "\n",
        "**Why this matters**\n",
        "This prevents:\n",
        "\n",
        "* reasoning on partial state\n",
        "* misleading summaries\n",
        "* corrupted decision chains\n",
        "\n",
        "Your agent enforces:\n",
        "\n",
        "> “You cannot reason about readiness unless data is loaded.”\n",
        "\n",
        "That’s a **non-negotiable trust property**.\n",
        "\n",
        "---\n",
        "\n",
        "## Test 4: Full Workflow Integration Holds Together\n",
        "\n",
        "### `test_portfolio_analysis_integration`\n",
        "\n",
        "This test validates **system coherence**, not correctness of a single node.\n",
        "\n",
        "**What this validates**\n",
        "\n",
        "* Nodes compose cleanly\n",
        "* State flows forward without loss\n",
        "* Portfolio analysis integrates seamlessly\n",
        "* Outputs are usable by downstream steps\n",
        "* No unexpected errors appear\n",
        "\n",
        "**Why this matters**\n",
        "This proves the agent is not:\n",
        "\n",
        "* a chain of fragile scripts\n",
        "* a prompt-driven blob\n",
        "* a tightly coupled mess\n",
        "\n",
        "It is a **state-centric, modular workflow**.\n",
        "\n",
        "---\n",
        "\n",
        "## Why These Tests Are Architecturally Important\n",
        "\n",
        "Together, these tests prove:\n",
        "\n",
        "* execution is gated by intent\n",
        "* execution order is enforced\n",
        "* readiness is required before reasoning\n",
        "* skipping logic is safe and explicit\n",
        "* state remains coherent across phases\n",
        "\n",
        "This is the exact behavior expected of:\n",
        "\n",
        "* production data pipelines\n",
        "* workflow engines\n",
        "* governed decision systems\n",
        "\n",
        "Very few “AI agents” meet this bar.\n",
        "\n",
        "---\n",
        "\n",
        "## What You’ve Achieved by Phase 3.2\n",
        "\n",
        "At this point, your agent:\n",
        "\n",
        "* understands its goal\n",
        "* knows its plan\n",
        "* has verified access to data\n",
        "* understands portfolio readiness\n",
        "* can explain what work remains\n",
        "* knows when *not* to act\n",
        "\n",
        "That is **operational intelligence**, not automation.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Will Read Extremely Well to Reviewers\n",
        "\n",
        "You can confidently say:\n",
        "\n",
        "> “My agent explicitly determines whether analysis is appropriate before performing it, and it enforces scope, order, and data prerequisites at every step.”\n",
        "\n",
        "That sentence alone differentiates you from:\n",
        "\n",
        "* prompt-based agents\n",
        "* notebook demos\n",
        "* black-box automation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L90W64CAGdx7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VDClfkhF8KA"
      },
      "outputs": [],
      "source": [
        "\"\"\"Test Phase 3.2: Portfolio Analysis Node\n",
        "\n",
        "Tests for the portfolio analysis node - tests the orchestration of portfolio analysis utilities.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(__file__).parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from agents.epo.nodes import portfolio_analysis_node, goal_node, planning_node, data_loading_node\n",
        "from config import ExperimentationPortfolioOrchestratorState, ExperimentationPortfolioOrchestratorConfig\n",
        "\n",
        "\n",
        "def test_portfolio_analysis_node_portfolio_wide():\n",
        "    \"\"\"Test portfolio analysis node for portfolio-wide analysis\"\"\"\n",
        "    # Set up state with portfolio-wide goal\n",
        "    state: ExperimentationPortfolioOrchestratorState = {\n",
        "        \"experiment_id\": None,\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    # Run goal and planning nodes\n",
        "    goal_result = goal_node(state)\n",
        "    state = {**state, **goal_result}\n",
        "\n",
        "    plan_result = planning_node(state)\n",
        "    state = {**state, **plan_result}\n",
        "\n",
        "    # Run data loading node\n",
        "    config = ExperimentationPortfolioOrchestratorConfig()\n",
        "    data_result = data_loading_node(state, config)\n",
        "    state = {**state, **data_result}\n",
        "\n",
        "    # Now run portfolio analysis node\n",
        "    result = portfolio_analysis_node(state, config)\n",
        "    state = {**state, **result}\n",
        "\n",
        "    assert \"analyzed_experiments\" in result\n",
        "    assert \"portfolio_summary\" in result\n",
        "    assert len(result[\"analyzed_experiments\"]) == 3  # E001, E002, E003\n",
        "\n",
        "    # Check portfolio summary\n",
        "    summary = result[\"portfolio_summary\"]\n",
        "    assert summary[\"total_experiments\"] == 3\n",
        "    assert summary[\"completed_count\"] == 1\n",
        "    assert summary[\"running_count\"] == 1\n",
        "    assert summary[\"planned_count\"] == 1\n",
        "    assert \"domains\" in summary\n",
        "\n",
        "    assert len(result.get(\"errors\", [])) == 0\n",
        "\n",
        "    print(\"✅ test_portfolio_analysis_node_portfolio_wide passed\")\n",
        "\n",
        "\n",
        "def test_portfolio_analysis_node_single_experiment():\n",
        "    \"\"\"Test portfolio analysis node skips for single experiment analysis\"\"\"\n",
        "    state: ExperimentationPortfolioOrchestratorState = {\n",
        "        \"experiment_id\": \"E001\",\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    # Run goal node (single experiment)\n",
        "    goal_result = goal_node(state)\n",
        "    state = {**state, **goal_result}\n",
        "\n",
        "    # Run portfolio analysis node (should skip)\n",
        "    config = ExperimentationPortfolioOrchestratorConfig()\n",
        "    result = portfolio_analysis_node(state, config)\n",
        "\n",
        "    # Should not have analyzed_experiments (skipped)\n",
        "    assert \"analyzed_experiments\" not in result\n",
        "    assert \"portfolio_summary\" not in result\n",
        "    assert len(result.get(\"errors\", [])) == 0\n",
        "\n",
        "    print(\"✅ test_portfolio_analysis_node_single_experiment passed\")\n",
        "\n",
        "\n",
        "def test_portfolio_analysis_node_missing_data():\n",
        "    \"\"\"Test portfolio analysis node error handling for missing data\"\"\"\n",
        "    state: ExperimentationPortfolioOrchestratorState = {\n",
        "        \"experiment_id\": None,\n",
        "        \"goal\": {\n",
        "            \"scope\": \"portfolio_wide\",\n",
        "            \"objective\": \"Analyze portfolio\"\n",
        "        },\n",
        "        \"portfolio_lookup\": {},  # Empty lookup\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    config = ExperimentationPortfolioOrchestratorConfig()\n",
        "    result = portfolio_analysis_node(state, config)\n",
        "\n",
        "    # Should have errors\n",
        "    assert len(result.get(\"errors\", [])) > 0\n",
        "    assert \"portfolio_analysis_node\" in result[\"errors\"][0]\n",
        "\n",
        "    print(\"✅ test_portfolio_analysis_node_missing_data passed\")\n",
        "\n",
        "\n",
        "def test_portfolio_analysis_integration():\n",
        "    \"\"\"Test portfolio analysis integrated with full workflow\"\"\"\n",
        "    state: ExperimentationPortfolioOrchestratorState = {\n",
        "        \"experiment_id\": None,\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    config = ExperimentationPortfolioOrchestratorConfig()\n",
        "\n",
        "    # Run full workflow up to portfolio analysis\n",
        "    goal_result = goal_node(state)\n",
        "    state = {**state, **goal_result}\n",
        "\n",
        "    plan_result = planning_node(state)\n",
        "    state = {**state, **plan_result}\n",
        "\n",
        "    data_result = data_loading_node(state, config)\n",
        "    state = {**state, **data_result}\n",
        "\n",
        "    portfolio_result = portfolio_analysis_node(state, config)\n",
        "    state = {**state, **portfolio_result}\n",
        "\n",
        "    # Check all data is present\n",
        "    assert \"analyzed_experiments\" in state\n",
        "    assert \"portfolio_summary\" in state\n",
        "    assert len(state[\"analyzed_experiments\"]) == 3\n",
        "\n",
        "    # Check analyzed experiments have correct structure\n",
        "    for exp in state[\"analyzed_experiments\"]:\n",
        "        assert \"experiment_id\" in exp\n",
        "        assert \"status\" in exp\n",
        "        assert \"needs_analysis\" in exp\n",
        "        assert \"needs_decision\" in exp\n",
        "\n",
        "    # Check summary has expected fields\n",
        "    summary = state[\"portfolio_summary\"]\n",
        "    assert summary[\"total_experiments\"] == 3\n",
        "    assert summary[\"experiments_with_analysis\"] >= 0\n",
        "    assert summary[\"experiments_needing_analysis\"] >= 0\n",
        "\n",
        "    assert len(state.get(\"errors\", [])) == 0\n",
        "\n",
        "    print(\"✅ test_portfolio_analysis_integration passed\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Testing Phase 3.2: Portfolio Analysis Node\\n\")\n",
        "\n",
        "    test_portfolio_analysis_node_portfolio_wide()\n",
        "    test_portfolio_analysis_node_single_experiment()\n",
        "    test_portfolio_analysis_node_missing_data()\n",
        "    test_portfolio_analysis_integration()\n",
        "\n",
        "    print(\"\\n✅ All Phase 3.2 node tests passed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "ylVhvvBJGPww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_017_EPO_2.0 % python test_epo_phase3_node.py\n",
        "Testing Phase 3.2: Portfolio Analysis Node\n",
        "\n",
        "✅ test_portfolio_analysis_node_portfolio_wide passed\n",
        "✅ test_portfolio_analysis_node_single_experiment passed\n",
        "✅ test_portfolio_analysis_node_missing_data passed\n",
        "✅ test_portfolio_analysis_integration passed\n",
        "\n",
        "✅ All Phase 3.2 node tests passed!"
      ],
      "metadata": {
        "id": "OVHRQGzPGRGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}