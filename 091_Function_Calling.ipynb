{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyQoZSJNyGLMvmPedIIw06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/091_Function_Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **1. Why Function Calling Exists**\n",
        "\n",
        "* **Old problem**: When you ask an LLM to output JSON, you often have to prompt-engineer it heavily — and even then it might return broken JSON, missing fields, or extra text.\n",
        "* **Function calling API**: Lets you skip that dance. You give the model a **list of tools** (with JSON Schema for parameters), and it returns a *structured* `tool_call` object instead of messy free text.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. How Function Calling Works**\n",
        "\n",
        "1. **Define real Python functions**\n",
        "\n",
        "   * These contain the actual business logic (e.g., `list_files`, `read_file`).\n",
        "2. **Make a function registry**\n",
        "\n",
        "   * A dictionary mapping function names → actual Python functions.\n",
        "3. **Describe each tool in JSON Schema**\n",
        "\n",
        "   * Includes `name`, `description`, `parameters` (with types & required fields).\n",
        "4. **Send tools to the model in the API call**\n",
        "\n",
        "   * `tools=[...]` parameter activates function calling mode.\n",
        "5. **Model’s decision**\n",
        "\n",
        "   * It can either return:\n",
        "\n",
        "     * A structured `tool_call` (function name + JSON args)\n",
        "     * Or just text (if no tool is needed)\n",
        "6. **Run the called function**\n",
        "\n",
        "   * You extract `tool_name` & `args` from `tool_calls[0]` and execute it.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. What This Solves**\n",
        "\n",
        "* **No more parsing headaches**: The API guarantees valid JSON for arguments.\n",
        "* **Predictable structure**: Function names and parameters are always where you expect.\n",
        "* **Mixed mode**: Model can choose between answering directly or calling a tool.\n",
        "* **Cleaner prompts**: You don’t waste tokens on “always answer in this JSON format…”\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Key Benefits for Agents**\n",
        "\n",
        "* **Reliability** → Less code for parsing and fixing broken outputs.\n",
        "* **Consistency** → Arguments match schema, no manual validation needed.\n",
        "* **Maintainability** → Adding a new tool just means adding it to the tool list and registry.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fivzFZ0TXiTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5T7qTK1-XU2B"
      },
      "outputs": [],
      "source": [
        "!pip -q install openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- 1. Load API key ---\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# --- 2. Define actual Python tool functions ---\n",
        "\n",
        "def tool_list_files():\n",
        "    import os\n",
        "    return os.listdir('/content/files')\n",
        "\n",
        "def tool_read_file(file_path: str):\n",
        "    import os\n",
        "    fp = os.path.join('/content/files', file_path)\n",
        "    if not os.path.exists(fp):\n",
        "        return f\"File not found: {file_path}\"\n",
        "    with open(fp, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "# --- 3. Tool registry ---\n",
        "TOOLS_REGISTRY = {\n",
        "    \"list_files\": tool_list_files,\n",
        "    \"read_file\": tool_read_file,\n",
        "}\n",
        "\n",
        "# --- 4. Tool schemas for function calling ---\n",
        "TOOLS_SCHEMAS = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of file names in /content/files\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {}\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in /content/files\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"file_path\": {\"type\": \"string\", \"description\": \"The exact name of the file to read\"}\n",
        "                },\n",
        "                \"required\": [\"file_path\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# --- 5. Run one step of the agent ---\n",
        "\n",
        "def run_agent(user_input: str):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a file assistant. Use available tools if needed.\"},\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ],\n",
        "        tools=TOOLS_SCHEMAS,\n",
        "        tool_choice=\"auto\"\n",
        "    )\n",
        "\n",
        "    msg = response.choices[0].message\n",
        "\n",
        "    if msg.tool_calls:  # model decided to call a function\n",
        "        for tool_call in msg.tool_calls:\n",
        "            name = tool_call.function.name\n",
        "            args = tool_call.function.arguments\n",
        "\n",
        "            print(f\"Model requested tool: {name}, args={args}\")\n",
        "\n",
        "            # Execute the matching Python function\n",
        "            if name in TOOLS_REGISTRY:\n",
        "                import json\n",
        "                args_dict = json.loads(args) if args else {}\n",
        "                result = TOOLS_REGISTRY[name](**args_dict)\n",
        "                print(\"Tool result:\", result)\n",
        "            else:\n",
        "                print(f\"Unknown tool: {name}\")\n",
        "    else:\n",
        "        print(\"Model replied with text:\", msg.content)\n",
        "\n",
        "# --- 6. Example run ---\n",
        "run_agent(\"List all the files in /content/files\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeVT7yjOX83k",
        "outputId": "10164065-d62a-4253-a627-e35d501f792e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model requested tool: list_files, args={}\n",
            "Tool result: ['003_gent Feedback and Memory.txt', '004_AGENT_Tools.txt', '002_Execute_the_Action.txt', '005_Using Function Calling Capabilities with LLMs.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# What’s different now\n",
        "\n",
        "* **No manual JSON parsing.** We stopped telling the model “please wrap JSON in `action`” and stopped scraping it with regex.\n",
        "\n",
        "  * Before: `extract_markdown_block` → `json.loads` → handle errors.\n",
        "  * Now: `msg.tool_calls` already has `name` and `arguments` as JSON.\n",
        "\n",
        "* **Tools are passed via the API, not embedded in prose.**\n",
        "\n",
        "  * Before: we stuffed tool specs (schemas/descriptions) into the system prompt.\n",
        "  * Now: tool definitions go in the `tools=[...]` parameter. The model sees them in a structured, native way.\n",
        "\n",
        "* **The model chooses `tool_choice=\"auto\"`.**\n",
        "\n",
        "  * Before: we forced it to output JSON every turn—even when no tool was needed.\n",
        "  * Now: it can return **either** a function call **or** plain text.\n",
        "\n",
        "# Why this improves the agent\n",
        "\n",
        "* **Reliability up.** The API guarantees arguments are JSON; far fewer “broken JSON” or formatting failures.\n",
        "* **Less prompt engineering.** You don’t need elaborate “always respond in JSON…” rules. Cleaner system prompts → fewer distractions.\n",
        "* **Shorter code, simpler loop.** No parser, no error scaffolding around parsing. Easier to read and maintain.\n",
        "* **Lower token usage (often).** You’re not reprinting big schemas in the prompt body each turn; the `tools` payload is handled separately by the API.\n",
        "* **Mixed-mode behavior.** The model can just answer when a tool isn’t needed (e.g., “What is this directory for?”), and call tools when they are.\n",
        "* **Easier to scale.** Adding a tool = add function + add entry in `tools` list + add to your registry. You don’t have to revise regexes or prompting tricks.\n",
        "\n",
        "# Practical takeaways vs. previous code\n",
        "\n",
        "1. **Parsing is gone.** Your agent logic becomes:\n",
        "   `call model → if tool_calls: dispatch → else: print text`.\n",
        "2. **Fewer failure modes.** Most “invalid JSON” cases disappear; remaining errors are actual runtime issues (missing file, wrong name), which are simpler to handle.\n",
        "3. **Cleaner separation of concerns.**\n",
        "\n",
        "   * Tool metadata lives in `tools=[...]`.\n",
        "   * Tool implementation lives in Python.\n",
        "   * The loop is tiny.\n",
        "4. **Easier iteration.** You can prototype new tools fast, and you’re not constantly debugging formatting.\n",
        "\n",
        "# Still keep in mind\n",
        "\n",
        "* **Validate anyway.** Even with function calling, keep light checks (e.g., file exists, args present).\n",
        "* **Multiple calls per turn.** The model can return more than one tool call; loop through `msg.tool_calls`.\n",
        "* **Memory still matters.** You still decide what conversation/state the model sees each step.\n",
        "* **Cost/latency.** Tools don’t fix those; smart memory policies still help.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jS-Tx1zQamAM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdUQPlvjaqLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}