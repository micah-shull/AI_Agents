{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUHQiaYCsziT/tP00Z3G4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/382_GCO_Prioritization_Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diwl9bR0nMS9"
      },
      "outputs": [],
      "source": [
        "\"\"\"Prioritization utilities for Governance & Compliance Orchestrator\n",
        "\n",
        "Prioritizes compliance issues by severity, urgency, and impact.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Any, List\n",
        "from config import GovernanceComplianceOrchestratorConfig\n",
        "\n",
        "\n",
        "def calculate_priority_score(\n",
        "    compliance_event: Dict[str, Any],\n",
        "    events_lookup: Dict[str, Dict[str, Any]],\n",
        "    config: GovernanceComplianceOrchestratorConfig\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Calculate priority score for a compliance event.\n",
        "\n",
        "    Args:\n",
        "        compliance_event: Compliance event dict\n",
        "        events_lookup: Lookup dict for events by event_id\n",
        "        config: Configuration with priority scoring weights\n",
        "\n",
        "    Returns:\n",
        "        Priority score (0.0 to 100.0)\n",
        "    \"\"\"\n",
        "    weights = config.priority_scoring_weights\n",
        "\n",
        "    # Severity score (0-100)\n",
        "    severity_map = {\"critical\": 100, \"high\": 75, \"medium\": 50, \"low\": 25}\n",
        "    severity = compliance_event.get(\"severity\", \"medium\")\n",
        "    severity_score = severity_map.get(severity, 50)\n",
        "\n",
        "    # Urgency score (based on risk type and severity)\n",
        "    risk_type = compliance_event.get(\"risk_type\", \"policy_violation\")\n",
        "    if risk_type == \"policy_violation\" and severity == \"critical\":\n",
        "        urgency_score = 100\n",
        "    elif risk_type == \"policy_violation\" and severity == \"high\":\n",
        "        urgency_score = 80\n",
        "    elif severity == \"critical\":\n",
        "        urgency_score = 90\n",
        "    else:\n",
        "        urgency_score = 50\n",
        "\n",
        "    # Impact score (based on severity and required action)\n",
        "    required_action = compliance_event.get(\"recommended_action\", \"\")\n",
        "    if \"block\" in required_action.lower() or \"escalate\" in required_action.lower():\n",
        "        impact_score = 90\n",
        "    elif \"review\" in required_action.lower():\n",
        "        impact_score = 60\n",
        "    else:\n",
        "        impact_score = 40\n",
        "\n",
        "    # Frequency score (simplified - could be enhanced with historical data)\n",
        "    frequency_score = 50  # Default, could be calculated from event frequency\n",
        "\n",
        "    # Calculate weighted priority score\n",
        "    priority_score = (\n",
        "        severity_score * weights.get(\"severity\", 0.40) +\n",
        "        urgency_score * weights.get(\"urgency\", 0.30) +\n",
        "        impact_score * weights.get(\"impact\", 0.20) +\n",
        "        frequency_score * weights.get(\"frequency\", 0.10)\n",
        "    )\n",
        "\n",
        "    return round(priority_score, 2)\n",
        "\n",
        "\n",
        "def prioritize_compliance_events(\n",
        "    compliance_events: List[Dict[str, Any]],\n",
        "    events_lookup: Dict[str, Dict[str, Any]],\n",
        "    config: GovernanceComplianceOrchestratorConfig\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Prioritize compliance events by score.\n",
        "\n",
        "    Args:\n",
        "        compliance_events: List of compliance events\n",
        "        events_lookup: Lookup dict for events by event_id\n",
        "        config: Configuration with priority scoring weights\n",
        "\n",
        "    Returns:\n",
        "        List of prioritized compliance events (sorted by priority score, descending)\n",
        "    \"\"\"\n",
        "    prioritized = []\n",
        "\n",
        "    for event in compliance_events:\n",
        "        priority_score = calculate_priority_score(event, events_lookup, config)\n",
        "\n",
        "        # Get agent name from event if available\n",
        "        event_id = event.get(\"event_id\")\n",
        "        agent_name = None\n",
        "        if event_id and event_id in events_lookup:\n",
        "            agent_name = events_lookup[event_id].get(\"agent_name\")\n",
        "\n",
        "        prioritized_event = event.copy()\n",
        "        prioritized_event[\"priority_score\"] = priority_score\n",
        "        prioritized_event[\"agent_name\"] = agent_name\n",
        "        prioritized.append(prioritized_event)\n",
        "\n",
        "    # Sort by priority score (descending)\n",
        "    return sorted(prioritized, key=lambda x: x.get(\"priority_score\", 0.0), reverse=True)\n",
        "\n",
        "\n",
        "def generate_summary(\n",
        "    agent_action_logs: List[Dict[str, Any]],\n",
        "    compliance_events: List[Dict[str, Any]],\n",
        "    bias_signals: List[Dict[str, Any]],\n",
        "    drift_signals: List[Dict[str, Any]],\n",
        "    risk_scores: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generate summary statistics for the governance analysis.\n",
        "\n",
        "    Args:\n",
        "        agent_action_logs: List of agent action log events\n",
        "        compliance_events: List of compliance events (violations)\n",
        "        bias_signals: List of bias signals\n",
        "        drift_signals: List of drift signals\n",
        "        risk_scores: Risk scores dict\n",
        "\n",
        "    Returns:\n",
        "        Summary dict with key statistics\n",
        "    \"\"\"\n",
        "    # Count violations by severity\n",
        "    severity_counts = {\"critical\": 0, \"high\": 0, \"medium\": 0, \"low\": 0}\n",
        "    for event in compliance_events:\n",
        "        severity = event.get(\"severity\", \"medium\")\n",
        "        if severity in severity_counts:\n",
        "            severity_counts[severity] += 1\n",
        "\n",
        "    # Get unique agents affected\n",
        "    agents_affected = set()\n",
        "    for event in agent_action_logs:\n",
        "        agent_name = event.get(\"agent_name\")\n",
        "        if agent_name:\n",
        "            agents_affected.add(agent_name)\n",
        "\n",
        "    # Get agents with violations\n",
        "    agents_with_violations = set()\n",
        "    for event in compliance_events:\n",
        "        event_id = event.get(\"event_id\")\n",
        "        # Could enhance this by looking up the event to get agent_name\n",
        "        # For now, we'll use a simpler approach\n",
        "        pass\n",
        "\n",
        "    return {\n",
        "        \"total_events_analyzed\": len(agent_action_logs),\n",
        "        \"total_violations\": len(compliance_events),\n",
        "        \"high_severity_count\": severity_counts.get(\"high\", 0) + severity_counts.get(\"critical\", 0),\n",
        "        \"critical_severity_count\": severity_counts.get(\"critical\", 0),\n",
        "        \"bias_signals_count\": len(bias_signals),\n",
        "        \"drift_signals_count\": len(drift_signals),\n",
        "        \"agents_affected\": sorted(list(agents_affected)),\n",
        "        \"overall_risk_score\": risk_scores.get(\"overall_risk_score\", 0.0),\n",
        "        \"severity_breakdown\": severity_counts\n",
        "    }\n",
        "\n"
      ]
    }
  ]
}