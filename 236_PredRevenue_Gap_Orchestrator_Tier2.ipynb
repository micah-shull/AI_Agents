{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNyaPyvPRfzkKaodcv6sRVk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/236_PredRevenue_Gap_Orchestrator_Tier2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading Utilities for Revenue Gap Orchestrator"
      ],
      "metadata": {
        "id": "Fp6YMfcX5Fh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhEvftF54_-i"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Data Loading Utilities for Revenue Gap Orchestrator\n",
        "\n",
        "Load and prepare data from CSV files.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "\n",
        "def load_sales_data(data_dir: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load sales data from retail_weekly_sales.csv\n",
        "\n",
        "    Args:\n",
        "        data_dir: Path to data directory\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with sales data\n",
        "    \"\"\"\n",
        "    sales_file = data_dir / \"retail_weekly_sales.csv\"\n",
        "\n",
        "    if not sales_file.exists():\n",
        "        raise FileNotFoundError(f\"Sales data file not found: {sales_file}\")\n",
        "\n",
        "    df = pd.read_csv(sales_file)\n",
        "\n",
        "    # Convert date column to datetime\n",
        "    df['week_start_date'] = pd.to_datetime(df['week_start_date'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_stock_data(data_dir: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load stock availability data from stock_availability.csv\n",
        "\n",
        "    Args:\n",
        "        data_dir: Path to data directory\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with stock data\n",
        "    \"\"\"\n",
        "    stock_file = data_dir / \"stock_availability.csv\"\n",
        "\n",
        "    if not stock_file.exists():\n",
        "        raise FileNotFoundError(f\"Stock data file not found: {stock_file}\")\n",
        "\n",
        "    df = pd.read_csv(stock_file)\n",
        "\n",
        "    # Convert date column to datetime\n",
        "    df['week_start'] = pd.to_datetime(df['week_start'])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_customer_data(data_dir: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load customer data from retail_customers.csv\n",
        "\n",
        "    Args:\n",
        "        data_dir: Path to data directory\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with customer data\n",
        "    \"\"\"\n",
        "    customer_file = data_dir / \"retail_customers.csv\"\n",
        "\n",
        "    if not customer_file.exists():\n",
        "        raise FileNotFoundError(f\"Customer data file not found: {customer_file}\")\n",
        "\n",
        "    df = pd.read_csv(customer_file)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def build_sales_lookup(sales_df: pd.DataFrame) -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary: customer_id -> list of sales records\n",
        "\n",
        "    Args:\n",
        "        sales_df: Sales DataFrame\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping customer_id to list of sales records\n",
        "    \"\"\"\n",
        "    lookup = {}\n",
        "\n",
        "    for customer_id, group in sales_df.groupby('customer_id'):\n",
        "        # Convert to list of dicts, handling datetime serialization\n",
        "        records = []\n",
        "        for _, row in group.iterrows():\n",
        "            record = row.to_dict()\n",
        "            # Convert datetime to string for JSON serialization\n",
        "            if 'week_start_date' in record and pd.notna(record['week_start_date']):\n",
        "                record['week_start_date'] = record['week_start_date'].strftime('%Y-%m-%d')\n",
        "            # Convert numpy types to Python types\n",
        "            for key, value in record.items():\n",
        "                if pd.isna(value):\n",
        "                    record[key] = None\n",
        "                elif isinstance(value, (pd.Timestamp,)):\n",
        "                    record[key] = value.strftime('%Y-%m-%d')\n",
        "                elif hasattr(value, 'item'):  # numpy scalar\n",
        "                    record[key] = value.item()\n",
        "            records.append(record)\n",
        "\n",
        "        lookup[str(customer_id)] = records\n",
        "\n",
        "    return lookup\n",
        "\n",
        "\n",
        "def filter_sales_by_customer(\n",
        "    sales_df: pd.DataFrame,\n",
        "    customer_id: Optional[str]\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Filter sales data by customer_id if provided\n",
        "\n",
        "    Args:\n",
        "        sales_df: Sales DataFrame\n",
        "        customer_id: Customer ID to filter by (None = all customers)\n",
        "\n",
        "    Returns:\n",
        "        Filtered DataFrame\n",
        "    \"\"\"\n",
        "    if customer_id is None:\n",
        "        return sales_df\n",
        "\n",
        "    return sales_df[sales_df['customer_id'] == int(customer_id)]\n",
        "\n",
        "\n",
        "def merge_sales_stock(\n",
        "    sales_df: pd.DataFrame,\n",
        "    stock_df: pd.DataFrame\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Merge sales and stock data on store_id and date\n",
        "\n",
        "    Args:\n",
        "        sales_df: Sales DataFrame\n",
        "        stock_df: Stock DataFrame\n",
        "\n",
        "    Returns:\n",
        "        Merged DataFrame with sales and stock information\n",
        "    \"\"\"\n",
        "    # Merge on store_id and date\n",
        "    merged = sales_df.merge(\n",
        "        stock_df,\n",
        "        left_on=['store_id', 'week_start_date'],\n",
        "        right_on=['store_id', 'week_start'],\n",
        "        how='left',\n",
        "        suffixes=('_sales', '_stock')\n",
        "    )\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "def convert_dataframe_to_dict_list(df: pd.DataFrame) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Convert DataFrame to list of dictionaries, handling special types\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame to convert\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        record = {}\n",
        "        for key, value in row.items():\n",
        "            # Handle datetime\n",
        "            if pd.isna(value):\n",
        "                record[key] = None\n",
        "            elif isinstance(value, pd.Timestamp):\n",
        "                record[key] = value.strftime('%Y-%m-%d')\n",
        "            elif hasattr(value, 'item'):  # numpy scalar\n",
        "                record[key] = value.item()\n",
        "            else:\n",
        "                record[key] = value\n",
        "        records.append(record)\n",
        "\n",
        "    return records\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading Node"
      ],
      "metadata": {
        "id": "vGTD3KNr5yyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loading_node(state: PredictiveRevenueGapState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Data Loading Node: Load sales, stock, and customer data.\n",
        "\n",
        "    Orchestrates loading all required data sources.\n",
        "    \"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    customer_id = state.get(\"customer_id\")\n",
        "    data_dir_str = state.get(\"data_dir\", \"data\")\n",
        "\n",
        "    # Convert data_dir to Path\n",
        "    data_dir = Path(data_dir_str)\n",
        "    if not data_dir.is_absolute():\n",
        "        # Relative to project root\n",
        "        from pathlib import Path as P\n",
        "        project_root = P(__file__).parent.parent.parent\n",
        "        data_dir = project_root / data_dir_str\n",
        "\n",
        "    try:\n",
        "        # Load all data sources\n",
        "        sales_df = load_sales_data(data_dir)\n",
        "        stock_df = load_stock_data(data_dir)\n",
        "        customers_df = load_customer_data(data_dir)\n",
        "\n",
        "        # Filter sales by customer if specified\n",
        "        if customer_id:\n",
        "            sales_df = filter_sales_by_customer(sales_df, customer_id)\n",
        "            # Also filter customer data\n",
        "            customers_df = customers_df[customers_df['customer_id'] == int(customer_id)]\n",
        "\n",
        "        # Build lookups\n",
        "        sales_lookup = build_sales_lookup(sales_df)\n",
        "\n",
        "        # Convert to dict lists for state\n",
        "        sales_history = convert_dataframe_to_dict_list(sales_df)\n",
        "        stock_data = convert_dataframe_to_dict_list(stock_df)\n",
        "        all_customers = convert_dataframe_to_dict_list(customers_df)\n",
        "\n",
        "        # If single customer, also store customer_data\n",
        "        customer_data = None\n",
        "        if customer_id and len(customers_df) > 0:\n",
        "            customer_data = all_customers[0]\n",
        "\n",
        "        return {\n",
        "            \"sales_history\": sales_history,\n",
        "            \"stock_data\": stock_data,\n",
        "            \"all_customers\": all_customers,\n",
        "            \"sales_lookup\": sales_lookup,\n",
        "            \"customer_data\": customer_data,\n",
        "            \"errors\": errors\n",
        "        }\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: {str(e)}\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: Unexpected error - {str(e)}\"]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "4HjJzRwt5wW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for Data Loading Utilities"
      ],
      "metadata": {
        "id": "82EeOzEs5oF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Tests for Data Loading Utilities\n",
        "\n",
        "Testing Phase 2: Data loading utilities before building the node\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Add project root to path\n",
        "PROJECT_ROOT = Path(__file__).parent.parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from agents.revenue_gap_orchestrator.utilities.data_loading import (\n",
        "    load_sales_data,\n",
        "    load_stock_data,\n",
        "    load_customer_data,\n",
        "    build_sales_lookup,\n",
        "    filter_sales_by_customer,\n",
        "    merge_sales_stock,\n",
        "    convert_dataframe_to_dict_list\n",
        ")\n",
        "\n",
        "\n",
        "def test_load_sales_data():\n",
        "    \"\"\"Test loading sales data\"\"\"\n",
        "    data_dir = PROJECT_ROOT / \"data\"\n",
        "\n",
        "    df = load_sales_data(data_dir)\n",
        "\n",
        "    assert isinstance(df, pd.DataFrame)\n",
        "    assert len(df) > 0\n",
        "    assert 'customer_id' in df.columns\n",
        "    assert 'week_start_date' in df.columns\n",
        "    assert 'weekly_spend' in df.columns\n",
        "    assert 'store_id' in df.columns\n",
        "    assert pd.api.types.is_datetime64_any_dtype(df['week_start_date'])\n",
        "    print(\"‚úÖ Load sales data test passed\")\n",
        "\n",
        "\n",
        "def test_load_stock_data():\n",
        "    \"\"\"Test loading stock data\"\"\"\n",
        "    data_dir = PROJECT_ROOT / \"data\"\n",
        "\n",
        "    df = load_stock_data(data_dir)\n",
        "\n",
        "    assert isinstance(df, pd.DataFrame)\n",
        "    assert len(df) > 0\n",
        "    assert 'store_id' in df.columns\n",
        "    assert 'sku' in df.columns\n",
        "    assert 'week_start' in df.columns\n",
        "    assert 'on_hand_units' in df.columns\n",
        "    assert pd.api.types.is_datetime64_any_dtype(df['week_start'])\n",
        "    print(\"‚úÖ Load stock data test passed\")\n",
        "\n",
        "\n",
        "def test_load_customer_data():\n",
        "    \"\"\"Test loading customer data\"\"\"\n",
        "    data_dir = PROJECT_ROOT / \"data\"\n",
        "\n",
        "    df = load_customer_data(data_dir)\n",
        "\n",
        "    assert isinstance(df, pd.DataFrame)\n",
        "    assert len(df) > 0\n",
        "    assert 'customer_id' in df.columns\n",
        "    assert 'age' in df.columns\n",
        "    assert 'household_size' in df.columns\n",
        "    assert 'loyalty_member' in df.columns\n",
        "    print(\"‚úÖ Load customer data test passed\")\n",
        "\n",
        "\n",
        "def test_build_sales_lookup():\n",
        "    \"\"\"Test building sales lookup dictionary\"\"\"\n",
        "    data_dir = PROJECT_ROOT / \"data\"\n",
        "    sales_df = load_sales_data(data_dir)\n",
        "\n",
        "    lookup = build_sales_lookup(sales_df)\n",
        "\n",
        "    assert isinstance(lookup, dict)\n",
        "    assert len(lookup) > 0\n",
        "\n",
        "    # Check first customer\n",
        "    first_customer_id = str(sales_df['customer_id'].iloc[0])\n",
        "    assert first_customer_id in lookup\n",
        "    assert isinstance(lookup[first_customer_id], list)\n",
        "    assert len(lookup[first_customer_id]) > 0\n",
        "\n",
        "    # Check record structure\n",
        "    first_record = lookup[first_customer_id][0]\n",
        "    assert 'customer_id' in first_record\n",
        "    assert 'week_start_date' in first_record\n",
        "    assert 'weekly_spend' in first_record\n",
        "    print(\"‚úÖ Build sales lookup test passed\")\n",
        "\n",
        "\n",
        "def test_filter_sales_by_customer():\n",
        "    \"\"\"Test filtering sales by customer_id\"\"\"\n",
        "    data_dir = PROJECT_ROOT / \"data\"\n",
        "    sales_df = load_sales_data(data_dir)\n",
        "\n",
        "    # Test with specific customer\n",
        "    customer_id = \"1\"\n",
        "    filtered = filter_sales_by_customer(sales_df, customer_id)\n",
        "\n",
        "    assert len(filtered) > 0\n",
        "    assert all(filtered['customer_id'] == int(customer_id))\n",
        "\n",
        "    # Test with None (all customers)\n",
        "    all_customers = filter_sales_by_customer(sales_df, None)\n",
        "    assert len(all_customers) == len(sales_df)\n",
        "    print(\"‚úÖ Filter sales by customer test passed\")\n",
        "\n",
        "\n",
        "def test_merge_sales_stock():\n",
        "    \"\"\"Test merging sales and stock data\"\"\"\n",
        "    data_dir = PROJECT_ROOT / \"data\"\n",
        "    sales_df = load_sales_data(data_dir)\n",
        "    stock_df = load_stock_data(data_dir)\n",
        "\n",
        "    merged = merge_sales_stock(sales_df, stock_df)\n",
        "\n",
        "    assert isinstance(merged, pd.DataFrame)\n",
        "    assert len(merged) > 0\n",
        "\n",
        "    # Check that merged columns exist\n",
        "    assert 'store_id' in merged.columns\n",
        "    assert 'week_start_date' in merged.columns\n",
        "    assert 'weekly_spend' in merged.columns\n",
        "    assert 'on_hand_units' in merged.columns\n",
        "    assert 'sku' in merged.columns\n",
        "\n",
        "    # Check that some records have stock data (not all will match)\n",
        "    assert merged['on_hand_units'].notna().any()\n",
        "    print(\"‚úÖ Merge sales stock test passed\")\n",
        "\n",
        "\n",
        "def test_convert_dataframe_to_dict_list():\n",
        "    \"\"\"Test converting DataFrame to list of dicts\"\"\"\n",
        "    data_dir = PROJECT_ROOT / \"data\"\n",
        "    sales_df = load_sales_data(data_dir)\n",
        "\n",
        "    # Take a small sample\n",
        "    sample_df = sales_df.head(5)\n",
        "    records = convert_dataframe_to_dict_list(sample_df)\n",
        "\n",
        "    assert isinstance(records, list)\n",
        "    assert len(records) == 5\n",
        "\n",
        "    # Check record structure\n",
        "    first_record = records[0]\n",
        "    assert isinstance(first_record, dict)\n",
        "    assert 'customer_id' in first_record\n",
        "    assert 'week_start_date' in first_record\n",
        "\n",
        "    # Check date is string\n",
        "    assert isinstance(first_record['week_start_date'], str)\n",
        "    print(\"‚úÖ Convert DataFrame to dict list test passed\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Testing Data Loading Utilities...\\n\")\n",
        "\n",
        "    test_load_sales_data()\n",
        "    test_load_stock_data()\n",
        "    test_load_customer_data()\n",
        "    test_build_sales_lookup()\n",
        "    test_filter_sales_by_customer()\n",
        "    test_merge_sales_stock()\n",
        "    test_convert_dataframe_to_dict_list()\n",
        "\n",
        "    print(\"\\n‚úÖ All data loading utility tests passed!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iWe0OiOg5lxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Data Loading"
      ],
      "metadata": {
        "id": "2xeFcVEO8ZlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac LG_Cursor_034_Predictive_Revenue_Gap_Orchestrator % python3 tests/test_data_loading_utilities.py\n",
        "Testing Data Loading Utilities...\n",
        "\n",
        "‚úÖ Load sales data test passed\n",
        "‚úÖ Load stock data test passed\n",
        "‚úÖ Load customer data test passed\n",
        "‚úÖ Build sales lookup test passed\n",
        "‚úÖ Filter sales by customer test passed\n",
        "‚úÖ Merge sales stock test passed\n",
        "‚úÖ Convert DataFrame to dict list test passed\n",
        "\n",
        "‚úÖ All data loading utility tests passed!"
      ],
      "metadata": {
        "id": "z7Y6B5bh8W-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Revenue Analysis Utilities for Revenue Gap Orchestrator\n",
        "\n",
        "# üéØ Big Picture: What Revenue Analysis Is Doing\n",
        "\n",
        "Revenue analysis establishes the **baseline logic** the orchestrator uses to judge:\n",
        "\n",
        "1. **What is normal?** (baseline behavior)\n",
        "2. **What changed?** (trend behavior)\n",
        "3. **What will happen if we do nothing?** (prediction behavior)\n",
        "\n",
        "This is foundational because ALL downstream nodes ‚Äî gap detection, scoring, ranking ‚Äî depend on these metrics being **correct, explainable, and stable**.\n",
        "\n",
        "In orchestrators, consistency and predictability matter more than model complexity.\n",
        "\n",
        "---\n",
        "\n",
        "# üß† What You Should Be Learning & Understanding\n",
        "\n",
        "Below is the ‚Äúorchestrator-builder‚Äôs perspective‚Äù ‚Äî not just what the code does, but **why** each part matters for multi-node workflows, error propagation, and interpretability.\n",
        "\n",
        "---\n",
        "\n",
        "# 1Ô∏è‚É£ **Baseline Calculation: Understanding ‚ÄúNormal‚Äù**\n",
        "\n",
        "Function: `calculate_customer_baseline`\n",
        "\n",
        "### What this is really doing:\n",
        "\n",
        "It defines the ‚Äúexpected weekly revenue‚Äù for a customer over the baseline period.\n",
        "\n",
        "This becomes your **control group** for comparison.\n",
        "\n",
        "### What to pay attention to:\n",
        "\n",
        "* Sorting by date ‚Äî ensures consistent behavior across upstream nodes.\n",
        "* Using **only the first N weeks** ‚Äî creates a stable reference, not influenced by recent anomalies.\n",
        "* Handles empty data (important in real pipelines).\n",
        "* Uses raw customer data ‚Äî no modeling, extremely reliable.\n",
        "\n",
        "### Why this matters for orchestrators:\n",
        "\n",
        "* Baselines must be **simple, deterministic, explainable**.\n",
        "* If baselines fluctuate, your gap detection will be noisy.\n",
        "* For enterprise systems, *explainability > complexity*.\n",
        "\n",
        "If you understand this, you‚Äôre already thinking like a senior orchestrator architect.\n",
        "\n",
        "---\n",
        "\n",
        "# 2Ô∏è‚É£ **Trend Analysis: Understanding Change**\n",
        "\n",
        "Function: `calculate_revenue_trend`\n",
        "\n",
        "### What this is really doing:\n",
        "\n",
        "Comparing early behavior (baseline) vs recent behavior to determine:\n",
        "\n",
        "* Is behavior worsening?\n",
        "* Improving?\n",
        "* Stable?\n",
        "* Do we have enough data to trust this signal?\n",
        "\n",
        "### Key concepts to learn:\n",
        "\n",
        "* **Trend stability** ‚Äî protects the orchestrator from overreacting.\n",
        "* **Recent vs baseline windows** ‚Äî two competing forces:\n",
        "\n",
        "  * Baseline: long-term normal\n",
        "  * Recent: short-term change\n",
        "* **Trend classification rules**:\n",
        "\n",
        "  * < ‚Äì15% ‚Üí ‚Äúdeclining‚Äù\n",
        "  * > +15% ‚Üí ‚Äúgrowing‚Äù\n",
        "  * else ‚Üí ‚Äústable‚Äù\n",
        "\n",
        "### Why this matters:\n",
        "\n",
        "Trend classification is a **gatekeeper** for gap detection:\n",
        "\n",
        "* If the trend is ‚Äústable,‚Äù many gap checks will never trigger.\n",
        "* If the trend is ‚Äúdeclining,‚Äù downstream rules will activate.\n",
        "\n",
        "This is how orchestrators avoid false positives.\n",
        "\n",
        "---\n",
        "\n",
        "# 3Ô∏è‚É£ **Prediction: Projecting Risk Forward**\n",
        "\n",
        "Function: `predict_revenue`\n",
        "\n",
        "### What this is really doing:\n",
        "\n",
        "Estimating future revenue to determine:\n",
        "\n",
        "* Is a revenue gap temporary?\n",
        "* Is decline accelerating?\n",
        "* Should intervention be triggered?\n",
        "\n",
        "### Concepts you should learn here:\n",
        "\n",
        "#### **A. Moving Average**\n",
        "\n",
        "The most stable short-term predictor ‚Äî preferred when recent data is valid.\n",
        "\n",
        "#### **B. Trend Projection**\n",
        "\n",
        "Simple linear projection ‚Äî used only when enough data exists.\n",
        "\n",
        "#### **C. Baseline Fallback**\n",
        "\n",
        "Important when customer is new or inconsistent.\n",
        "\n",
        "#### **D. Confidence Score**\n",
        "\n",
        "This is CRITICAL for orchestrators.\n",
        "\n",
        "* It determines how much the orchestrator should trust its own prediction.\n",
        "* Higher confidence ‚Üí can escalate intervention.\n",
        "* Lower confidence ‚Üí orchestrator may avoid acting.\n",
        "\n",
        "If you're building enterprise orchestrators, **confidence modeling** is essential.\n",
        "\n",
        "---\n",
        "\n",
        "# 4Ô∏è‚É£ **Multi-Customer Pipeline**\n",
        "\n",
        "Function: `analyze_all_customers_revenue`\n",
        "\n",
        "This shows how the orchestrator performs calculations at scale.\n",
        "\n",
        "Learning objectives:\n",
        "\n",
        "* **Loop over all entities (customers)**\n",
        "* **Apply deterministic functions**\n",
        "* **Merge results into a unified, machine-readable dictionary**\n",
        "* **Keep enriched state consistent across nodes**\n",
        "\n",
        "This builds your intuition for:\n",
        "\n",
        "* Stateless vs stateful node design\n",
        "* How utilities feed orchestrator nodes\n",
        "* Batch processing patterns\n",
        "\n",
        "---\n",
        "\n",
        "# üß© What Makes This ‚ÄúBest-In-Class‚Äù Architecturally?\n",
        "\n",
        "### ‚úî Stability over complexity\n",
        "\n",
        "You‚Äôre not training ML models yet ‚Äî you're building **reliable signals**.\n",
        "\n",
        "### ‚úî Predictable feature engineering\n",
        "\n",
        "Everything is deterministic and interpretable.\n",
        "\n",
        "### ‚úî Clear separation of concerns\n",
        "\n",
        "Utilities do the math ‚Üí nodes orchestrate decisions ‚Üí LLM handles explanation.\n",
        "\n",
        "### ‚úî Allows LLMs to add value later\n",
        "\n",
        "The structured output of these utilities is ideal for:\n",
        "\n",
        "* Explanation\n",
        "* Recommendation generation\n",
        "* Summarization\n",
        "* Debugging\n",
        "\n",
        "### ‚úî Perfect for automated decision-making\n",
        "\n",
        "Your scoring node will rely on:\n",
        "\n",
        "* baseline\n",
        "* trend_percentage\n",
        "* predicted_next_week\n",
        "* predicted_next_month\n",
        "* confidence\n",
        "\n",
        "These are canonical risk-scoring signals.\n",
        "\n",
        "---\n",
        "\n",
        "# üß± Most Important Skills to Focus On (as an orchestrator builder)\n",
        "\n",
        "Here‚Äôs what you want to master from this utility module:\n",
        "\n",
        "---\n",
        "\n",
        "## **Skill 1 ‚Äî Temporal Windowing**\n",
        "\n",
        "Choosing:\n",
        "\n",
        "* how many weeks define a baseline\n",
        "* how many weeks define a trend\n",
        "* how far to predict\n",
        "\n",
        "This affects sensitivity and robustness.\n",
        "\n",
        "---\n",
        "\n",
        "## **Skill 2 ‚Äî Threshold Design**\n",
        "\n",
        "The ¬±15% trend thresholds are business rules.\n",
        "\n",
        "You should learn:\n",
        "\n",
        "* how to make thresholds configurable\n",
        "* how different thresholds change risk detection\n",
        "* how to validate thresholds using real data\n",
        "\n",
        "---\n",
        "\n",
        "## **Skill 3 ‚Äî Data Quality Handling**\n",
        "\n",
        "Look at how the code:\n",
        "\n",
        "* checks for insufficient data\n",
        "* sorts data deterministically\n",
        "* avoids division by zero\n",
        "* returns safe defaults\n",
        "\n",
        "This robustness is what makes a best-in-class orchestrator reliable.\n",
        "\n",
        "---\n",
        "\n",
        "## **Skill 4 ‚Äî Combining Multiple Signals**\n",
        "\n",
        "Revenue analysis produces **multiple independent features**:\n",
        "\n",
        "* baseline avg\n",
        "* recent avg\n",
        "* trend %\n",
        "* predictions\n",
        "* confidence\n",
        "\n",
        "These features will later power:\n",
        "\n",
        "* gap detection\n",
        "* scoring\n",
        "* ranking\n",
        "\n",
        "Learn how to treat each feature as:\n",
        "\n",
        "* isolated\n",
        "* explainable\n",
        "* reusable\n",
        "\n",
        "---\n",
        "\n",
        "## **Skill 5 ‚Äî Deterministic Logic**\n",
        "\n",
        "Best orchestrators avoid ‚Äúhidden randomness.‚Äù\n",
        "\n",
        "Every utility is:\n",
        "\n",
        "* repeatable\n",
        "* deterministic\n",
        "* auditable\n",
        "\n",
        "This is essential for enterprise systems.\n",
        "\n",
        "---\n",
        "\n",
        "# üéì Summary: What You Should Take Away\n",
        "\n",
        "Revenue analysis is not about ML ‚Äî it's about building **strong, stable signals** and **interpretable metrics** that downstream nodes can rely on.\n",
        "\n",
        "If you master:\n",
        "\n",
        "* baseline logic\n",
        "* trend logic\n",
        "* prediction logic\n",
        "* confidence modeling\n",
        "* windowing\n",
        "* threshold design\n",
        "* deterministic processing\n",
        "\n",
        "‚Ä¶you will develop the skillset required to build **enterprise-grade AI orchestrators** that are reliable, explainable, controllable, and safe.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9K2wJmyY73Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Revenue Analysis Utilities for Revenue Gap Orchestrator\n",
        "\n",
        "Calculate revenue baselines, trends, and predictions for customers.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, List, Any, Optional\n",
        "from datetime import datetime, timedelta\n",
        "import statistics\n",
        "\n",
        "\n",
        "def calculate_customer_baseline(\n",
        "    sales_records: List[Dict[str, Any]],\n",
        "    baseline_weeks: int = 4\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculate baseline revenue metrics for a customer.\n",
        "\n",
        "    Args:\n",
        "        sales_records: List of sales records for the customer (sorted by date)\n",
        "        baseline_weeks: Number of weeks to use for baseline calculation\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with baseline metrics\n",
        "    \"\"\"\n",
        "    if not sales_records:\n",
        "        return {\n",
        "            \"total_revenue\": 0.0,\n",
        "            \"average_weekly_spend\": 0.0,\n",
        "            \"weeks_active\": 0,\n",
        "            \"baseline_weeks_avg\": 0.0\n",
        "        }\n",
        "\n",
        "    # Sort by date to ensure correct order\n",
        "    sorted_records = sorted(\n",
        "        sales_records,\n",
        "        key=lambda x: x.get('week_start_date', '')\n",
        "    )\n",
        "\n",
        "    # Calculate total revenue\n",
        "    total_revenue = sum(record.get('weekly_spend', 0.0) for record in sorted_records)\n",
        "    weeks_active = len(sorted_records)\n",
        "    average_weekly_spend = total_revenue / weeks_active if weeks_active > 0 else 0.0\n",
        "\n",
        "    # Calculate baseline (first N weeks)\n",
        "    baseline_records = sorted_records[:baseline_weeks]\n",
        "    baseline_revenue = sum(record.get('weekly_spend', 0.0) for record in baseline_records)\n",
        "    baseline_weeks_avg = baseline_revenue / len(baseline_records) if baseline_records else 0.0\n",
        "\n",
        "    return {\n",
        "        \"total_revenue\": round(total_revenue, 2),\n",
        "        \"average_weekly_spend\": round(average_weekly_spend, 2),\n",
        "        \"weeks_active\": weeks_active,\n",
        "        \"baseline_weeks_avg\": round(baseline_weeks_avg, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_revenue_trend(\n",
        "    sales_records: List[Dict[str, Any]],\n",
        "    baseline_weeks: int = 4,\n",
        "    recent_weeks: int = 4\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculate revenue trend (declining/stable/growing).\n",
        "\n",
        "    Args:\n",
        "        sales_records: List of sales records for the customer (sorted by date)\n",
        "        baseline_weeks: Number of weeks for baseline period\n",
        "        recent_weeks: Number of recent weeks for comparison\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with trend analysis\n",
        "    \"\"\"\n",
        "    if not sales_records or len(sales_records) < max(baseline_weeks, recent_weeks):\n",
        "        return {\n",
        "            \"revenue_trend\": \"insufficient_data\",\n",
        "            \"recent_weeks_avg\": 0.0,\n",
        "            \"baseline_weeks_avg\": 0.0,\n",
        "            \"trend_percentage\": 0.0\n",
        "        }\n",
        "\n",
        "    # Sort by date\n",
        "    sorted_records = sorted(\n",
        "        sales_records,\n",
        "        key=lambda x: x.get('week_start_date', '')\n",
        "    )\n",
        "\n",
        "    # Baseline period (first N weeks)\n",
        "    baseline_records = sorted_records[:baseline_weeks]\n",
        "    baseline_avg = sum(r.get('weekly_spend', 0.0) for r in baseline_records) / len(baseline_records)\n",
        "\n",
        "    # Recent period (last N weeks)\n",
        "    recent_records = sorted_records[-recent_weeks:]\n",
        "    recent_avg = sum(r.get('weekly_spend', 0.0) for r in recent_records) / len(recent_records)\n",
        "\n",
        "    # Calculate trend percentage\n",
        "    if baseline_avg > 0:\n",
        "        trend_percentage = ((recent_avg - baseline_avg) / baseline_avg) * 100\n",
        "    else:\n",
        "        trend_percentage = 0.0\n",
        "\n",
        "    # Classify trend\n",
        "    if trend_percentage < -15.0:\n",
        "        trend = \"declining\"\n",
        "    elif trend_percentage > 15.0:\n",
        "        trend = \"growing\"\n",
        "    else:\n",
        "        trend = \"stable\"\n",
        "\n",
        "    return {\n",
        "        \"revenue_trend\": trend,\n",
        "        \"recent_weeks_avg\": round(recent_avg, 2),\n",
        "        \"baseline_weeks_avg\": round(baseline_avg, 2),\n",
        "        \"trend_percentage\": round(trend_percentage, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "def predict_revenue(\n",
        "    sales_records: List[Dict[str, Any]],\n",
        "    prediction_horizon_weeks: int = 4,\n",
        "    baseline_weeks: int = 4,\n",
        "    recent_weeks: int = 4\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Predict future revenue using simple methods.\n",
        "\n",
        "    Args:\n",
        "        sales_records: List of sales records for the customer\n",
        "        prediction_horizon_weeks: Weeks ahead to predict\n",
        "        baseline_weeks: Weeks for baseline calculation\n",
        "        recent_weeks: Weeks for recent average\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with predictions\n",
        "    \"\"\"\n",
        "    if not sales_records:\n",
        "        return {\n",
        "            \"predicted_next_week\": 0.0,\n",
        "            \"predicted_next_month\": 0.0,\n",
        "            \"prediction_method\": \"no_data\",\n",
        "            \"confidence\": 0.0\n",
        "        }\n",
        "\n",
        "    # Sort by date\n",
        "    sorted_records = sorted(\n",
        "        sales_records,\n",
        "        key=lambda x: x.get('week_start_date', '')\n",
        "    )\n",
        "\n",
        "    # Method 1: Moving average (recent weeks)\n",
        "    recent_records = sorted_records[-recent_weeks:]\n",
        "    moving_avg = sum(r.get('weekly_spend', 0.0) for r in recent_records) / len(recent_records)\n",
        "\n",
        "    # Method 2: Trend projection\n",
        "    baseline_records = sorted_records[:baseline_weeks]\n",
        "    baseline_avg = sum(r.get('weekly_spend', 0.0) for r in baseline_records) / len(baseline_records)\n",
        "    recent_avg = sum(r.get('weekly_spend', 0.0) for r in recent_records) / len(recent_records)\n",
        "\n",
        "    trend_per_week = (recent_avg - baseline_avg) / max(len(sorted_records), 1)\n",
        "    trend_projection = recent_avg + (trend_per_week * prediction_horizon_weeks)\n",
        "\n",
        "    # Method 3: Baseline (fallback)\n",
        "    baseline_prediction = baseline_avg\n",
        "\n",
        "    # Choose prediction method based on data quality\n",
        "    if len(sorted_records) >= recent_weeks:\n",
        "        # Use moving average if we have enough recent data\n",
        "        predicted_next_week = moving_avg\n",
        "        predicted_next_month = moving_avg * prediction_horizon_weeks\n",
        "        prediction_method = \"moving_average\"\n",
        "        confidence = min(0.9, len(sorted_records) / 12.0)  # Higher confidence with more data\n",
        "    elif len(sorted_records) >= baseline_weeks:\n",
        "        # Use baseline if limited data\n",
        "        predicted_next_week = baseline_prediction\n",
        "        predicted_next_month = baseline_prediction * prediction_horizon_weeks\n",
        "        prediction_method = \"baseline\"\n",
        "        confidence = 0.6\n",
        "    else:\n",
        "        # Insufficient data\n",
        "        predicted_next_week = 0.0\n",
        "        predicted_next_month = 0.0\n",
        "        prediction_method = \"insufficient_data\"\n",
        "        confidence = 0.0\n",
        "\n",
        "    return {\n",
        "        \"predicted_next_week\": round(predicted_next_week, 2),\n",
        "        \"predicted_next_month\": round(predicted_next_month, 2),\n",
        "        \"prediction_method\": prediction_method,\n",
        "        \"confidence\": round(confidence, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_all_customers_revenue(\n",
        "    sales_lookup: Dict[str, List[Dict[str, Any]]],\n",
        "    baseline_weeks: int = 4,\n",
        "    recent_weeks: int = 4,\n",
        "    prediction_horizon_weeks: int = 4\n",
        ") -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Analyze revenue for all customers.\n",
        "\n",
        "    Args:\n",
        "        sales_lookup: Dictionary mapping customer_id to sales records\n",
        "        baseline_weeks: Weeks for baseline calculation\n",
        "        recent_weeks: Weeks for recent trend analysis\n",
        "        prediction_horizon_weeks: Weeks ahead to predict\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping customer_id to revenue analysis\n",
        "    \"\"\"\n",
        "    customer_baselines = {}\n",
        "\n",
        "    for customer_id, sales_records in sales_lookup.items():\n",
        "        # Calculate baseline\n",
        "        baseline = calculate_customer_baseline(sales_records, baseline_weeks)\n",
        "\n",
        "        # Calculate trend\n",
        "        trend = calculate_revenue_trend(sales_records, baseline_weeks, recent_weeks)\n",
        "\n",
        "        # Predict revenue\n",
        "        prediction = predict_revenue(\n",
        "            sales_records,\n",
        "            prediction_horizon_weeks,\n",
        "            baseline_weeks,\n",
        "            recent_weeks\n",
        "        )\n",
        "\n",
        "        # Combine all metrics\n",
        "        customer_baselines[customer_id] = {\n",
        "            \"customer_id\": customer_id,\n",
        "            **baseline,\n",
        "            **trend,\n",
        "            **prediction\n",
        "        }\n",
        "\n",
        "    return customer_baselines\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxbJ5DMT70gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for Revenue Analysis Utilities"
      ],
      "metadata": {
        "id": "CUwrnIDv7-Rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Tests for Revenue Analysis Utilities\n",
        "\n",
        "Testing Phase 3: Revenue analysis utilities before building the node\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "PROJECT_ROOT = Path(__file__).parent.parent\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "from agents.revenue_gap_orchestrator.utilities.revenue_analysis import (\n",
        "    calculate_customer_baseline,\n",
        "    calculate_revenue_trend,\n",
        "    predict_revenue,\n",
        "    analyze_all_customers_revenue\n",
        ")\n",
        "\n",
        "\n",
        "def test_calculate_customer_baseline():\n",
        "    \"\"\"Test baseline calculation\"\"\"\n",
        "    sales_records = [\n",
        "        {\"week_start_date\": \"2025-09-06\", \"weekly_spend\": 50.0},\n",
        "        {\"week_start_date\": \"2025-09-13\", \"weekly_spend\": 45.0},\n",
        "        {\"week_start_date\": \"2025-09-20\", \"weekly_spend\": 55.0},\n",
        "        {\"week_start_date\": \"2025-09-27\", \"weekly_spend\": 40.0},\n",
        "    ]\n",
        "\n",
        "    baseline = calculate_customer_baseline(sales_records, baseline_weeks=4)\n",
        "\n",
        "    assert baseline[\"total_revenue\"] == 190.0\n",
        "    assert baseline[\"weeks_active\"] == 4\n",
        "    assert baseline[\"average_weekly_spend\"] == 47.5\n",
        "    assert baseline[\"baseline_weeks_avg\"] == 47.5\n",
        "    print(\"‚úÖ Calculate customer baseline test passed\")\n",
        "\n",
        "\n",
        "def test_calculate_customer_baseline_empty():\n",
        "    \"\"\"Test baseline calculation with empty records\"\"\"\n",
        "    baseline = calculate_customer_baseline([], baseline_weeks=4)\n",
        "\n",
        "    assert baseline[\"total_revenue\"] == 0.0\n",
        "    assert baseline[\"weeks_active\"] == 0\n",
        "    assert baseline[\"average_weekly_spend\"] == 0.0\n",
        "    print(\"‚úÖ Calculate customer baseline (empty) test passed\")\n",
        "\n",
        "\n",
        "def test_calculate_revenue_trend_declining():\n",
        "    \"\"\"Test trend calculation for declining revenue\"\"\"\n",
        "    sales_records = [\n",
        "        {\"week_start_date\": \"2025-09-06\", \"weekly_spend\": 50.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-09-13\", \"weekly_spend\": 48.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-09-20\", \"weekly_spend\": 46.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-09-27\", \"weekly_spend\": 44.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-10-04\", \"weekly_spend\": 30.0},  # Recent\n",
        "        {\"week_start_date\": \"2025-10-11\", \"weekly_spend\": 28.0},  # Recent\n",
        "        {\"week_start_date\": \"2025-10-18\", \"weekly_spend\": 26.0},  # Recent\n",
        "        {\"week_start_date\": \"2025-10-25\", \"weekly_spend\": 24.0},  # Recent\n",
        "    ]\n",
        "\n",
        "    trend = calculate_revenue_trend(sales_records, baseline_weeks=4, recent_weeks=4)\n",
        "\n",
        "    assert trend[\"revenue_trend\"] == \"declining\"\n",
        "    assert trend[\"trend_percentage\"] < -15.0\n",
        "    print(\"‚úÖ Calculate revenue trend (declining) test passed\")\n",
        "\n",
        "\n",
        "def test_calculate_revenue_trend_growing():\n",
        "    \"\"\"Test trend calculation for growing revenue\"\"\"\n",
        "    sales_records = [\n",
        "        {\"week_start_date\": \"2025-09-06\", \"weekly_spend\": 30.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-09-13\", \"weekly_spend\": 32.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-09-20\", \"weekly_spend\": 34.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-09-27\", \"weekly_spend\": 36.0},  # Baseline\n",
        "        {\"week_start_date\": \"2025-10-04\", \"weekly_spend\": 50.0},  # Recent\n",
        "        {\"week_start_date\": \"2025-10-11\", \"weekly_spend\": 52.0},  # Recent\n",
        "        {\"week_start_date\": \"2025-10-18\", \"weekly_spend\": 54.0},  # Recent\n",
        "        {\"week_start_date\": \"2025-10-25\", \"weekly_spend\": 56.0},  # Recent\n",
        "    ]\n",
        "\n",
        "    trend = calculate_revenue_trend(sales_records, baseline_weeks=4, recent_weeks=4)\n",
        "\n",
        "    assert trend[\"revenue_trend\"] == \"growing\"\n",
        "    assert trend[\"trend_percentage\"] > 15.0\n",
        "    print(\"‚úÖ Calculate revenue trend (growing) test passed\")\n",
        "\n",
        "\n",
        "def test_calculate_revenue_trend_stable():\n",
        "    \"\"\"Test trend calculation for stable revenue\"\"\"\n",
        "    sales_records = [\n",
        "        {\"week_start_date\": \"2025-09-06\", \"weekly_spend\": 50.0},\n",
        "        {\"week_start_date\": \"2025-09-13\", \"weekly_spend\": 48.0},\n",
        "        {\"week_start_date\": \"2025-09-20\", \"weekly_spend\": 52.0},\n",
        "        {\"week_start_date\": \"2025-09-27\", \"weekly_spend\": 50.0},\n",
        "        {\"week_start_date\": \"2025-10-04\", \"weekly_spend\": 49.0},\n",
        "        {\"week_start_date\": \"2025-10-11\", \"weekly_spend\": 51.0},\n",
        "        {\"week_start_date\": \"2025-10-18\", \"weekly_spend\": 50.0},\n",
        "        {\"week_start_date\": \"2025-10-25\", \"weekly_spend\": 52.0},\n",
        "    ]\n",
        "\n",
        "    trend = calculate_revenue_trend(sales_records, baseline_weeks=4, recent_weeks=4)\n",
        "\n",
        "    assert trend[\"revenue_trend\"] == \"stable\"\n",
        "    assert -15.0 <= trend[\"trend_percentage\"] <= 15.0\n",
        "    print(\"‚úÖ Calculate revenue trend (stable) test passed\")\n",
        "\n",
        "\n",
        "def test_predict_revenue():\n",
        "    \"\"\"Test revenue prediction\"\"\"\n",
        "    sales_records = [\n",
        "        {\"week_start_date\": \"2025-09-06\", \"weekly_spend\": 50.0},\n",
        "        {\"week_start_date\": \"2025-09-13\", \"weekly_spend\": 48.0},\n",
        "        {\"week_start_date\": \"2025-09-20\", \"weekly_spend\": 52.0},\n",
        "        {\"week_start_date\": \"2025-09-27\", \"weekly_spend\": 50.0},\n",
        "        {\"week_start_date\": \"2025-10-04\", \"weekly_spend\": 49.0},\n",
        "        {\"week_start_date\": \"2025-10-11\", \"weekly_spend\": 51.0},\n",
        "        {\"week_start_date\": \"2025-10-18\", \"weekly_spend\": 50.0},\n",
        "        {\"week_start_date\": \"2025-10-25\", \"weekly_spend\": 52.0},\n",
        "    ]\n",
        "\n",
        "    prediction = predict_revenue(sales_records, prediction_horizon_weeks=4)\n",
        "\n",
        "    assert \"predicted_next_week\" in prediction\n",
        "    assert \"predicted_next_month\" in prediction\n",
        "    assert \"prediction_method\" in prediction\n",
        "    assert \"confidence\" in prediction\n",
        "    assert prediction[\"predicted_next_week\"] > 0\n",
        "    assert prediction[\"predicted_next_month\"] > 0\n",
        "    print(\"‚úÖ Predict revenue test passed\")\n",
        "\n",
        "\n",
        "def test_analyze_all_customers_revenue():\n",
        "    \"\"\"Test analyzing all customers\"\"\"\n",
        "    sales_lookup = {\n",
        "        \"1\": [\n",
        "            {\"week_start_date\": \"2025-09-06\", \"weekly_spend\": 50.0},\n",
        "            {\"week_start_date\": \"2025-09-13\", \"weekly_spend\": 45.0},\n",
        "            {\"week_start_date\": \"2025-09-20\", \"weekly_spend\": 55.0},\n",
        "            {\"week_start_date\": \"2025-09-27\", \"weekly_spend\": 40.0},\n",
        "        ],\n",
        "        \"2\": [\n",
        "            {\"week_start_date\": \"2025-09-06\", \"weekly_spend\": 100.0},\n",
        "            {\"week_start_date\": \"2025-09-13\", \"weekly_spend\": 95.0},\n",
        "            {\"week_start_date\": \"2025-09-20\", \"weekly_spend\": 105.0},\n",
        "            {\"week_start_date\": \"2025-09-27\", \"weekly_spend\": 100.0},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    results = analyze_all_customers_revenue(sales_lookup, baseline_weeks=4, recent_weeks=4)\n",
        "\n",
        "    assert len(results) == 2\n",
        "    assert \"1\" in results\n",
        "    assert \"2\" in results\n",
        "\n",
        "    # Check structure\n",
        "    customer_1 = results[\"1\"]\n",
        "    assert \"customer_id\" in customer_1\n",
        "    assert \"total_revenue\" in customer_1\n",
        "    assert \"revenue_trend\" in customer_1\n",
        "    assert \"predicted_next_week\" in customer_1\n",
        "    print(\"‚úÖ Analyze all customers revenue test passed\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Testing Revenue Analysis Utilities...\\n\")\n",
        "\n",
        "    test_calculate_customer_baseline()\n",
        "    test_calculate_customer_baseline_empty()\n",
        "    test_calculate_revenue_trend_declining()\n",
        "    test_calculate_revenue_trend_growing()\n",
        "    test_calculate_revenue_trend_stable()\n",
        "    test_predict_revenue()\n",
        "    test_analyze_all_customers_revenue()\n",
        "\n",
        "    print(\"\\n‚úÖ All revenue analysis utility tests passed!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mjFG4MxL78QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Revenue Utils"
      ],
      "metadata": {
        "id": "YJtolEGC8koD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac LG_Cursor_034_Predictive_Revenue_Gap_Orchestrator % python3 tests/test_revenue_analysis_utilities.py\n",
        "Testing Revenue Analysis Utilities...\n",
        "\n",
        "‚úÖ Calculate customer baseline test passed\n",
        "‚úÖ Calculate customer baseline (empty) test passed\n",
        "‚úÖ Calculate revenue trend (declining) test passed\n",
        "‚úÖ Calculate revenue trend (growing) test passed\n",
        "‚úÖ Calculate revenue trend (stable) test passed\n",
        "‚úÖ Predict revenue test passed\n",
        "‚úÖ Analyze all customers revenue test passed\n",
        "\n",
        "‚úÖ All revenue analysis utility tests passed!"
      ],
      "metadata": {
        "id": "jfRB7rGk8jcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Your current orchestrator framework is **both fully functional as-is** *and* intentionally designed to be **extremely flexible** so that you can plug in more sophisticated ML components later without rewriting anything.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **1. Current Framework: Simple, Interpretable, Reliable**\n",
        "\n",
        "The current revenue analysis utilities (baseline, trend, prediction) are intentionally:\n",
        "\n",
        "* Deterministic\n",
        "* Explainable\n",
        "* Lightweight\n",
        "* Fast\n",
        "* Easy to audit\n",
        "\n",
        "They use **rolling windows**, not ML models, because:\n",
        "\n",
        "* MVPs need interpretability\n",
        "* It avoids overfitting\n",
        "* It avoids needing a training pipeline\n",
        "* It keeps the orchestrator focused on *workflow logic*, not ML training\n",
        "\n",
        "This is how *actual enterprise orchestrator MVPs* are built.\n",
        "\n",
        "---\n",
        "\n",
        "# üöÄ **2. Adding ML? You simply plug it in as another utility module**\n",
        "\n",
        "Yes ‚Äî if a company wants ML predictions, you **add one new utility** and **one new node**, without removing or breaking anything.\n",
        "\n",
        "For example:\n",
        "\n",
        "```\n",
        "utilities/\n",
        "  revenue_analysis.py\n",
        "  revenue_ml_prediction.py   ‚Üê NEW\n",
        "nodes/\n",
        "  revenue_analysis_node.py\n",
        "  revenue_ml_prediction_node.py  ‚Üê NEW\n",
        "```\n",
        "\n",
        "This new module might include:\n",
        "\n",
        "* forecast models (Prophet, ARIMA, XGBoost, LSTM, Transformers)\n",
        "* probability-of-churn models\n",
        "* customer lifetime value (CLV) models\n",
        "* uplift models\n",
        "* anomaly detection models\n",
        "\n",
        "Then in the orchestrator flow:\n",
        "\n",
        "### Current Flow:\n",
        "\n",
        "```\n",
        "plan ‚Üí data load ‚Üí revenue analysis ‚Üí gap detection ‚Üí scoring ‚Üí ranking ‚Üí report\n",
        "```\n",
        "\n",
        "### With ML Added:\n",
        "\n",
        "```\n",
        "plan ‚Üí data load ‚Üí revenue analysis ‚Üí ML prediction ‚Üí gap detection ‚Üí scoring ‚Üí ranking ‚Üí report\n",
        "```\n",
        "\n",
        "ML predictions simply *augment* the state.\n",
        "\n",
        "---\n",
        "\n",
        "# üß† **3. The State Architecture Already Supports ML Outputs**\n",
        "\n",
        "Your `PredictiveRevenueGapState` (from your STATE_DESIGN doc) already contains patterns like:\n",
        "\n",
        "* `baseline_weeks`\n",
        "* `recent_weeks`\n",
        "* `predicted_next_week`\n",
        "* `predicted_next_month`\n",
        "* `confidence`\n",
        "\n",
        "You can easily extend it with ML fields:\n",
        "\n",
        "* `ml_predicted_next_week`\n",
        "* `ml_predicted_monthly_revenue`\n",
        "* `ml_churn_probability`\n",
        "* `ml_gap_probability`\n",
        "* `ml_confidence_score`\n",
        "\n",
        "No breaking changes.\n",
        "Just add keys.\n",
        "\n",
        "---\n",
        "\n",
        "# üß© **4. Why your architecture is ideal for ML add-ons**\n",
        "\n",
        "Your orchestrator is:\n",
        "\n",
        "### üîπ Node-based\n",
        "\n",
        "Each step is independent ‚Äî perfect for swapping in ML logic.\n",
        "\n",
        "### üîπ State-driven\n",
        "\n",
        "All intermediate computations live in the state, so new model outputs are easy to store.\n",
        "\n",
        "### üîπ Modular utilities\n",
        "\n",
        "ML logic can live in its own file without touching existing utilities.\n",
        "\n",
        "### üîπ Workflow-sequenced\n",
        "\n",
        "ML predictions can be placed anywhere in the sequence:\n",
        "\n",
        "* before gap detection\n",
        "* before scoring\n",
        "* as the final scoring mechanism\n",
        "* or as the ranking engine\n",
        "\n",
        "### üîπ LLM-friendly\n",
        "\n",
        "You can even use:\n",
        "\n",
        "* LLMs for explanation\n",
        "* ML for prediction\n",
        "* Stock data for reasoning\n",
        "  All at once.\n",
        "\n",
        "---\n",
        "\n",
        "# üèóÔ∏è **5. How ML is added (simple example)**\n",
        "\n",
        "### New utility (e.g., XGBoost)\n",
        "\n",
        "```python\n",
        "def ml_predict_revenue(customer_features: Dict[str, Any], model):\n",
        "    prediction = model.predict([customer_features])\n",
        "    return {\n",
        "        \"ml_predicted_next_week\": float(prediction[0]),\n",
        "        \"ml_confidence_score\": 0.85\n",
        "    }\n",
        "```\n",
        "\n",
        "### New node\n",
        "\n",
        "```python\n",
        "def revenue_ml_prediction_node(state):\n",
        "    features = extract_ml_features(state.sales_history)\n",
        "    ml_results = ml_predict_revenue(features, state.ml_model)\n",
        "    state.update(ml_results)\n",
        "    return state\n",
        "```\n",
        "\n",
        "That's it.\n",
        "\n",
        "---\n",
        "\n",
        "# üéØ **6. Bottom Line**\n",
        "\n",
        "### ‚úî Your current framework is MVP-ready\n",
        "\n",
        "### ‚úî It is fully functional with interpretable revenue logic\n",
        "\n",
        "### ‚úî It is designed for scalability\n",
        "\n",
        "### ‚úî ML can be added later through a **completely clean extension path**\n",
        "\n",
        "### ‚úî No code rewrites are needed\n",
        "\n",
        "### ‚úî Best practice orchestration architecture used in enterprise AI\n",
        "\n"
      ],
      "metadata": {
        "id": "gzf-LO_3Czrw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rXtlXOo0C7z7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}