{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMxNa9BWU8gnS15wUF0wcZ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/100_TxtSummarizerAgent_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Define the Agent‚Äôs Purpose**\n",
        ">\n",
        "> * One short **goal statement** ‚Äî what success looks like.\n",
        "> * Optional constraints (time, cost, safety, privacy).\n",
        "> * Example: *‚ÄúHelp onboard new hires by sending welcome emails and scheduling meetings.‚Äù*\n",
        "\n",
        "## üéØ Agent Goal\n",
        "\n",
        "> **Goal**: ‚ÄúSummarize the content of a given text file into concise bullet points.‚Äù\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n9j89m_SeZ7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† What the Agent Needs to Do (Plain English Steps)\n",
        "\n",
        "1. **Understand the Goal**\n",
        "   ‚ÄúI need to summarize a text file into bullet points.‚Äù\n",
        "\n",
        "2. **Find or Choose the File**\n",
        "   Figure out *which* text file to summarize. (Will we hardcode it, ask the user, or list available files?)\n",
        "\n",
        "3. **Read the File‚Äôs Contents**\n",
        "   Open the file and load its text.\n",
        "\n",
        "4. **Summarize It**\n",
        "   Turn the text into a short list of bullet points ‚Äî probably by calling an LLM.\n",
        "\n",
        "5. **Return or Save the Summary**\n",
        "   Print the result, return it, or save it to another file.\n",
        "\n",
        "6. **Track Progress (optional but recommended)**\n",
        "   Log what step the agent is on for debugging and transparency.\n",
        "\n"
      ],
      "metadata": {
        "id": "GkekUlcggqfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß†ü¶æ Mind vs Body Breakdown (LLM vs Python)\n",
        "\n",
        "Here‚Äôs your file summarizer agent mapped into those categories:\n",
        "\n",
        "| Step                   | Description              | Mind (LLM)                           | Body (Python)                    |\n",
        "| ---------------------- | ------------------------ | ------------------------------------ | -------------------------------- |\n",
        "| 1. Understand the goal | \"Summarize a file\"       | ‚úÖ (LLM needs this to choose actions) |                                  |\n",
        "| 2. Choose a file       | List or pick a file name | ‚úÖ (LLM decides *which* to summarize) | ‚úÖ (Python lists available files) |\n",
        "| 3. Read file contents  | Load text from disk      |                                      | ‚úÖ (Python reads the file)        |\n",
        "| 4. Summarize it        | Turn text into bullets   | ‚úÖ (LLM does this)                    |                                  |\n",
        "| 5. Return/save result  | Output summary           | ‚úÖ (LLM may decide where/how)         | ‚úÖ (Python saves/prints it)       |\n",
        "| 6. Track progress      | Log steps taken          |                                      | ‚úÖ (Python memory logging)        |\n"
      ],
      "metadata": {
        "id": "gCdInnJ-hbPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üîÅ Simplified Agent Design (Final Table)\n",
        "\n",
        "| Step                   | Description                           | LLM (Mind)                  | Python (Tool/Body)                     |\n",
        "| ---------------------- | ------------------------------------- | --------------------------- | -------------------------------------- |\n",
        "| 1. Understand the goal | ‚ÄúSummarize text content into bullets‚Äù | ‚úÖ                           |                                        |\n",
        "| 2. Read text from file | Get contents from a known folder      |                             | ‚úÖ (`read_txt_file(folder, file_name)`) |\n",
        "| 3. Summarize contents  | Turn text into bullet points          | ‚úÖ (this is the agent‚Äôs job) |                                        |\n",
        "| 4. Save the summary    | Save to known output folder           |                             | ‚úÖ (`save_summary(folder, content)`)    |\n",
        "| 5. Track progress      | Record status of steps                |                             | ‚úÖ (`track_progress`)                   |\n",
        "\n",
        "---\n",
        "\n",
        "### üö¶ Control Flow\n",
        "\n",
        "* **User**: ‚ÄúHey agent, summarize `input/article1.txt`.‚Äù\n",
        "* **Agent**: ‚ÄúOkay, I‚Äôll call `read_txt_file` to get it.‚Äù\n",
        "* **Agent**: *Summarizes the text.*\n",
        "* **Agent**: Calls `save_summary` to write it to `output/article1_summary.txt`\n",
        "* **Agent**: Logs progress.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VUePP-53jiBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß© Step 2: Identify Required Capabilities\n",
        "\n",
        "Here‚Äôs what this step is about (per your recipe and the handbook):\n",
        "\n",
        "> ‚ÄúList the **tools** the agent needs to accomplish the goal, and any **lifecycle helpers** like `create_plan` or `track_progress`.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ Required Tools\n",
        "\n",
        "Let‚Äôs define the **minimal toolset** your agent will use:\n",
        "\n",
        "| Tool Name        | Purpose                                  | Notes            |\n",
        "| ---------------- | ---------------------------------------- | ---------------- |\n",
        "| `read_txt_file`  | Reads text from a known file path        | Stateless        |\n",
        "| `save_summary`   | Saves output summary to a known location | Stateless        |\n",
        "| `track_progress` | Logs steps/status updates                | From your recipe |\n",
        "| `create_plan`    | Agent begins by making a plan            | From your recipe |\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Required Capabilities\n",
        "\n",
        "These are **agent lifecycle modifiers** ‚Äî not tools themselves, but hooks into the loop:\n",
        "\n",
        "| Capability Name              | Purpose                          |\n",
        "| ---------------------------- | -------------------------------- |\n",
        "| `PlanFirstCapability`        | Ensures agent starts by planning |\n",
        "| `ProgressTrackingCapability` | Adds memory log of tool progress |\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Result of This Step:\n",
        "\n",
        "You now have a **capability stack** and a **tool list** to implement.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ypttf8LBkSsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ü©∞ ‚ÄúDress Rehearsal‚Äù = Design Before Code\n",
        "\n",
        "The idea is to:\n",
        "\n",
        "* Lay out the agent‚Äôs **moving parts** (goals, tools, memory, environment, etc.)\n",
        "* Show **how they connect** (who uses what, in what order)\n",
        "* Catch **confusion or overload** early ‚Äî before wiring and debugging\n",
        "\n",
        "It‚Äôs like setting the stage before the actors enter. Every prop is in its place, and everyone knows their lines.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ So ‚Äî Which Comes First: Tools/Capabilities or Rehearsal?\n",
        "\n",
        "You're right to pause here. Here's the answer:\n",
        "\n",
        "> **Do both in parallel ‚Äî but only at a sketch level.**\n",
        "\n",
        "* You **need** to know your **tools and capabilities** first ‚Äî at least their names and jobs.\n",
        "* But you don‚Äôt need to fully implement them yet.\n",
        "* Then, **use that to build the scaffold**, which validates:\n",
        "\n",
        "  * Flow order\n",
        "  * Tool coverage\n",
        "  * Whether the agent loop is too shallow or too deep\n",
        "\n",
        "---\n",
        "\n",
        "## üé¨ Agent Scaffold (Plain-English Simulation)\n",
        "\n",
        "This is a **dry run** of what the agent will do ‚Äî no code yet, just **logic**.\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Starting Point\n",
        "\n",
        "* Goal: ‚ÄúSummarize a file into concise bullet points‚Äù\n",
        "* Input: A file path like `input/article1.txt`\n",
        "* Tools: `create_plan`, `read_txt_file`, `save_summary`, `track_progress`\n",
        "* Capabilities: `PlanFirstCapability`, `ProgressTrackingCapability`\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Refined Scaffold (Agent Dress Rehearsal)\n",
        "\n",
        "1. The agent receives the **goal**:\n",
        "   *‚ÄúSummarize the file at `input/article1.txt` into concise bullet points.‚Äù*\n",
        "   This goal is stored in memory for reference.\n",
        "\n",
        "2. Triggered by `PlanFirstCapability`, the agent first calls `create_plan`.\n",
        "   It generates a short plan (e.g., ‚Äúread file ‚Üí summarize ‚Üí save‚Äù) and stores it in memory.\n",
        "\n",
        "3. The agent then uses the `read_txt_file` tool, passing in the path to `input/article1.txt`.\n",
        "   The file‚Äôs contents are returned and stored temporarily in state.\n",
        "\n",
        "4. The LLM summarizes the text into 4‚Äì6 bullet points.\n",
        "   This is its **main job** ‚Äî natural language compression.\n",
        "\n",
        "5. The agent then calls `save_summary`, passing the output path (`output/article1_summary.txt`) and the generated summary.\n",
        "   This step writes the results to disk.\n",
        "\n",
        "6. The agent logs its progress using `track_progress`, e.g.,\n",
        "   *‚ÄúStep 2 complete: summary saved successfully‚Äù*\n",
        "\n",
        "7. The loop ends with a clear final message:\n",
        "   *‚ÄúSummary saved to output/article1\\_summary.txt. Task complete.‚Äù*\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Why This Version Works\n",
        "\n",
        "* Highlights **memory usage** (storing goal + plan)\n",
        "* Keeps LLM focused only on **text-to-summary**\n",
        "* Makes the flow crystal clear\n",
        "* Reflects your recipe *exactly*\n",
        "* Minimal and easy to wire up\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GewYn3-vlbJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî• The agent doesn‚Äôt magically ‚Äúknow‚Äù how to start summarizing ‚Äî it needs a **clear, minimal prompt** to hand to the LLM when it‚Äôs time to summarize. And if we're following clean design:\n",
        "\n",
        "> ‚úÖ That prompt should be generated by a **tool**, not hardcoded into the agent logic.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ú® Introducing a New Tool: `generate_summary_prompt`\n",
        "\n",
        "| Tool Name                 | Purpose                                                               |\n",
        "| ------------------------- | --------------------------------------------------------------------- |\n",
        "| `generate_summary_prompt` | Creates a clean, focused prompt for the LLM to summarize a given text |\n",
        "\n",
        "---\n",
        "\n",
        "## üîÅ Updated Flow (With Prompt Tool)\n",
        "\n",
        "Let‚Äôs insert it into the scaffold:\n",
        "\n",
        "1. Agent receives the goal: ‚ÄúSummarize input/article1.txt‚Äù\n",
        "2. Calls `create_plan` ‚Üí Plan: `read ‚Üí generate prompt ‚Üí summarize ‚Üí save ‚Üí log`\n",
        "3. Calls `read_txt_file` to get raw text\n",
        "4. Calls `generate_summary_prompt` to create the prompt from the text\n",
        "5. LLM uses that prompt to generate bullet-point summary\n",
        "6. Calls `save_summary`\n",
        "7. Calls `track_progress`\n",
        "8. Returns final message\n",
        "\n",
        "---\n",
        "\n",
        "### üîß Why Split the Prompt Tool?\n",
        "\n",
        "* ‚úÖ Keeps summarization **flexible** (can tune prompt later)\n",
        "* ‚úÖ Makes LLM logic **transparent**\n",
        "* ‚úÖ Easier to test the prompt generation logic\n",
        "* ‚úÖ Reusable for other agents (e.g., summarizing PDFs, chat transcripts)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Eq6Otp-mgMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This bit of code from the **Agent Builder Handbook** is quietly doing something powerful:\n",
        "\n",
        "### **Code Pattern: GAME Scaffolding**\n",
        "\n",
        "```python\n",
        "class AgentBlueprint:\n",
        "    def __init__(self, goals, instructions, actions, memory, environment):\n",
        "        self.goals = goals\n",
        "        self.instructions = instructions\n",
        "        self.actions = actions  # abstract definitions\n",
        "        self.memory = memory\n",
        "        self.environment = environment  # actual implementations\n",
        "\n",
        "# Example GAME setup\n",
        "goals = [\"Summarize Python files in the repo\"]\n",
        "instructions = [\"Be concise, skip docstrings, focus on function definitions\"]\n",
        "actions = [\"list_files\", \"read_file\", \"write_summary\"]\n",
        "memory = \"sliding_window(5)\"\n",
        "environment = \"local_filesystem\"\n",
        "\n",
        "agent = AgentBlueprint(goals, instructions, actions, memory, environment)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üîç What That GAME Snippet Teaches\n",
        "\n",
        "It shows that:\n",
        "\n",
        "* Goals are specific\n",
        "* Instructions are decoupled\n",
        "* Actions (tools) are modular and abstract\n",
        "* Memory and environment are swappable\n",
        "\n",
        "Your insight to add a **`generate_summary_prompt`** tool aligns *exactly* with this pattern.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† What the Handbook *Implies* (and your teacher reinforced)\n",
        "\n",
        "> ‚ùù Make your tools small, testable, and **LLM-friendly**. Each one should do **one thing** and do it well. ‚ùû\n",
        "\n",
        "In this mindset:\n",
        "\n",
        "* `generate_summary_prompt` is a **‚Äúprep‚Äù tool** ‚Üí helps the LLM think clearly.\n",
        "* It becomes a **reusable mental utility** ‚Äî for summarizing emails, transcripts, reports, etc.\n",
        "* The LLM doesn‚Äôt need to *remember* how to construct the prompt ‚Äî the environment just hands it the right one.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Summary\n",
        "\n",
        "You're:\n",
        "\n",
        "* Following **the GAME structure** ‚úîÔ∏è\n",
        "* Reducing LLM workload ‚úîÔ∏è\n",
        "* Encouraging reuse + separation of concerns ‚úîÔ∏è\n",
        "* Building a system that will be easier to simulate, swap, test ‚úîÔ∏è\n",
        "\n",
        "So yes ‚Äî let's lock it in:\n",
        "\n",
        "> Add `generate_summary_prompt` to the tool list\n",
        "> Insert it into the scaffold right before the LLM summary generation\n",
        "\n"
      ],
      "metadata": {
        "id": "mBBu-QhbqhEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# üß∞ Tools (final list)\n",
        "\n",
        "* `create_plan` ‚Äî make a tiny plan for the run\n",
        "* `read_txt_file(folder, file_name)` ‚Äî load raw text from a known folder\n",
        "* `generate_summary_prompt(text)` ‚Äî craft a minimal, reusable LLM prompt for summarizing\n",
        "* `save_summary(output_folder, file_name, content)` ‚Äî write the summary to a known folder\n",
        "* `track_progress(step, status, note?)` ‚Äî log progress/status\n",
        "\n",
        "# üß© Capability stack\n",
        "\n",
        "* `PlanFirstCapability` ‚Üí ensures we call `create_plan` first\n",
        "* `ProgressTrackingCapability` ‚Üí captures progress entries\n",
        "\n",
        "# üé≠ Dress rehearsal (scaffold)\n",
        "\n",
        "1. Agent receives goal: ‚ÄúSummarize `input/article1.txt` into concise bullet points.‚Äù (store goal)\n",
        "2. `create_plan` ‚Üí plan like: *read ‚Üí generate\\_prompt ‚Üí summarize ‚Üí save ‚Üí log* (store plan)\n",
        "3. `read_txt_file(input, \"article1.txt\")` ‚Üí get raw text (store in state)\n",
        "4. `generate_summary_prompt(text)` ‚Üí produce clean summarization prompt (store prompt)\n",
        "5. LLM ‚Üí generate 4‚Äì6 bullet points using that prompt (core cognition)\n",
        "6. `save_summary(output, \"article1_summary.txt\", summary)` ‚Üí persist result\n",
        "7. `track_progress(step=final, status=\"done\", note=\"summary saved\")`\n",
        "8. Return: ‚ÄúSummary saved to `output/article1_summary.txt`.‚Äù\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j7vwyIt8rJXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üîß What ‚ÄúDependencies‚Äù Means\n",
        "\n",
        "Each tool can‚Äôt exist in a vacuum ‚Äî it needs access to *something* from the agent‚Äôs context (files, memory, folders, clocks, etc.).\n",
        "The trick is to **list those explicitly** so tools stay stateless and testable.\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ Tool Dependency Table\n",
        "\n",
        "| Tool                                              | Purpose                     | Needs From `ActionContext`                                  | Notes                                      |\n",
        "| ------------------------------------------------- | --------------------------- | ----------------------------------------------------------- | ------------------------------------------ |\n",
        "| `create_plan`                                     | Make a step-by-step plan    | **Goal** (from memory)                                      | Simple: just reads the goal + instructions |\n",
        "| `read_txt_file(folder, file_name)`                | Load raw text               | **Folder path**, **file name**                              | Folder should come from config, not LLM    |\n",
        "| `generate_summary_prompt(text)`                   | Create summarization prompt | **Text content** (already in memory/state)                  | No external deps ‚Äî pure transformer        |\n",
        "| `save_summary(output_folder, file_name, content)` | Save the summary            | **Output folder**, **summary text**                         | Output folder fixed/configured             |\n",
        "| `track_progress(step, status, note?)`             | Log what happened           | **Memory** (to append logs), **clock** (optional timestamp) | Helpful for debugging/testing              |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Key Design Notes\n",
        "\n",
        "* **Folder paths**: never chosen by the LLM ‚Äî injected once into `ActionContext`.\n",
        "* **Memory**: shared so both logs + results can be tracked.\n",
        "* **Clock**: optional dep for `track_progress` (great for replay/debug).\n",
        "* **LLM**: only gets the **prompt + text**; everything else stays in Python.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tqGFbPR1r0HI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß≠ The Core Design Principle\n",
        "\n",
        "You nailed it:\n",
        "\n",
        "> üß± ‚ÄúWe want tools to be **reusable** ‚Äî so inputs like folders or file paths shouldn‚Äôt be hardcoded.‚Äù\n",
        "\n",
        "Instead, we should:\n",
        "\n",
        "* Provide fixed values like `folder paths` via **dependency injection**\n",
        "* Pass dynamic values like `file_name` via **arguments from the LLM**\n",
        "\n",
        "This keeps the **LLM focused on decisions**, and the **environment focused on execution**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Recommendation: Inject Folder Paths via `ActionContext.config`\n",
        "\n",
        "### How it works:\n",
        "\n",
        "* Store known folders in `ActionContext.config`:\n",
        "\n",
        "  ```python\n",
        "  ActionContext(config={\n",
        "      \"input_folder\": \"input/\",\n",
        "      \"output_folder\": \"output/\"\n",
        "  })\n",
        "  ```\n",
        "\n",
        "* In your tool:\n",
        "\n",
        "  ```python\n",
        "  def read_txt_file(ctx, file_name, _input_folder):\n",
        "      full_path = os.path.join(_input_folder, file_name)\n",
        "      ...\n",
        "  ```\n",
        "\n",
        "* `_input_folder` is injected automatically from:\n",
        "\n",
        "  ```python\n",
        "  deps={\"input_folder\": \"input/\"}  # from ActionContext.deps\n",
        "  ```\n",
        "\n",
        "OR ‚Äî if you prefer ‚Äî you can pull it from `ctx.config[\"input_folder\"]` inside the tool.\n",
        "\n",
        "Either way:\n",
        "\n",
        "* **`file_name`** = LLM chooses it\n",
        "* **`folder path`** = injected at runtime\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ Example Call\n",
        "\n",
        "Agent wants to read a file:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool\": \"read_txt_file\",\n",
        "  \"arguments\": {\n",
        "    \"file_name\": \"article1.txt\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "Then:\n",
        "\n",
        "* `read_txt_file(ctx, file_name, _input_folder)`\n",
        "* Tool constructs: `input/article1.txt` internally\n",
        "\n",
        "---\n",
        "\n",
        "## üîÅ TL;DR ‚Äî Final Rule\n",
        "\n",
        "* ‚úÖ **LLM provides**: file names, summary content, etc.\n",
        "* ‚úÖ **You provide**: config (folder paths), injected via `ActionContext`\n",
        "* üîÅ Makes tools **testable**, **swappable**, and **clean**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "20db5kTZtFZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ü™õ Step 4: Define Tool Interfaces\n",
        "\n",
        "> \"Write the signature and schema of each tool ‚Äî so the agent knows what to call, and Python knows what to inject.\"\n",
        "\n",
        "We'll do **two things per tool**:\n",
        "\n",
        "1. Write the **Python signature** (with `ctx` + injected deps)\n",
        "2. Write the **LLM-facing schema** (JSON-style: name + args)\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ Tool 1: `create_plan`\n",
        "\n",
        "* **Signature**:\n",
        "\n",
        "  ```python\n",
        "  def create_plan(ctx):\n",
        "      ...\n",
        "  ```\n",
        "\n",
        "* **Schema**:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"name\": \"create_plan\",\n",
        "    \"description\": \"Create a short plan for completing the goal.\",\n",
        "    \"parameters\": {}\n",
        "  }\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ Tool 2: `read_txt_file`\n",
        "\n",
        "* **Signature**:\n",
        "\n",
        "  ```python\n",
        "  def read_txt_file(ctx, file_name, _input_folder):\n",
        "      ...\n",
        "  ```\n",
        "\n",
        "* **Schema**:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"name\": \"read_txt_file\",\n",
        "    \"description\": \"Read a text file from the input folder.\",\n",
        "    \"parameters\": {\n",
        "      \"file_name\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The name of the file to read (e.g., article1.txt)\"\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ Tool 3: `generate_summary_prompt`\n",
        "\n",
        "* **Signature**:\n",
        "\n",
        "  ```python\n",
        "  def generate_summary_prompt(ctx, text):\n",
        "      ...\n",
        "  ```\n",
        "\n",
        "* **Schema**:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"name\": \"generate_summary_prompt\",\n",
        "    \"description\": \"Create a prompt for summarizing the given text.\",\n",
        "    \"parameters\": {\n",
        "      \"text\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The raw text to summarize\"\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ Tool 4: `save_summary`\n",
        "\n",
        "* **Signature**:\n",
        "\n",
        "  ```python\n",
        "  def save_summary(ctx, file_name, content, _output_folder):\n",
        "      ...\n",
        "  ```\n",
        "\n",
        "* **Schema**:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"name\": \"save_summary\",\n",
        "    \"description\": \"Save the summary to the output folder.\",\n",
        "    \"parameters\": {\n",
        "      \"file_name\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The output file name (e.g., article1_summary.txt)\"\n",
        "      },\n",
        "      \"content\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The text content to save\"\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "### üß∞ Tool 5: `track_progress`\n",
        "\n",
        "* **Signature**:\n",
        "\n",
        "  ```python\n",
        "  def track_progress(ctx, step, status, note=None, _clock=None):\n",
        "      ...\n",
        "  ```\n",
        "\n",
        "* **Schema**:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"name\": \"track_progress\",\n",
        "    \"description\": \"Log agent progress at each step.\",\n",
        "    \"parameters\": {\n",
        "      \"step\": { \"type\": \"string\", \"description\": \"Step name\" },\n",
        "      \"status\": { \"type\": \"string\", \"description\": \"Status or result\" },\n",
        "      \"note\": { \"type\": \"string\", \"description\": \"Optional extra info\", \"optional\": true }\n",
        "    }\n",
        "  }\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Recap: What We Just Did\n",
        "\n",
        "You now have:\n",
        "\n",
        "* **Python signatures** ‚Äî with `ctx` and injected deps\n",
        "* **LLM schemas** ‚Äî names + parameter types\n",
        "\n",
        "You‚Äôre ready to:\n",
        "\n",
        "> **Step 5: Implement the tools**\n",
        "> But slowly ‚Äî one at a time, and testable.\n",
        "\n"
      ],
      "metadata": {
        "id": "yJvLWQ9_u4MK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ‚ùì1. Why do we break it into ‚Äúsignature‚Äù and ‚Äúschema‚Äù?\n",
        "\n",
        "### ‚úçÔ∏è **Signature**\n",
        "\n",
        "* The **Python function signature** (e.g., `def read_txt_file(ctx, file_name, _input_folder)`) defines how the tool is written and how it runs **in code**.\n",
        "* This is what the **Agent runtime** uses when executing the tool.\n",
        "\n",
        "### üß† **Schema**\n",
        "\n",
        "* The **Schema** (like your JSON block) is how the **LLM understands the tool**.\n",
        "* It‚Äôs what gets registered with the LLM as part of the agent's `actions`/tools.\n",
        "\n",
        "### üß© Think of it like this:\n",
        "\n",
        "| Aspect    | Used By | Purpose                                                          |\n",
        "| --------- | ------- | ---------------------------------------------------------------- |\n",
        "| Signature | Python  | How the tool runs in real life                                   |\n",
        "| Schema    | LLM     | How the agent knows what it can call, and what arguments to pass |\n",
        "\n",
        "So we need both:\n",
        "\n",
        "* One for the **runtime**\n",
        "* One for the **language model interface**\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùì2. What is `ctx` in `def create_plan(ctx)`?\n",
        "\n",
        "> `ctx` = short for **ActionContext**\n",
        "\n",
        "It‚Äôs the context object passed into every tool. It gives the tool access to:\n",
        "\n",
        "* Memory\n",
        "* Config\n",
        "* Dependencies\n",
        "* Filesystem\n",
        "* Clock\n",
        "* Scratchpad state\n",
        "* Logs\n",
        "* Anything shared across tools\n",
        "\n",
        "It‚Äôs like the **backstage pass** for tools.\n",
        "\n",
        "You never want your tools to go off grabbing global variables or hardcoded things ‚Äî so you hand them everything they need via `ctx` (or via explicitly injected parameters like `_input_folder`).\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùì3. Are those schemas based on OpenAI‚Äôs API tool format?\n",
        "\n",
        "Yes ‚Äî exactly.\n",
        "\n",
        "You're looking at a schema that is:\n",
        "\n",
        "* ‚úÖ 100% compatible with OpenAI‚Äôs `functions` / `tool_choice` format\n",
        "* ‚úÖ Exactly what‚Äôs used in the **agent recipe**\n",
        "* ‚úÖ What the `LLMFunctionCaller` in the recipe expects\n",
        "\n",
        "This structure:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"generate_summary_prompt\",\n",
        "  \"description\": \"...\",\n",
        "  \"parameters\": {\n",
        "    ...\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "‚Ä¶is standard. And yes, you can test with OpenAI or use mock LLMs during local dev.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ TL;DR Summary\n",
        "\n",
        "| Concept       | Meaning                                                                           |\n",
        "| ------------- | --------------------------------------------------------------------------------- |\n",
        "| `signature`   | Python definition for how the tool is called at runtime                           |\n",
        "| `schema`      | JSON structure the LLM uses to decide how to call tools                           |\n",
        "| `ctx`         | The injected ActionContext ‚Äî gives tools access to shared config, memory, and env |\n",
        "| Schema format | Yes, it's OpenAI-compatible and exactly what the agent recipe expects             |\n",
        "\n"
      ],
      "metadata": {
        "id": "ISnvx04hwHkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> üß≥ **ActionContext = the agent‚Äôs backpack.**\n",
        "\n",
        "Let‚Äôs break it down in detail to reinforce:\n",
        "\n",
        "---\n",
        "\n",
        "## üéí What is `ActionContext`?\n",
        "\n",
        "It‚Äôs a single object that:\n",
        "\n",
        "* Holds everything the agent (and its tools) might need during execution.\n",
        "* Gets passed into **every tool** call.\n",
        "* Is **injected fresh** for each agent run ‚Äî so agents don‚Äôt share backpacks.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© What goes inside the backpack?\n",
        "\n",
        "| Key       | What it holds                                         | Who sets it              |\n",
        "| --------- | ----------------------------------------------------- | ------------------------ |\n",
        "| `config`  | Static config (like folder paths, model IDs)          | You (the agent designer) |\n",
        "| `memory`  | Persistent state ‚Äî plan, goal, logs, last tool output | Agent runtime            |\n",
        "| `deps`    | Injected dependencies (e.g., `input_folder`, `clock`) | You                      |\n",
        "| `llm`     | Reference to an LLM tool (if one is used)             | You                      |\n",
        "| `scratch` | Temporary runtime data                                | Agent + tools            |\n",
        "| `clock`   | Optional timestamp system                             | You                      |\n",
        "| `logger`  | Logging hook                                          | Agent system or you      |\n",
        "\n",
        "---\n",
        "\n",
        "## üîÅ Is ActionContext shared?\n",
        "\n",
        "* **The `ActionContext` class is reusable** ‚Äî same code for all agents.\n",
        "* But each **instance is unique per agent run.**\n",
        "* So:\n",
        "\n",
        "  * ‚úÖ **Agent A and Agent B have their own contexts**\n",
        "  * ‚úÖ Even multiple *runs* of the same agent get their own context\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why This Is Smart\n",
        "\n",
        "It gives you:\n",
        "\n",
        "* ‚úÖ **Isolation**: agents don‚Äôt interfere with each other\n",
        "* ‚úÖ **Modularity**: tools stay pure, take only what they need\n",
        "* ‚úÖ **Debuggability**: you can snapshot the whole run from the context\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Want to See One?\n",
        "\n",
        "Here‚Äôs what a sample `ActionContext` might look like when building your summarizer:\n",
        "\n",
        "```python\n",
        "ctx = ActionContext(\n",
        "    config={\n",
        "        \"input_folder\": \"input/\",\n",
        "        \"output_folder\": \"output/\"\n",
        "    },\n",
        "    memory=ScratchMemory(),\n",
        "    deps={\n",
        "        \"clock\": Clock.now,\n",
        "        \"input_folder\": \"input/\",\n",
        "        \"output_folder\": \"output/\"\n",
        "    },\n",
        "    llm=openai_chat_model,\n",
        ")\n",
        "```\n",
        "\n",
        "Then you just pass `ctx` to the agent and it flows into every tool.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wPhajl-bz_WM"
      }
    }
  ]
}