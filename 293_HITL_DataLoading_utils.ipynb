{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWgHaN2CESBtEyO42irVXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/293_HITL_DataLoading_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading utilities for HITL Orchestrator"
      ],
      "metadata": {
        "id": "PZHt1XR4EqXC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0oYC4J4Ejyv"
      },
      "outputs": [],
      "source": [
        "\"\"\"Data loading utilities for HITL Orchestrator\"\"\"\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "\n",
        "def load_tasks(data_dir: str, tasks_file: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load tasks from JSON file.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        tasks_file: Name of tasks file\n",
        "\n",
        "    Returns:\n",
        "        List of task dictionaries\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / tasks_file\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def load_agent_outputs(data_dir: str, agent_outputs_file: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load agent outputs from JSON file.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        agent_outputs_file: Name of agent outputs file\n",
        "\n",
        "    Returns:\n",
        "        List of agent output dictionaries\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / agent_outputs_file\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def load_routing_policy(data_dir: str, routing_policy_file: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Load routing policy from JSON file.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        routing_policy_file: Name of routing policy file\n",
        "\n",
        "    Returns:\n",
        "        Routing policy dictionary\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / routing_policy_file\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def load_human_reviews(data_dir: str, human_reviews_file: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load existing human reviews from JSON file (optional).\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        human_reviews_file: Name of human reviews file\n",
        "\n",
        "    Returns:\n",
        "        List of human review dictionaries (empty list if file doesn't exist)\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / human_reviews_file\n",
        "    if not file_path.exists():\n",
        "        return []\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def load_audit_logs(data_dir: str, audit_logs_file: str) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load existing audit logs from JSON file (optional).\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        audit_logs_file: Name of audit logs file\n",
        "\n",
        "    Returns:\n",
        "        List of audit log dictionaries (empty list if file doesn't exist)\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / audit_logs_file\n",
        "    if not file_path.exists():\n",
        "        return []\n",
        "\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "def build_task_output_lookup(\n",
        "    tasks: List[Dict[str, Any]],\n",
        "    agent_outputs: List[Dict[str, Any]]\n",
        ") -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary mapping task_id to combined task + output data.\n",
        "\n",
        "    Args:\n",
        "        tasks: List of tasks\n",
        "        agent_outputs: List of agent outputs\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping task_id to combined task and output data\n",
        "    \"\"\"\n",
        "    lookup = {}\n",
        "\n",
        "    # Create task lookup\n",
        "    task_lookup = {task[\"task_id\"]: task for task in tasks}\n",
        "\n",
        "    # Create output lookup\n",
        "    output_lookup = {output[\"task_id\"]: output for output in agent_outputs}\n",
        "\n",
        "    # Combine\n",
        "    for task_id in task_lookup.keys():\n",
        "        task_data = task_lookup[task_id].copy()\n",
        "        output_data = output_lookup.get(task_id, {})\n",
        "\n",
        "        lookup[task_id] = {\n",
        "            \"task\": task_data,\n",
        "            \"agent_output\": output_data.get(\"agent_output\", {}),\n",
        "            \"confidence_score\": output_data.get(\"confidence_score\", 0.0)\n",
        "        }\n",
        "\n",
        "    return lookup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This part **is** pretty straightforward, and thatâ€™s a *good thing*. Iâ€™ll keep this **short, high-level, and conceptual**.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§  Big Picture: What This File Is For\n",
        "\n",
        "This file is the **â€œloader dockâ€** for your orchestrator.\n",
        "\n",
        "Its job is simple:\n",
        "\n",
        "> **Take data from files on disk and turn it into clean, usable memory for the agent.**\n",
        "\n",
        "No decisions.\n",
        "No AI.\n",
        "No logic.\n",
        "\n",
        "Just **getting the ingredients ready** before cooking.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ“¦ Part 1: Loading Data from Files\n",
        "\n",
        "All these functions follow the same pattern:\n",
        "\n",
        "```python\n",
        "load_tasks\n",
        "load_agent_outputs\n",
        "load_routing_policy\n",
        "load_human_reviews\n",
        "load_audit_logs\n",
        "```\n",
        "\n",
        "### Conceptually:\n",
        "\n",
        "Each one answers a question like:\n",
        "\n",
        "> â€œHey orchestrator, can you go read this file and give me the data inside?â€\n",
        "\n",
        "They:\n",
        "\n",
        "1. Find the file\n",
        "2. Open it\n",
        "3. Read the JSON\n",
        "4. Hand back Python dictionaries/lists\n",
        "\n",
        "Think of them as:\n",
        "\n",
        "* librarians\n",
        "* not judges\n",
        "* not decision-makers\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” Why separate loaders?\n",
        "\n",
        "Because each dataset has a **different role** in the system:\n",
        "\n",
        "* tasks = work to do\n",
        "* agent outputs = proposed answers\n",
        "* routing policy = rules\n",
        "* human reviews = feedback\n",
        "* audit logs = history\n",
        "\n",
        "Separating them:\n",
        "\n",
        "* keeps things clean\n",
        "* makes testing easier\n",
        "* avoids mixing responsibilities\n",
        "\n",
        "This is **good system hygiene**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ›¡ï¸ Why some loaders are â€œoptionalâ€\n",
        "\n",
        "```python\n",
        "if not file_path.exists():\n",
        "    return []\n",
        "```\n",
        "\n",
        "This is subtle but important.\n",
        "\n",
        "It means:\n",
        "\n",
        "* The system can start **fresh**\n",
        "* Or resume from **past runs**\n",
        "* Without crashing\n",
        "\n",
        "Thatâ€™s how real systems survive restarts.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ”— Part 2: `build_task_output_lookup`\n",
        "\n",
        "## ðŸ§  â€œMaking the Agent Fast and Organizedâ€\n",
        "\n",
        "This is the **only function here that does anything slightly clever**.\n",
        "\n",
        "### What problem it solves\n",
        "\n",
        "Right now you have:\n",
        "\n",
        "* a list of tasks\n",
        "* a list of agent outputs\n",
        "\n",
        "But your orchestrator keeps asking:\n",
        "\n",
        "> â€œFor THIS task, what did the agent say?â€\n",
        "\n",
        "Searching lists over and over is slow and messy.\n",
        "\n",
        "---\n",
        "\n",
        "### What this function does (in human terms)\n",
        "\n",
        "1. **Indexes tasks by ID**\n",
        "2. **Indexes agent outputs by ID**\n",
        "3. **Stitches them together**\n",
        "4. **Stores them in one place**\n",
        "\n",
        "So now you can instantly say:\n",
        "\n",
        "> â€œGive me everything about task_003.â€\n",
        "\n",
        "---\n",
        "\n",
        "### The result looks like this (conceptually)\n",
        "\n",
        "```text\n",
        "task_id â†’ {\n",
        "  task info,\n",
        "  agent output,\n",
        "  confidence score\n",
        "}\n",
        "```\n",
        "\n",
        "This is **preparing the ground** for:\n",
        "\n",
        "* routing decisions\n",
        "* human review packets\n",
        "* audit logs\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸŽ¯ Why This Matters (Conceptually)\n",
        "\n",
        "This file teaches an important lesson:\n",
        "\n",
        "> **Smart agents arenâ€™t smart because they â€œthink harderâ€ â€”\n",
        "> theyâ€™re smart because their data is organized.**\n",
        "\n",
        "Youâ€™re designing:\n",
        "\n",
        "* clarity\n",
        "* reliability\n",
        "* speed\n",
        "* debuggability\n",
        "\n",
        "Thatâ€™s real engineering.\n",
        "\n",
        "---\n",
        "\n",
        "# âœ… Big Takeaway\n",
        "\n",
        "This module:\n",
        "\n",
        "* loads facts\n",
        "* avoids assumptions\n",
        "* prepares clean inputs\n",
        "* keeps the orchestrator honest\n",
        "\n",
        "Itâ€™s intentionally boring â€” and thatâ€™s exactly why itâ€™s correct.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZSJXwz5qrpgu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "od2WL3NorwzL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}