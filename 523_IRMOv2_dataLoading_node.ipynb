{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8CuULljrccffhxIrxzCMt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/523_IRMOv2_dataLoading_node.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Data Loading Node – Establishing the Trust Boundary for the Entire Agent\n",
        "\n",
        "The `data_loading_node` is the **first execution step** in the orchestrator’s plan, and it is intentionally designed as the system’s **trust boundary**.\n",
        "\n",
        "Before the agent evaluates risk, analyzes trends, or produces executive recommendations, it must first prove that it is reasoning over **complete, valid, and intentional data**.\n",
        "\n",
        "This node is where that guarantee is enforced.\n",
        "\n",
        "---\n",
        "\n",
        "## What This Node Does in Practice\n",
        "\n",
        "At a high level, the data loading node performs four critical functions:\n",
        "\n",
        "1. **Loads all required datasets**\n",
        "2. **Validates them before use**\n",
        "3. **Builds deterministic lookup structures**\n",
        "4. **Scopes analysis intentionally when requested**\n",
        "\n",
        "Only after these steps succeed does the agent proceed.\n",
        "\n",
        "If anything fails, execution stops.\n",
        "\n",
        "---\n",
        "\n",
        "## Defensive Execution: No Silent Failure\n",
        "\n",
        "All data loading is wrapped in a single `try/except` block, and any exception is captured and returned explicitly through the agent’s error channel.\n",
        "\n",
        "This design ensures:\n",
        "\n",
        "* No partial execution\n",
        "* No misleading downstream analysis\n",
        "* No reports generated from incomplete data\n",
        "\n",
        "If the agent produces output, leadership can be confident that *every required dataset loaded successfully*.\n",
        "\n",
        "This is a fundamental difference from many AI systems that attempt to “do their best” with whatever data happens to be available.\n",
        "\n",
        "---\n",
        "\n",
        "## Explicit Data Domains, Loaded Intentionally\n",
        "\n",
        "The node loads each dataset using a dedicated, validated loader:\n",
        "\n",
        "* Agent inventory\n",
        "* System integrations\n",
        "* Workflows\n",
        "* Risk signals\n",
        "* KPI and cost metrics\n",
        "* Historical snapshots (v2)\n",
        "* Ownership review history (v2)\n",
        "* Expected vs actual value (v2)\n",
        "\n",
        "Each dataset represents a **distinct dimension of reality**:\n",
        "\n",
        "* Configuration\n",
        "* Current-state signals\n",
        "* Historical memory\n",
        "* Governance intent\n",
        "\n",
        "Nothing is inferred. Everything is declared.\n",
        "\n",
        "---\n",
        "\n",
        "## Deterministic Lookups: Explainability at Scale\n",
        "\n",
        "Once the raw data is loaded, the node immediately builds **explicit lookup tables**.\n",
        "\n",
        "This step is critical.\n",
        "\n",
        "Rather than allowing downstream logic to repeatedly scan lists or infer relationships dynamically, the agent constructs deterministic mappings such as:\n",
        "\n",
        "* Agent → workflows\n",
        "* Agent → risks\n",
        "* Agent → KPIs\n",
        "* Agent → historical snapshots\n",
        "* Agent → governance reviews\n",
        "* Agent → expected vs actual value\n",
        "\n",
        "These lookups make the agent’s reasoning:\n",
        "\n",
        "* Faster\n",
        "* More transparent\n",
        "* Fully traceable\n",
        "\n",
        "When the agent later explains *why* an issue was prioritized, those explanations trace cleanly back through these structures.\n",
        "\n",
        "---\n",
        "\n",
        "## Intentional Scoping: Portfolio or Single-Agent Analysis\n",
        "\n",
        "The optional `agent_id` filter is a subtle but powerful feature.\n",
        "\n",
        "It allows the same agent to operate in two modes:\n",
        "\n",
        "* **Portfolio mode** – analyze the entire ecosystem\n",
        "* **Focused mode** – analyze a single agent in depth\n",
        "\n",
        "This filtering happens *after* data loading and validation, not before.\n",
        "\n",
        "That choice matters because:\n",
        "\n",
        "* Data integrity is preserved\n",
        "* Comparisons remain valid\n",
        "* The agent’s behavior is predictable\n",
        "\n",
        "Scope is a **business decision**, not a side effect of missing data.\n",
        "\n",
        "---\n",
        "\n",
        "## Clean State Updates, No Hidden Mutation\n",
        "\n",
        "The node returns a clear, structured update to state:\n",
        "\n",
        "* Loaded datasets\n",
        "* Derived lookups\n",
        "* Preserved error context\n",
        "\n",
        "Nothing is mutated implicitly.\n",
        "Everything that downstream nodes rely on is explicitly returned.\n",
        "\n",
        "This makes the system:\n",
        "\n",
        "* Easier to test\n",
        "* Easier to reason about\n",
        "* Easier to audit\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Matters to Executives (Even If They Never See the Code)\n",
        "\n",
        "This node quietly enforces properties that leaders care deeply about:\n",
        "\n",
        "* **Reliability** – the agent won’t run on bad data\n",
        "* **Predictability** – execution either succeeds or stops\n",
        "* **Transparency** – inputs and relationships are explicit\n",
        "* **Control** – scope is intentional, not accidental\n",
        "* **Safety** – no partial or misleading outputs\n",
        "\n",
        "Many AI agents *appear* intelligent but fail operationally because they lack this discipline.\n",
        "\n",
        "This one doesn’t.\n",
        "\n",
        "---\n",
        "\n",
        "## Architectural Takeaway\n",
        "\n",
        "The data loading node is not a utility step.\n",
        "It is a **governance gate**.\n",
        "\n",
        "By validating inputs, enforcing completeness, and building deterministic relationships, it ensures that every conclusion produced later—risk scores, trends, prioritization, and reports—rests on a foundation leadership can trust.\n",
        "\n",
        "This is how you build AI systems that don’t surprise people.\n",
        "\n"
      ],
      "metadata": {
        "id": "yuanO8OvxEoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSxPEexHwWMm"
      },
      "outputs": [],
      "source": [
        "def data_loading_node(\n",
        "    state: IntegrationRiskManagementOrchestratorState,\n",
        "    config: IntegrationRiskManagementOrchestratorConfig\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Data Loading Node: Load all data files\"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    data_dir = config.data_dir\n",
        "\n",
        "    try:\n",
        "        # Load all data files\n",
        "        agents = load_agents(data_dir, config.agents_file)\n",
        "        systems = load_system_integrations(data_dir, config.systems_file)\n",
        "        workflows = load_workflows(data_dir, config.workflows_file)\n",
        "        risks = load_risk_signals(data_dir, config.risks_file)\n",
        "        kpis = load_kpis_cost(data_dir, config.kpis_file)\n",
        "\n",
        "        # v2: Load historical data\n",
        "        snapshots = load_historical_snapshots(data_dir, config.historical_snapshots_file)\n",
        "        reviews = load_ownership_review_history(data_dir, config.ownership_review_history_file)\n",
        "        expected_vs_actual = load_expected_vs_actual_value(data_dir, config.expected_vs_actual_value_file)\n",
        "\n",
        "        # Build lookups\n",
        "        lookups = build_lookups(agents, systems, workflows, risks, kpis, snapshots, reviews, expected_vs_actual)\n",
        "\n",
        "        # Filter by agent_id if specified\n",
        "        agent_id = state.get(\"agent_id\")\n",
        "        if agent_id:\n",
        "            agents = [a for a in agents if a[\"agent_id\"] == agent_id]\n",
        "            workflows = [w for w in workflows if w[\"agent_id\"] == agent_id]\n",
        "            risks = [r for r in risks if r[\"agent_id\"] == agent_id]\n",
        "            kpis = [k for k in kpis if k[\"agent_id\"] == agent_id]\n",
        "            snapshots = [s for s in snapshots if s[\"agent_id\"] == agent_id]\n",
        "            reviews = [r for r in reviews if r[\"agent_id\"] == agent_id]\n",
        "            expected_vs_actual = [e for e in expected_vs_actual if e[\"agent_id\"] == agent_id]\n",
        "\n",
        "        return {\n",
        "            \"agents\": agents,\n",
        "            \"system_integrations\": systems,\n",
        "            \"workflows\": workflows,\n",
        "            \"risk_signals\": risks,\n",
        "            \"kpis_cost_metrics\": kpis,\n",
        "            \"historical_snapshots\": snapshots,\n",
        "            \"ownership_review_history\": reviews,\n",
        "            \"expected_vs_actual_value\": expected_vs_actual,\n",
        "            **lookups,\n",
        "            \"errors\": errors\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: {str(e)}\"]\n",
        "        }"
      ]
    }
  ]
}