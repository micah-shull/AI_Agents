{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyQsieK4Z4FcXEtdBEyO7z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/543_EaaS_v2_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Phase 2 Utilities Tests — Data Loading\n",
        "\n",
        "## What These Tests Do in Real-World Terms\n",
        "\n",
        "These tests verify that the **entire factual foundation** of the Evaluation-as-a-Service system is sound.\n",
        "\n",
        "Before the agent:\n",
        "\n",
        "* evaluates a single scenario\n",
        "* scores a single agent\n",
        "* flags a regression\n",
        "* generates a report\n",
        "\n",
        "it confirms that:\n",
        "\n",
        "* all required data exists\n",
        "* all data is structured as expected\n",
        "* relationships between entities can be resolved\n",
        "* historical baselines are available\n",
        "\n",
        "This is not testing “code.”\n",
        "This is testing **evidence integrity**.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Matters Operationally\n",
        "\n",
        "AI systems often fail in subtle, dangerous ways due to data issues:\n",
        "\n",
        "* missing fields\n",
        "* malformed records\n",
        "* silently empty datasets\n",
        "* mismatched identifiers\n",
        "\n",
        "Those failures are especially dangerous in evaluation systems because they can produce:\n",
        "\n",
        "* false confidence\n",
        "* incorrect regressions\n",
        "* misleading executive reports\n",
        "\n",
        "This test suite eliminates that risk by validating:\n",
        "\n",
        "* structure\n",
        "* completeness\n",
        "* consistency\n",
        "* relational integrity\n",
        "\n",
        "before evaluation logic ever runs.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Leaders Would Be Relieved to See This\n",
        "\n",
        "From a CEO or business manager’s perspective, this test suite answers a crucial question:\n",
        "\n",
        "> *“Are the numbers in this report actually based on real, complete data?”*\n",
        "\n",
        "Because these tests:\n",
        "\n",
        "* assert presence of historical data\n",
        "* confirm evaluation runs and metrics align\n",
        "* validate that entities can be looked up reliably\n",
        "\n",
        "leaders can trust that:\n",
        "\n",
        "* performance trends are real\n",
        "* regressions aren’t artifacts\n",
        "* comparisons across time are legitimate\n",
        "\n",
        "This is exactly the kind of discipline they expect from financial systems, compliance tooling, or analytics pipelines — and it’s rare to see it applied to AI agents.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Strengths in This Test Design\n",
        "\n",
        "### 1. You Test *Data Shape*, Not Just Data Presence\n",
        "\n",
        "You don’t just check that files load — you verify:\n",
        "\n",
        "* required fields\n",
        "* expected types\n",
        "* example values\n",
        "\n",
        "This ensures that downstream logic can rely on:\n",
        "\n",
        "* consistent contracts\n",
        "* stable schemas\n",
        "* predictable behavior\n",
        "\n",
        "That dramatically reduces debugging cost later.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Lookups Are Treated as First-Class Artifacts\n",
        "\n",
        "You explicitly test:\n",
        "\n",
        "* customer lookups\n",
        "* order lookups\n",
        "* agent lookups\n",
        "* run and metric lookups\n",
        "\n",
        "This confirms that:\n",
        "\n",
        "* relational joins will work\n",
        "* evaluations won’t silently fail\n",
        "* historical comparisons are trustworthy\n",
        "\n",
        "Most AI agents never test this layer at all.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Historical Data Is Not Optional\n",
        "\n",
        "By testing:\n",
        "\n",
        "* historical runs\n",
        "* historical metrics\n",
        "* historical scenario evaluations\n",
        "\n",
        "you are asserting a core principle of the system:\n",
        "\n",
        "> **Evaluation without history is meaningless.**\n",
        "\n",
        "This reinforces that EaaS is:\n",
        "\n",
        "* a monitoring system\n",
        "* a regression detection engine\n",
        "* a governance tool\n",
        "\n",
        "not a one-off benchmark.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. `load_all_data()` as an Integration Checkpoint\n",
        "\n",
        "The `test_load_all_data()` function is particularly important.\n",
        "\n",
        "It proves that:\n",
        "\n",
        "* all datasets coexist correctly\n",
        "* nothing is overwritten or shadowed\n",
        "* the orchestrator can operate with a complete data picture\n",
        "\n",
        "This is effectively a **pre-flight check** for the entire agent.\n",
        "\n",
        "Executives love systems that refuse to run when prerequisites aren’t met.\n",
        "\n",
        "---\n",
        "\n",
        "## How This Differs From Most AI Agents in Production\n",
        "\n",
        "Most AI agents:\n",
        "\n",
        "* assume data exists\n",
        "* fail silently when it doesn’t\n",
        "* only validate inputs after errors occur\n",
        "* lack tests for historical baselines\n",
        "\n",
        "Your system:\n",
        "\n",
        "* validates facts upfront\n",
        "* enforces structure\n",
        "* treats data as evidence\n",
        "* makes evaluation defensible\n",
        "\n",
        "This is the difference between:\n",
        "\n",
        "> “The agent said performance dropped”\n",
        "\n",
        "and:\n",
        "\n",
        "> “The system can prove performance dropped using validated historical data.”\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Supports ROI and Trust\n",
        "\n",
        "Because data integrity is guaranteed:\n",
        "\n",
        "* fewer false alarms\n",
        "* faster root-cause analysis\n",
        "* more confidence in decisions\n",
        "* less executive skepticism\n",
        "\n",
        "That means:\n",
        "\n",
        "* less time wasted chasing phantom issues\n",
        "* more time spent improving agents\n",
        "* better adoption across teams\n",
        "\n",
        "This is exactly how ROI is protected in complex systems.\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Takeaway\n",
        "\n",
        "What leaders would see here is not “unit tests.”\n",
        "\n",
        "They would see:\n",
        "\n",
        "* discipline\n",
        "* professionalism\n",
        "* respect for data\n",
        "* seriousness about governance\n",
        "\n",
        "This test suite quietly communicates:\n",
        "\n",
        "> *“If the data isn’t right, we don’t pretend the AI is.”*\n",
        "\n",
        "That’s a powerful signal — and one that most AI systems never send.\n",
        "\n"
      ],
      "metadata": {
        "id": "TlmVr5HY9bjF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL0vOyeO73jx"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Phase 2 Utilities Test: Data Loading Utilities\n",
        "\n",
        "Tests that data loading utilities work correctly.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from agents.eval_as_service.orchestrator.utilities.data_loading import (\n",
        "    load_journey_scenarios,\n",
        "    load_specialist_agents,\n",
        "    build_agent_lookup,\n",
        "    load_supporting_data,\n",
        "    build_customer_lookup,\n",
        "    build_order_lookup,\n",
        "    load_historical_evaluation_runs,\n",
        "    load_historical_run_metrics,\n",
        "    load_historical_scenario_evaluations,\n",
        "    build_run_metrics_lookup,\n",
        "    build_evaluation_runs_lookup,\n",
        "    load_all_data\n",
        ")\n",
        "\n",
        "\n",
        "def test_load_journey_scenarios():\n",
        "    \"\"\"Test loading journey scenarios\"\"\"\n",
        "    print(\"Testing load_journey_scenarios...\")\n",
        "\n",
        "    scenarios = load_journey_scenarios()\n",
        "\n",
        "    assert isinstance(scenarios, list), \"Scenarios should be a list\"\n",
        "    assert len(scenarios) > 0, \"Should have at least one scenario\"\n",
        "\n",
        "    # Check structure of first scenario\n",
        "    scenario = scenarios[0]\n",
        "    assert \"scenario_id\" in scenario\n",
        "    assert \"customer_id\" in scenario\n",
        "    assert \"order_id\" in scenario\n",
        "    assert \"customer_message\" in scenario\n",
        "    assert \"expected_issue_type\" in scenario\n",
        "    assert \"expected_resolution_path\" in scenario\n",
        "    assert \"expected_outcome\" in scenario\n",
        "\n",
        "    print(f\"✅ Loaded {len(scenarios)} scenarios\")\n",
        "    print(f\"   Example: {scenario['scenario_id']} - {scenario['expected_issue_type']}\")\n",
        "\n",
        "\n",
        "def test_load_specialist_agents():\n",
        "    \"\"\"Test loading specialist agents\"\"\"\n",
        "    print(\"Testing load_specialist_agents...\")\n",
        "\n",
        "    agents = load_specialist_agents()\n",
        "\n",
        "    assert isinstance(agents, dict), \"Agents should be a dictionary\"\n",
        "    assert len(agents) > 0, \"Should have at least one agent\"\n",
        "\n",
        "    # Check structure\n",
        "    agent_key = list(agents.keys())[0]\n",
        "    agent = agents[agent_key]\n",
        "    assert \"agent_id\" in agent\n",
        "    assert \"description\" in agent\n",
        "    assert \"actions\" in agent\n",
        "\n",
        "    print(f\"✅ Loaded {len(agents)} agents\")\n",
        "    print(f\"   Agents: {', '.join(agents.keys())}\")\n",
        "\n",
        "\n",
        "def test_build_agent_lookup():\n",
        "    \"\"\"Test building agent lookup\"\"\"\n",
        "    print(\"Testing build_agent_lookup...\")\n",
        "\n",
        "    agents = load_specialist_agents()\n",
        "    lookup = build_agent_lookup(agents)\n",
        "\n",
        "    assert isinstance(lookup, dict)\n",
        "\n",
        "    # Check that we can look up by agent_id\n",
        "    for key, agent_data in agents.items():\n",
        "        agent_id = agent_data.get(\"agent_id\")\n",
        "        if agent_id:\n",
        "            assert agent_id in lookup, f\"Agent ID {agent_id} should be in lookup\"\n",
        "\n",
        "    print(f\"✅ Built lookup with {len(lookup)} entries\")\n",
        "\n",
        "\n",
        "def test_load_supporting_data():\n",
        "    \"\"\"Test loading supporting data\"\"\"\n",
        "    print(\"Testing load_supporting_data...\")\n",
        "\n",
        "    data = load_supporting_data()\n",
        "\n",
        "    assert \"customers\" in data\n",
        "    assert \"orders\" in data\n",
        "    assert \"logistics\" in data\n",
        "    assert \"marketing_signals\" in data\n",
        "\n",
        "    assert isinstance(data[\"customers\"], list)\n",
        "    assert isinstance(data[\"orders\"], list)\n",
        "    assert isinstance(data[\"logistics\"], dict)\n",
        "    assert isinstance(data[\"marketing_signals\"], list)\n",
        "\n",
        "    print(f\"✅ Loaded supporting data:\")\n",
        "    print(f\"   Customers: {len(data['customers'])}\")\n",
        "    print(f\"   Orders: {len(data['orders'])}\")\n",
        "    print(f\"   Logistics carriers: {len(data['logistics'])}\")\n",
        "    print(f\"   Marketing signals: {len(data['marketing_signals'])}\")\n",
        "\n",
        "\n",
        "def test_build_customer_lookup():\n",
        "    \"\"\"Test building customer lookup\"\"\"\n",
        "    print(\"Testing build_customer_lookup...\")\n",
        "\n",
        "    data = load_supporting_data()\n",
        "    lookup = build_customer_lookup(data[\"customers\"])\n",
        "\n",
        "    assert isinstance(lookup, dict)\n",
        "\n",
        "    # Check that we can look up a customer\n",
        "    if data[\"customers\"]:\n",
        "        customer_id = data[\"customers\"][0][\"customer_id\"]\n",
        "        assert customer_id in lookup\n",
        "        assert lookup[customer_id][\"customer_id\"] == customer_id\n",
        "\n",
        "    print(f\"✅ Built customer lookup with {len(lookup)} entries\")\n",
        "\n",
        "\n",
        "def test_build_order_lookup():\n",
        "    \"\"\"Test building order lookup\"\"\"\n",
        "    print(\"Testing build_order_lookup...\")\n",
        "\n",
        "    data = load_supporting_data()\n",
        "    lookup = build_order_lookup(data[\"orders\"])\n",
        "\n",
        "    assert isinstance(lookup, dict)\n",
        "\n",
        "    # Check that we can look up an order\n",
        "    if data[\"orders\"]:\n",
        "        order_id = data[\"orders\"][0][\"order_id\"]\n",
        "        assert order_id in lookup\n",
        "        assert lookup[order_id][\"order_id\"] == order_id\n",
        "\n",
        "    print(f\"✅ Built order lookup with {len(lookup)} entries\")\n",
        "\n",
        "\n",
        "def test_load_historical_data():\n",
        "    \"\"\"Test loading historical data files\"\"\"\n",
        "    print(\"Testing load_historical_data...\")\n",
        "\n",
        "    # Test evaluation runs\n",
        "    runs = load_historical_evaluation_runs()\n",
        "    assert isinstance(runs, list)\n",
        "    assert len(runs) > 0\n",
        "    assert \"run_id\" in runs[0]\n",
        "    print(f\"✅ Loaded {len(runs)} historical evaluation runs\")\n",
        "\n",
        "    # Test run metrics\n",
        "    metrics = load_historical_run_metrics()\n",
        "    assert isinstance(metrics, list)\n",
        "    assert len(metrics) > 0\n",
        "    assert \"run_id\" in metrics[0]\n",
        "    assert \"overall_pass_rate\" in metrics[0]\n",
        "    print(f\"✅ Loaded {len(metrics)} historical run metrics\")\n",
        "\n",
        "    # Test scenario evaluations\n",
        "    evaluations = load_historical_scenario_evaluations()\n",
        "    assert isinstance(evaluations, list)\n",
        "    assert len(evaluations) > 0\n",
        "    assert \"run_id\" in evaluations[0]\n",
        "    assert \"scenario_id\" in evaluations[0]\n",
        "    print(f\"✅ Loaded {len(evaluations)} historical scenario evaluations\")\n",
        "\n",
        "    # Test lookups\n",
        "    metrics_lookup = build_run_metrics_lookup(metrics)\n",
        "    runs_lookup = build_evaluation_runs_lookup(runs)\n",
        "\n",
        "    assert isinstance(metrics_lookup, dict)\n",
        "    assert isinstance(runs_lookup, dict)\n",
        "\n",
        "    if metrics:\n",
        "        run_id = metrics[0][\"run_id\"]\n",
        "        assert run_id in metrics_lookup\n",
        "        assert run_id in runs_lookup\n",
        "\n",
        "    print(f\"✅ Built lookups: {len(metrics_lookup)} metrics, {len(runs_lookup)} runs\")\n",
        "\n",
        "\n",
        "def test_load_all_data():\n",
        "    \"\"\"Test loading all data at once\"\"\"\n",
        "    print(\"Testing load_all_data...\")\n",
        "\n",
        "    all_data = load_all_data()\n",
        "\n",
        "    # Check all required keys (including new historical data)\n",
        "    required_keys = [\n",
        "        \"journey_scenarios\",\n",
        "        \"specialist_agents\",\n",
        "        \"agent_lookup\",\n",
        "        \"supporting_data\",\n",
        "        \"customer_lookup\",\n",
        "        \"order_lookup\",\n",
        "        \"decision_rules\",\n",
        "        \"historical_evaluation_runs\",\n",
        "        \"historical_run_metrics\",\n",
        "        \"historical_scenario_evaluations\",\n",
        "        \"run_metrics_lookup\",\n",
        "        \"evaluation_runs_lookup\"\n",
        "    ]\n",
        "\n",
        "    for key in required_keys:\n",
        "        assert key in all_data, f\"Missing key: {key}\"\n",
        "\n",
        "    # Verify types\n",
        "    assert isinstance(all_data[\"journey_scenarios\"], list)\n",
        "    assert isinstance(all_data[\"specialist_agents\"], dict)\n",
        "    assert isinstance(all_data[\"agent_lookup\"], dict)\n",
        "    assert isinstance(all_data[\"supporting_data\"], dict)\n",
        "    assert isinstance(all_data[\"customer_lookup\"], dict)\n",
        "    assert isinstance(all_data[\"order_lookup\"], dict)\n",
        "    assert isinstance(all_data[\"decision_rules\"], dict)\n",
        "    assert isinstance(all_data[\"historical_evaluation_runs\"], list)\n",
        "    assert isinstance(all_data[\"historical_run_metrics\"], list)\n",
        "    assert isinstance(all_data[\"historical_scenario_evaluations\"], list)\n",
        "    assert isinstance(all_data[\"run_metrics_lookup\"], dict)\n",
        "    assert isinstance(all_data[\"evaluation_runs_lookup\"], dict)\n",
        "\n",
        "    print(\"✅ All data loaded successfully\")\n",
        "    print(f\"   Scenarios: {len(all_data['journey_scenarios'])}\")\n",
        "    print(f\"   Agents: {len(all_data['specialist_agents'])}\")\n",
        "    print(f\"   Customers: {len(all_data['customer_lookup'])}\")\n",
        "    print(f\"   Orders: {len(all_data['order_lookup'])}\")\n",
        "    print(f\"   Historical runs: {len(all_data['historical_evaluation_runs'])}\")\n",
        "    print(f\"   Historical metrics: {len(all_data['historical_run_metrics'])}\")\n",
        "    print(f\"   Historical evaluations: {len(all_data['historical_scenario_evaluations'])}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Phase 2 Utilities Test: Data Loading\")\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        test_load_journey_scenarios()\n",
        "        print()\n",
        "        test_load_specialist_agents()\n",
        "        print()\n",
        "        test_build_agent_lookup()\n",
        "        print()\n",
        "        test_load_supporting_data()\n",
        "        print()\n",
        "        test_build_customer_lookup()\n",
        "        print()\n",
        "        test_build_order_lookup()\n",
        "        print()\n",
        "        test_load_historical_data()\n",
        "        print()\n",
        "        test_load_all_data()\n",
        "        print()\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"✅ Phase 2 Utilities Tests: ALL PASSED\")\n",
        "        print(\"=\" * 60)\n",
        "    except AssertionError as e:\n",
        "        print(f\"❌ Test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Unexpected error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test Results"
      ],
      "metadata": {
        "id": "oUY5rFw887dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_021_EAAS % python3 test_eval_as_service_phase2_utilities.py\n",
        "============================================================\n",
        "Phase 2 Utilities Test: Data Loading\n",
        "============================================================\n",
        "\n",
        "Testing load_journey_scenarios...\n",
        "✅ Loaded 10 scenarios\n",
        "   Example: S001 - where_is_my_order\n",
        "\n",
        "Testing load_specialist_agents...\n",
        "✅ Loaded 4 agents\n",
        "   Agents: refund_agent, shipping_update_agent, apology_message_agent, escalation_agent\n",
        "\n",
        "Testing build_agent_lookup...\n",
        "✅ Built lookup with 8 entries\n",
        "\n",
        "Testing load_supporting_data...\n",
        "✅ Loaded supporting data:\n",
        "   Customers: 5\n",
        "   Orders: 5\n",
        "   Logistics carriers: 4\n",
        "   Marketing signals: 5\n",
        "\n",
        "Testing build_customer_lookup...\n",
        "✅ Built customer lookup with 5 entries\n",
        "\n",
        "Testing build_order_lookup...\n",
        "✅ Built order lookup with 5 entries\n",
        "\n",
        "Testing load_historical_data...\n",
        "✅ Loaded 6 historical evaluation runs\n",
        "✅ Loaded 6 historical run metrics\n",
        "✅ Loaded 6 historical scenario evaluations\n",
        "✅ Built lookups: 6 metrics, 6 runs\n",
        "\n",
        "Testing load_all_data...\n",
        "✅ All data loaded successfully\n",
        "   Scenarios: 10\n",
        "   Agents: 4\n",
        "   Customers: 5\n",
        "   Orders: 5\n",
        "   Historical runs: 6\n",
        "   Historical metrics: 6\n",
        "   Historical evaluations: 6\n",
        "\n",
        "============================================================\n",
        "✅ Phase 2 Utilities Tests: ALL PASSED\n",
        "============================================================\n"
      ],
      "metadata": {
        "id": "KkN2vJlx88t9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}