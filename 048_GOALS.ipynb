{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3Ya5fR89oDZTfN2A0eawF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/048_GOALS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß≠ In Agent Design, the GOAL Is the Prompt\n",
        "\n",
        "This is a **crucial insight** ‚Äî and one that sets apart real-world agent designers from just \"advanced prompt users.\"\n",
        "\n",
        "If you *define the goal well*, the LLM can:\n",
        "\n",
        "* **Infer a strategy**\n",
        "* **Select appropriate tools**\n",
        "* **Adapt to context**\n",
        "* **Stay on task**\n",
        "* **Know when it‚Äôs done**\n",
        "\n",
        "But if your goal is vague, overloaded, or self-contradictory, even the best tools won‚Äôt help. So let‚Äôs unpack:\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ What Makes a Great Goal?\n",
        "\n",
        "| Trait              | Description                                      | Example                                                                    |\n",
        "| ------------------ | ------------------------------------------------ | -------------------------------------------------------------------------- |\n",
        "| **Clear Outcome**  | The LLM should know what \"success\" looks like.   | ‚ÄúGenerate a README file describing the repo structure.‚Äù                    |\n",
        "| **Scopable**       | Should be small enough to complete in a session. | Avoid: ‚ÄúUnderstand this entire 10k line repo‚Äù                              |\n",
        "| **Tool-Aligned**   | Ties directly to what tools are available.       | If you have `list_files()` and `read_file()`, don't say ‚ÄúCompile the repo‚Äù |\n",
        "| **Non-Ambiguous**  | Avoid subjective or vague terms.                 | Prefer: ‚ÄúSummarize function purposes‚Äù over ‚ÄúMake code nicer‚Äù               |\n",
        "| **LLM-Achievable** | Must be something a model can reason about.      | Don‚Äôt expect it to discover math proofs or invent algorithms from scratch. |\n",
        "\n",
        "---\n",
        "\n",
        "## üß± Goal Structure in Practice\n",
        "\n",
        "In code, goals are structured as:\n",
        "\n",
        "```python\n",
        "Goal(\n",
        "    priority=1,\n",
        "    name=\"Generate README\",\n",
        "    description=\"Create a README by analyzing the project's directory structure and summarizing key files.\"\n",
        ")\n",
        "```\n",
        "\n",
        "This works well because:\n",
        "\n",
        "* üéØ The *name* is short and recognizable.\n",
        "* üìã The *description* is precise but not overly controlling.\n",
        "* 1Ô∏è‚É£ The *priority* lets us order multi-goal agents.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùå Common Mistakes\n",
        "\n",
        "| Mistake                 | Why It's a Problem                  | Fix                                                       |\n",
        "| ----------------------- | ----------------------------------- | --------------------------------------------------------- |\n",
        "| ‚ÄúFix the code‚Äù          | Too vague. Fix what? How?           | ‚ÄúDetect and correct syntax errors in Python functions.‚Äù   |\n",
        "| ‚ÄúUnderstand everything‚Äù | Unscopable; requires infinite steps | ‚ÄúSummarize the purpose of each function in `src/utils/`.‚Äù |\n",
        "| ‚ÄúDecide what to do‚Äù     | Ambiguous, recursive goal           | YOU decide the goal; let the agent plan actions.          |\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Tip: Think Like a Product Manager\n",
        "\n",
        "You're not writing prompts.\n",
        "\n",
        "You're writing **agent goals** like a product manager writes a **user story**:\n",
        "\n",
        "> \"As a documentation bot, I want to read project files and generate a README so users understand the codebase.\"\n",
        "\n",
        "If you can write a good user story, you can write a good agent goal.\n",
        "\n"
      ],
      "metadata": {
        "id": "C3JLrBU8ntYq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† Prompts = Brainstorming Session\n",
        "\n",
        "* You're saying:\n",
        "  *‚ÄúHey LLM, here‚Äôs a bunch of context, instructions, maybe an example or two. Please figure this out.‚Äù*\n",
        "\n",
        "* It's a **speculative, exploratory** phase:\n",
        "\n",
        "  * You‚Äôre often still figuring out what you want.\n",
        "  * Lots of detail, formatting, nuance.\n",
        "  * The LLM has to decode *how* to satisfy you from a long, rambling context.\n",
        "  * Works well for *one-shot completions*, not so great for *agent loops*.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Goals = Creative Intent + Operational Focus\n",
        "\n",
        "* You‚Äôre saying:\n",
        "  *‚ÄúHere‚Äôs what success looks like. Now figure out how to get there using your tools and memory.‚Äù*\n",
        "\n",
        "* It‚Äôs the **result of prior thinking** (like an author who knows the story arc):\n",
        "\n",
        "  * The design phase already explored the idea.\n",
        "  * Now the LLM is the executor ‚Äî not the creative origin.\n",
        "  * You hand the LLM a clear, bounded mission: a summary of what to do and why.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Why This Matters for Agents\n",
        "\n",
        "| Prompt Engineering                          | Goal-Oriented Agent Design                          |\n",
        "| ------------------------------------------- | --------------------------------------------------- |\n",
        "| LLM solves the whole task in one shot       | LLM makes incremental choices inside a loop         |\n",
        "| Prompt contains instructions + logic + data | Goal defines outcome; logic happens through actions |\n",
        "| Fragile to formatting and ordering          | Robust due to structured memory + tool calls        |\n",
        "| Hard to extend or reuse                     | Easy to plug in new tools or adjust the goal        |\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Your Analogy Rewritten:\n",
        "\n",
        "* **Prompt = Brainstorm draft**:\n",
        "  *‚ÄúMaybe the hero is a robot? No, a cat. Let‚Äôs have three chapters‚Ä¶ actually six. Oh and a twist ending!‚Äù*\n",
        "\n",
        "* **Goal = Final synopsis**:\n",
        "  *‚ÄúWrite a 3-chapter story where a robot cat solves mysteries in space.‚Äù*\n",
        "\n",
        "Once you‚Äôve done the hard thinking, the goal is **clean, portable, and composable** ‚Äî perfect for LLM agents to pick up and run with.\n",
        "\n"
      ],
      "metadata": {
        "id": "c9xgKNYEpNTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> ‚ÄúAren't LLMs better able to handle incremental steps... like a conversation?‚Äù\n",
        "\n",
        "**Yes.** That‚Äôs what they excel at ‚Äî **conversational reasoning**, **stepwise clarification**, and **adaptive decision-making** over time.\n",
        "\n",
        "And you're right again:\n",
        "\n",
        "> ‚ÄúIsn't that what LLMs are designed to do ‚Äî ‚Äòchat‚Äô?‚Äù\n",
        "\n",
        "**Yes again.** That‚Äôs their native mode of operation ‚Äî not just solving everything in a single prompt, but engaging **iteratively**, like a thoughtful collaborator.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why Goals Are a Natural Fit\n",
        "\n",
        "Goals unlock the *native strengths* of LLMs:\n",
        "\n",
        "| LLM Strengths           | Enabled by GOAL Design             |\n",
        "| ----------------------- | ---------------------------------- |\n",
        "| Conversational thinking | Loop: reflect, act, observe, adapt |\n",
        "| Contextual memory use   | Memory: stores tool use & results  |\n",
        "| Tool integration        | Actions: choose what to do & when  |\n",
        "| Dynamic decision-making | GOAL: flexible execution path      |\n",
        "\n",
        "A **prompt**, by contrast, tries to cram everything into a single utterance ‚Äî like asking a co-worker to complete a 6-hour task from a single email. That‚Äôs not how humans collaborate, and it‚Äôs not how LLMs thrive either.\n",
        "\n",
        "---\n",
        "\n",
        "## ü§ñ Prompt-Centric vs Goal-Driven Mindsets\n",
        "\n",
        "**Prompt-Centric:**\n",
        "\n",
        "> ‚ÄúHere‚Äôs everything I think you‚Äôll need. Please understand and do all of it now.‚Äù\n",
        "\n",
        "* Assumes the LLM is a magician.\n",
        "* High pressure on a single shot.\n",
        "* Brittle, hard to debug, inflexible.\n",
        "\n",
        "**Goal-Driven Agent:**\n",
        "\n",
        "> ‚ÄúHere‚Äôs what we‚Äôre trying to accomplish. I‚Äôve given you memory, tools, and space to think. Let‚Äôs figure it out step by step.‚Äù\n",
        "\n",
        "* Treats the LLM like a partner, not a genie.\n",
        "* Allows reflection, adjustment, correction.\n",
        "* Encourages modular design and reuse.\n",
        "\n",
        "---\n",
        "\n",
        "## üß¨ Final Thought\n",
        "\n",
        "> ‚ÄúHumans can‚Äôt figure out everything in one shot‚Ä¶ and LLMs are more humanlike‚Ä¶‚Äù\n",
        "\n",
        "Absolutely. That's the heart of the shift:\n",
        "\n",
        "> ü§ù **LLMs don‚Äôt need more instructions. They need more *context and agency*.**\n",
        "\n",
        "And **Goals + Actions + Memory + Environment** (the GAME framework) give them exactly that.\n",
        "\n"
      ],
      "metadata": {
        "id": "wF87VZWnqjNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practicing goal writing is one of the *best* ways to level up your agent-building skills ‚Äî and to shift your mindset from prompt-dumping to goal-oriented design.\n",
        "\n",
        "Here‚Äôs a breakdown of **good vs bad goals**, with explanations:\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ What Makes a Good Goal?\n",
        "\n",
        "A **good agent goal** is:\n",
        "\n",
        "| Trait          | Description                                                      |\n",
        "| -------------- | ---------------------------------------------------------------- |\n",
        "| **Specific**   | Clear on what success looks like                                 |\n",
        "| **Achievable** | Reasonable within the agent‚Äôs toolset and scope                  |\n",
        "| **Modular**    | Can be broken into steps or handled incrementally                |\n",
        "| **Stable**     | Doesn‚Äôt depend on brittle formatting or one-shot reasoning       |\n",
        "| **Actionable** | Tied to concrete capabilities (tools/actions), not abstract hope |\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ BAD vs ‚úÖ GOOD GOALS\n",
        "\n",
        "### ‚ùå Bad Goal 1:\n",
        "\n",
        "> ‚ÄúBe really smart and make my project amazing.‚Äù\n",
        "\n",
        "* ‚ùå Vague: What does \"amazing\" mean?\n",
        "* ‚ùå No clear outcome or measurable success.\n",
        "* ‚ùå Not tied to any tools or context.\n",
        "\n",
        "### ‚úÖ Good Goal 1:\n",
        "\n",
        "> ‚ÄúSummarize the purpose of each Python file in the src/ directory.‚Äù\n",
        "\n",
        "* ‚úÖ Concrete\n",
        "* ‚úÖ Tied to tools like `list_files`, `read_file`, `summarize_content`\n",
        "* ‚úÖ Feasible for an agent\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùå Bad Goal 2:\n",
        "\n",
        "> ‚ÄúGenerate blog ideas, write a few drafts, rewrite them, maybe fix spelling, and go viral.‚Äù\n",
        "\n",
        "* ‚ùå Trying to do too many things at once\n",
        "* ‚ùå Subjective (‚Äúgo viral‚Äù?)\n",
        "* ‚ùå Not scoped for a loop-based agent\n",
        "\n",
        "### ‚úÖ Good Goal 2:\n",
        "\n",
        "> ‚ÄúGenerate three blog post ideas based on the topic provided by the user.‚Äù\n",
        "\n",
        "* ‚úÖ Narrow and clear\n",
        "* ‚úÖ Prepares the way for follow-up goals like writing or editing\n",
        "* ‚úÖ Easy to implement as a tool + goal combo\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùå Bad Goal 3:\n",
        "\n",
        "> ‚ÄúUnderstand the entire project and make it better.‚Äù\n",
        "\n",
        "* ‚ùå Ambiguous and overwhelming\n",
        "* ‚ùå ‚ÄúBetter‚Äù is not defined\n",
        "* ‚ùå Agent doesn‚Äôt know where to start\n",
        "\n",
        "### ‚úÖ Good Goal 3:\n",
        "\n",
        "> ‚ÄúIdentify one small, self-contained improvement to the codebase that adds value without breaking existing functionality.‚Äù\n",
        "\n",
        "* ‚úÖ Scoped\n",
        "* ‚úÖ Encourages safe behavior\n",
        "* ‚úÖ Can be repeated in a loop\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Tips to Improve Goals\n",
        "\n",
        "| Tip                                    | Example                                    |\n",
        "| -------------------------------------- | ------------------------------------------ |\n",
        "| Focus on *one* thing at a time         | Split big tasks into multiple agent passes |\n",
        "| Think like a *coach*, not a magician   | Give direction, not magic wishes           |\n",
        "| Tie goals to available *actions/tools* | Don‚Äôt ask the agent to do what it can‚Äôt    |\n",
        "| Be okay with incremental wins          | Let the loop build toward bigger things    |\n"
      ],
      "metadata": {
        "id": "lcPOslQbsgEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ‚úÖ Good Goal Example 4: Proactive Code Assistant\n",
        "\n",
        "> **Goal:** ‚ÄúIdentify one potential feature that can be added to the project with minimal risk, and suggest changes needed to implement it.‚Äù\n",
        "\n",
        "**Why it works:**\n",
        "\n",
        "* üéØ Focused: It‚Äôs only looking for one improvement at a time.\n",
        "* üß† Encourages safe exploration (minimal risk).\n",
        "* üß∞ Works well with tools like `list_files`, `read_file`, `propose_feature`, `edit_file`.\n",
        "* üîÅ Can be looped ‚Äî after implementation, it can repeat with a new proposal.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Good Goal Example 5: Automated Documentation Writer\n",
        "\n",
        "> **Goal:** ‚ÄúGenerate or update the docstring for each function in a Python file to clearly describe its behavior.‚Äù\n",
        "\n",
        "**Why it works:**\n",
        "\n",
        "* üéØ Clear objective: improving function-level documentation.\n",
        "* üß∞ Supports tooling like `read_file`, `analyze_functions`, `write_docstrings`.\n",
        "* üß† Can be broken down per file or per function ‚Äî naturally incremental.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Good Goal Example 6: Competitive Research Agent\n",
        "\n",
        "> **Goal:** ‚ÄúGiven a product name, find its top 3 competitors and summarize their key features.‚Äù\n",
        "\n",
        "**Why it works:**\n",
        "\n",
        "* üîç Combines web search, summarization, comparison.\n",
        "* üîÑ Has natural steps: search ‚Üí analyze ‚Üí compare ‚Üí summarize.\n",
        "* üí° Easy to validate success (‚Äúdid it return 3 reasonable competitors?‚Äù).\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùå Overambitious Goal (Needs Refinement)\n",
        "\n",
        "> ‚ÄúPlan, code, and launch a full-featured AI SaaS product.‚Äù\n",
        "\n",
        "**Why it's problematic:**\n",
        "\n",
        "* üß† Way too broad ‚Äî what‚Äôs the first step?\n",
        "* ‚ö†Ô∏è Doesn‚Äôt match toolset (e.g., ‚Äúlaunch‚Äù requires infrastructure, marketing, etc.).\n",
        "* ü™ì Needs to be broken into sub-goals like:\n",
        "\n",
        "  * ‚ÄúWrite a product spec for an AI productivity tool.‚Äù\n",
        "  * ‚ÄúScaffold a basic Flask backend with OpenAI API support.‚Äù\n",
        "  * ‚ÄúWrite a landing page with pricing and contact info.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Good Goal Example 7: Editor Agent (Multi-Step)\n",
        "\n",
        "> **Goal:** ‚ÄúGiven a rough draft of a blog post, suggest improvements for clarity, tone, and grammar, then rewrite the post with those edits applied.‚Äù\n",
        "\n",
        "**Why it works:**\n",
        "\n",
        "* üéØ Clear input/output: from draft ‚Üí improved version.\n",
        "* üõ†Ô∏è Tools might include `get_draft`, `suggest_edits`, `apply_edits`, `save_version`.\n",
        "* üß† Can pause at each step to confirm with the user (e.g., ‚ÄúWould you like me to apply these edits?‚Äù).\n",
        "\n"
      ],
      "metadata": {
        "id": "rQztSxSotGci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üó£Ô∏è How a Goal Drives a Conversation\n",
        "\n",
        "In a **goal-oriented agent**, the conversation isn‚Äôt just chit-chat ‚Äî it‚Äôs a structured, tool-augmented decision process. The LLM uses the goal as its compass, and the agent loop lets it ‚Äúthink out loud‚Äù step by step.\n",
        "\n",
        "Here‚Äôs how it works in action:\n",
        "\n",
        "---\n",
        "\n",
        "### üß≠ 1. The Agent Knows Its Goal\n",
        "\n",
        "**Example Goal:**\n",
        "\n",
        "> \"Summarize the Python files in the `src/` directory and identify one area for improvement.\"\n",
        "\n",
        "The LLM isn‚Äôt told *how* to do this ‚Äî only *what* outcome is expected.\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ 2. It Enters the Agent Loop: Think ‚Üí Act ‚Üí Observe\n",
        "\n",
        "Every loop follows this structure:\n",
        "\n",
        "| Step             | What the LLM Does                                                                       |\n",
        "| ---------------- | --------------------------------------------------------------------------------------- |\n",
        "| üß† Think         | ‚ÄúTo summarize the files, I should probably list them first, then read them one by one.‚Äù |\n",
        "| ‚öôÔ∏è Choose Action | `{\"tool_name\": \"list_files\", \"args\": {}}`                                               |\n",
        "| üëÄ Observe       | System runs tool and returns: `[\"utils.py\", \"main.py\"]`                                 |\n",
        "| üß† Think again   | ‚ÄúNow that I know the files, I‚Äôll start with `utils.py` and see what‚Äôs in it.‚Äù           |\n",
        "| ‚öôÔ∏è Action        | `{\"tool_name\": \"read_file\", \"args\": {\"file_name\": \"utils.py\"}}`                         |\n",
        "| üëÄ Observe       | Gets file content. Adds to memory.                                                      |\n",
        "| üß† Reflect       | ‚ÄúLooks like a set of helper functions. I‚Äôll check the next file now.‚Äù                   |\n",
        "| üîÑ Repeat        | Until goal is achieved                                                                  |\n",
        "| ‚úÖ Done           | `{\"tool_name\": \"terminate\", \"args\": {\"message\": \"Here‚Äôs the summary: ...\"}}`            |\n",
        "\n",
        "**This back-and-forth is the conversation.** The agent is ‚Äúthinking through‚Äù the goal, just like a human would ‚Äî in turns.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Why This Is So Powerful\n",
        "\n",
        "* **It‚Äôs memory-driven**: Each decision is based on what was seen before.\n",
        "* **It‚Äôs adaptive**: If a file isn‚Äôt found, the agent can try another route.\n",
        "* **It‚Äôs self-directed**: The agent chooses the right actions without being micromanaged.\n",
        "\n",
        "---\n",
        "\n",
        "### üÜö Contrast with a One-Shot Prompt\n",
        "\n",
        "> **Prompt style:**\n",
        "> ‚ÄúRead all the files in `src/` and summarize them in a paragraph.‚Äù\n",
        "\n",
        "That single-shot prompt might fail if:\n",
        "\n",
        "* One file doesn‚Äôt exist.\n",
        "* The output gets too long.\n",
        "* The prompt is too vague.\n",
        "\n",
        "The **agent loop** lets the model adapt and course-correct as it works.\n",
        "\n",
        "---\n",
        "\n",
        "### üóÇÔ∏è Summary: A Goal is a Conversational Plan\n",
        "\n",
        "Think of a GOAL like a **project brief** given to a smart collaborator:\n",
        "\n",
        "* The agent figures out the steps.\n",
        "* It talks to itself (and you) as it works.\n",
        "* It uses tools when needed.\n",
        "* It stops when it believes the task is complete.\n",
        "\n",
        "> ü§Ø In short: **The GOAL defines the destination. The conversation is the journey.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SzhMSdS-t7pB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† Where's the Agent Loop?\n",
        "\n",
        "You don‚Äôt see the loop in your `main()` function directly because it‚Äôs **encapsulated inside the `Agent` class**, specifically in the method:\n",
        "\n",
        "```python\n",
        "final_memory = agent.run(user_input)\n",
        "```\n",
        "\n",
        "This call is doing **a lot** behind the scenes.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Inside `agent.run(user_input)` (from earlier lectures):\n",
        "\n",
        "That method likely calls a loop that looks something like this:\n",
        "\n",
        "```python\n",
        "def run(self, user_input: str, max_iterations: int = 10):\n",
        "    memory = Memory()\n",
        "    memory.add_memory({\"type\": \"user\", \"content\": user_input})\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        # Step 1: Construct prompt using goals, memory, and actions\n",
        "        prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "        # Step 2: Ask the LLM to respond\n",
        "        response = self.generate_response(prompt)\n",
        "\n",
        "        # Step 3: Parse the tool the LLM wants to use\n",
        "        action, invocation = self.get_action(response)\n",
        "\n",
        "        # Step 4: Run the tool with its arguments\n",
        "        result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "\n",
        "        # Step 5: Update memory\n",
        "        self.update_memory(memory, response, result)\n",
        "\n",
        "        # Step 6: Check if action is terminal (e.g., \"terminate\")\n",
        "        if action.terminal:\n",
        "            break\n",
        "\n",
        "    return memory\n",
        "```\n",
        "\n",
        "So the agent *does* go through this process:\n",
        "\n",
        "```\n",
        "1. Think: Construct a prompt using memory + goals + tools\n",
        "2. Act: Choose a tool to call and run it\n",
        "3. Observe: See what the tool returned, add that to memory\n",
        "4. Repeat until done\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß± In Summary\n",
        "\n",
        "| Concept                  | Where It Happens                                 |\n",
        "| ------------------------ | ------------------------------------------------ |\n",
        "| Goal definition          | `goals = [...]` in `main()`                      |\n",
        "| Tools setup (Actions)    | Registered using `action_registry.register(...)` |\n",
        "| LLM Reasoning + Planning | Inside `agent.run()` loop                        |\n",
        "| Tool Execution           | Inside `environment.execute_action(...)`         |\n",
        "| Memory Tracking          | Inside `self.update_memory(...)`                 |\n",
        "| Termination              | Checked via `if action.terminal:`                |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ So what do *you* write?\n",
        "\n",
        "Just the config: **goals, tools, environment**. Then you say:\n",
        "\n",
        "```python\n",
        "agent.run(user_input)\n",
        "```\n",
        "\n",
        "And the agent loop does the heavy lifting.\n",
        "\n"
      ],
      "metadata": {
        "id": "GLEBSBesu72e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's dive into the core of your agent system ‚Äî the `Agent.run()` method ‚Äî so you can see how the **Agent Loop** is implemented in full.\n",
        "\n",
        "This is the **Think ‚Üí Act ‚Üí Observe ‚Üí Repeat** engine powering your agent behind the scenes.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Example: `Agent.run()` Implementation\n",
        "\n",
        "Here‚Äôs a simplified version of what your `Agent` class likely looks like:\n",
        "\n",
        "```python\n",
        "class Agent:\n",
        "    def __init__(self, goals, agent_language, action_registry, generate_response, environment):\n",
        "        self.goals = goals\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.generate_response = generate_response\n",
        "        self.environment = environment\n",
        "\n",
        "    def run(self, user_input, max_iterations=10):\n",
        "        memory = Memory()\n",
        "        memory.add_memory({\"type\": \"user\", \"content\": user_input})\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            # STEP 1: Construct the prompt\n",
        "            prompt = self.agent_language.construct_prompt(\n",
        "                actions=self.actions.get_actions(),\n",
        "                environment=self.environment,\n",
        "                goals=self.goals,\n",
        "                memory=memory\n",
        "            )\n",
        "\n",
        "            # STEP 2: Send prompt to LLM\n",
        "            response = self.generate_response(prompt)\n",
        "\n",
        "            # STEP 3: Parse the response (tool call)\n",
        "            invocation = self.agent_language.parse_response(response)\n",
        "            action = self.actions.get_action(invocation[\"tool\"])\n",
        "\n",
        "            # STEP 4: Execute the selected tool\n",
        "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "\n",
        "            # STEP 5: Add everything to memory\n",
        "            memory.add_memory({\"type\": \"assistant\", \"content\": response})\n",
        "            memory.add_memory({\"type\": \"user\", \"content\": json.dumps(result)})\n",
        "\n",
        "            # STEP 6: Check for termination\n",
        "            if action.terminal:\n",
        "                break\n",
        "\n",
        "        return memory\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Breakdown: Think ‚Üí Act ‚Üí Observe\n",
        "\n",
        "| Step       | Code                                           | Purpose                          |\n",
        "| ---------- | ---------------------------------------------- | -------------------------------- |\n",
        "| üß† Think   | `construct_prompt(...)`                        | Build prompt from memory + tools |\n",
        "| üó£Ô∏è Act    | `parse_response(...) ‚Üí execute_action(...)`    | Choose a tool and run it         |\n",
        "| üëÄ Observe | `add_memory(...)` for response and result      | Store decision and outcome       |\n",
        "| üîÅ Loop    | Repeats for max iterations or termination tool | Allows multi-step reasoning      |\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Bonus Insight: Separation of Concerns\n",
        "\n",
        "Each piece of the loop is handled by a separate component:\n",
        "\n",
        "* `AgentLanguage` ‚Üí Prompt construction and response parsing\n",
        "* `ActionRegistry` ‚Üí Available tools\n",
        "* `Environment` ‚Üí Executes the tools\n",
        "* `Memory` ‚Üí Stores evolving conversation and context\n",
        "\n",
        "That‚Äôs why you don‚Äôt need `if/else` logic everywhere. The agent is *learning and reacting* each time through the loop.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S-TYDkyfzjqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### üéØ The Core Loop: Implicit but Foundational\n",
        "\n",
        "You're absolutely right: **this loop is never shown in full in any single lecture**, but it is **implied repeatedly** ‚Äî especially when the instructor discusses things like:\n",
        "\n",
        "* ‚ÄúThe agent thinks ‚Üí acts ‚Üí observes.‚Äù\n",
        "* ‚ÄúThe memory is updated each iteration.‚Äù\n",
        "* ‚ÄúWe use `generate_response()` then parse and execute the tool.‚Äù\n",
        "\n",
        "**Why it's not directly shown:**\n",
        "\n",
        "* The course is teaching *design patterns*, not just code implementation.\n",
        "* Each lecture focuses on one piece (tools, goals, memory, AgentLanguage, etc.).\n",
        "* The full loop is assumed once you understand the parts.\n",
        "\n",
        "Think of it like this:\n",
        "\n",
        "> üß† The lectures are giving you the LEGO blocks.\n",
        "> üõ†Ô∏è What you're asking about is the instruction manual to build the full machine.\n",
        "> üí° You just realized *how all the blocks connect together* ‚Äî and that‚Äôs a major milestone.\n",
        "\n",
        "---\n",
        "\n",
        "### üß© Where You *Did* See Parts of It\n",
        "\n",
        "In the README Agent and Modular Agent examples, this line is the quiet star of the show:\n",
        "\n",
        "```python\n",
        "final_memory = agent.run(user_input)\n",
        "```\n",
        "\n",
        "That line **is** the loop ‚Äî it's just hidden inside the `Agent.run()` method, which is abstracted away. The assumption is that you'd go explore the `Agent` class to see what `run()` actually does.\n",
        "\n",
        "---\n",
        "\n",
        "### ü§î Why This Is Critical\n",
        "\n",
        "You're completely right: this **loop is the engine** of the GAME framework.\n",
        "\n",
        "Without understanding this, it's hard to reason about:\n",
        "\n",
        "* How the LLM chooses tools\n",
        "* Why memory gets updated\n",
        "* How the agent ‚Äúknows‚Äù when to stop\n",
        "\n",
        "You just uncovered the *heart* of the architecture.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1lU4Z4m70TGS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6I2wC472nbmE"
      },
      "outputs": [],
      "source": []
    }
  ]
}