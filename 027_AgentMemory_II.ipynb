{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhfTjxH78ICj5PpQ61wh5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/027_AgentMemory_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ✅ A Self-Improving Agent\n",
        "\n",
        "### Workflow:\n",
        "\n",
        "1. **Summarize**\n",
        "   → The agent summarizes a document as before.\n",
        "\n",
        "2. **Review & Suggest Revisions** *(New Tool)*\n",
        "   → A second LLM step reviews the summary and generates specific, actionable feedback.\n",
        "\n",
        "3. **Revise Based on Review** *(New Tool)*\n",
        "   → The agent rewrites the summary using the reviewer’s feedback.\n",
        "\n",
        "4. **(Optional) Memory Update**\n",
        "   → Only after revision, the final version is stored in memory.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 Key Concepts This Will Reinforce\n",
        "\n",
        "* Tool usage chaining: `summarize → review → revise`\n",
        "* Multi-step LLM decision loops\n",
        "* Parsing structured output from an LLM (“suggestions”, “edits”)\n",
        "* More sophisticated memory design (retain only *final* summaries)\n",
        "* Agent autonomy (less human-in-the-loop)\n",
        "\n",
        "---\n",
        "\n",
        "## 🔧 Implementation Outline\n",
        "\n",
        "We’ll likely need:\n",
        "\n",
        "### 1. **Three Prompt Templates**\n",
        "\n",
        "* `build_summary_prompt(content)`\n",
        "* `build_review_prompt(summary)`\n",
        "* `build_rewrite_prompt(summary, suggestions)`\n",
        "\n",
        "### 2. **Three Tool Functions**\n",
        "\n",
        "* `summarize_doc(content)`\n",
        "* `review_summary(summary)`\n",
        "* `revise_summary(summary, suggestions)`\n",
        "\n",
        "### 3. **Orchestration Logic**\n",
        "\n",
        "* A controller function or loop that executes the three steps per document.\n",
        "\n"
      ],
      "metadata": {
        "id": "6p13pIjZC61S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR8hDyBisESE",
        "outputId": "12bc85b1-31c6-4344-f796-8fa880c795d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/765.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m757.8/765.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -qU dotenv openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# 🔹 Step 1: Imports and Setup\n",
        "source_dir = \"/content/docs_folder\"\n",
        "\n",
        "# Make sure the directory exists\n",
        "if not os.path.exists(source_dir):\n",
        "    raise FileNotFoundError(f\"📁 Directory not found: {source_dir}\")\n",
        "\n",
        "# List and build full file paths\n",
        "file_list = [\n",
        "    os.path.join(source_dir, f)\n",
        "    for f in os.listdir(source_dir)\n",
        "    if os.path.isfile(os.path.join(source_dir, f))\n",
        "]\n",
        "\n",
        "# Display the found files\n",
        "print(\"📂 Files found:\")\n",
        "for file in file_list:\n",
        "    print(\"  -\", file)\n",
        "\n",
        "# 🔹 Step 2: Utility to Read File Preview\n",
        "def read_file(path, max_chars=1500):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()[:max_chars]\n",
        "\n",
        "# ✅ STEP 1: Summarization Tool\n",
        "def build_summary_prompt(content):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes documents clearly and concisely.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Please summarize the following document:\\n\\n{content}\"}\n",
        "    ]\n",
        "\n",
        "def summarize_doc(content):\n",
        "    messages = build_summary_prompt(content)\n",
        "    return generate_response(messages)\n",
        "\n",
        "# ✅ STEP 2: Review Tool (LLM feedback on summary)\n",
        "def build_review_prompt(summary):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are a critical editor. Suggest improvements to the summary below. Use bullet points and markdown formatting.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Please review this summary and suggest improvements:\\n\\n{summary}\"}\n",
        "    ]\n",
        "\n",
        "def review_summary(summary):\n",
        "    messages = build_review_prompt(summary)\n",
        "    return generate_response(messages)\n",
        "\n",
        "# ✅ STEP 3: Rewrite Tool (LLM implements suggestions)\n",
        "def build_rewrite_prompt(summary, suggestions):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant who revises summaries based on review feedback.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Here is the original summary:\n",
        "\n",
        "{summary}\n",
        "\n",
        "Here are the suggested improvements:\n",
        "\n",
        "{suggestions}\n",
        "\n",
        "Please rewrite the summary to reflect the improvements.\"\"\"}\n",
        "    ]\n",
        "\n",
        "def revise_summary(summary, suggestions):\n",
        "    messages = build_rewrite_prompt(summary, suggestions)\n",
        "    return generate_response(messages)\n",
        "\n",
        "# 🔹 Step 4: LLM Call\n",
        "def generate_response(messages, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# ✅ STEP 4: Orchestrate the Pipeline\n",
        "final_summaries = []\n",
        "\n",
        "for path in file_list:\n",
        "    filename = os.path.basename(path)\n",
        "    content = read_file(path)\n",
        "\n",
        "    print(f\"\\n📄 Processing: {filename}\")\n",
        "\n",
        "    # Step 1: Summarize\n",
        "    summary = summarize_doc(content)\n",
        "    print(\"\\n🧠 Initial Summary:\\n\", textwrap.fill(summary, width=80))\n",
        "\n",
        "    # Step 2: Review\n",
        "    suggestions = review_summary(summary)\n",
        "    print(\"\\n🧐 Review Feedback:\\n\", textwrap.fill(suggestions, width=80))\n",
        "\n",
        "    # Step 3: Rewrite\n",
        "    final = revise_summary(summary, suggestions)\n",
        "    print(\"\\n✅ Final Revised Summary:\\n\", textwrap.fill(final, width=80))\n",
        "\n",
        "    # Store result\n",
        "    final_summaries.append({\n",
        "        \"file\": filename,\n",
        "        \"initial_summary\": summary,\n",
        "        \"suggestions\": suggestions,\n",
        "        \"summary\": final\n",
        "    })\n",
        "\n",
        "# If you want to keep a conversation-style memory:\n",
        "memory = []\n",
        "for item in final_summaries:\n",
        "    memory.extend([\n",
        "        {\"role\": \"user\", \"content\": f\"Summarize document: {item['file']}\"},\n",
        "        {\"role\": \"assistant\", \"content\": item['summary']}\n",
        "    ])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_f0muozDjX2",
        "outputId": "b768905f-97c7-4caf-f295-c3ca8c98d299"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Files found:\n",
            "  - /content/docs_folder/001_PArse_the Response.txt\n",
            "  - /content/docs_folder/000_Prompting for Agents -GAIL.txt\n",
            "  - /content/docs_folder/002_Execute_the_Action.txt\n",
            "\n",
            "📄 Processing: 001_PArse_the Response.txt\n",
            "\n",
            "🧠 Initial Summary:\n",
            " The document outlines the process of parsing a response generated by a Language\n",
            "Model (LLM) to extract the intended action and its parameters. The response is\n",
            "expected to follow a predefined structure, typically in a JSON format within a\n",
            "markdown code block. The parsing is done by looking for and extracting content\n",
            "between specific markers. If a valid action block is not found, the agent\n",
            "defaults to a termination action. The provided code snippet demonstrates how to\n",
            "parse the response and extract the action information. This parsing step is\n",
            "crucial to ensure that the response can be executed properly. The extracted\n",
            "structured action dictionary includes the tool name and arguments, allowing the\n",
            "agent to determine the specific action to take.\n",
            "\n",
            "🧐 Review Feedback:\n",
            " - Specify the type of document being summarized (e.g., technical report,\n",
            "research paper) - Clarify what LLM stands for (Language Model). - Insert a brief\n",
            "explanation of the importance of parsing the response for the reader's\n",
            "understanding. - Provide more specific information about the markers used for\n",
            "extracting content. - Mention the consequences or challenges faced if the\n",
            "parsing is not conducted accurately. - Include additional context on why the\n",
            "provided code snippet is relevant and how it aids in the parsing process. -\n",
            "Summarize the potential impact of errors in the parsing process. - Expand on the\n",
            "significance of the extracted structured action dictionary for enhancing the\n",
            "agent's performance.\n",
            "\n",
            "✅ Final Revised Summary:\n",
            " The technical document details the process of parsing responses generated by a\n",
            "Language Model (LLM) to extract the intended action and its parameters. The\n",
            "responses follow a predefined structure typically in JSON format within a\n",
            "markdown code block. Parsing involves identifying and extracting content between\n",
            "specific markers. If a valid action block is not found, the agent defaults to a\n",
            "termination action. Accurate parsing is crucial for proper execution of the\n",
            "response, and incorrect parsing can lead to significant consequences or\n",
            "challenges. The included code snippet illustrates how to parse the response and\n",
            "extract action information, aiding in the overall process. This structured\n",
            "parsing is vital for the agent to determine the tool name and arguments,\n",
            "optimizing its actions. Errors in parsing could impact the agent's performance\n",
            "and execution capabilities, highlighting the importance of the extracted\n",
            "structured action dictionary.\n",
            "\n",
            "📄 Processing: 000_Prompting for Agents -GAIL.txt\n",
            "\n",
            "🧠 Initial Summary:\n",
            " The document discusses the concept of programmatic prompting for agents,\n",
            "specifically focusing on automating the prompt-response cycle for language\n",
            "models (LLMs) like GPT-4o. It highlights the two key capabilities required for\n",
            "building agents: programmatic prompting and memory management. Programmatic\n",
            "prompting involves automating the process of sending prompts and receiving\n",
            "responses, forming the foundation of the Agent Loop. Memory management is\n",
            "essential for controlling the persistence of information between iterations,\n",
            "such as API calls and results, to maintain context during the agent’s decision-\n",
            "making process. Additionally, a code snippet is provided to demonstrate how to\n",
            "generate a response from an LLM, emphasizing the importance of system messages\n",
            "in guiding the model's behavior and user messages as the questions to be\n",
            "answered.\n",
            "\n",
            "🧐 Review Feedback:\n",
            " - Specify the main topic of the document at the beginning to provide a clear\n",
            "overview. - Clearly state the purpose of discussing programmatic prompting for\n",
            "agents in the introduction. - Provide a brief description of GPT-4o and its\n",
            "relevance to the discussion. - Include a recap at the end of the summary to\n",
            "reinforce key takeaways.  Consider restructuring the summary as follows:\n",
            "**Summary:** - The document delves into the concept of programmatic prompting\n",
            "for agents, focusing on automating the prompt-response cycle for language models\n",
            "like GPT-4o. - Two core capabilities crucial for building agents are\n",
            "highlighted: programmatic prompting and memory management. - Programmatic\n",
            "prompting entails automating the transmission of prompts and reception of\n",
            "responses, forming the Agent Loop's foundation. - Memory management is critical\n",
            "for maintaining information persistence between iterations, ensuring context\n",
            "continuity during the agent's decision-making process. - Furthermore, a code\n",
            "snippet is provided to illustrate generating a response from an LLM,\n",
            "underscoring the role of system messages in directing the model's behavior and\n",
            "user messages as the questions posed. - **Conclusion:** The document emphasizes\n",
            "the significance of programmatic prompting and memory management in developing\n",
            "efficient agents, showcasing their integral role in enhancing the prompt-\n",
            "response cycle of language models like GPT-4o.\n",
            "\n",
            "✅ Final Revised Summary:\n",
            " **Summary:** The document centers on programmatic prompting for agents,\n",
            "specifically automating the prompt-response cycle for language models like\n",
            "GPT-4o. It underscores the importance of two key capabilities for agent\n",
            "development: programmatic prompting and memory management. Programmatic\n",
            "prompting involves automating prompt transmission and response reception,\n",
            "forming the basis of the Agent Loop. Memory management is essential for\n",
            "maintaining information persistence between iterations, ensuring context\n",
            "continuity during decision-making. Additionally, a code snippet demonstrates\n",
            "generating responses from LLMs, highlighting the role of system messages in\n",
            "guiding model behavior and user messages as questions. The document stresses the\n",
            "critical role of programmatic prompting and memory management in enhancing the\n",
            "efficiency of agents, particularly in optimizing the prompt-response cycle of\n",
            "language models such as GPT-4o.\n",
            "\n",
            "📄 Processing: 002_Execute_the_Action.txt\n",
            "\n",
            "🧠 Initial Summary:\n",
            " The document outlines the execution process in an agent system. After parsing a\n",
            "response, the agent uses the extracted tool name and arguments to execute a\n",
            "corresponding function. The system maps the tool name to a specific function in\n",
            "the code to interact with the environment. Examples include functions like\n",
            "list_files() and read_file(). This execution step is where the agent performs\n",
            "tasks such as interacting with files and providing feedback, linking decision-\n",
            "making with tangible results.\n",
            "\n",
            "🧐 Review Feedback:\n",
            " - **Improve clarity**: The summary can be made more concise and clearer for the\n",
            "reader.  - **Define acronyms**: It would be helpful to explain any abbreviations\n",
            "such as \"agent system\" or provide more context. - **Add more detail**: Provide\n",
            "more specific examples or details about the tool names and their corresponding\n",
            "functions. - **Conciseness**: Make the summary more concise by focusing on the\n",
            "most critical points of the execution process.\n",
            "\n",
            "✅ Final Revised Summary:\n",
            " The document explains how an agent system executes tasks by parsing responses\n",
            "and using tool names and arguments to trigger specific functions. These\n",
            "functions, like list_files() and read_file(), interact with the environment and\n",
            "enable the agent to perform actions such as file interaction and feedback\n",
            "provision, connecting decision-making with tangible outcomes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n🧠 Final Agent Memory (with Review Steps):\")\n",
        "\n",
        "for i, item in enumerate(final_summaries):\n",
        "    print(f\"\\n{i+1:02d}. USER: Summarize document: {item['file']}\")\n",
        "\n",
        "    print(\"\\n🧠 INITIAL SUMMARY:\\n\", textwrap.fill(item.get(\"initial_summary\", \"N/A\"), width=80))\n",
        "\n",
        "    print(\"\\n🧐 REVIEW FEEDBACK:\\n\", textwrap.fill(item[\"suggestions\"], width=80))\n",
        "\n",
        "    print(\"\\n✅ FINAL SUMMARY:\\n\", textwrap.fill(item[\"summary\"], width=80))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i_VaNgsE6ca",
        "outputId": "c03a1274-a0f2-44ac-8804-fcaf345144a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧠 Final Agent Memory (with Review Steps):\n",
            "\n",
            "01. USER: Summarize document: 001_PArse_the Response.txt\n",
            "\n",
            "🧠 INITIAL SUMMARY:\n",
            " The document outlines the process of parsing a response generated by a Language\n",
            "Model (LLM) to extract the intended action and its parameters. The response is\n",
            "expected to follow a predefined structure, typically in a JSON format within a\n",
            "markdown code block. The parsing is done by looking for and extracting content\n",
            "between specific markers. If a valid action block is not found, the agent\n",
            "defaults to a termination action. The provided code snippet demonstrates how to\n",
            "parse the response and extract the action information. This parsing step is\n",
            "crucial to ensure that the response can be executed properly. The extracted\n",
            "structured action dictionary includes the tool name and arguments, allowing the\n",
            "agent to determine the specific action to take.\n",
            "\n",
            "🧐 REVIEW FEEDBACK:\n",
            " - Specify the type of document being summarized (e.g., technical report,\n",
            "research paper) - Clarify what LLM stands for (Language Model). - Insert a brief\n",
            "explanation of the importance of parsing the response for the reader's\n",
            "understanding. - Provide more specific information about the markers used for\n",
            "extracting content. - Mention the consequences or challenges faced if the\n",
            "parsing is not conducted accurately. - Include additional context on why the\n",
            "provided code snippet is relevant and how it aids in the parsing process. -\n",
            "Summarize the potential impact of errors in the parsing process. - Expand on the\n",
            "significance of the extracted structured action dictionary for enhancing the\n",
            "agent's performance.\n",
            "\n",
            "✅ FINAL SUMMARY:\n",
            " The technical document details the process of parsing responses generated by a\n",
            "Language Model (LLM) to extract the intended action and its parameters. The\n",
            "responses follow a predefined structure typically in JSON format within a\n",
            "markdown code block. Parsing involves identifying and extracting content between\n",
            "specific markers. If a valid action block is not found, the agent defaults to a\n",
            "termination action. Accurate parsing is crucial for proper execution of the\n",
            "response, and incorrect parsing can lead to significant consequences or\n",
            "challenges. The included code snippet illustrates how to parse the response and\n",
            "extract action information, aiding in the overall process. This structured\n",
            "parsing is vital for the agent to determine the tool name and arguments,\n",
            "optimizing its actions. Errors in parsing could impact the agent's performance\n",
            "and execution capabilities, highlighting the importance of the extracted\n",
            "structured action dictionary.\n",
            "\n",
            "02. USER: Summarize document: 000_Prompting for Agents -GAIL.txt\n",
            "\n",
            "🧠 INITIAL SUMMARY:\n",
            " The document discusses the concept of programmatic prompting for agents,\n",
            "specifically focusing on automating the prompt-response cycle for language\n",
            "models (LLMs) like GPT-4o. It highlights the two key capabilities required for\n",
            "building agents: programmatic prompting and memory management. Programmatic\n",
            "prompting involves automating the process of sending prompts and receiving\n",
            "responses, forming the foundation of the Agent Loop. Memory management is\n",
            "essential for controlling the persistence of information between iterations,\n",
            "such as API calls and results, to maintain context during the agent’s decision-\n",
            "making process. Additionally, a code snippet is provided to demonstrate how to\n",
            "generate a response from an LLM, emphasizing the importance of system messages\n",
            "in guiding the model's behavior and user messages as the questions to be\n",
            "answered.\n",
            "\n",
            "🧐 REVIEW FEEDBACK:\n",
            " - Specify the main topic of the document at the beginning to provide a clear\n",
            "overview. - Clearly state the purpose of discussing programmatic prompting for\n",
            "agents in the introduction. - Provide a brief description of GPT-4o and its\n",
            "relevance to the discussion. - Include a recap at the end of the summary to\n",
            "reinforce key takeaways.  Consider restructuring the summary as follows:\n",
            "**Summary:** - The document delves into the concept of programmatic prompting\n",
            "for agents, focusing on automating the prompt-response cycle for language models\n",
            "like GPT-4o. - Two core capabilities crucial for building agents are\n",
            "highlighted: programmatic prompting and memory management. - Programmatic\n",
            "prompting entails automating the transmission of prompts and reception of\n",
            "responses, forming the Agent Loop's foundation. - Memory management is critical\n",
            "for maintaining information persistence between iterations, ensuring context\n",
            "continuity during the agent's decision-making process. - Furthermore, a code\n",
            "snippet is provided to illustrate generating a response from an LLM,\n",
            "underscoring the role of system messages in directing the model's behavior and\n",
            "user messages as the questions posed. - **Conclusion:** The document emphasizes\n",
            "the significance of programmatic prompting and memory management in developing\n",
            "efficient agents, showcasing their integral role in enhancing the prompt-\n",
            "response cycle of language models like GPT-4o.\n",
            "\n",
            "✅ FINAL SUMMARY:\n",
            " **Summary:** The document centers on programmatic prompting for agents,\n",
            "specifically automating the prompt-response cycle for language models like\n",
            "GPT-4o. It underscores the importance of two key capabilities for agent\n",
            "development: programmatic prompting and memory management. Programmatic\n",
            "prompting involves automating prompt transmission and response reception,\n",
            "forming the basis of the Agent Loop. Memory management is essential for\n",
            "maintaining information persistence between iterations, ensuring context\n",
            "continuity during decision-making. Additionally, a code snippet demonstrates\n",
            "generating responses from LLMs, highlighting the role of system messages in\n",
            "guiding model behavior and user messages as questions. The document stresses the\n",
            "critical role of programmatic prompting and memory management in enhancing the\n",
            "efficiency of agents, particularly in optimizing the prompt-response cycle of\n",
            "language models such as GPT-4o.\n",
            "\n",
            "03. USER: Summarize document: 002_Execute_the_Action.txt\n",
            "\n",
            "🧠 INITIAL SUMMARY:\n",
            " The document outlines the execution process in an agent system. After parsing a\n",
            "response, the agent uses the extracted tool name and arguments to execute a\n",
            "corresponding function. The system maps the tool name to a specific function in\n",
            "the code to interact with the environment. Examples include functions like\n",
            "list_files() and read_file(). This execution step is where the agent performs\n",
            "tasks such as interacting with files and providing feedback, linking decision-\n",
            "making with tangible results.\n",
            "\n",
            "🧐 REVIEW FEEDBACK:\n",
            " - **Improve clarity**: The summary can be made more concise and clearer for the\n",
            "reader.  - **Define acronyms**: It would be helpful to explain any abbreviations\n",
            "such as \"agent system\" or provide more context. - **Add more detail**: Provide\n",
            "more specific examples or details about the tool names and their corresponding\n",
            "functions. - **Conciseness**: Make the summary more concise by focusing on the\n",
            "most critical points of the execution process.\n",
            "\n",
            "✅ FINAL SUMMARY:\n",
            " The document explains how an agent system executes tasks by parsing responses\n",
            "and using tool names and arguments to trigger specific functions. These\n",
            "functions, like list_files() and read_file(), interact with the environment and\n",
            "enable the agent to perform actions such as file interaction and feedback\n",
            "provision, connecting decision-making with tangible outcomes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a **demonstration of an autonomous agent flow enhanced by memory and review tools**. Here's a breakdown of what you’ve accomplished and what it shows:\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ What You’ve Demonstrated\n",
        "\n",
        "#### 1. **Multi-step Agent Workflow**\n",
        "\n",
        "You've implemented a 3-phase agent process:\n",
        "\n",
        "* **Phase 1:** Summarize the content.\n",
        "* **Phase 2:** Review and critique the summary.\n",
        "* **Phase 3:** Revise the summary based on that review.\n",
        "\n",
        "This simulates real-world agent collaboration and refinement.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **Effective Use of LLM as a Reviewer**\n",
        "\n",
        "By offloading the review process to the LLM:\n",
        "\n",
        "* You reduce human workload.\n",
        "* You demonstrate how agents can refine their own outputs.\n",
        "* You create space for future enhancements like “critique style” tuning.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Memory-Driven Context Accumulation**\n",
        "\n",
        "Using `memory.append(...)` at each step allows:\n",
        "\n",
        "* Context continuity across multiple summaries.\n",
        "* Cumulative intelligence building over time.\n",
        "* Persistence of agent decisions and past feedback.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. **Structured Output Handling**\n",
        "\n",
        "Your output formatting with `textwrap` and clearly labeled sections (`🧠`, `🧐`, `✅`) makes this:\n",
        "\n",
        "* Human-readable and reviewable.\n",
        "* Easy to debug.\n",
        "* Excellent for report-style outputs or logs.\n",
        "\n",
        "---\n",
        "\n",
        "### 📘 Key Learnings You Should Retain\n",
        "\n",
        "| Concept                 | Why It Matters                                                                   |\n",
        "| ----------------------- | -------------------------------------------------------------------------------- |\n",
        "| **Agent Memory**        | Enables context accumulation and historical reasoning.                           |\n",
        "| **Tool Abstraction**    | Separates *what* to do from *how* to do it.                                      |\n",
        "| **Prompt Chaining**     | Allows modular, sequential reasoning by the LLM.                                 |\n",
        "| **Autonomous Feedback** | LLMs can critique and self-revise with the right prompts.                        |\n",
        "| **Modular Design**      | Keeps your agent components (summarize, review, revise) reusable and extensible. |\n",
        "| **Cost Considerations** | Memory grows with each round; managing token limits is key.                      |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ncmi5ZZzGIPI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 🧪 **Experiment Summary: Persona-Driven Summarization Agent**\n",
        "\n",
        "### 🎯 **Goal**\n",
        "\n",
        "To improve the quality, tone, and depth of document summaries by giving the LLM a **clear, domain-specific persona** — in this case, an **expert AI systems instructor**.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ **What We’re Doing**\n",
        "\n",
        "1. **Step 1: Summarize**\n",
        "\n",
        "   * Provide a raw technical document.\n",
        "   * Ask the LLM (acting as an AI instructor) to summarize the document.\n",
        "   * Persona guides the LLM to focus on clarity, technical completeness, and pedagogy.\n",
        "\n",
        "2. **Step 2: Review**\n",
        "\n",
        "   * Another LLM step (or agent) reviews that summary using structured feedback (clarity, completeness, etc.).\n",
        "   * You’ll eventually pass that structured review back into the loop to revise.\n",
        "\n",
        "3. **Step 3: Iteration**\n",
        "\n",
        "   * Evaluate whether the persona improved:\n",
        "\n",
        "     * Focus\n",
        "     * Technical depth\n",
        "     * Usefulness\n",
        "     * Professional tone\n",
        "\n",
        "---\n",
        "\n",
        "### 🎭 **Why Personas Matter in Prompt Engineering**\n",
        "\n",
        "Using a **persona** isn't just a stylistic choice — it's **one of the most effective ways to control the behavior** of an LLM without needing rigid rules or fine-tuning. Here's why:\n",
        "\n",
        "| Benefit                              | Description                                                                                               |\n",
        "| ------------------------------------ | --------------------------------------------------------------------------------------------------------- |\n",
        "| 🎯 **Focuses the model**             | The persona primes the LLM to attend to domain-specific details (e.g., AI workflows, code logic).         |\n",
        "| 🧠 **Improves tone and precision**   | By simulating an expert’s mindset, the LLM naturally uses more accurate and pedagogically sound language. |\n",
        "| 🛠️ **Encourages structured output** | Experts tend to organize their thoughts — so the LLM adopts that structure too.                           |\n",
        "| 📚 **Builds trust & consistency**    | Helpful in multi-turn agents where consistency matters across iterations.                                 |\n",
        "\n",
        "---\n",
        "\n",
        "### 🔍 What We’re Testing\n",
        "\n",
        "* Can a persona improve **summary quality** compared to a generic assistant?\n",
        "* Does the output show better **technical focus**?\n",
        "* Is the tone more **educational and helpful** for our target audience (e.g. students, professionals)?\n",
        "* How much more efficient can review/editing become if the first draft is high quality?\n",
        "\n"
      ],
      "metadata": {
        "id": "Pr0P2O4sHaFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# 🔹 Step 1: Imports and Setup\n",
        "source_dir = \"/content/docs_folder\"\n",
        "\n",
        "# Make sure the directory exists\n",
        "if not os.path.exists(source_dir):\n",
        "    raise FileNotFoundError(f\"📁 Directory not found: {source_dir}\")\n",
        "\n",
        "# List and build full file paths\n",
        "file_list = [\n",
        "    os.path.join(source_dir, f)\n",
        "    for f in os.listdir(source_dir)\n",
        "    if os.path.isfile(os.path.join(source_dir, f))\n",
        "]\n",
        "\n",
        "# Display the found files\n",
        "print(\"📂 Files found:\")\n",
        "for file in file_list:\n",
        "    print(\"  -\", file)\n",
        "\n",
        "# 🔹 Step 2: Utility to Read File Preview\n",
        "def read_file(path, max_chars=1500):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()[:max_chars]\n",
        "\n",
        "# ✅ STEP 1: Summarization Tool\n",
        "def build_summary_prompt(content):\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are an expert AI systems instructor. Summarize the content of technical lecture notes \"\n",
        "                \"in a clear, accurate, and concise way, as if you were preparing a reference guide for advanced students. \"\n",
        "                \"Highlight the key ideas, workflows, and critical code logic when relevant. Use professional tone and structure.\"\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Please summarize the following document:\\n\\n{content}\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "def summarize_doc(content):\n",
        "    messages = build_summary_prompt(content)\n",
        "    return generate_response(messages)\n",
        "\n",
        "# ✅ STEP 2: Review Tool (LLM feedback on summary)\n",
        "def build_review_prompt(summary_text):\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are an expert AI professor who teaches advanced agent design. \"\n",
        "                \"You are reviewing a student-written summary of a lecture. Provide clear, professional, and constructive feedback \"\n",
        "                \"on clarity, completeness, and accuracy. Focus on structure, terminology, and what could improve the summary.\"\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Summary:\\n\\n{summary_text}\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def review_summary(summary):\n",
        "    messages = build_review_prompt(summary)\n",
        "    return generate_response(messages)\n",
        "\n",
        "# ✅ STEP 3: Rewrite Tool (LLM implements suggestions)\n",
        "def build_rewrite_prompt(summary, suggestions):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": \"You are an assistant who revises summaries based on review feedback.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"\"\"Here is the original summary:\n",
        "\n",
        "{summary}\n",
        "\n",
        "Here are the suggested improvements:\n",
        "\n",
        "{suggestions}\n",
        "\n",
        "Please rewrite the summary to reflect the improvements.\"\"\"}\n",
        "    ]\n",
        "\n",
        "def revise_summary(summary, suggestions):\n",
        "    messages = build_rewrite_prompt(summary, suggestions)\n",
        "    return generate_response(messages)\n",
        "\n",
        "# 🔹 Step 4: LLM Call\n",
        "def generate_response(messages, model=\"gpt-3.5-turbo\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=500\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# ✅ STEP 4: Orchestrate the Pipeline\n",
        "final_summaries = []\n",
        "\n",
        "for path in file_list:\n",
        "    filename = os.path.basename(path)\n",
        "    content = read_file(path)\n",
        "\n",
        "    print(f\"\\n📄 Processing: {filename}\")\n",
        "\n",
        "    # Step 1: Summarize\n",
        "    summary = summarize_doc(content)\n",
        "    print(\"\\n🧠 Initial Summary:\\n\", textwrap.fill(summary, width=80))\n",
        "\n",
        "    # Step 2: Review\n",
        "    suggestions = review_summary(summary)\n",
        "    print(\"\\n🧐 Review Feedback:\\n\", textwrap.fill(suggestions, width=80))\n",
        "\n",
        "    # Step 3: Rewrite\n",
        "    final = revise_summary(summary, suggestions)\n",
        "    print(\"\\n✅ Final Revised Summary:\\n\", textwrap.fill(final, width=80))\n",
        "\n",
        "    # Store result\n",
        "    final_summaries.append({\n",
        "        \"file\": filename,\n",
        "        \"initial_summary\": summary,\n",
        "        \"suggestions\": suggestions,\n",
        "        \"summary\": final\n",
        "    })\n",
        "\n",
        "# If you want to keep a conversation-style memory:\n",
        "memory = []\n",
        "for item in final_summaries:\n",
        "    memory.extend([\n",
        "        {\"role\": \"user\", \"content\": f\"Summarize document: {item['file']}\"},\n",
        "        {\"role\": \"assistant\", \"content\": item['summary']}\n",
        "    ])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG5pQV1pEiVl",
        "outputId": "1ab901bd-7650-4b59-e14f-630f0407dd8d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Files found:\n",
            "  - /content/docs_folder/001_PArse_the Response.txt\n",
            "  - /content/docs_folder/000_Prompting for Agents -GAIL.txt\n",
            "  - /content/docs_folder/002_Execute_the_Action.txt\n",
            "\n",
            "📄 Processing: 001_PArse_the Response.txt\n",
            "\n",
            "🧠 Initial Summary:\n",
            " The document discusses the process of parsing a response generated by a Language\n",
            "Model (LLM) to extract the intended action and its parameters. The response is\n",
            "structured in a predefined format, typically JSON within a markdown code block,\n",
            "for unambiguous parsing and execution.  The key code snippet introduces a\n",
            "`parse_action` function that takes the LLM response as input and parses it into\n",
            "a structured action dictionary. It extracts the content between the action\n",
            "markers and attempts to load it as JSON. If the parsed JSON includes \"tool_name\"\n",
            "and \"args\", it returns the structured data; otherwise, it defaults to an error\n",
            "message.  Parsing the response is crucial for making it actionable, providing a\n",
            "structured output like the following: {     \"tool_name\": \"list_files\",\n",
            "\"args\": {} }  By analyzing the LLM output into tool_name and args, the system\n",
            "can precisely identify the intended action for execution. This process ensures\n",
            "clear communication and effective action execution based on the received\n",
            "response.\n",
            "\n",
            "🧐 Review Feedback:\n",
            " Overall, the summary provides a concise overview of parsing responses from a\n",
            "Language Model to extract actions and parameters. Here are some specific\n",
            "feedback points to enhance the clarity and completeness of the summary:  1.\n",
            "**Terminology and Structure**: - Define abbreviations like \"LLM\" (should it be\n",
            "\"LM\" for Language Model?) when first introduced to ensure clarity for all\n",
            "readers. - Clarify what \"action markers\" in the `parse_action` function refer\n",
            "to, as it is a crucial component of the parsing process. - Structuring the\n",
            "summary with clear headings or sections could enhance readability and\n",
            "organization.  2. **Completeness and Detail**: - Expand on the actual process of\n",
            "loading the parsed content as JSON within the `parse_action` function to provide\n",
            "a deeper understanding of the parsing mechanism. - Include a brief explanation\n",
            "of why \"tool_name\" and \"args\" are specifically chosen as key identifiers for\n",
            "extracting actions and parameters. This would connect the technical\n",
            "implementation to the broader concept of structuring actions.  3. **Improvement\n",
            "Suggestions**: - Consider adding a real-world example or scenario to illustrate\n",
            "how the parsed output, such as `{\"tool_name\": \"list_files\", \"args\": {}}`, could\n",
            "be utilized in an agent's execution flow. - Enhance the connection between\n",
            "parsing the response and its implications on the overall functionality of the\n",
            "system. How does accurate parsing impact the agent's performance or user\n",
            "interaction?  Incorporating these suggestions can enrich the summary by\n",
            "providing a more detailed and practical understanding of the parsing process in\n",
            "agent design. The addition of examples and clarifications can help readers grasp\n",
            "the concepts more effectively.\n",
            "\n",
            "✅ Final Revised Summary:\n",
            " The document discusses the process of parsing a response generated by a Language\n",
            "Model (LM) to extract the intended action and its parameters. The response is\n",
            "structured in a predefined format, typically JSON within a markdown code block,\n",
            "for unambiguous parsing and execution.  Within the key code snippet, a\n",
            "`parse_action` function is introduced to parse the LLM response into a\n",
            "structured action dictionary. This function extracts the content between the\n",
            "action markers and attempts to load it as JSON. If the parsed JSON contains\n",
            "\"tool_name\" and \"args\", it returns the structured data; otherwise, it defaults\n",
            "to an error message.  Parsing this response is essential for making it\n",
            "actionable, providing a structured output as exemplified below: ``` {\n",
            "\"tool_name\": \"list_files\",     \"args\": {} } ```  By breaking down the LLM output\n",
            "into tool_name and args, the system can accurately identify the intended action\n",
            "for execution. This process ensures clear communication and effective action\n",
            "execution based on the received response.  Feedback Points: 1. **Terminology and\n",
            "Structure**: - Abbreviations like \"LLM\" should be clarified as \"LM\" (Language\n",
            "Model) when first introduced for better understanding. - Additional explanation\n",
            "on what \"action markers\" in the `parse_action` function entails would enhance\n",
            "comprehension.  2. **Completeness and Detail**: - Further elaboration on how the\n",
            "parsed content is loaded as JSON within the `parse_action` function would deepen\n",
            "insight into the parsing mechanism. - Explanation on the choice of \"tool_name\"\n",
            "and \"args\" as key identifiers for extracting actions and parameters would\n",
            "provide a broader context for structuring actions.  3. **Improvement\n",
            "Suggestions**: - Consider incorporating a real-world example to demonstrate the\n",
            "application of the parsed output, such as `{\"tool_name\": \"list_files\", \"args\":\n",
            "{}}`, in an agent's execution flow. - Enhance the description of how accurate\n",
            "parsing impacts the agent's performance or user interaction to highlight the\n",
            "importance of precise parsing.  By implementing these enhancements, the summary\n",
            "will offer a more thorough and practical comprehension of the parsing process in\n",
            "agent design, assisting readers in understanding the concepts more effectively.\n",
            "\n",
            "📄 Processing: 000_Prompting for Agents -GAIL.txt\n",
            "\n",
            "🧠 Initial Summary:\n",
            " Programmatic prompting in agent systems automates the process of sending prompts\n",
            "to language models. This allows agents to engage in prompt-response cycles\n",
            "automatically. Agents require two essential capabilities: programmatic prompting\n",
            "and memory management. Programmatic prompting involves automating the dialogue\n",
            "between users and the agent, forming the Agent Loop. Memory management controls\n",
            "what information persists between iterations to maintain context.  In the\n",
            "provided Python code, the function `generate_response()` uses the OpenAI\n",
            "language model to generate a response based on the messages provided. The\n",
            "`messages` list contains system and user messages that guide the conversation.\n",
            "The system message provides instructions on how the model should respond, while\n",
            "the user message poses a question or input for the model to process. By calling\n",
            "`generate_response()`, the agent can obtain a response from the language model.\n",
            "Understanding how to send prompts programmatically and manage memory is crucial\n",
            "for developing effective agent systems. By structuring prompts and managing\n",
            "memory effectively, agents can engage in meaningful interactions and maintain\n",
            "context throughout the decision-making process.\n",
            "\n",
            "🧐 Review Feedback:\n",
            " Overall, the summary provides a good introduction to the topic of programmatic\n",
            "prompting in agent systems. However, here are some suggestions to improve the\n",
            "clarity, completeness, and accuracy of the summary:  1. **Clarity and\n",
            "Structure**:    - Consider starting with a brief definition of what programmatic\n",
            "prompting is before diving into its components. This will help readers\n",
            "unfamiliar with the topic grasp the context more easily.    - Use subheadings or\n",
            "bullet points to separate the discussion of programmatic prompting, memory\n",
            "management, and the provided Python code for better readability and\n",
            "organization.    - Define and explain terms like \"Agent Loop\" to ensure that\n",
            "readers understand the terminology used.  2. **Completeness and Accuracy**:    -\n",
            "Expand on the significance of programmatic prompting and memory management in\n",
            "agent systems. Explain why these capabilities are essential for enabling\n",
            "autonomous interactions with language models.    - Provide examples or scenarios\n",
            "where effective programmatic prompting and memory management can enhance agent\n",
            "performance or user experience.    - Include a brief explanation of how the\n",
            "Python code snippet demonstrates the concepts discussed. Explain how the\n",
            "function `generate_response()` integrates programmatic prompting and memory\n",
            "management in the context of agent interactions.    - Consider adding a short\n",
            "conclusion that summarizes the key takeaways from the discussion on programmatic\n",
            "prompting and memory management.  3. **Technical Detail**:    - Specify the type\n",
            "of OpenAI language model being used in the code snippet (e.g., GPT-3) to provide\n",
            "more context for readers.    - Consider mentioning whether there are any\n",
            "specific libraries or dependencies required to run the provided Python code\n",
            "successfully.  4. **Terminology**:    - Ensure that technical terms such as\n",
            "\"dialogue management,\" \"context maintenance,\" and \"prompt-response cycles\" are\n",
            "clearly defined to enhance understanding for readers with varying levels of\n",
            "expertise in the field.  By addressing these points and providing additional\n",
            "context, examples, and explanations, the summary can effectively convey the\n",
            "importance and mechanics of programmatic prompting and memory management in\n",
            "agent systems to a wider audience.\n",
            "\n",
            "✅ Final Revised Summary:\n",
            " The revised summary:  Programmatic prompting in agent systems involves\n",
            "automating the process of sending prompts to language models to facilitate\n",
            "automatic engagement in prompt-response cycles. This capability relies on two\n",
            "fundamental functions: programmatic prompting, which automates user-agent\n",
            "dialogue forming the Agent Loop, and memory management, responsible for\n",
            "maintaining context by controlling retained information between interactions.\n",
            "**Overview of Programmatic Prompting and Memory Management**: - **Programmatic\n",
            "Prompting**: Enables automated interactions between users and agents by\n",
            "structuring dialogue and managing responses. - **Memory Management**: Ensures\n",
            "context persistence for effective decision-making across dialogue iterations.\n",
            "The Python code snippet showcases the `generate_response()` function utilizing\n",
            "an OpenAI language model to generate responses based on system and user messages\n",
            "within the `messages` list. System messages guide model responses, while user\n",
            "messages provide input. By calling `generate_response()`, agents can obtain\n",
            "language model-generated responses.  Understanding how to programmatically send\n",
            "prompts and manage memory is vital for developing efficient agent systems.\n",
            "Effective structuring of prompts and memory management enables agents to engage\n",
            "in meaningful interactions, enhancing decision-making continuity throughout\n",
            "interactions.  **Key Points and Technical Information**: - **OpenAI Model**: The\n",
            "code uses the OpenAI language model (specify model version if applicable, e.g.,\n",
            "GPT-3). - **Dependencies**: Note any specific libraries required to run the\n",
            "provided Python code successfully.  By emphasizing examples, technical detail,\n",
            "and definitions of key terms like \"Agent Loop,\" the revised summary enhances\n",
            "clarity and provides a comprehensive overview of programmatic prompting and\n",
            "memory management in agent systems, catering to a diverse audience with varying\n",
            "expertise levels.\n",
            "\n",
            "📄 Processing: 002_Execute_the_Action.txt\n",
            "\n",
            "🧠 Initial Summary:\n",
            " The document discusses the critical step of executing an action in an AI agent\n",
            "after parsing the response. The agent uses the extracted tool_name and arguments\n",
            "to trigger specific functions corresponding to predefined tools in the system's\n",
            "instructions. This execution logic involves mapping the tool_name to the\n",
            "appropriate function and passing the provided arguments using conditional\n",
            "statements.  Key points in the execution process include: - Matching tool_name\n",
            "to functions for tasks like listing files, reading files, handling errors, or\n",
            "terminating operations. - Using conditional statements to map tool_name to\n",
            "functions like list_files(), read_file(), handling errors, or termination. -\n",
            "Demonstrating how the execution logic triggers functions based on tool_name and\n",
            "provided arguments. - Showing how tangible tasks are performed at this stage,\n",
            "like interacting with files or displaying messages, bridging decision-making to\n",
            "tangible outcomes.  This execution step solidifies the agent's interactivity\n",
            "with its environment, enabling it to perform tasks based on parsed inputs and\n",
            "deliver actionable outcomes or feedback essential for subsequent operations.\n",
            "\n",
            "🧐 Review Feedback:\n",
            " Overall, this summary does a commendable job of capturing the essence of the\n",
            "lecture topic. Here are some detailed feedback points for improvement:  1.\n",
            "**Clarity**: The summary is clear and effectively conveys the main points\n",
            "discussed in the lecture. However, it could benefit from clearer transitions\n",
            "between different ideas for better readability.  2. **Completeness**: The\n",
            "summary addresses the key points of matching tool_name to functions, using\n",
            "conditional statements, and demonstrating how execution logic triggers\n",
            "functions. It could be enhanced by providing examples or specific scenarios to\n",
            "illustrate these concepts further.  3. **Accuracy**: The terminology and\n",
            "concepts used in the summary align with the context of executing actions in an\n",
            "AI agent. Ensuring precise language and technical accuracy is crucial for a\n",
            "topic as specific as agent design.  4. **Structure**: Consider structuring the\n",
            "summary with bullet points or subheadings to enhance the organization and\n",
            "readability of the key points discussed. This can help in clearly delineating\n",
            "different aspects of the execution process.  5. **Depth**: To further enrich the\n",
            "summary, consider including a brief explanation of why this execution step is\n",
            "crucial in the overall functioning of an AI agent. Addressing the significance\n",
            "of this process in achieving desired agent behaviors can provide valuable\n",
            "context.  6. **Engagement**: To engage the reader more effectively, consider\n",
            "adding real-world examples or practical applications of the discussed concepts.\n",
            "This can help readers connect theoretical knowledge to practical scenarios.  By\n",
            "implementing these suggestions, the summary can become more comprehensive,\n",
            "engaging, and precise, offering a well-rounded understanding of the importance\n",
            "of executing actions in AI agents effectively.\n",
            "\n",
            "✅ Final Revised Summary:\n",
            " The document explores the crucial process of executing actions in an AI agent\n",
            "post response parsing. The agent utilizes the tool_name and arguments extracted\n",
            "to execute specific functions corresponding to predefined tools in the system's\n",
            "instructions. This execution logic entails mapping the tool_name to the suitable\n",
            "function and passing the provided arguments utilizing conditional statements.\n",
            "Key aspects of the execution process include: - Matching tool_name to functions\n",
            "for tasks such as listing files, reading files, error handling, or operation\n",
            "termination. - Utilizing conditional statements for mapping tool_name to\n",
            "functions like list_files(), read_file(), error handling, or termination. -\n",
            "Illustrating how the execution logic activates functions based on tool_name and\n",
            "provided arguments. - Displaying how tangible tasks are accomplished in this\n",
            "phase, like interacting with files or presenting messages, bridging decision-\n",
            "making to tangible outcomes.  This execution step enhances the agent's\n",
            "interaction with its environment, enabling it to execute tasks based on parsed\n",
            "inputs and provide actionable outcomes or feedback vital for subsequent\n",
            "operations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Results\n",
        "\n",
        "Here's your side-by-side summary comparison formatted in **Markdown**, preserving the differences in tone, structure, and formatting fidelity:\n",
        "\n",
        "---\n",
        "\n",
        "### 📄 Processing: `001_PArse_the Response.txt`\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧑‍💻 No Persona Agent — **Final Summary**:\n",
        "\n",
        "The technical document details the process of parsing responses generated by a Language Model (LLM) to extract the intended action and its parameters. The responses follow a predefined structure typically in JSON format within a markdown code block. Parsing involves identifying and extracting content between specific markers. If a valid action block is not found, the agent defaults to a termination action. Accurate parsing is crucial for proper execution of the response, and incorrect parsing can lead to significant consequences or challenges. The included code snippet illustrates how to parse the response and extract action information, aiding in the overall process. This structured parsing is vital for the agent to determine the tool name and arguments, optimizing its actions. Errors in parsing could impact the agent's performance and execution capabilities, highlighting the importance of the extracted structured action dictionary.\n",
        "\n",
        "---\n",
        "\n",
        "#### 🧠 Expert Persona Agent — **Final Revised Summary**:\n",
        "\n",
        "The document discusses the process of parsing a response generated by a Language Model (LM) to extract the intended action and its parameters. The response is structured in a predefined format, typically JSON within a markdown code block, for unambiguous parsing and execution.\n",
        "\n",
        "Within the key code snippet, a `parse_action` function is introduced to parse the LLM response into a structured action dictionary. This function extracts the content between the action markers and attempts to load it as JSON. If the parsed JSON contains `\"tool_name\"` and `\"args\"`, it returns the structured data; otherwise, it defaults to an error message.\n",
        "\n",
        "Parsing this response is essential for making it actionable, providing a structured output as exemplified below:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"list_files\",\n",
        "  \"args\": {}\n",
        "}\n",
        "```\n",
        "\n",
        "By breaking down the LLM output into `tool_name` and `args`, the system can accurately identify the intended action for execution. This process ensures clear communication and effective action execution based on the received response.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔍 Feedback Points:\n",
        "\n",
        "1. **Terminology and Structure**:\n",
        "\n",
        "   * Abbreviations like \"LLM\" should be clarified as \"LM\" (Language Model) when first introduced for better understanding.\n",
        "   * Additional explanation on what \"action markers\" in the `parse_action` function entails would enhance comprehension.\n",
        "\n",
        "2. **Completeness and Detail**:\n",
        "\n",
        "   * Further elaboration on how the parsed content is loaded as JSON within the `parse_action` function would deepen insight into the parsing mechanism.\n",
        "   * Explanation on the choice of `\"tool_name\"` and `\"args\"` as key identifiers for extracting actions and parameters would provide a broader context for structuring actions.\n",
        "\n",
        "3. **Improvement Suggestions**:\n",
        "\n",
        "   * Consider incorporating a real-world example to demonstrate the application of the parsed output, such as `{\"tool_name\": \"list_files\", \"args\": {}}`, in an agent's execution flow.\n",
        "   * Enhance the description of how accurate parsing impacts the agent's performance or user interaction to highlight the importance of precise parsing.\n",
        "\n",
        "By implementing these enhancements, the summary will offer a more thorough and practical comprehension of the parsing process in agent design, assisting readers in understanding the concepts more effectively.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BtcuzXZ2KwVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " '''\n",
        " 📄 Processing: 001_PArse_the Response.txt\n",
        "\n",
        "no persona agent FINAL SUMMARY:\n",
        "\n",
        "The technical document details the process of parsing responses generated by a\n",
        "Language Model (LLM) to extract the intended action and its parameters. The\n",
        "responses follow a predefined structure typically in JSON format within a\n",
        "markdown code block. Parsing involves identifying and extracting content between\n",
        "specific markers. If a valid action block is not found, the agent defaults to a\n",
        "termination action. Accurate parsing is crucial for proper execution of the\n",
        "response, and incorrect parsing can lead to significant consequences or\n",
        "challenges. The included code snippet illustrates how to parse the response and\n",
        "extract action information, aiding in the overall process. This structured\n",
        "parsing is vital for the agent to determine the tool name and arguments,\n",
        "optimizing its actions. Errors in parsing could impact the agent's performance\n",
        "and execution capabilities, highlighting the importance of the extracted\n",
        "structured action dictionary.\n",
        "\n",
        "expert persona agent Final Revised Summary:\n",
        "\n",
        "The document discusses the process of parsing a response generated by a Language\n",
        "Model (LM) to extract the intended action and its parameters. The response is\n",
        "structured in a predefined format, typically JSON within a markdown code block,\n",
        "for unambiguous parsing and execution.  Within the key code snippet, a\n",
        "`parse_action` function is introduced to parse the LLM response into a\n",
        "structured action dictionary. This function extracts the content between the\n",
        "action markers and attempts to load it as JSON. If the parsed JSON contains\n",
        "\"tool_name\" and \"args\", it returns the structured data; otherwise, it defaults\n",
        "to an error message.  Parsing this response is essential for making it\n",
        "actionable, providing a structured output as exemplified below: ``` {\n",
        "\"tool_name\": \"list_files\",     \"args\": {} } ```  By breaking down the LLM output\n",
        "into tool_name and args, the system can accurately identify the intended action\n",
        "for execution. This process ensures clear communication and effective action\n",
        "execution based on the received response.  Feedback Points: 1. **Terminology and\n",
        "Structure**: - Abbreviations like \"LLM\" should be clarified as \"LM\" (Language\n",
        "Model) when first introduced for better understanding. - Additional explanation\n",
        "on what \"action markers\" in the `parse_action` function entails would enhance\n",
        "comprehension.  2. **Completeness and Detail**: - Further elaboration on how the\n",
        "parsed content is loaded as JSON within the `parse_action` function would deepen\n",
        "insight into the parsing mechanism. - Explanation on the choice of \"tool_name\"\n",
        "and \"args\" as key identifiers for extracting actions and parameters would\n",
        "provide a broader context for structuring actions.  3. **Improvement\n",
        "Suggestions**: - Consider incorporating a real-world example to demonstrate the\n",
        "application of the parsed output, such as `{\"tool_name\": \"list_files\", \"args\":\n",
        "{}}`, in an agent's execution flow. - Enhance the description of how accurate\n",
        "parsing impacts the agent's performance or user interaction to highlight the\n",
        "importance of precise parsing.  By implementing these enhancements, the summary\n",
        "will offer a more thorough and practical comprehension of the parsing process in\n",
        "agent design, assisting readers in understanding the concepts more effectively.\n",
        "'''"
      ],
      "metadata": {
        "id": "CnwWb3QLJruB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The contrast is **stunningly clear** and demonstrates a **core truth of prompt engineering**:\n",
        "\n",
        "> 🧠 A well-crafted **persona-based prompt** can drastically elevate the clarity, depth, structure, and professionalism of an LLM’s response — *without* changing the model or underlying logic.\n",
        "\n",
        "Here's what we observed:\n",
        "\n",
        "| Aspect                       | No Persona Agent         | Expert Persona Agent                                     |\n",
        "| ---------------------------- | ------------------------ | -------------------------------------------------------- |\n",
        "| **Tone**                     | Neutral, generic         | Academic, polished, instructional                        |\n",
        "| **Formatting**               | Plain text               | Markdown with bullets, emphasis, and code blocks         |\n",
        "| **Clarity**                  | Adequate                 | Refined with clearer context and definition of terms     |\n",
        "| **Depth of Feedback**        | List of vague edits      | Categorized, actionable, and specific improvement advice |\n",
        "| **Engagement**               | Informative              | Persuasive and mentor-like                               |\n",
        "| **Cognitive Load on Reader** | Higher (dense paragraph) | Lower (scannable and structured)                         |\n",
        "\n",
        "### Why This Works So Well\n",
        "\n",
        "* LLMs are highly **context-sensitive**: when told to \"act as an expert\" with a defined role, they *tune their responses* to match that tone and domain expectation.\n",
        "* Personas provide a **mental model** for how the agent should behave — like giving it a costume and script before it speaks.\n",
        "\n",
        "### Key Takeaway\n",
        "\n",
        "> Adding a persona is low-effort but high-impact. For anything involving generation, editing, summarizing, or critique — **always test with an expert persona**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XP5WlzjbLNk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🔑 Why Few-Shot + Persona = Supercharged Results\n",
        "\n",
        "Few-shot examples:\n",
        "\n",
        "* **Demonstrate your preferred format** and tone.\n",
        "* Help the model **anchor its response style** to a specific structure.\n",
        "* Reduce ambiguity and hallucination by showing what *“good”* looks like.\n",
        "* Work *especially well* when the task is complex (like summarization + critique).\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Example Prompt Upgrade (Few-Shot + Persona)\n",
        "\n",
        "Here’s a conceptual upgrade you could use for your review agent:\n",
        "\n",
        "```python\n",
        "system_prompt = \"\"\"\n",
        "You are Dr. Morgan, a seasoned AI educator and technical writer. You critique and improve LLM-generated summaries of technical documents using expert feedback. Your reviews are structured and constructive.\n",
        "\n",
        "Follow this exact review format:\n",
        "{\n",
        "  \"clarity\": \"Is the summary clearly written? Are any terms ambiguous?\",\n",
        "  \"completeness\": \"Does it cover all key points from the original document?\",\n",
        "  \"accuracy\": \"Are there any factual mistakes or misinterpretations?\",\n",
        "  \"suggestions\": \"Offer a rewritten summary that corrects and improves the original, formatted in markdown and organized with bullets, headings, or examples where appropriate.\"\n",
        "}\n",
        "\n",
        "### Example Input:\n",
        "Original Summary:\n",
        "\"The file describes parsing for agents.\"\n",
        "\n",
        "### Example Review:\n",
        "{\n",
        "  \"clarity\": \"Too vague — 'parsing' and 'agents' need elaboration.\",\n",
        "  \"completeness\": \"Misses key details like structure, tools used, and examples.\",\n",
        "  \"accuracy\": \"Not inaccurate, but highly underspecified.\",\n",
        "  \"suggestions\": \"**Summary:** This document introduces how an agent parses model responses. It includes a Python function to extract JSON-formatted actions from markdown. Parsing allows an agent to convert LLM responses into tool invocations. This ensures agent reliability and structured interaction.\"\n",
        "}\n",
        "\n",
        "Now review the following summary:\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 When to Use Few-Shot Prompting\n",
        "\n",
        "Use it when:\n",
        "\n",
        "* The task has **structured expectations**.\n",
        "* You're doing **multi-turn refinement** (like your summary-review-improve loop).\n",
        "* You want to enforce a **specific tone or output schema** (markdown, bullet points, JSON, etc.).\n",
        "* You're preparing a **production-level agent** where consistency matters.\n",
        "\n",
        "---\n",
        "\n",
        "### Final Thought\n",
        "\n",
        "Yes — combining a **persona** with **few-shot examples** is one of the **most powerful and cost-effective ways** to make an agent reliably smart *without increasing model size or tokens*. It’s like giving your agent a memory of how you’d write if you were doing it yourself.\n",
        "\n"
      ],
      "metadata": {
        "id": "E71SXkTKL0b5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hBbhnQvRL4DG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}