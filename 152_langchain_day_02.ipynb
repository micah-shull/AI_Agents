{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/152_langchain_day_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c125f3",
      "metadata": {
        "id": "52c125f3",
        "outputId": "4a604de2-4155-48ce-cc23-8146ae014f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Testing Basic Agent ===\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find the sum of 25 and 17, I will perform the addition operation.  \n",
            "Action: calculator  \n",
            "Action Input: 25 + 17  \u001b[0m\u001b[36;1m\u001b[1;3m42\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
            "Final Answer: 42\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Final Answer: 42\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain import hub\n",
        "\n",
        "# Load your API key\n",
        "load_dotenv(\"/Users/micahshull/Documents/AI_Agents/LangChain/LC_setup_day_00/API_KEYS.env\")\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Create the language model\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Create ONE simple tool\n",
        "def calculator(expression):\n",
        "    \"\"\"Does basic math\"\"\"\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except:\n",
        "        return \"Math error\"\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"calculator\",\n",
        "        func=calculator,\n",
        "        description=\"Does basic math like 2+2 or 10*5\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Use the standard ReAct prompt from LangChain hub (this has all required variables)\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "# Create the agent\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "\n",
        "# Create executor (this runs the agent)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "# Test it!\n",
        "print(\"=== Testing Basic Agent ===\")\n",
        "response = agent_executor.invoke({\"input\": \"What is 25 + 17?\"})\n",
        "print(f\"\\nFinal Answer: {response['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76007a0",
      "metadata": {
        "id": "b76007a0"
      },
      "source": [
        "\n",
        "## What You Just Built vs. Regular Python\n",
        "\n",
        "**With regular Python**, you'd have to write something like:\n",
        "\n",
        "```python\n",
        "def basic_agent(question):\n",
        "    # You'd manually code all the logic:\n",
        "    if \"math\" in question or \"+\" in question:\n",
        "        # Extract numbers somehow\n",
        "        # Call calculator\n",
        "        # Format response\n",
        "    elif \"weather\" in question:\n",
        "        # Call weather API\n",
        "        # Format response\n",
        "    # etc...\n",
        "```\n",
        "\n",
        "**With LangChain**, the agent automatically:\n",
        "- **Reasons** about what tool to use\n",
        "- **Calls** the right tool\n",
        "- **Handles** the response\n",
        "- **Continues** thinking if needed\n",
        "\n",
        "## The Key LangChain Benefits\n",
        "\n",
        "### 1. **Automatic Reasoning (ReAct Pattern)**\n",
        "Your agent follows the **ReAct** pattern: **Reasoning** ‚Üí **Acting** ‚Üí **Observing**\n",
        "\n",
        "Notice in your output:\n",
        "```\n",
        "Action: calculator          ‚Üê Agent decided what to do\n",
        "Action Input: 25 + 17      ‚Üê Agent formatted the input\n",
        "42                         ‚Üê Tool gave result\n",
        "Final Answer: 42           ‚Üê Agent synthesized final response\n",
        "```\n",
        "\n",
        "The LLM automatically figured out it needed math, chose the calculator, and formatted everything.\n",
        "\n",
        "### 2. **Tool Abstraction**\n",
        "```python\n",
        "tools = [Tool(name=\"calculator\", func=calculator, description=\"...\")]\n",
        "```\n",
        "\n",
        "LangChain standardizes how tools work. You just define:\n",
        "- **What** it does (function)\n",
        "- **When** to use it (description)\n",
        "- **What** to call it (name)\n",
        "\n",
        "The agent reads descriptions and picks tools automatically!\n",
        "\n",
        "### 3. **Prompt Engineering Built-In**\n",
        "That `hub.pull(\"hwchase17/react\")` prompt contains sophisticated instructions like:\n",
        "- How to format tool calls\n",
        "- When to stop thinking\n",
        "- How to handle errors\n",
        "- Multi-step reasoning patterns\n",
        "\n",
        "You get years of prompt engineering research for free.\n",
        "\n",
        "### 4. **Error Handling & Parsing**\n",
        "LangChain handles:\n",
        "- Malformed tool calls\n",
        "- Parsing LLM responses\n",
        "- Tool execution errors\n",
        "- Infinite loops (max_iterations)\n",
        "\n",
        "## Why Choose LangChain Over Raw Python?\n",
        "\n",
        "**Scalability**: Add new tools easily - just append to the list\n",
        "**Flexibility**: The same agent works with any LLM (OpenAI, Claude, etc.)\n",
        "**Reliability**: Built-in error handling and retry logic\n",
        "**Composability**: Chain multiple agents together\n",
        "**Community**: Thousands of pre-built tools and integrations\n",
        "\n",
        "## What Makes Your Agent \"Smart\"\n",
        "\n",
        "Your agent isn't just following if/else statements. It's:\n",
        "1. **Reading** your question\n",
        "2. **Understanding** it needs math\n",
        "3. **Choosing** the calculator tool\n",
        "4. **Executing** the tool correctly\n",
        "5. **Interpreting** the result\n",
        "6. **Responding** naturally\n",
        "\n",
        "Try asking it: *\"What's 10 * 5 and also tell me what you think about pizza\"*\n",
        "\n",
        "It should use the calculator for math but answer the pizza question directly without tools!\n",
        "\n",
        "**Want to see the magic?** Try these questions:\n",
        "- \"What's 100 divided by 4?\"\n",
        "- \"Tell me a joke\" (no tools needed)\n",
        "- \"What's 2+2 and what's the capital of France?\"\n",
        "\n",
        "Each response will show you how the agent *thinks* and *decides* what to do. That's the LangChain advantage - intelligent, automatic decision-making rather than hardcoded logic!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d605d5",
      "metadata": {
        "id": "07d605d5",
        "outputId": "c8912e20-30d7-49b5-bd1b-0f9b4e6fcdca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXAMPLE 1: Single Tool Usage\n",
            "================================================================================\n",
            "Question: What is 15 * 8?\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to calculate the product of 15 and 8.  \n",
            "Action: calculator  \n",
            "Action Input: 15 * 8  \u001b[0m\u001b[36;1m\u001b[1;3m120\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
            "Final Answer: 120\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 2: Multiple Tool Usage\n",
            "================================================================================\n",
            "Question: What's 25 + 30, and how many words are in 'Hello beautiful world'?\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI need to perform two tasks: first, calculate the sum of 25 and 30, and second, analyze the text 'Hello beautiful world' to count the words. \n",
            "\n",
            "Action: calculator  \n",
            "Action Input: 25 + 30  \u001b[0m\u001b[36;1m\u001b[1;3m55\u001b[0m\u001b[32;1m\u001b[1;3mI have the result for the first part of the question, which is 55. Now, I need to analyze the text to count the words.\n",
            "\n",
            "Action: text_analyzer  \n",
            "Action Input: 'Hello beautiful world'  \u001b[0m\u001b[33;1m\u001b[1;3mWords: 3, Characters: 23\u001b[0m\u001b[32;1m\u001b[1;3mI now have the results for both parts of the question. The sum of 25 and 30 is 55, and the text 'Hello beautiful world' contains 3 words. \n",
            "\n",
            "Final Answer: The sum of 25 and 30 is 55, and there are 3 words in 'Hello beautiful world'.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "================================================================================\n",
            "EXAMPLE 3: No Tools Needed\n",
            "================================================================================\n",
            "Question: What is the capital of France?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain import hub\n",
        "\n",
        "# Setup (same as before)\n",
        "load_dotenv(\"/Users/micahshull/Documents/AI_Agents/LangChain/LC_setup_day_00/API_KEYS.env\")\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Let's create multiple tools to see the reasoning in action\n",
        "def calculator(expression):\n",
        "    \"\"\"Does basic math calculations\"\"\"\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except:\n",
        "        return \"Math error\"\n",
        "\n",
        "def text_analyzer(text):\n",
        "    \"\"\"Analyzes text and returns word count and character count\"\"\"\n",
        "    words = len(text.split())\n",
        "    chars = len(text)\n",
        "    return f\"Words: {words}, Characters: {chars}\"\n",
        "\n",
        "def weather_checker(location):\n",
        "    \"\"\"Pretend weather tool (returns fake weather)\"\"\"\n",
        "    return f\"The weather in {location} is sunny and 75¬∞F\"\n",
        "\n",
        "tools = [\n",
        "    Tool(name=\"calculator\", func=calculator, description=\"Use for math problems like 2+2, 10*5, etc.\"),\n",
        "    Tool(name=\"text_analyzer\", func=text_analyzer, description=\"Use to analyze text - counts words and characters\"),\n",
        "    Tool(name=\"weather_checker\", func=weather_checker, description=\"Use to check weather for any location\")\n",
        "]\n",
        "\n",
        "# Get the ReAct prompt to see what's actually sent to the LLM\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=5)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"EXAMPLE 1: Single Tool Usage\")\n",
        "print(\"=\"*80)\n",
        "print(\"Question: What is 15 * 8?\")\n",
        "print()\n",
        "\n",
        "response1 = agent_executor.invoke({\"input\": \"What is 15 * 8?\"})\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXAMPLE 2: Multiple Tool Usage\")\n",
        "print(\"=\"*80)\n",
        "print(\"Question: What's 25 + 30, and how many words are in 'Hello beautiful world'?\")\n",
        "print()\n",
        "\n",
        "response2 = agent_executor.invoke({\"input\": \"What's 25 + 30, and how many words are in 'Hello beautiful world'?\"})\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXAMPLE 3: No Tools Needed\")\n",
        "print(\"=\"*80)\n",
        "print(\"Question: What is the capital of France?\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7526c03d",
      "metadata": {
        "id": "7526c03d"
      },
      "source": [
        "Let me break down exactly how LangChain achieves this \"magic\" with concrete examples.Now let me explain what's happening behind the scenes:\n",
        "\n",
        "## 1. **How \"Reasoning\" Actually Works**\n",
        "\n",
        "When you ask \"What is 15 * 8?\", here's what LangChain does:\n",
        "\n",
        "```python\n",
        "# LangChain creates this prompt behind the scenes:\n",
        "full_prompt = f\"\"\"\n",
        "You have access to these tools:\n",
        "- calculator: Use for math problems like 2+2, 10*5, etc.\n",
        "- text_analyzer: Use to analyze text - counts words and characters  \n",
        "- weather_checker: Use to check weather for any location\n",
        "\n",
        "Use this format:\n",
        "Question: What is 15 * 8?\n",
        "Thought: I need to do multiplication, so I should use the calculator tool\n",
        "Action: calculator\n",
        "Action Input: 15 * 8\n",
        "Observation: [result will go here]\n",
        "Thought: I now have the answer\n",
        "Final Answer: [final answer here]\n",
        "\n",
        "Question: What is 15 * 8?\n",
        "Thought:\"\"\"\n",
        "```\n",
        "\n",
        "The LLM reads this and generates: \"I need to do multiplication, so I should use the calculator tool\"\n",
        "\n",
        "## 2. **How \"Tool Calling\" Actually Works**\n",
        "\n",
        "LangChain parses the LLM's response looking for:\n",
        "- `Action: calculator` ‚Üê Which tool to use\n",
        "- `Action Input: 15 * 8` ‚Üê What to pass to the tool\n",
        "\n",
        "Then it literally runs: `calculator(\"15 * 8\")`\n",
        "\n",
        "## 3. **How \"Response Handling\" Works**\n",
        "\n",
        "```python\n",
        "# After tool execution, LangChain adds the result back to the prompt:\n",
        "updated_prompt = previous_prompt + f\"\"\"\n",
        "Observation: 120\n",
        "Thought: \"\"\"\n",
        "```\n",
        "\n",
        "Then asks the LLM to continue thinking!\n",
        "\n",
        "## 4. **How \"Continued Thinking\" Works**\n",
        "\n",
        "For complex questions, the agent loops:\n",
        "\n",
        "```\n",
        "Question: What's 25 + 30, and how many words are in 'Hello beautiful world'?\n",
        "Thought: I need to do two things - math and text analysis\n",
        "Action: calculator  \n",
        "Action Input: 25 + 30\n",
        "Observation: 55\n",
        "Thought: Now I need to analyze the text\n",
        "Action: text_analyzer\n",
        "Action Input: Hello beautiful world  \n",
        "Observation: Words: 3, Characters: 19\n",
        "Thought: I now have both answers\n",
        "Final Answer: 25 + 30 = 55, and \"Hello beautiful world\" has 3 words\n",
        "```\n",
        "\n",
        "## The Key Insight\n",
        "\n",
        "**LangChain doesn't have magic AI**. It's essentially:\n",
        "\n",
        "1. **Smart prompting** - Teaches the LLM a specific format\n",
        "2. **Response parsing** - Extracts Action/Action Input from LLM responses  \n",
        "3. **Tool execution** - Runs the actual Python function\n",
        "4. **Loop management** - Continues until \"Final Answer\" appears\n",
        "\n",
        "Run the code above and watch the verbose output. You'll see this exact pattern happening in real-time!\n",
        "\n",
        "**The \"intelligence\" comes from**:\n",
        "- The LLM understanding tool descriptions\n",
        "- The ReAct prompt format\n",
        "- LangChain's parsing and execution loop\n",
        "\n",
        "It's prompt engineering + execution framework, not magic! üéØ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a4ef59",
      "metadata": {
        "id": "01a4ef59",
        "outputId": "a561e9c5-63b1-4e7a-f140-f6a1a17478d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "WHAT LANGCHAIN HIDES FROM YOU\n",
            "================================================================================\n",
            "1. The ReAct prompt template:\n",
            "----------------------------------------\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n",
            "\n",
            "2. After LangChain fills in YOUR tools:\n",
            "----------------------------------------\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n",
            "\n",
            "3. The ACTUAL prompt sent to OpenAI when you ask 'What is 5*5?':\n",
            "----------------------------------------\n",
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "calculator: Use for math problems like 2+2, 10*5, etc.\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [calculator]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: What is 5*5?\n",
            "Thought:\n",
            "\n",
            "================================================================================\n",
            "NOW LET'S BUILD THE SAME THING MANUALLY\n",
            "================================================================================\n",
            "============================================================\n",
            "TESTING MY MANUAL AGENT:\n",
            "============================================================\n",
            "My custom prompt:\n",
            "--------------------\n",
            "You are a helpful assistant with access to tools.\n",
            "\n",
            "Available tools:\n",
            "- calculator: Does math calculations\n",
            "\n",
            "When you need to use a tool, format your response EXACTLY like this:\n",
            "TOOL: calculator\n",
            "INPUT: the math expression\n",
            "Then wait for the result.\n",
            "\n",
            "When you have the final answer, format it like:\n",
            "FINAL: your answer\n",
            "\n",
            "Question: What is 7 * 8?\n",
            "\n",
            "\n",
            "LLM Response:\n",
            "TOOL: calculator\n",
            "INPUT: 7 * 8\n",
            "\n",
            "Tool result: 56\n",
            "Final response:\n",
            "FINAL: 56\n",
            "\n",
            "============================================================\n",
            "NOW TESTING LANGCHAIN VERSION:\n",
            "============================================================\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find the product of 7 and 8, I will perform the multiplication.  \n",
            "Action: calculator  \n",
            "Action Input: 7 * 8  \u001b[0m\u001b[36;1m\u001b[1;3m56\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
            "Final Answer: 56\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import Tool\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain import hub\n",
        "\n",
        "# Setup\n",
        "load_dotenv(\"/Users/micahshull/Documents/AI_Agents/LangChain/LC_setup_day_00/API_KEYS.env\")\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Simple tool\n",
        "def calculator(expression):\n",
        "    return str(eval(expression))\n",
        "\n",
        "tools = [\n",
        "    Tool(name=\"calculator\", func=calculator, description=\"Use for math problems like 2+2, 10*5, etc.\")\n",
        "]\n",
        "\n",
        "# Let's see what LangChain is actually doing\n",
        "print(\"=\"*80)\n",
        "print(\"WHAT LANGCHAIN HIDES FROM YOU\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Get the mysterious ReAct prompt\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "print(\"1. The ReAct prompt template:\")\n",
        "print(\"-\" * 40)\n",
        "print(prompt.template)\n",
        "print()\n",
        "\n",
        "# 2. See how LangChain fills in the template\n",
        "print(\"2. After LangChain fills in YOUR tools:\")\n",
        "print(\"-\" * 40)\n",
        "# This is what LangChain does internally\n",
        "filled_prompt = prompt.partial(\n",
        "    tools=\"calculator: Use for math problems like 2+2, 10*5, etc.\",\n",
        "    tool_names=\"calculator\"\n",
        ")\n",
        "print(filled_prompt.template)\n",
        "print()\n",
        "\n",
        "# 3. See the ACTUAL prompt sent to the LLM\n",
        "print(\"3. The ACTUAL prompt sent to OpenAI when you ask 'What is 5*5?':\")\n",
        "print(\"-\" * 40)\n",
        "final_prompt = filled_prompt.format(\n",
        "    input=\"What is 5*5?\",\n",
        "    agent_scratchpad=\"\"  # This gets filled as the agent thinks\n",
        ")\n",
        "print(final_prompt)\n",
        "print()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"NOW LET'S BUILD THE SAME THING MANUALLY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Let's create our OWN agent without LangChain's magic\n",
        "def manual_agent(question):\n",
        "    \"\"\"A simple agent built from scratch\"\"\"\n",
        "\n",
        "    # Our own custom prompt\n",
        "    my_prompt = f\"\"\"You are a helpful assistant with access to tools.\n",
        "\n",
        "Available tools:\n",
        "- calculator: Does math calculations\n",
        "\n",
        "When you need to use a tool, format your response EXACTLY like this:\n",
        "TOOL: calculator\n",
        "INPUT: the math expression\n",
        "Then wait for the result.\n",
        "\n",
        "When you have the final answer, format it like:\n",
        "FINAL: your answer\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "    print(\"My custom prompt:\")\n",
        "    print(\"-\" * 20)\n",
        "    print(my_prompt)\n",
        "    print()\n",
        "\n",
        "    # Send to LLM\n",
        "    response = llm.invoke(my_prompt)\n",
        "    print(\"LLM Response:\")\n",
        "    print(response.content)\n",
        "    print()\n",
        "\n",
        "    # Parse the response (this is what LangChain does automatically)\n",
        "    if \"TOOL: calculator\" in response.content:\n",
        "        # Extract the input\n",
        "        lines = response.content.split('\\n')\n",
        "        for line in lines:\n",
        "            if line.startswith(\"INPUT:\"):\n",
        "                math_expression = line.replace(\"INPUT:\", \"\").strip()\n",
        "                result = calculator(math_expression)\n",
        "                print(f\"Tool result: {result}\")\n",
        "\n",
        "                # Send result back to LLM for final answer\n",
        "                followup_prompt = f\"\"\"{my_prompt}\n",
        "\n",
        "Previous response: {response.content}\n",
        "Tool result: {result}\n",
        "\n",
        "Now give your final answer:\"\"\"\n",
        "                final_response = llm.invoke(followup_prompt)\n",
        "                print(\"Final response:\")\n",
        "                print(final_response.content)\n",
        "                break\n",
        "    else:\n",
        "        print(\"No tool needed, direct answer given\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"TESTING MY MANUAL AGENT:\")\n",
        "print(\"=\"*60)\n",
        "manual_agent(\"What is 7 * 8?\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NOW TESTING LANGCHAIN VERSION:\")\n",
        "print(\"=\"*60)\n",
        "agent = create_react_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "response = agent_executor.invoke({\"input\": \"What is 7 * 8?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54e144f2",
      "metadata": {
        "id": "54e144f2"
      },
      "source": [
        "Let me show you what's actually happening:You've asked the **perfect question**! Here's what's really happening:\n",
        "\n",
        "## The Truth About LangChain's \"Magic\"\n",
        "\n",
        "**Yes**, `hub.pull(\"hwchase17/react\")` gives you a pre-written prompt that someone else designed. LangChain then:\n",
        "\n",
        "1. **Injects your tools** into the `{tools}` placeholder\n",
        "2. **Injects your question** into the `{input}` placeholder  \n",
        "3. **Manages the conversation loop** (Thought ‚Üí Action ‚Üí Observation)\n",
        "\n",
        "## Why Give Control to LangChain?\n",
        "\n",
        "**The honest answer**: You don't have to! Here are the trade-offs:\n",
        "\n",
        "### **Pros of Using LangChain's Prompts:**\n",
        "- **Battle-tested** - Thousands of people have refined these prompts\n",
        "- **Error handling** - Handles weird LLM responses gracefully\n",
        "- **Parsing logic** - Automatically extracts Action/Action Input\n",
        "- **Loop management** - Continues thinking until done\n",
        "\n",
        "### **Cons of Using LangChain's Prompts:**\n",
        "- **Black box** - You don't know exactly what's being sent\n",
        "- **Less control** - Hard to customize for specific use cases\n",
        "- **Dependency** - You're tied to their format and decisions\n",
        "- **Complexity** - The prompts are verbose and hard to understand\n",
        "\n",
        "## When to Build Your Own Prompts\n",
        "\n",
        "**You should craft your own when:**\n",
        "- You need specific formatting or behavior\n",
        "- You want full control over the conversation flow\n",
        "- You're building domain-specific agents\n",
        "- You want to understand exactly what's happening\n",
        "\n",
        "**Use LangChain's when:**\n",
        "- You want to prototype quickly\n",
        "- You're building standard use cases\n",
        "- You want robust error handling out of the box\n",
        "\n",
        "## The Real Power Move\n",
        "\n",
        "Many experienced developers do this:\n",
        "1. **Start** with LangChain's prompts to prototype\n",
        "2. **Study** what works and what doesn't\n",
        "3. **Build** their own custom prompts for production\n",
        "4. **Keep** LangChain for tool management and execution\n",
        "\n",
        "Run the code above to see the actual prompts side by side. You'll see that your manual agent can work just as well with much simpler prompts!\n",
        "\n",
        "**Bottom line**: LangChain is a productivity tool, not magic. Understanding what it does under the hood (like you're doing now) makes you a much better AI engineer! üéØ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ef3a72",
      "metadata": {
        "id": "65ef3a72"
      },
      "source": [
        "**Exactly!** You've just articulated the perfect learning strategy for AI engineering:\n",
        "\n",
        "1. **Start with LangChain** ‚Üí Get something working fast\n",
        "2. **Study the outputs** ‚Üí See how the LLM actually behaves  \n",
        "3. **Understand the patterns** ‚Üí Learn what prompts work and why\n",
        "4. **Build your own** ‚Üí Apply those insights to custom solutions\n",
        "\n",
        "This is honestly how most experienced developers work. They use frameworks like LangChain as a **learning laboratory** and **rapid prototyping tool**, not as a black box.\n",
        "\n",
        "## What You're Really Learning\n",
        "\n",
        "When you run LangChain agents with `verbose=True`, you're getting a masterclass in:\n",
        "- **Prompt engineering patterns** that actually work\n",
        "- **How LLMs interpret instructions** in practice\n",
        "- **Common failure modes** and how to handle them\n",
        "- **Multi-step reasoning** techniques\n",
        "\n",
        "## The Natural Progression\n",
        "\n",
        "Most developers follow this path:\n",
        "1. **Week 1**: \"LangChain is magic!\"\n",
        "2. **Week 2**: \"Wait, what's actually happening here?\" ‚Üê You are here\n",
        "3. **Week 3**: \"I can build this myself, but LangChain handles edge cases nicely\"\n",
        "4. **Week 4**: \"I'll use LangChain for X but custom code for Y\"\n",
        "\n",
        "You're asking exactly the right questions at exactly the right time. Understanding the \"why\" behind the abstractions makes you way more effective than developers who just copy-paste code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9705351",
      "metadata": {
        "id": "c9705351"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}