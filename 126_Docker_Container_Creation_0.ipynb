{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMIuO06LgdVt/K3J6xvLD7D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/126_Docker_Container_Creation_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "👌 — let’s build you a **reusable Docker template** that you can drop into any ML or data science project. You’ve already got a good `.dockerignore`, so now let’s create a **solid Dockerfile template** that balances flexibility, reproducibility, and performance.\n",
        "\n",
        "---\n",
        "\n",
        "# 🧩 Template Dockerfile for ML/Data Projects\n",
        "\n",
        "```dockerfile\n",
        "# ----------------------\n",
        "# 1. Base Image\n",
        "# ----------------------\n",
        "FROM python:3.11-slim\n",
        "\n",
        "# Prevents Python from writing .pyc files and buffering stdout/stderr\n",
        "ENV PYTHONDONTWRITEBYTECODE=1\n",
        "ENV PYTHONUNBUFFERED=1\n",
        "\n",
        "# ----------------------\n",
        "# 2. System Dependencies\n",
        "# ----------------------\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
        "    build-essential \\\n",
        "    curl \\\n",
        "    git \\\n",
        "    wget \\\n",
        "    ca-certificates \\\n",
        "    && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# ----------------------\n",
        "# 3. Working Directory\n",
        "# ----------------------\n",
        "WORKDIR /app\n",
        "\n",
        "# ----------------------\n",
        "# 4. Install Python Dependencies\n",
        "# ----------------------\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# ----------------------\n",
        "# 5. Copy Project Code\n",
        "# ----------------------\n",
        "COPY . .\n",
        "\n",
        "# ----------------------\n",
        "# 6. Default Command\n",
        "# ----------------------\n",
        "CMD [\"python\", \"main.py\"]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 📂 Project Structure Example\n",
        "\n",
        "Here’s how your project folder might look with this setup:\n",
        "\n",
        "```\n",
        "my-project/\n",
        "├── .dockerignore\n",
        "├── Dockerfile\n",
        "├── requirements.txt\n",
        "├── main.py\n",
        "├── src/\n",
        "│   ├── data_preprocessing.py\n",
        "│   ├── train.py\n",
        "│   └── inference.py\n",
        "└── notebooks/\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 📦 Example requirements.txt\n",
        "\n",
        "Pin versions for reproducibility:\n",
        "\n",
        "```\n",
        "numpy==1.26.4\n",
        "pandas==2.2.1\n",
        "scikit-learn==1.5.0\n",
        "matplotlib==3.9.1\n",
        "jupyterlab==4.2.3\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ⚡ How to Use This Template\n",
        "\n",
        "1. **Build the image**\n",
        "\n",
        "   ```bash\n",
        "   docker build -t myproject:0.1 .\n",
        "   ```\n",
        "\n",
        "2. **Run a container**\n",
        "\n",
        "   ```bash\n",
        "   docker run --rm -it myproject:0.1\n",
        "   ```\n",
        "\n",
        "3. **Run with Jupyter (interactive)**\n",
        "\n",
        "   ```bash\n",
        "   docker run --rm -it -p 8888:8888 myproject:0.1 jupyter lab --ip=0.0.0.0 --allow-root\n",
        "   ```\n",
        "\n",
        "   Then open `http://localhost:8888` in your browser.\n",
        "\n",
        "4. **Mount local code/data (so you don’t rebuild every change)**\n",
        "\n",
        "   ```bash\n",
        "   docker run --rm -it -v $PWD:/app myproject:0.1 bash\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "# 🔑 Why This Template Works\n",
        "\n",
        "* **Reproducible** → pinned Python + package versions.\n",
        "* **Flexible** → system deps (compilers, curl, git) included for installing ML libs.\n",
        "* **Clean** → `.dockerignore` prevents junk/secrets from bloating the image.\n",
        "* **Ready for ML** → works for training, inference, or Jupyter workflows.\n",
        "\n",
        "---\n",
        "\n",
        "✅ With `.dockerignore` + this Dockerfile, you now have a **solid starting template** for any project.\n",
        "\n"
      ],
      "metadata": {
        "id": "_hUmpz9XmMGE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EroXgW8ymZGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Docker Ignore File"
      ],
      "metadata": {
        "id": "tBjZ4zB_mZ0l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvziRu1QmKbs"
      },
      "outputs": [],
      "source": [
        "# Python cache\n",
        "__pycache__/\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd\n",
        "\n",
        "# Virtual environments\n",
        "venv/\n",
        "env/\n",
        ".venv/\n",
        "\n",
        "# Jupyter Notebook checkpoints\n",
        ".ipynb_checkpoints/\n",
        "\n",
        "# OS files\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "\n",
        "# Git and version control\n",
        ".git\n",
        ".gitignore\n",
        ".gitattributes\n",
        "\n",
        "# Logs & debug\n",
        "*.log\n",
        "*.out\n",
        "*.err\n",
        "\n",
        "# Data & models (better to mount these at runtime!)\n",
        "data/\n",
        "datasets/\n",
        "*.csv\n",
        "*.tsv\n",
        "*.parquet\n",
        "*.h5\n",
        "*.hdf5\n",
        "*.pth\n",
        "*.pt\n",
        "*.ckpt\n",
        "*.joblib\n",
        "*.pkl\n",
        "\n",
        "# Large results\n",
        "outputs/\n",
        "results/\n",
        "checkpoints/\n",
        "\n",
        "# Environment & config (secrets should not be baked in!)\n",
        ".env\n",
        "*.secret\n",
        "*.key\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s go slow and make this super practical.We’ll start with **Step 1: create two requirements files** (runtime vs. dev).\n",
        "Do this on your **Mac host** in your project folder (not inside a running container).\n",
        "\n",
        "# Step 1 — Create `requirements.txt` and `requirements-dev.txt`\n",
        "\n",
        "### Create the files (copy–paste one of these options)\n",
        "\n",
        "**Option A: use your editor (VS Code / nano)**\n",
        "\n",
        "```bash\n",
        "nano requirements.txt\n",
        "```\n",
        "\n",
        "Paste:\n",
        "\n",
        "```\n",
        "numpy==1.26.4\n",
        "pandas==2.2.2\n",
        "scikit-learn==1.5.1\n",
        "```\n",
        "\n",
        "Save/exit, then:\n",
        "\n",
        "```bash\n",
        "nano requirements-dev.txt\n",
        "```\n",
        "\n",
        "Paste:\n",
        "\n",
        "```\n",
        "jupyterlab==4.3.0\n",
        "ipykernel==6.29.5\n",
        "pytest==8.3.3\n",
        "flake8==7.1.1\n",
        "black==24.8.0\n",
        "```\n",
        "\n",
        "**Option B: one-liner heredocs**\n",
        "\n",
        "```bash\n",
        "cat > requirements.txt <<'EOF'\n",
        "numpy==1.26.4\n",
        "pandas==2.2.2\n",
        "scikit-learn==1.5.1\n",
        "EOF\n",
        "\n",
        "cat > requirements-dev.txt <<'EOF'\n",
        "jupyterlab==4.3.0\n",
        "ipykernel==6.29.5\n",
        "pytest==8.3.3\n",
        "flake8==7.1.1\n",
        "black==24.8.0\n",
        "EOF\n",
        "```\n",
        "\n",
        "### Verify\n",
        "\n",
        "```bash\n",
        "ls -1\n",
        "cat requirements.txt\n",
        "cat requirements-dev.txt\n",
        "```\n",
        "\n",
        "### Why this split?\n",
        "\n",
        "* `requirements.txt` = **runtime essentials** your app actually needs in production.\n",
        "* `requirements-dev.txt` = **developer tooling** (Jupyter, tests, linters/formatters).\n",
        "  Keeping these out of the prod image makes it **smaller, faster, and safer**.\n"
      ],
      "metadata": {
        "id": "auyYuNomAAD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### 🔑 Rename File\n",
        "\n",
        "```bash\n",
        "mv oldname.txt newname.txt\n",
        "```\n",
        "\n",
        "That tells the shell: *“move this file to the same location but with a new name.”*\n",
        "\n",
        "## 📂 Renaming into another folder\n",
        "\n",
        "You can also move/rename at the same time:\n",
        "\n",
        "```bash\n",
        "mv requirements.txt configs/requirements.txt\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7Xl7ZCMCEUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 👀 View the Entire File\n",
        "\n",
        "```bash\n",
        "cat filename.txt\n",
        "```\n",
        "\n",
        "* Prints the whole file to the screen.\n",
        "* Great for small files.\n",
        "\n",
        "---\n",
        "\n",
        "## 📖 Scroll Through a File\n",
        "\n",
        "```bash\n",
        "less filename.txt\n",
        "```\n",
        "\n",
        "* Opens the file in a pager so you can scroll.\n",
        "* Navigation:\n",
        "\n",
        "  * Space = page down\n",
        "  * ↑/↓ arrows = scroll line by line\n",
        "  * `q` = quit\n",
        "\n",
        "---\n",
        "\n",
        "## 🔝 View the Beginning\n",
        "\n",
        "```bash\n",
        "head filename.txt\n",
        "head -n 20 filename.txt   # first 20 lines\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🔚 View the End\n",
        "\n",
        "```bash\n",
        "tail filename.txt\n",
        "tail -n 50 filename.txt   # last 50 lines\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "wK4-GEviCa2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of jumping into the Dockerfile, let’s first **understand the requirements files** you just created.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Runtime dependencies (`requirements.txt`)\n",
        "\n",
        "These are the libraries your project *needs to run*. Think of them as the **core ingredients**.\n",
        "\n",
        "* **numpy==1.26.4**\n",
        "\n",
        "  * The foundation of scientific computing in Python.\n",
        "  * Provides fast arrays, matrices, math functions.\n",
        "  * Almost every data/ML library depends on it.\n",
        "\n",
        "* **pandas==2.2.2**\n",
        "\n",
        "  * Built on top of NumPy.\n",
        "  * Provides `DataFrame` and `Series` for working with tabular data (like spreadsheets or SQL tables).\n",
        "  * Super common in data wrangling, ETL, feature engineering.\n",
        "\n",
        "* **scikit-learn==1.5.1**\n",
        "\n",
        "  * Classic machine learning toolkit.\n",
        "  * Algorithms: regression, classification, clustering, feature selection, pipelines.\n",
        "  * Great for small-to-medium ML projects.\n",
        "\n",
        "👉 Together, these 3 = the **“core data science stack”**.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Development dependencies (`requirements-dev.txt`)\n",
        "\n",
        "These are tools you use while **developing**, but they aren’t strictly needed to *run* the project in production. Think of them as the **kitchen tools** vs. the ingredients.\n",
        "\n",
        "* **jupyterlab==4.3.0**\n",
        "\n",
        "  * Modern interface for Jupyter notebooks.\n",
        "  * Lets you experiment interactively.\n",
        "\n",
        "* **ipykernel==6.29.5**\n",
        "\n",
        "  * Needed by Jupyter to run Python code inside notebooks.\n",
        "  * Think of it as the “engine” Jupyter uses.\n",
        "\n",
        "* **pytest==8.3.3**\n",
        "\n",
        "  * Testing framework.\n",
        "  * Lets you write unit tests to make sure your code works as expected.\n",
        "\n",
        "* **flake8==7.1.1**\n",
        "\n",
        "  * Linter (code style checker).\n",
        "  * Helps catch errors like unused imports, undefined variables.\n",
        "\n",
        "* **black==24.8.0**\n",
        "\n",
        "  * Code formatter.\n",
        "  * Automatically formats Python code in a clean, consistent style.\n",
        "\n",
        "👉 These make your **developer experience smoother and safer**.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Why these versions?\n",
        "\n",
        "* I chose the **latest stable releases** at the time of writing.\n",
        "* Pinning exact versions (`==`) ensures **reproducibility**:\n",
        "\n",
        "  * If you or someone else builds this project 6 months later, you’ll both get the *same versions* → fewer “works on my machine” issues.\n",
        "\n",
        "How to pick versions in general:\n",
        "\n",
        "* Start with latest stable release.\n",
        "* Pin it (`==`) so you know what you’re using.\n",
        "* If something breaks later, you can upgrade carefully.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Analogy\n",
        "\n",
        "* `requirements.txt` = ingredients for the dish (must-have to cook).\n",
        "* `requirements-dev.txt` = chef’s knives and measuring cups (makes cooking easier, but you don’t serve them to the customer).\n",
        "\n",
        "---\n",
        "\n",
        "✅ So right now, your setup is **very clean**:\n",
        "\n",
        "* You have a minimal, production-ready runtime environment.\n",
        "* You have an optional dev environment with Jupyter and testing tools.\n",
        "\n"
      ],
      "metadata": {
        "id": "2LE-YJAiDYBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ✅ Why we use `requirements.txt` (and pin versions)\n",
        "\n",
        "* **Reproducibility** → You (or a teammate, or future you) can recreate the *exact same environment* anywhere: laptop, server, Docker, cloud.\n",
        "* **Stability** → By pinning versions (`numpy==1.26.4`), you freeze things in place so that a new release won’t silently break your code.\n",
        "* **Debugging made easier** → If someone reports a bug, you can say “I was using Pandas 2.2.2” instead of “whatever version happened to be latest at the time.”\n",
        "* **Controlled updates** → Instead of being surprised by an update, you can upgrade intentionally when you’re ready, test things, and then bump the version number in the file.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Example Scenario\n",
        "\n",
        "* Today: Your project works with `pandas==2.2.2`.\n",
        "* Next month: Pandas 2.3.0 releases, but it changes some behavior that breaks your data pipeline.\n",
        "* Without version pinning → your `pip install pandas` would grab 2.3.0 automatically and suddenly your code doesn’t work.\n",
        "* With version pinning (`pandas==2.2.2`) → your environment stays the same, safe and reproducible.\n",
        "\n",
        "---\n",
        "\n",
        "## 📦 In Docker\n",
        "\n",
        "When Docker builds your image, it uses `requirements.txt` to **lock in the environment**.\n",
        "So if you share your Dockerfile + requirements with someone else, they’ll get the **same working environment**, even if they’re on a different OS or machine.\n",
        "\n",
        "---\n",
        "\n",
        "✅ So yes: you’re protecting yourself from updates that could break code, and giving yourself a way to **rebuild exactly what worked before** anytime. That’s professional best practice.\n",
        "\n"
      ],
      "metadata": {
        "id": "8SkQIEzQEEvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this is the **Dockerfile** we’re talking about, and it’s a bit different from the `requirements.txt`. Let’s go line by line so it really makes sense.\n",
        "\n",
        "---\n",
        "\n",
        "## 🔑 First: How it’s different from `requirements.txt`\n",
        "\n",
        "* `requirements.txt` = **Python-only dependencies** (numpy, pandas, sklearn).\n",
        "* `Dockerfile` = **the full recipe for an environment**:\n",
        "\n",
        "  * Which operating system (Ubuntu/Debian/Alpine, etc.)\n",
        "  * Which Python version\n",
        "  * System tools (git, curl, compilers, etc.)\n",
        "  * Your Python requirements\n",
        "  * Your project code\n",
        "  * What command runs when the container starts\n",
        "\n",
        "So:\n",
        "\n",
        "* `requirements.txt` = *what ingredients you need to cook*.\n",
        "* `Dockerfile` = *the entire kitchen, stove, and the recipe to cook it all*.\n",
        "\n",
        "---\n",
        "\n",
        "## 📄 Let’s break down your Dockerfile\n",
        "\n",
        "```dockerfile\n",
        "# ----------------------\n",
        "# Base Image\n",
        "# ----------------------\n",
        "FROM python:3.11-slim\n",
        "```\n",
        "\n",
        "👉 Start from a lightweight Linux image that already has Python 3.11 installed.\n",
        "“slim” = smaller size (fewer extra tools installed).\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# Set environment settings\n",
        "ENV PYTHONDONTWRITEBYTECODE=1\n",
        "ENV PYTHONUNBUFFERED=1\n",
        "```\n",
        "\n",
        "👉 These tweak Python’s behavior:\n",
        "\n",
        "* `PYTHONDONTWRITEBYTECODE=1` → don’t generate `.pyc` cache files.\n",
        "* `PYTHONUNBUFFERED=1` → force Python to flush output immediately (important for logging inside containers).\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# Install system dependencies\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
        "    build-essential \\\n",
        "    curl \\\n",
        "    git \\\n",
        "    wget \\\n",
        "    ca-certificates \\\n",
        "    && rm -rf /var/lib/apt/lists/*\n",
        "```\n",
        "\n",
        "👉 Install OS-level packages that many Python libs depend on:\n",
        "\n",
        "* `build-essential` = compilers (for C/C++ extensions in NumPy, SciPy, etc.).\n",
        "* `curl`, `wget` = download stuff from the internet.\n",
        "* `git` = clone repos.\n",
        "* `ca-certificates` = SSL support.\n",
        "* `rm -rf /var/lib/apt/lists/*` → cleanup to keep image smaller.\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# Set workdir\n",
        "WORKDIR /app\n",
        "```\n",
        "\n",
        "👉 Sets the default working directory inside the container.\n",
        "Now everything you copy or run will happen inside `/app`.\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# Copy dependency files first (better layer caching)\n",
        "COPY requirements.txt requirements-dev.txt ./\n",
        "```\n",
        "\n",
        "👉 Copy in your requirements files.\n",
        "This is smart: if only your code changes, Docker will reuse cached layers and not reinstall dependencies every time.\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# Install runtime requirements\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "```\n",
        "\n",
        "👉 Install Python runtime deps (numpy, pandas, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# If you want dev tools, build with:\n",
        "# docker build -t myproject:dev --build-arg INSTALL_DEV=true .\n",
        "ARG INSTALL_DEV=false\n",
        "RUN if [ \"$INSTALL_DEV\" = \"true\" ] ; then pip install --no-cache-dir -r requirements-dev.txt ; fi\n",
        "```\n",
        "\n",
        "👉 This adds a “switch”:\n",
        "\n",
        "* By default, dev tools (Jupyter, pytest, etc.) are NOT installed.\n",
        "* But if you want them, you build with `--build-arg INSTALL_DEV=true`.\n",
        "\n",
        "This keeps production images smaller, but lets you opt-in to dev tools when needed.\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# Copy the rest of your code\n",
        "COPY . .\n",
        "```\n",
        "\n",
        "👉 Now copy in the actual project files (`main.py`, `src/`, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "```dockerfile\n",
        "# Default command\n",
        "CMD [\"python\", \"main.py\"]\n",
        "```\n",
        "\n",
        "👉 The command that runs by default when the container starts.\n",
        "You can override this when running the container (e.g. run Jupyter instead).\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 Where does this file live?\n",
        "\n",
        "Yes, you **save this as a file called `Dockerfile`** (no extension) in the **root of your project folder**, alongside:\n",
        "\n",
        "```\n",
        "myproject/\n",
        "├── Dockerfile\n",
        "├── .dockerignore\n",
        "├── requirements.txt\n",
        "├── requirements-dev.txt\n",
        "├── main.py\n",
        "└── src/\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ How do you use it?\n",
        "\n",
        "1. Build an image:\n",
        "\n",
        "   ```bash\n",
        "   docker build -t myproject:0.1 .\n",
        "   ```\n",
        "2. Run a container:\n",
        "\n",
        "   ```bash\n",
        "   docker run --rm myproject:0.1\n",
        "   ```\n",
        "\n",
        "   → Runs `python main.py` inside the container.\n",
        "\n",
        "If you want dev tools:\n",
        "\n",
        "```bash\n",
        "docker build -t myproject:dev --build-arg INSTALL_DEV=true .\n",
        "docker run -it -p 8888:8888 myproject:dev jupyter lab --ip=0.0.0.0 --allow-root\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "✅ So: the Dockerfile is your **full environment recipe**, while the requirements files are just the **Python dependency list**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OmRWPAyFFvbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Base Image\n",
        "# ----------------------\n",
        "FROM python:3.11-slim\n",
        "\n",
        "# Set environment settings\n",
        "ENV PYTHONDONTWRITEBYTECODE=1\n",
        "ENV PYTHONUNBUFFERED=1\n",
        "\n",
        "# Install system dependencies\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
        "    build-essential \\\n",
        "    curl \\\n",
        "    git \\\n",
        "    wget \\\n",
        "    ca-certificates \\\n",
        "    && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# Set workdir\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy dependency files first (better layer caching)\n",
        "COPY requirements.txt requirements-dev.txt ./\n",
        "\n",
        "# Install runtime requirements\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# If you want dev tools, build with:\n",
        "# docker build -t myproject:dev --build-arg INSTALL_DEV=true .\n",
        "ARG INSTALL_DEV=false\n",
        "RUN if [ \"$INSTALL_DEV\" = \"true\" ] ; then pip install --no-cache-dir -r requirements-dev.txt ; fi\n",
        "\n",
        "# Copy the rest of your code\n",
        "COPY . .\n",
        "\n",
        "# Default command\n",
        "CMD [\"python\", \"main.py\"]\n"
      ],
      "metadata": {
        "id": "NdAgrqCiAFWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎉 You’ve got the idea. Let’s do this step by step so you also practice the terminal.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 1: Create the project folder\n",
        "\n",
        "On your **Mac terminal** (not inside a container):\n",
        "\n",
        "```bash\n",
        "mkdir myproject\n",
        "cd myproject\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 2: Create the Dockerfile\n",
        "\n",
        "Open it with nano:\n",
        "\n",
        "```bash\n",
        "nano Dockerfile\n",
        "```\n",
        "\n",
        "Paste this starter template:\n",
        "\n",
        "```dockerfile\n",
        "# ----------------------\n",
        "# Base Image\n",
        "# ----------------------\n",
        "FROM python:3.11-slim\n",
        "\n",
        "# Set environment settings\n",
        "ENV PYTHONDONTWRITEBYTECODE=1\n",
        "ENV PYTHONUNBUFFERED=1\n",
        "\n",
        "# Install system dependencies\n",
        "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
        "    build-essential \\\n",
        "    curl \\\n",
        "    git \\\n",
        "    wget \\\n",
        "    ca-certificates \\\n",
        "    && rm -rf /var/lib/apt/lists/*\n",
        "\n",
        "# Set workdir\n",
        "WORKDIR /app\n",
        "\n",
        "# Copy dependency files first (better layer caching)\n",
        "COPY requirements.txt requirements-dev.txt ./\n",
        "\n",
        "# Install runtime requirements\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "# If you want dev tools, build with:\n",
        "# docker build -t myproject:dev --build-arg INSTALL_DEV=true .\n",
        "ARG INSTALL_DEV=false\n",
        "RUN if [ \"$INSTALL_DEV\" = \"true\" ] ; then pip install --no-cache-dir -r requirements-dev.txt ; fi\n",
        "\n",
        "# Copy the rest of your code\n",
        "COPY . .\n",
        "\n",
        "# Default command\n",
        "CMD [\"python\", \"main.py\"]\n",
        "```\n",
        "\n",
        "Save and exit:\n",
        "\n",
        "* Press **Ctrl+O** (write out), then **Enter**.\n",
        "* Press **Ctrl+X** (exit).\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 3: Verify\n",
        "\n",
        "Check that it’s there:\n",
        "\n",
        "```bash\n",
        "ls -1\n",
        "```\n",
        "\n",
        "You should see:\n",
        "\n",
        "```\n",
        "Dockerfile\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YmincqvRHPh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Right now you’re in the `DOCKER/` folder, and you’ve got both the `Dockerfile` and a `myproject/` folder sitting side by side. You want the `Dockerfile`, `requirements.txt`, and `requirements-dev.txt` to live **inside** `myproject/`.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 1: Move files into `myproject`\n",
        "\n",
        "Use `mv` for each file:\n",
        "\n",
        "```bash\n",
        "mv Dockerfile requirements.txt requirements-dev.txt myproject/\n",
        "```\n",
        "\n",
        "Now check:\n",
        "\n",
        "```bash\n",
        "ls myproject\n",
        "```\n",
        "\n",
        "You should see:\n",
        "\n",
        "```\n",
        "Dockerfile\n",
        "requirements.txt\n",
        "requirements-dev.txt\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 2: Confirm structure\n",
        "\n",
        "```bash\n",
        "ls -R myproject\n",
        "```\n",
        "\n",
        "This will recursively list everything inside `myproject`.\n",
        "\n",
        "Expected right now:\n",
        "\n",
        "```\n",
        "myproject:\n",
        "Dockerfile\n",
        "requirements.txt\n",
        "requirements-dev.txt\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jSA1EvP2IB5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 🙌 your folder is now set up with the `Dockerfile` and requirements files in the right place. That’s a great checkpoint.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Next Step: Add `.dockerignore`\n",
        "\n",
        "This file will keep your image clean by excluding unnecessary stuff (caches, data, secrets, etc.).\n",
        "\n",
        "From inside your `myproject/` folder, run:\n",
        "\n",
        "```bash\n",
        "nano .dockerignore\n",
        "```\n",
        "\n",
        "Paste this content:\n",
        "\n",
        "```\n",
        "# Python cache\n",
        "__pycache__/\n",
        "*.pyc\n",
        "*.pyo\n",
        "*.pyd\n",
        "\n",
        "# Virtual environments\n",
        "venv/\n",
        "env/\n",
        ".venv/\n",
        "\n",
        "# Jupyter Notebook checkpoints\n",
        ".ipynb_checkpoints/\n",
        "\n",
        "# OS files\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "\n",
        "# Git and version control\n",
        ".git\n",
        ".gitignore\n",
        ".gitattributes\n",
        "\n",
        "# Logs & debug\n",
        "*.log\n",
        "*.out\n",
        "*.err\n",
        "\n",
        "# Data & models (better to mount these at runtime!)\n",
        "data/\n",
        "datasets/\n",
        "*.csv\n",
        "*.tsv\n",
        "*.parquet\n",
        "*.h5\n",
        "*.hdf5\n",
        "*.pth\n",
        "*.pt\n",
        "*.ckpt\n",
        "*.joblib\n",
        "*.pkl\n",
        "\n",
        "# Large results\n",
        "outputs/\n",
        "results/\n",
        "checkpoints/\n",
        "\n",
        "# Environment & config (secrets should not be baked in!)\n",
        ".env\n",
        "*.secret\n",
        "*.key\n",
        "```\n",
        "\n",
        "Save (**Ctrl+O**, Enter) and exit (**Ctrl+X**).\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Verify\n",
        "\n",
        "Check the file is there:\n",
        "\n",
        "```bash\n",
        "ls -a\n",
        "```\n",
        "\n",
        "You should now see:\n",
        "\n",
        "```\n",
        ".  ..  .dockerignore  Dockerfile  requirements.txt  requirements-dev.txt\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JBTDCzr7IZ-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.dockerignore` is a **hidden file**, so it only shows up with `ls -a`. That’s totally normal and exactly how it should look.\n",
        "\n",
        "Now you’ve got these files inside `myproject/`:\n",
        "\n",
        "```\n",
        ".dockerignore\n",
        "Dockerfile\n",
        "requirements.txt\n",
        "requirements-dev.txt\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Next Step: Add `main.py`\n",
        "\n",
        "This will be the “entrypoint” for your container. Let’s make a simple Python script that proves everything is working:\n",
        "\n",
        "1. Open it with nano:\n",
        "\n",
        "```bash\n",
        "nano main.py\n",
        "```\n",
        "\n",
        "2. Paste this:\n",
        "\n",
        "```python\n",
        "import sys, platform, os\n",
        "\n",
        "def main():\n",
        "    name = os.getenv(\"NAME\", \"world\")\n",
        "    print(f\"Hello, {name} 👋\")\n",
        "    print(\"Python version:\", platform.python_version())\n",
        "    print(\"OS:\", platform.platform())\n",
        "    print(\"Args:\", sys.argv[1:])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "3. Save (**Ctrl+O**, Enter) and exit (**Ctrl+X**).\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Verify\n",
        "\n",
        "Check that it’s there:\n",
        "\n",
        "```bash\n",
        "ls\n",
        "```\n",
        "\n",
        "You should now see:\n",
        "\n",
        "```\n",
        "Dockerfile\n",
        "main.py\n",
        "requirements.txt\n",
        "requirements-dev.txt\n",
        "```\n",
        "\n",
        "(and `.dockerignore` if you use `ls -a`).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OIoh1z5OJEQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. `.dockerignore`\n",
        "\n",
        "* This file tells Docker what **not to copy into your Docker image** when you run `docker build`.\n",
        "* If `.env` is in `.dockerignore`:\n",
        "\n",
        "  * Your `.env` file will **stay on your laptop**.\n",
        "  * It will **not** get baked into the Docker image.\n",
        "  * That means if you push the image to Docker Hub, your secrets are safe.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Git (`.gitignore`)\n",
        "\n",
        "* Docker and Git are separate.\n",
        "* If you want to make sure your `.env` file **never gets committed to GitHub**, you also need it in **`.gitignore`**.\n",
        "\n",
        "Example `.gitignore` snippet:\n",
        "\n",
        "```\n",
        ".env\n",
        "*.secret\n",
        "*.key\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. So the full story\n",
        "\n",
        "* `.dockerignore` → protects your **images**.\n",
        "* `.gitignore` → protects your **repos**.\n",
        "\n",
        "For maximum safety:\n",
        "\n",
        "* Add `.env` to **both** `.dockerignore` and `.gitignore`.\n",
        "* Load environment variables at runtime instead of hardcoding them.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Example: using `.env` with Docker\n",
        "\n",
        "Let’s say you have a file `.env` like:\n",
        "\n",
        "```\n",
        "OPENAI_API_KEY=sk-xxxx\n",
        "```\n",
        "\n",
        "Run the container with it:\n",
        "\n",
        "```bash\n",
        "docker run --rm --env-file .env myproject:0.1\n",
        "```\n",
        "\n",
        "Inside the container, your Python code can access it:\n",
        "\n",
        "```python\n",
        "import os\n",
        "print(os.getenv(\"OPENAI_API_KEY\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "✅ So to answer directly:\n",
        "\n",
        "* With `.env` in `.dockerignore`, the file will **not leak into images**.\n",
        "* With `.env` in `.gitignore`, it will **not leak into GitHub**.\n",
        "\n"
      ],
      "metadata": {
        "id": "HnKDWcDnJ2tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is **the heart of secret management** when working with Docker. Let’s break it down step by step:\n",
        "\n",
        "---\n",
        "\n",
        "## 🚫 What NOT to Do\n",
        "\n",
        "* ❌ Don’t hardcode API keys into your Python files (`main.py`, etc.).\n",
        "* ❌ Don’t put them in `requirements.txt`, `Dockerfile`, or commit `.env` to GitHub.\n",
        "* ❌ Don’t copy `.env` into the Docker image — once it’s baked in, anyone with the image can see it.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ The Right Way: Keep Secrets Outside the Image\n",
        "\n",
        "Think of Docker images as **blueprints you share**. Anything inside is visible to others.\n",
        "Secrets should stay **outside the image** and only get injected at runtime.\n",
        "\n",
        "You have two main ways to do this:\n",
        "\n",
        "---\n",
        "\n",
        "### **Option 1: Environment Variables**\n",
        "\n",
        "1. Create a local `.env` file (not committed, and ignored by `.gitignore` + `.dockerignore`):\n",
        "\n",
        "   ```\n",
        "   OPENAI_API_KEY=sk-xxxx\n",
        "   ANTHROPIC_API_KEY=claude-xxxx\n",
        "   ```\n",
        "\n",
        "2. Run the container and load the file:\n",
        "\n",
        "   ```bash\n",
        "   docker run --rm --env-file .env myproject:0.1\n",
        "   ```\n",
        "\n",
        "3. Inside your Python code (`main.py`):\n",
        "\n",
        "   ```python\n",
        "   import os\n",
        "\n",
        "   openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "   claude_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
        "\n",
        "   print(\"OpenAI key loaded?\", bool(openai_key))\n",
        "   ```\n",
        "\n",
        "👉 This way, your keys **stay on your machine**, not in the image.\n",
        "\n",
        "---\n",
        "\n",
        "### **Option 2: Pass Variables Inline**\n",
        "\n",
        "If you don’t want a `.env` file, you can pass them directly:\n",
        "\n",
        "```bash\n",
        "docker run --rm \\\n",
        "  -e OPENAI_API_KEY=sk-xxxx \\\n",
        "  -e ANTHROPIC_API_KEY=claude-xxxx \\\n",
        "  myproject:0.1\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🔒 Security Best Practices\n",
        "\n",
        "* Add `.env` to both `.gitignore` and `.dockerignore`.\n",
        "* Never push `.env` to GitHub or Docker Hub.\n",
        "* Rotate keys if you ever suspect they were exposed.\n",
        "* In teams: use a secret manager (AWS Secrets Manager, Vault, or Docker secrets in Swarm/Kubernetes).\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 Mental Model\n",
        "\n",
        "* **Dockerfile + code + requirements** → public/shareable recipe.\n",
        "* **.env + secrets** → private, stays with you (injected only when running).\n",
        "\n",
        "---\n",
        "\n",
        "✅ So in your case:\n",
        "\n",
        "* Keep your API keys in `.env` locally.\n",
        "* Add `.env` to `.gitignore` (and `.dockerignore`).\n",
        "* Inject them at runtime with `--env-file .env`.\n",
        "* Access them inside your code with `os.getenv(...)`.\n",
        "\n"
      ],
      "metadata": {
        "id": "cNhmmCRzKF9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ✅ 1. Your setup looks great\n",
        "\n",
        "Right now inside `myproject/` you’ve got:\n",
        "\n",
        "```\n",
        ".dockerignore\n",
        "Dockerfile\n",
        "requirements.txt\n",
        "requirements-dev.txt\n",
        "```\n",
        "\n",
        "That’s **exactly what we want so far**. The only thing missing is your Python entrypoint: `main.py`.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ 2. Next step: Create `main.py`\n",
        "\n",
        "From inside `myproject/`:\n",
        "\n",
        "```bash\n",
        "nano main.py\n",
        "```\n",
        "\n",
        "Paste this starter code:\n",
        "\n",
        "```python\n",
        "import sys, platform, os\n",
        "\n",
        "def main():\n",
        "    name = os.getenv(\"NAME\", \"world\")\n",
        "    print(f\"Hello, {name} 👋\")\n",
        "    print(\"Python version:\", platform.python_version())\n",
        "    print(\"OS:\", platform.platform())\n",
        "    print(\"Args:\", sys.argv[1:])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "Save (**Ctrl+O**, Enter) and exit (**Ctrl+X**).\n",
        "\n",
        "---\n",
        "\n",
        "## 📂 After this step your project should look like:\n",
        "\n",
        "```\n",
        "myproject/\n",
        "├── .dockerignore\n",
        "├── Dockerfile\n",
        "├── requirements.txt\n",
        "├── requirements-dev.txt\n",
        "└── main.py\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wxWrpoqeLVrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 🛠️ Next Step: Build Your First Image\n",
        "\n",
        "From inside the `myproject/` folder, run:\n",
        "\n",
        "```bash\n",
        "docker build -t myproject:0.1 .\n",
        "```\n",
        "\n",
        "* `docker build` = command to build an image.\n",
        "* `-t myproject:0.1` = tag the image with the name `myproject` and version `0.1`.\n",
        "* `.` = build context (the current folder).\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Then, run the container\n",
        "\n",
        "Once the build finishes:\n",
        "\n",
        "```bash\n",
        "docker run --rm myproject:0.1\n",
        "```\n",
        "\n",
        "Expected output:\n",
        "\n",
        "```\n",
        "Hello, world 👋\n",
        "Python version: 3.11.x\n",
        "OS: Linux-...\n",
        "Args: []\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "✅ That’s the big milestone: you’ll have **built and run your first Dockerized Python app**.\n",
        "\n"
      ],
      "metadata": {
        "id": "PZvzEIhtLuHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boom 🚀 nice work — you’ve just built and run your first Docker container from scratch! Now let’s explore what’s inside so you can see it really is a “little computer” running your code.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 1: Run it interactively\n",
        "\n",
        "So far you’ve run:\n",
        "\n",
        "```bash\n",
        "docker run --rm myproject:0.1\n",
        "```\n",
        "\n",
        "which just ran `main.py` and exited.\n",
        "\n",
        "If you want to **get a shell inside the container**, do:\n",
        "\n",
        "```bash\n",
        "docker run -it myproject:0.1 bash\n",
        "```\n",
        "\n",
        "* `-it` = interactive terminal.\n",
        "* `bash` = start a Bash shell instead of running `main.py`.\n",
        "\n",
        "Your prompt will change to something like:\n",
        "\n",
        "```\n",
        "root@123abc:/app#\n",
        "```\n",
        "\n",
        "You’re now *inside the container’s Linux environment*. 🎉\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 2: Inspect the filesystem\n",
        "\n",
        "Inside the container, try:\n",
        "\n",
        "```bash\n",
        "ls\n",
        "```\n",
        "\n",
        "You should see:\n",
        "\n",
        "```\n",
        "Dockerfile\n",
        "requirements.txt\n",
        "requirements-dev.txt\n",
        "main.py\n",
        "```\n",
        "\n",
        "(the files you copied in with `COPY . .`).\n",
        "\n",
        "Check the Python version:\n",
        "\n",
        "```bash\n",
        "python --version\n",
        "```\n",
        "\n",
        "See what processes are running:\n",
        "\n",
        "```bash\n",
        "ps aux\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 3: Explore from the outside\n",
        "\n",
        "Even without starting a shell, you can **peek into a container**:\n",
        "\n",
        "1. Run a container in the background:\n",
        "\n",
        "   ```bash\n",
        "   docker run -d --name mytest myproject:0.1 sleep 300\n",
        "   ```\n",
        "\n",
        "   * `-d` = detached (runs in background).\n",
        "   * `--name mytest` = give it a name so you don’t have to copy the ID.\n",
        "   * `sleep 300` = keep it alive for 5 minutes so you can inspect it.\n",
        "\n",
        "2. Check running containers:\n",
        "\n",
        "   ```bash\n",
        "   docker ps\n",
        "   ```\n",
        "\n",
        "3. Exec into it:\n",
        "\n",
        "   ```bash\n",
        "   docker exec -it mytest bash\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠️ Step 4: Inspect image layers\n",
        "\n",
        "See how your image was built:\n",
        "\n",
        "```bash\n",
        "docker history myproject:0.1\n",
        "```\n",
        "\n",
        "List all images you’ve built:\n",
        "\n",
        "```bash\n",
        "docker images\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "✅ So you’ve got two flavors of inspection:\n",
        "\n",
        "* **Inside the container**: `docker run -it ... bash`\n",
        "* **From outside**: `docker ps`, `docker exec`, `docker history`, `docker images`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ie1f75XDPy7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ah, nice catch 👀 — that’s actually a good lesson about Docker images.\n",
        "\n",
        "You’re inside `python:3.11-slim`, which is a **“slim” base image**.\n",
        "👉 Slim images don’t include extra tools like `ps`, `top`, or even `man` pages — to keep them small.\n",
        "\n",
        "That’s why `ps` is missing.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Option 1: Install it yourself\n",
        "\n",
        "Inside the container (as root), you could add it:\n",
        "\n",
        "```bash\n",
        "apt-get update && apt-get install -y procps\n",
        "```\n",
        "\n",
        "* `procps` is the package that provides `ps`, `top`, etc.\n",
        "* After installing, you can run:\n",
        "\n",
        "  ```bash\n",
        "  ps aux\n",
        "  ```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Option 2: Use what’s already there\n",
        "\n",
        "Even without `ps`, you can explore processes with:\n",
        "\n",
        "```bash\n",
        "cat /proc/self/status\n",
        "cat /proc/cpuinfo\n",
        "cat /proc/meminfo\n",
        "```\n",
        "\n",
        "These give you insights into the container’s own process, CPU, and memory.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Option 3: Inspect from the outside\n",
        "\n",
        "From your **Mac terminal** (outside the container), you can run:\n",
        "\n",
        "```bash\n",
        "docker top <container_id>\n",
        "```\n",
        "\n",
        "That shows processes running inside the container.\n",
        "\n",
        "---\n",
        "\n",
        "So don’t worry — nothing’s broken. It’s just that slim images strip out “nice-to-have” tools.\n",
        "\n"
      ],
      "metadata": {
        "id": "ziOyJYZZQlZu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8-UaXoiZHThR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}