{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPLOlnB6RJNJqhWCbFMYn6+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/189__B2B_Sales_Orchestrator_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B2B Sales Orchestrator Agent - Scaffold Plan\n",
        "\n",
        "**Status:** üìã Planning Phase - Review Before Implementation  \n",
        "**Purpose:** Build MVP sales orchestrator that researches companies, plans personalized outreach, and generates reports  \n",
        "**Learning Focus:** Multi-source data orchestration, LLM-powered personalization, conditional routing (future), state management\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "Build an orchestrator agent that takes a company name/URL as input, performs research, generates personalized outreach plans, and creates comprehensive lead research reports. This MVP focuses on the **research ‚Üí planning ‚Üí reporting** workflow without actual email/LinkedIn sending.\n",
        "\n",
        "**Key Learning Goals:**\n",
        "- Practice multi-source data collection (web search, company data)\n",
        "- Learn LLM-powered personalization patterns\n",
        "- Build orchestrator patterns for multi-stage workflows\n",
        "- Create actionable, formatted reports\n",
        "\n",
        "**MVP Scope (Incremental Approach):**\n",
        "- ‚úÖ Single company input (Target for testing)\n",
        "- ‚úÖ Real web research (Tavily API - user has key)\n",
        "- ‚úÖ **Fixed template for decision-makers** (not LLM-generated, focus on orchestration)\n",
        "- ‚úÖ **Fixed defaults for ICP scoring** (not configurable, get logic working first)\n",
        "- ‚úÖ **Dummy data for personalization** (get MVP working, then improve incrementally)\n",
        "- ‚úÖ Markdown reports as output\n",
        "- ‚ùå No CRM integration (mock state only)\n",
        "- ‚ùå No email/LinkedIn sending (just generate drafts)\n",
        "- ‚ùå No real contact enrichment APIs (use placeholders)\n",
        "\n",
        "**Development Philosophy:**\n",
        "Start with templates/defaults/dummy data ‚Üí Get orchestration working ‚Üí Replace dummy data incrementally (one section at a time) ‚Üí Test ‚Üí Debug ‚Üí Isolate issues ‚Üí Move to next section\n",
        "\n",
        "---\n",
        "\n",
        "## What This Agent Does (MVP)\n",
        "\n",
        "1. **Research** company background, industry, pain points, buying signals\n",
        "2. **Plan** personalized outreach strategy (message drafts, channel selection, timing)\n",
        "3. **Generate** comprehensive lead research report and outreach plan\n",
        "\n",
        "**Input:** Company name and website URL (optional product/service description)  \n",
        "**Output:** Lead research report (markdown) + Outreach plan (JSON + markdown)\n",
        "\n",
        "---\n",
        "\n",
        "## State Schema (Plain English)\n",
        "\n",
        "The agent will track:\n",
        "\n",
        "**Input Fields:**\n",
        "- `company_name`: Company name to research (e.g., \"Acme Corp\")\n",
        "- `company_website`: Optional website URL\n",
        "- `product_service`: Optional description of what we're selling (for personalization)\n",
        "\n",
        "**Research Data:**\n",
        "- `company_research`: Raw research data from web search\n",
        "  - Company overview (industry, size, revenue estimates, growth stage)\n",
        "  - Recent news/articles (pain points, buying signals)\n",
        "  - Technology stack (if available)\n",
        "  - Job postings (hiring signals, needs)\n",
        "  - Industry trends (market context)\n",
        "- `decision_makers`: Mock/synthetic decision-maker data (for MVP)\n",
        "  - Name, title, LinkedIn placeholder\n",
        "  - Role in decision-making process\n",
        "  - Contact preference (email vs LinkedIn)\n",
        "\n",
        "**Analysis Results:**\n",
        "- `company_profile`: Structured company profile\n",
        "  - Industry, size, revenue estimate, growth stage\n",
        "  - Key pain points (from research)\n",
        "  - Buying signals (funding, hiring, expansion)\n",
        "  - ICP fit score (0-100, based on criteria)\n",
        "  - Technology alignment\n",
        "- `pain_points`: Extracted pain points and challenges\n",
        "- `buying_signals`: Identified buying signals (funding, hiring, news, etc.)\n",
        "- `fit_assessment`: ICP fit analysis\n",
        "  - Fit score (0-100)\n",
        "  - Fit reasons (why it's a good/bad fit)\n",
        "  - Priority level (high/medium/low)\n",
        "\n",
        "**Outreach Planning:**\n",
        "- `outreach_plan`: Personalized outreach strategy\n",
        "  - Target contact (decision-maker)\n",
        "  - Channel recommendation (email vs LinkedIn)\n",
        "  - Timing recommendation (best day/time)\n",
        "  - Value proposition (personalized based on research)\n",
        "  - Message drafts (initial + follow-up sequence)\n",
        "  - Personalization elements (company-specific hooks)\n",
        "\n",
        "**Output:**\n",
        "- `research_report`: Generated lead research report (markdown)\n",
        "- `outreach_plan_markdown`: Formatted outreach plan (markdown)\n",
        "- `report_file_paths`: Paths to saved report files\n",
        "\n",
        "**Metadata:**\n",
        "- `errors`: Any errors encountered\n",
        "- `processing_time`: Time taken\n",
        "- `research_sources`: List of sources used for research\n",
        "\n",
        "---\n",
        "\n",
        "## Node Design (Minimal Linear Flow for MVP)\n",
        "\n",
        "Following your guide: **Start with minimal linear flow, add conditional routing later when needed.**\n",
        "\n",
        "### Node 1: `goal_node` - Define Research Goal\n",
        "**Purpose:** Set up the research and outreach planning framework\n",
        "\n",
        "**What it does:**\n",
        "- Define research goal (understand company, identify pain points, assess fit)\n",
        "- Set up outreach planning objective (create personalized outreach strategy)\n",
        "- Structure goal as dictionary with:\n",
        "  - Research objectives (what to find out)\n",
        "  - Outreach objectives (what to create)\n",
        "  - Product/service context (for personalization)\n",
        "  - ICP criteria (ideal customer profile match criteria)\n",
        "\n",
        "**Input (State):**\n",
        "- `company_name`\n",
        "- `company_website` (optional)\n",
        "- `product_service` (optional)\n",
        "\n",
        "**Output (State):**\n",
        "- `goal`: Research and outreach planning goal definition\n",
        "\n",
        "**Logic:**\n",
        "- Fixed structure (template-based, no LLM needed)\n",
        "- Use standard research objectives\n",
        "- Include product/service context if provided\n",
        "\n",
        "---\n",
        "\n",
        "### Node 2: `planning_node` - Create Research & Outreach Plan\n",
        "**Purpose:** Define the research strategy and outreach planning approach\n",
        "\n",
        "**What it does:**\n",
        "- Create execution plan based on goal\n",
        "- Define research steps (company overview, pain points, buying signals, decision-makers)\n",
        "- Define outreach planning steps (personalization strategy, message crafting, channel selection)\n",
        "- Structure plan as list of steps\n",
        "\n",
        "**Input (State):**\n",
        "- `goal`\n",
        "\n",
        "**Output (State):**\n",
        "- `plan`: Execution plan with research and outreach planning steps\n",
        "\n",
        "**Logic:**\n",
        "- Template-based plan (no LLM needed)\n",
        "- Plan structure: step number, action, node responsible\n",
        "\n",
        "---\n",
        "\n",
        "### Node 3: `research_node` - Collect Company Data\n",
        "**Purpose:** Research company using web search and extract structured insights\n",
        "\n",
        "**What it does:**\n",
        "- Perform web searches for:\n",
        "  - Company overview (industry, size, revenue, growth stage)\n",
        "  - Recent news/articles (pain points, challenges, initiatives)\n",
        "  - Technology stack (if available)\n",
        "  - Job postings (hiring signals, needs)\n",
        "  - Industry trends (market context)\n",
        "- Use multiple search queries (per framework-specific search strategy pattern)\n",
        "- Collect data from multiple sources (Tavily, web search, etc.)\n",
        "- Extract structured insights:\n",
        "  - Company profile (industry, size, revenue estimate, growth stage)\n",
        "  - Pain points (from news, articles, job postings)\n",
        "  - Buying signals (funding, hiring, expansion, technology adoption)\n",
        "  - Technology alignment (if available)\n",
        "\n",
        "**Input (State):**\n",
        "- `company_name`\n",
        "- `company_website` (optional - helps with search)\n",
        "- `goal` (research objectives)\n",
        "- `plan` (research steps)\n",
        "\n",
        "**Output (State):**\n",
        "- `company_research`: Raw research data (search results, articles, etc.)\n",
        "- `company_profile`: Structured company profile\n",
        "- `pain_points`: Extracted pain points\n",
        "- `buying_signals`: Identified buying signals\n",
        "- `research_sources`: List of sources used\n",
        "\n",
        "**Logic:**\n",
        "- Web search API calls (Tavily, SerpAPI, or Bing)\n",
        "- Multiple targeted queries (e.g., \"{company} industry\", \"{company} challenges\", \"{company} funding\")\n",
        "- LLM-powered extraction (summarize search results, extract structured data)\n",
        "- **Error handling:**\n",
        "  - API failures ‚Üí fail gracefully, log error, continue with available data\n",
        "  - No results found ‚Üí log warning, use partial data\n",
        "  - Invalid responses ‚Üí retry once, then fail gracefully\n",
        "\n",
        "**Challenges:**\n",
        "- Extracting structured data from unstructured web search results\n",
        "- Identifying relevant pain points from news/articles\n",
        "- Determining company size/revenue from public sources (may need estimates)\n",
        "- Identifying buying signals from various sources\n",
        "\n",
        "---\n",
        "\n",
        "### Node 4: `analyze_node` - Analyze Fit & Generate Decision-Makers\n",
        "**Purpose:** Assess ICP fit and generate mock decision-maker data\n",
        "\n",
        "**What it does:**\n",
        "- Analyze company profile against **fixed default ICP criteria**\n",
        "- Calculate fit score (0-100) using **deterministic algorithm**\n",
        "- Generate fit assessment (fit reasons, priority level)\n",
        "- **Generate decision-makers using fixed template** (not LLM-generated for MVP):\n",
        "  - Use template structure: VP/Director level roles\n",
        "  - Create synthetic contact data (name, title, LinkedIn placeholder)\n",
        "  - Mark clearly as \"PLACEHOLDER\" or \"FAKE\"\n",
        "  - Recommend contact preference (email vs LinkedIn)\n",
        "\n",
        "**Input (State):**\n",
        "- `company_profile`\n",
        "- `pain_points`\n",
        "- `buying_signals`\n",
        "- `goal` (ICP criteria)\n",
        "\n",
        "**Output (State):**\n",
        "- `fit_assessment`: ICP fit analysis (score, reasons, priority)\n",
        "- `decision_makers`: Mock decision-maker data (synthetic for MVP)\n",
        "\n",
        "**Logic:**\n",
        "- Fit scoring algorithm (deterministic, based on **fixed default ICP criteria**)\n",
        "- **Fixed template for decision-makers** (not LLM-generated for MVP):\n",
        "  - Template: [\"VP of Sales\", \"Director of Operations\", \"VP of Engineering\"]\n",
        "  - Generate 1-3 decision-makers using template\n",
        "  - Mark clearly as \"PLACEHOLDER\" in output\n",
        "- **Error handling:**\n",
        "  - Missing company data ‚Üí lower fit score, log warning\n",
        "  - Use default template structure (no LLM calls needed for MVP)\n",
        "\n",
        "**Notes:**\n",
        "- **MVP:** Fixed template (focus on orchestration, not data quality)\n",
        "- **Phase 2:** Replace with LLM-generated or real APIs\n",
        "- Clearly mark all placeholder data in output\n",
        "\n",
        "---\n",
        "\n",
        "### Node 5: `outreach_plan_node` - Generate Personalized Outreach Plan\n",
        "**Purpose:** Create personalized outreach strategy and message drafts\n",
        "\n",
        "**What it does:**\n",
        "- **MVP: Use dummy data for personalization** (get orchestration working first):\n",
        "  - Use template message with company name insertion\n",
        "  - Use dummy pain points and buying signals\n",
        "  - Generate basic outreach plan structure\n",
        "- **Phase 2: Replace with LLM-powered personalization**:\n",
        "  - Analyze company research and pain points (real data)\n",
        "  - Craft personalized value proposition (based on research findings)\n",
        "  - Select best channel (email vs LinkedIn) based on decision-maker profile\n",
        "  - Determine optimal timing (industry patterns, timezone)\n",
        "  - Create initial message draft (personalized, value-focused, concise)\n",
        "  - Create follow-up sequence (if no response)\n",
        "- Include personalization elements (dummy for MVP, real for Phase 2):\n",
        "  - Company-specific hooks (reference recent news, funding, initiatives)\n",
        "  - Pain point references (address specific challenges)\n",
        "  - Value proposition alignment (connect product/service to company needs)\n",
        "\n",
        "**Input (State):**\n",
        "- `company_profile`\n",
        "- `pain_points`\n",
        "- `buying_signals`\n",
        "- `fit_assessment`\n",
        "- `decision_makers`\n",
        "- `product_service` (for personalization)\n",
        "- `goal` (outreach objectives)\n",
        "\n",
        "**Output (State):**\n",
        "- `outreach_plan`: Personalized outreach strategy\n",
        "  - Target contact (decision-maker)\n",
        "  - Channel recommendation\n",
        "  - Timing recommendation\n",
        "  - Value proposition\n",
        "  - Message drafts (initial + follow-ups)\n",
        "  - Personalization elements\n",
        "\n",
        "**Logic:**\n",
        "- **MVP: Template-based with dummy data** (company name insertion only)\n",
        "- **Phase 2: LLM-powered message generation** (personalized based on real research)\n",
        "- Template-based structure (ensure consistent format)\n",
        "- **Error handling:**\n",
        "  - LLM API failures ‚Üí retry once, then fail gracefully (Phase 2)\n",
        "  - Invalid responses ‚Üí log error, use fallback template\n",
        "\n",
        "**Development Strategy:**\n",
        "- **MVP:** Get basic outreach plan structure working (dummy data)\n",
        "- **Phase 2:** Replace dummy data with real research ‚Üí test ‚Üí debug ‚Üí isolate issues\n",
        "- **Phase 3:** Improve message quality (LLM personalization) ‚Üí test ‚Üí debug\n",
        "\n",
        "---\n",
        "\n",
        "### Node 6: `report_node` - Generate Lead Research Report\n",
        "**Purpose:** Generate comprehensive markdown reports (research report + outreach plan)\n",
        "\n",
        "**What it does:**\n",
        "- Generate lead research report using Jinja2 template:\n",
        "  - Company overview\n",
        "  - Key decision-makers (marked as placeholder for MVP)\n",
        "  - Pain points and challenges\n",
        "  - Buying signals\n",
        "  - Fit assessment\n",
        "  - Recommended outreach approach\n",
        "- Generate outreach plan document:\n",
        "  - Outreach strategy summary\n",
        "  - Personalized message drafts\n",
        "  - Follow-up sequence\n",
        "  - Channel and timing recommendations\n",
        "- Save reports to files (e.g., `lead_research_<company>_<timestamp>.md`)\n",
        "\n",
        "**Input (State):**\n",
        "- `company_profile`\n",
        "- `pain_points`\n",
        "- `buying_signals`\n",
        "- `fit_assessment`\n",
        "- `decision_makers`\n",
        "- `outreach_plan`\n",
        "- `research_sources`\n",
        "\n",
        "**Output (State):**\n",
        "- `research_report`: Generated lead research report (markdown)\n",
        "- `outreach_plan_markdown`: Formatted outreach plan (markdown)\n",
        "- `report_file_paths`: Paths to saved report files\n",
        "\n",
        "**Logic:**\n",
        "- Jinja2 template rendering\n",
        "- Format markdown with proper headers, sections, tables\n",
        "- Include clear indicators for placeholder/synthetic data (decision-makers)\n",
        "- **Error handling:** Template render fail ‚Üí fail immediately (can't produce output without template)\n",
        "\n",
        "---\n",
        "\n",
        "## Graph Wiring (MVP: Linear Flow)\n",
        "\n",
        "**Start with linear flow only:**\n",
        "\n",
        "```\n",
        "goal ‚Üí planning ‚Üí research ‚Üí analyze ‚Üí outreach_plan ‚Üí report ‚Üí END\n",
        "```\n",
        "\n",
        "**Rationale:** MVP doesn't need conditional routing initially. All companies go through the same research ‚Üí planning ‚Üí reporting pipeline. We can add conditional routing later if we want to:\n",
        "- Skip certain research steps for known companies\n",
        "- Route to different outreach strategies based on fit score\n",
        "- Handle batch processing (multiple companies)\n",
        "\n",
        "**Later Enhancement (Not MVP):**\n",
        "- After `analyze_node`: if fit score < 50, route to \"low priority\" report format\n",
        "- After `research_node`: if insufficient data, route to enhanced research or flag for manual review\n",
        "- Batch processing: if directory/CSV input, route to batch processing subgraph\n",
        "\n",
        "But for MVP: **Linear flow is sufficient.**\n",
        "\n",
        "---\n",
        "\n",
        "## Error Handling Strategy Matrix\n",
        "\n",
        "| Error Type | Strategy | Example |\n",
        "|------------|----------|---------|\n",
        "| **Company name not found** | Fail gracefully | Log warning, continue with partial data, note in report |\n",
        "| **Web search API failure** | Retry once, then fail gracefully | Log error, use available data, continue with partial results |\n",
        "| **No research results** | Log warning, continue | Use partial data, note data gaps in report |\n",
        "| **LLM API failure** | Retry once, then fail gracefully | Log error, use fallback template, continue |\n",
        "| **Invalid LLM response** | Retry once, then fail gracefully | Log error, use fallback, continue |\n",
        "| **Template render fail** | Fail immediately | Can't produce output without template |\n",
        "| **File write fail** | Fail immediately | Can't save reports |\n",
        "\n",
        "**Principle:** Fail fast for output issues; fail gracefully for research/analysis issues (continue with partial data, log warnings).\n",
        "\n",
        "---\n",
        "\n",
        "## Data Sources & Research Strategy\n",
        "\n",
        "### Web Search Queries (Framework-Specific Pattern)\n",
        "\n",
        "**Research Strategy:**\n",
        "```python\n",
        "RESEARCH_QUERIES = {\n",
        "    \"company_overview\": [\n",
        "        f\"{company_name} company overview\",\n",
        "        f\"{company_name} industry size revenue\",\n",
        "        f\"{company_name} growth stage funding\"\n",
        "    ],\n",
        "    \"pain_points\": [\n",
        "        f\"{company_name} challenges problems\",\n",
        "        f\"{company_name} pain points\",\n",
        "        f\"{company_name} recent news struggles\"\n",
        "    ],\n",
        "    \"buying_signals\": [\n",
        "        f\"{company_name} funding raised\",\n",
        "        f\"{company_name} hiring jobs\",\n",
        "        f\"{company_name} expansion growth\",\n",
        "        f\"{company_name} technology adoption\"\n",
        "    ],\n",
        "    \"technology\": [\n",
        "        f\"{company_name} technology stack\",\n",
        "        f\"{company_name} software tools\",\n",
        "        f\"{company_name} infrastructure\"\n",
        "    ]\n",
        "}\n",
        "```\n",
        "\n",
        "**Data Sources:**\n",
        "- **Primary:** Tavily API (web search) or SerpAPI/Google Search\n",
        "- **Secondary:** Company website (if provided)\n",
        "- **Future:** Crunchbase, Pitchbook (if API access available)\n",
        "\n",
        "**Research Collection:**\n",
        "- Execute multiple queries per category\n",
        "- Collect top N results per query\n",
        "- Aggregate and deduplicate results\n",
        "- Extract structured data using LLM\n",
        "\n",
        "---\n",
        "\n",
        "## ICP Fit Scoring (Deterministic - Fixed Defaults for MVP)\n",
        "\n",
        "**ICP Criteria (Fixed Defaults - MVP):**\n",
        "- Company size (employee count): 100-1000 employees = high fit (20 points)\n",
        "- Industry: Retail/Technology = high fit (20 points)\n",
        "- Growth stage: Established = medium fit (15 points)\n",
        "- Technology alignment: Using similar tools = high fit (20 points)\n",
        "- Pain points: Match our solution = high fit (25 points)\n",
        "\n",
        "**Scoring Formula:**\n",
        "- Each criterion contributes points (fixed for MVP)\n",
        "- Total score: 0-100\n",
        "- Priority levels:\n",
        "  - High: 70-100\n",
        "  - Medium: 40-69\n",
        "  - Low: 0-39\n",
        "\n",
        "**MVP Strategy:**\n",
        "- Use fixed defaults to get scoring logic working\n",
        "- **Phase 2:** Make criteria configurable (via goal/config)\n",
        "- **Phase 3:** Add more sophisticated scoring (ML models, etc.)\n",
        "\n",
        "---\n",
        "\n",
        "## Folder Structure\n",
        "\n",
        "```\n",
        "project_root/\n",
        "‚îú‚îÄ‚îÄ agents/\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ b2b_sales_orchestrator_agent.py    # LangGraph workflow (after smoke test)\n",
        "‚îú‚îÄ‚îÄ nodes/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ goal_node.py                       # Node 1: Define research goal\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ planning_node.py                   # Node 2: Create research plan\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ research_node.py                   # Node 3: Collect company data\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ analyze_node.py                    # Node 4: Analyze fit & generate decision-makers\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ outreach_plan_node.py              # Node 5: Generate personalized outreach plan\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ report_node.py                     # Node 6: Generate reports\n",
        "‚îú‚îÄ‚îÄ prompts/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ base_analyzer.py                   # Base prompt class (reuse existing)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ research_prompt.py                 # Research extraction prompt\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ outreach_prompt.py                 # Outreach planning prompt\n",
        "‚îú‚îÄ‚îÄ templates/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ lead_research_report.md.j2         # Jinja2 template for research report\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ outreach_plan.md.j2                # Jinja2 template for outreach plan\n",
        "‚îú‚îÄ‚îÄ utils/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ web_search.py                      # Web search utilities (Tavily/SerpAPI)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ research_parser.py                 # Research data extraction utilities\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ validators.py                      # Data validation utilities (reuse existing)\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ test_mvp_runner.py                 # ‚≠ê Smoke test (create first)\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ test_sales_orchestrator.py         # Integration test (after wiring)\n",
        "‚îú‚îÄ‚îÄ config.py                              # State schema (SalesOrchestratorState TypedDict) + AgentConfig\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îî‚îÄ‚îÄ sales_reports/                         # Output directory for reports\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Implementation Order (Following Your Guide)\n",
        "\n",
        "1. **Goal node** (simplest, defines structure) - Fixed logic, no dependencies\n",
        "2. **Planning node** (uses goal) - Template-based, depends on goal structure\n",
        "3. **Research node** (most complex, depends on setup) - Web search, LLM extraction\n",
        "4. **Analyze node** (scoring logic, depends on research) - Fit assessment, mock data generation\n",
        "5. **Outreach plan node** (LLM-powered, depends on analyze) - Personalized message generation\n",
        "6. **Report node** (formats output) - Template rendering, file saving\n",
        "\n",
        "**Why this order:** Build from simplest ‚Üí most complex, test each before dependencies.\n",
        "\n",
        "---\n",
        "\n",
        "## Testing Strategy\n",
        "\n",
        "### ‚≠ê Smoke Test First (Before LangGraph)\n",
        "Create `test_mvp_runner.py` that:\n",
        "- Manually calls nodes in sequence\n",
        "- Tests with sample company name (e.g., \"Zoom\", \"Notion\", \"Stripe\")\n",
        "- Verifies state contracts (what each node reads/writes)\n",
        "- Catches 90% of contract issues before graph complexity\n",
        "\n",
        "**Example:**\n",
        "```python\n",
        "def test_linear_flow():\n",
        "    state = {\n",
        "        \"company_name\": \"Zoom\",\n",
        "        \"company_website\": \"https://zoom.us\",\n",
        "        \"product_service\": \"AI-driven sales analytics platform\",\n",
        "        \"errors\": []\n",
        "    }\n",
        "    \n",
        "    state = goal_node(state)\n",
        "    assert \"goal\" in state\n",
        "    \n",
        "    state = planning_node(state)\n",
        "    assert \"plan\" in state\n",
        "    \n",
        "    state = research_node(state)\n",
        "    assert \"company_profile\" in state\n",
        "    \n",
        "    state = analyze_node(state)\n",
        "    assert \"fit_assessment\" in state\n",
        "    \n",
        "    state = outreach_plan_node(state)\n",
        "    assert \"outreach_plan\" in state\n",
        "    \n",
        "    state = report_node(state)\n",
        "    assert \"research_report\" in state\n",
        "    \n",
        "    print(\"‚úÖ All nodes passed smoke test!\")\n",
        "```\n",
        "\n",
        "### Unit Tests\n",
        "- Test web search utilities with real API calls (mock responses)\n",
        "- Test research parser with sample search results\n",
        "- Test fit scoring algorithm with known inputs\n",
        "- Test outreach message generation (personalization logic)\n",
        "\n",
        "### Integration Tests\n",
        "- Test full workflow with real company names (Zoom, Notion, Stripe)\n",
        "- Test error handling (API failures, no results, etc.)\n",
        "- Validate output reports (markdown format, completeness)\n",
        "\n",
        "---\n",
        "\n",
        "## Key Challenges & Solutions\n",
        "\n",
        "### Challenge 1: Extracting Structured Data from Web Search\n",
        "**Problem:** Web search returns unstructured text, need to extract structured company profile.\n",
        "\n",
        "**Solution:**\n",
        "- Use LLM to extract structured data from search results\n",
        "- Define clear extraction schema (company profile, pain points, buying signals)\n",
        "- Use Pydantic schemas for validation\n",
        "- Retry logic if extraction fails\n",
        "\n",
        "### Challenge 2: Generating Personalized Messages\n",
        "**Problem:** Need truly personalized messages, not generic templates.\n",
        "\n",
        "**Solution:**\n",
        "- Use LLM with company research context\n",
        "- Include specific pain points and buying signals in prompt\n",
        "- Generate company-specific hooks (reference recent news, funding)\n",
        "- Validate personalization (check for company name, specific references)\n",
        "\n",
        "### Challenge 3: Mock Decision-Maker Data\n",
        "**Problem:** Need realistic but clearly synthetic decision-makers.\n",
        "\n",
        "**Solution (MVP):**\n",
        "- Use **fixed template** (not LLM-generated)\n",
        "- Template: [\"VP of Sales\", \"Director of Operations\", \"VP of Engineering\"]\n",
        "- Generate 1-3 decision-makers using template\n",
        "- Mark clearly as \"PLACEHOLDER\" in output\n",
        "- **Phase 2:** Replace with LLM-generated or real APIs\n",
        "\n",
        "### Challenge 4: ICP Fit Scoring\n",
        "**Problem:** Need objective fit scoring criteria.\n",
        "\n",
        "**Solution:**\n",
        "- Define clear ICP criteria upfront\n",
        "- Use deterministic scoring algorithm\n",
        "- Make criteria configurable (via goal or config)\n",
        "- Document scoring rationale in report\n",
        "\n",
        "---\n",
        "\n",
        "## Success Criteria\n",
        "\n",
        "### MVP Success Criteria\n",
        "- ‚úÖ Successfully researches real companies using web search\n",
        "- ‚úÖ Extracts structured company profile, pain points, buying signals\n",
        "- ‚úÖ Calculates ICP fit score\n",
        "- ‚úÖ Generates personalized outreach messages\n",
        "- ‚úÖ Creates comprehensive lead research reports\n",
        "- ‚úÖ Handles API failures gracefully (continues with partial data)\n",
        "\n",
        "### Quality Gates\n",
        "- Smoke test passes (all nodes execute in sequence)\n",
        "- Unit tests pass (web search, research parser, fit scorer)\n",
        "- Integration test passes (full workflow with real company)\n",
        "- Reports render correctly from templates\n",
        "- Personalization validated (messages contain company-specific elements)\n",
        "- Error handling works for common failure modes\n",
        "\n",
        "---\n",
        "\n",
        "## Future Enhancements (Not MVP)\n",
        "\n",
        "1. **Conditional Routing:** Route based on fit score (high fit ‚Üí proposal, low fit ‚Üí nurture)\n",
        "2. **Batch Processing:** Support CSV input with multiple companies\n",
        "3. **Real Contact Enrichment:** Integrate Apollo, Clearbit, or Clay APIs\n",
        "4. **Response Handling:** Analyze email/LinkedIn responses and route accordingly\n",
        "5. **CRM Integration:** Sync with HubSpot, Salesforce\n",
        "6. **Follow-up Sequences:** Automated follow-up tracking and sending\n",
        "7. **Lead Scoring:** More sophisticated scoring with ML models\n",
        "8. **Multi-Channel Outreach:** Actual email/LinkedIn sending\n",
        "\n",
        "---\n",
        "\n",
        "## Decisions Made ‚úÖ\n",
        "\n",
        "1. **Input Format:** ‚úÖ Single company name (Target for MVP testing)\n",
        "2. **Web Search API:** ‚úÖ Tavily (user has API key)\n",
        "3. **Decision-Maker Generation:** ‚úÖ Fixed template (not LLM-generated for MVP)\n",
        "4. **ICP Criteria:** ‚úÖ Fixed defaults (not configurable for MVP)\n",
        "5. **Message Personalization:** ‚úÖ Dummy data initially, replace incrementally\n",
        "\n",
        "**Development Strategy:**\n",
        "- Phase 1: MVP with templates/defaults/dummy data ‚Üí Get orchestration working\n",
        "- Phase 2: Replace dummy data incrementally ‚Üí Test ‚Üí Debug ‚Üí Isolate ‚Üí Next section\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps ‚úÖ\n",
        "\n",
        "1. ‚úÖ Review and refine scaffold plan\n",
        "2. ‚úÖ Create `PROJECT_REQUIREMENTS.md` entry\n",
        "3. ‚è≠Ô∏è Begin implementation following the implementation order:\n",
        "   - Create state schema in `config.py`\n",
        "   - Implement nodes (goal ‚Üí planning ‚Üí research ‚Üí analyze ‚Üí outreach ‚Üí report)\n",
        "   - Create smoke test runner\n",
        "   - Wire nodes into LangGraph\n",
        "4. ‚è≠Ô∏è Test with Target company\n",
        "5. ‚è≠Ô∏è Iterate on quality improvements (incremental approach)\n",
        "\n",
        "---\n",
        "\n",
        "*End of Scaffold Plan*\n",
        "\n"
      ],
      "metadata": {
        "id": "aRXrr0GOxbog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # B2B Sales Orchestrator Agent - Project Requirements\n",
        "\n",
        "**Project:** B2B Sales Orchestrator Agent (MVP)  \n",
        "**Status:** Planning ‚Üí Implementation  \n",
        "**Last Updated:** Initial setup\n",
        "\n",
        "---\n",
        "\n",
        "## Quick Reference\n",
        "\n",
        "| Setting | Value |\n",
        "|---------|-------|\n",
        "| **LLM Model** | `gpt-4o-mini` (default) |\n",
        "| **Temperature** | `0.3` |\n",
        "| **API Keys Location** | `API_KEYS.env` |\n",
        "| **Output Directory** | `sales_reports/` |\n",
        "| **Test Company** | Target (for MVP testing) |\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "Build an MVP sales orchestrator agent that:\n",
        "1. Researches companies using web search (Tavily)\n",
        "2. Generates personalized outreach plans\n",
        "3. Creates comprehensive lead research reports\n",
        "\n",
        "**MVP Philosophy:** Start with templates/defaults/dummy data, get orchestration working, then improve quality incrementally.\n",
        "\n",
        "---\n",
        "\n",
        "## Input & Output\n",
        "\n",
        "### Input Format\n",
        "- **Single company name** (for MVP)\n",
        "- **Optional:** Company website URL\n",
        "- **Optional:** Product/service description (for personalization)\n",
        "\n",
        "**MVP Test Input:**\n",
        "```python\n",
        "{\n",
        "    \"company_name\": \"Target\",\n",
        "    \"company_website\": \"https://target.com\",\n",
        "    \"product_service\": \"AI-driven sales analytics platform\"  # Optional\n",
        "}\n",
        "```\n",
        "\n",
        "### Output Format\n",
        "- **Lead Research Report** (markdown) - Saved to `sales_reports/`\n",
        "- **Outreach Plan** (markdown) - Saved to `sales_reports/`\n",
        "\n",
        "---\n",
        "\n",
        "## Data Sources & APIs\n",
        "\n",
        "### Web Research\n",
        "- **Primary:** Tavily API (web search)\n",
        "- **API Key:** `TAVILY_API_KEY` in `API_KEYS.env`\n",
        "- **Strategy:** Multiple targeted queries per company\n",
        "\n",
        "### Decision-Makers (MVP)\n",
        "- **Approach:** Fixed template (not LLM-generated)\n",
        "- **Format:** Synthetic/placeholder data\n",
        "- **Marking:** Clearly labeled as \"PLACEHOLDER\" or \"FAKE\" in output\n",
        "- **Future:** Replace with real LinkedIn/contact enrichment APIs\n",
        "\n",
        "### ICP Scoring (MVP)\n",
        "- **Approach:** Fixed defaults (not configurable)\n",
        "- **Scoring:** Deterministic algorithm with default criteria\n",
        "- **Future:** Make configurable via goal/config\n",
        "\n",
        "### Personalization (MVP)\n",
        "- **Approach:** Dummy data initially, then replace incrementally\n",
        "- **Strategy:** Get MVP working, then improve each section:\n",
        "  1. Get basic orchestration working\n",
        "  2. Replace dummy data in research ‚Üí test\n",
        "  3. Replace dummy data in outreach ‚Üí test\n",
        "  4. Replace dummy data in reports ‚Üí test\n",
        "- **Future:** Full LLM-powered personalization based on research\n",
        "\n",
        "---\n",
        "\n",
        "## Development Approach\n",
        "\n",
        "### Phase 1: MVP with Templates/Dummy Data\n",
        "**Goal:** Get orchestration working end-to-end\n",
        "\n",
        "- Use fixed templates for decision-makers\n",
        "- Use default ICP criteria\n",
        "- Use dummy data for personalization\n",
        "- Focus on: node execution, state management, graph wiring, error handling\n",
        "\n",
        "### Phase 2: Incremental Quality Improvements\n",
        "**Goal:** Replace dummy data with real data, one section at a time\n",
        "\n",
        "**Order:**\n",
        "1. **Research quality** ‚Üí Real web search extraction\n",
        "2. **Outreach personalization** ‚Üí Real LLM-generated messages\n",
        "3. **Fit scoring** ‚Üí Real ICP criteria and scoring\n",
        "4. **Decision-makers** ‚Üí Real LinkedIn/contact data (if APIs available)\n",
        "\n",
        "**Strategy:** Replace ‚Üí Test ‚Üí Debug ‚Üí Isolate issues ‚Üí Move to next section\n",
        "\n",
        "---\n",
        "\n",
        "## Technical Decisions\n",
        "\n",
        "### Web Search API\n",
        "- **Choice:** Tavily\n",
        "- **Rationale:** User has API key, good for research use cases\n",
        "- **Location:** API key in `API_KEYS.env`\n",
        "\n",
        "### Decision-Maker Generation\n",
        "- **MVP:** Fixed template (not LLM-generated)\n",
        "- **Rationale:** Focus on orchestration first, not data quality\n",
        "- **Future:** LLM-generated or real APIs\n",
        "\n",
        "### ICP Scoring\n",
        "- **MVP:** Fixed defaults\n",
        "- **Rationale:** Get scoring logic working, then make it smart\n",
        "- **Future:** Configurable criteria\n",
        "\n",
        "### Personalization\n",
        "- **MVP:** Dummy data\n",
        "- **Rationale:** Incremental approach - test orchestration, then improve quality\n",
        "- **Future:** Full LLM personalization based on research\n",
        "\n",
        "---\n",
        "\n",
        "## Code Patterns\n",
        "\n",
        "### State Schema\n",
        "- Use `TypedDict` for type safety\n",
        "- Keep state flat when possible\n",
        "- Document field purpose with comments\n",
        "\n",
        "### Error Handling\n",
        "- **API failures:** Retry once, then fail gracefully\n",
        "- **Missing data:** Log warnings, continue with partial data\n",
        "- **Template failures:** Fail immediately (can't produce output)\n",
        "\n",
        "### Testing Strategy\n",
        "- **Smoke test first:** Manual node execution before LangGraph wiring\n",
        "- **Unit tests:** Web search, research parser, fit scorer\n",
        "- **Integration tests:** Full workflow with real company (Target)\n",
        "\n",
        "---\n",
        "\n",
        "## Folder Structure\n",
        "\n",
        "```\n",
        "project_root/\n",
        "‚îú‚îÄ‚îÄ agents/\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ b2b_sales_orchestrator_agent.py\n",
        "‚îú‚îÄ‚îÄ nodes/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ goal_node.py\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ planning_node.py\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ research_node.py\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ analyze_node.py\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ outreach_plan_node.py\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ report_node.py\n",
        "‚îú‚îÄ‚îÄ prompts/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ base_analyzer.py (reuse existing)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ research_prompt.py\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ outreach_prompt.py\n",
        "‚îú‚îÄ‚îÄ templates/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ lead_research_report.md.j2\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ outreach_plan.md.j2\n",
        "‚îú‚îÄ‚îÄ utils/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ web_search.py (Tavily integration)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ research_parser.py\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ validators.py (reuse existing)\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ test_mvp_runner.py (smoke test)\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ test_sales_orchestrator.py\n",
        "‚îú‚îÄ‚îÄ config.py\n",
        "‚îî‚îÄ‚îÄ sales_reports/ (output directory)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Success Criteria (MVP)\n",
        "\n",
        "### Functional Requirements\n",
        "- ‚úÖ Successfully researches Target using Tavily\n",
        "- ‚úÖ Extracts basic company profile (industry, size estimates)\n",
        "- ‚úÖ Generates outreach plan with template decision-makers\n",
        "- ‚úÖ Calculates ICP fit score using defaults\n",
        "- ‚úÖ Creates markdown reports (research + outreach plan)\n",
        "- ‚úÖ Handles API failures gracefully\n",
        "\n",
        "### Quality Requirements\n",
        "- ‚úÖ All nodes execute in sequence (smoke test passes)\n",
        "- ‚úÖ State contracts work correctly (each node reads/writes expected fields)\n",
        "- ‚úÖ Reports render from templates without errors\n",
        "- ‚úÖ Error handling works for common failure modes\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. ‚úÖ Review scaffold plan\n",
        "2. ‚úÖ Create PROJECT_REQUIREMENTS.md (this file)\n",
        "3. ‚è≠Ô∏è Create state schema in `config.py`\n",
        "4. ‚è≠Ô∏è Implement nodes (goal ‚Üí planning ‚Üí research ‚Üí analyze ‚Üí outreach ‚Üí report)\n",
        "5. ‚è≠Ô∏è Create smoke test runner\n",
        "6. ‚è≠Ô∏è Wire nodes into LangGraph\n",
        "7. ‚è≠Ô∏è Test with Target company\n",
        "8. ‚è≠Ô∏è Iterate on quality improvements\n",
        "\n",
        "---\n",
        "\n",
        "## Notes\n",
        "\n",
        "- **Tavily API Key:** Add `TAVILY_API_KEY` to `API_KEYS.env` if not already present\n",
        "- **Test Company:** Use Target for MVP testing\n",
        "- **Incremental Approach:** Focus on orchestration first, then improve data quality section by section\n",
        "\n",
        "---\n",
        "\n",
        "*This document will be updated as we build and learn.*\n",
        "\n"
      ],
      "metadata": {
        "id": "LKXf5A7Bx9rA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B2B Sales Orchestrator Agent"
      ],
      "metadata": {
        "id": "t9k2qYsTxtoc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBNyhzN9xKV2"
      },
      "outputs": [],
      "source": [
        "\"\"\"B2B Sales Orchestrator Agent - LangGraph workflow\"\"\"\n",
        "\n",
        "import logging\n",
        "from langgraph.graph import StateGraph, END\n",
        "from config import SalesOrchestratorState\n",
        "from nodes import (\n",
        "    goal_node,\n",
        "    planning_node,\n",
        "    research_node,\n",
        "    analyze_node,\n",
        "    outreach_plan_node,\n",
        "    report_node\n",
        ")\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def create_agent() -> StateGraph:\n",
        "    \"\"\"Create and compile the B2B Sales Orchestrator agent workflow\n",
        "\n",
        "    Returns:\n",
        "        Compiled LangGraph agent ready for execution\n",
        "    \"\"\"\n",
        "    # Create StateGraph with our state schema\n",
        "    workflow = StateGraph(SalesOrchestratorState)\n",
        "\n",
        "    # Add all nodes\n",
        "    workflow.add_node(\"goal\", goal_node)\n",
        "    workflow.add_node(\"planning\", planning_node)\n",
        "    workflow.add_node(\"research\", research_node)\n",
        "    workflow.add_node(\"analyze\", analyze_node)\n",
        "    workflow.add_node(\"outreach_plan\", outreach_plan_node)\n",
        "    workflow.add_node(\"report\", report_node)\n",
        "\n",
        "    # Linear flow: goal ‚Üí planning ‚Üí research ‚Üí analyze ‚Üí outreach_plan ‚Üí report ‚Üí END\n",
        "    workflow.add_edge(\"goal\", \"planning\")\n",
        "    workflow.add_edge(\"planning\", \"research\")\n",
        "    workflow.add_edge(\"research\", \"analyze\")\n",
        "    workflow.add_edge(\"analyze\", \"outreach_plan\")\n",
        "    workflow.add_edge(\"outreach_plan\", \"report\")\n",
        "    workflow.add_edge(\"report\", END)\n",
        "\n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"goal\")\n",
        "\n",
        "    # Compile and return\n",
        "    agent = workflow.compile()\n",
        "    logger.info(\"‚úÖ B2B Sales Orchestrator agent compiled successfully\")\n",
        "\n",
        "    return agent\n",
        "\n",
        "\n",
        "def run_agent(company_name: str, company_website: str = None,\n",
        "              product_service: str = None) -> SalesOrchestratorState:\n",
        "    \"\"\"Run the sales orchestrator agent for a company\n",
        "\n",
        "    Args:\n",
        "        company_name: Company name to research\n",
        "        company_website: Optional website URL\n",
        "        product_service: Optional product/service description\n",
        "\n",
        "    Returns:\n",
        "        Final state with research report and outreach plan\n",
        "    \"\"\"\n",
        "    # Create agent\n",
        "    agent = create_agent()\n",
        "\n",
        "    # Initialize state\n",
        "    initial_state: SalesOrchestratorState = {\n",
        "        \"company_name\": company_name,\n",
        "        \"company_website\": company_website,\n",
        "        \"product_service\": product_service,\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    # Run agent\n",
        "    logger.info(f\"üöÄ Starting sales orchestrator for {company_name}...\")\n",
        "    final_state = agent.invoke(initial_state)\n",
        "\n",
        "    logger.info(f\"‚úÖ Agent completed for {company_name}\")\n",
        "    if final_state.get(\"errors\"):\n",
        "        logger.warning(f\"‚ö†Ô∏è  Errors encountered: {len(final_state['errors'])}\")\n",
        "\n",
        "    return final_state\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"Run agent directly from command line\"\"\"\n",
        "    import sys\n",
        "\n",
        "    # Set up logging\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(levelname)s: %(message)s'\n",
        "    )\n",
        "\n",
        "    # Get company name from command line or use default\n",
        "    if len(sys.argv) > 1:\n",
        "        company_name = sys.argv[1]\n",
        "        company_website = sys.argv[2] if len(sys.argv) > 2 else None\n",
        "        product_service = sys.argv[3] if len(sys.argv) > 3 else None\n",
        "    else:\n",
        "        # Default to Target for testing\n",
        "        company_name = \"Target\"\n",
        "        company_website = \"https://target.com\"\n",
        "        product_service = \"AI-driven sales analytics platform\"\n",
        "\n",
        "    # Run agent\n",
        "    result = run_agent(company_name, company_website, product_service)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üìä Agent Execution Summary\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Company: {result.get('company_name', 'Unknown')}\")\n",
        "    print(f\"Fit Score: {result.get('fit_assessment', {}).get('fit_score', 'N/A')}/100\")\n",
        "    print(f\"Priority: {result.get('fit_assessment', {}).get('priority_level', 'N/A')}\")\n",
        "    print(f\"Reports Generated: {len(result.get('report_file_paths', {}))}\")\n",
        "\n",
        "    if result.get(\"report_file_paths\"):\n",
        "        print(\"\\nüìÑ Report Files:\")\n",
        "        for report_type, path in result[\"report_file_paths\"].items():\n",
        "            print(f\"  {report_type}: {path}\")\n",
        "\n",
        "    if result.get(\"errors\"):\n",
        "        print(f\"\\n‚ö†Ô∏è  Errors: {len(result['errors'])}\")\n",
        "        for error in result[\"errors\"]:\n",
        "            print(f\"  - {error}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "UFHAlYIfzAbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac LG_Cursor_012 % python tests/test_sales_orchestrator.py\n",
        "============================================================\n",
        "üß™ Integration Test: B2B Sales Orchestrator Agent (LangGraph)\n",
        "============================================================\n",
        "\n",
        "üì• Initial State:\n",
        "  Company: Target\n",
        "  Website: https://target.com\n",
        "  Product: AI-driven sales analytics platform\n",
        "\n",
        "------------------------------------------------------------\n",
        "Running LangGraph workflow...\n",
        "------------------------------------------------------------\n",
        "INFO: ‚úÖ B2B Sales Orchestrator agent compiled successfully\n",
        "INFO: üéØ Defining research and outreach planning goal...\n",
        "INFO: ‚úÖ Goal defined for Target\n",
        "INFO: üìã Creating execution plan...\n",
        "INFO: ‚úÖ Execution plan created\n",
        "INFO: üîç Researching company using web search...\n",
        "INFO: Executing 4 search queries for Target...\n",
        "INFO: Searching: Target company overview industry size revenue\n",
        "INFO:   Found 3 results for 'company overview industry size revenue'\n",
        "INFO: Searching: Target recent news challenges problems\n",
        "INFO:   Found 3 results for 'recent news challenges problems'\n",
        "INFO: Searching: Target funding hiring expansion growth\n",
        "INFO:   Found 3 results for 'funding hiring expansion growth'\n",
        "INFO: Searching: Target technology stack software tools\n",
        "INFO:   Found 3 results for 'technology stack software tools'\n",
        "INFO: Calling LLM to extract structured data...\n",
        "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
        "INFO: ‚úÖ Successfully extracted structured data from search results\n",
        "INFO: ‚úÖ Research complete\n",
        "INFO:    Company profile: 5 fields\n",
        "INFO:    Pain points: 5 found\n",
        "INFO:    Buying signals: 2 found\n",
        "INFO:    Sources: 12 unique\n",
        "INFO: üîç Analyzing company fit and generating decision-makers...\n",
        "INFO: ‚úÖ Fit analysis complete: Score 74/100, Priority: high\n",
        "INFO: ‚úÖ Generated 3 decision-makers (template-based)\n",
        "INFO: üìß Generating personalized outreach plan...\n",
        "INFO: ‚úÖ Outreach plan generated\n",
        "INFO:    Target: PLACEHOLDER - Sales 1\n",
        "INFO:    Channel: linkedin\n",
        "INFO:    Messages: 3 drafts\n",
        "INFO: üìÑ Generating lead research report and outreach plan...\n",
        "INFO: Rendering research report template...\n",
        "INFO: Rendering outreach plan template...\n",
        "INFO: Saving research report to lead_research_Target_20251103_171551.md...\n",
        "INFO: Saving outreach plan to outreach_plan_Target_20251103_171551.md...\n",
        "INFO: ‚úÖ Reports generated successfully\n",
        "INFO:    Research report: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_012/sales_reports/lead_research_Target_20251103_171551.md\n",
        "INFO:    Outreach plan: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_012/sales_reports/outreach_plan_Target_20251103_171551.md\n",
        "\n",
        "------------------------------------------------------------\n",
        "Verifying final state...\n",
        "------------------------------------------------------------\n",
        "‚úÖ All required fields present in final state\n",
        "\n",
        "============================================================\n",
        "‚úÖ Integration test passed!\n",
        "   Company: Target\n",
        "   Fit Score: 74/100\n",
        "   Priority: high\n",
        "   Pain Points: 5\n",
        "   Buying Signals: 2\n",
        "   Reports: 2\n",
        "   Errors: 0\n",
        "\n",
        "üìÑ Generated Reports:\n",
        "   research_report: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_012/sales_reports/lead_research_Target_20251103_171551.md\n",
        "   outreach_plan: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_012/sales_reports/outreach_plan_Target_20251103_171551.md\n",
        "============================================================\n",
        "\n",
        "============================================================\n",
        "üß™ Testing run_agent() convenience function\n",
        "============================================================\n",
        "INFO: ‚úÖ B2B Sales Orchestrator agent compiled successfully\n",
        "INFO: üöÄ Starting sales orchestrator for Target...\n",
        "INFO: üéØ Defining research and outreach planning goal...\n",
        "INFO: ‚úÖ Goal defined for Target\n",
        "INFO: üìã Creating execution plan...\n",
        "INFO: ‚úÖ Execution plan created\n",
        "INFO: üîç Researching company using web search...\n",
        "INFO: Executing 4 search queries for Target...\n",
        "INFO: Searching: Target company overview industry size revenue\n",
        "INFO:   Found 3 results for 'company overview industry size revenue'\n",
        "INFO: Searching: Target recent news challenges problems\n",
        "INFO:   Found 3 results for 'recent news challenges problems'\n",
        "INFO: Searching: Target funding hiring expansion growth\n",
        "INFO:   Found 3 results for 'funding hiring expansion growth'\n",
        "INFO: Searching: Target technology stack software tools\n",
        "INFO:   Found 3 results for 'technology stack software tools'\n",
        "INFO: Calling LLM to extract structured data...\n",
        "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
        "INFO: ‚úÖ Successfully extracted structured data from search results\n",
        "INFO: ‚úÖ Research complete\n",
        "INFO:    Company profile: 5 fields\n",
        "INFO:    Pain points: 4 found\n",
        "INFO:    Buying signals: 0 found\n",
        "INFO:    Sources: 12 unique\n",
        "INFO: üîç Analyzing company fit and generating decision-makers...\n",
        "INFO: ‚úÖ Fit analysis complete: Score 74/100, Priority: high\n",
        "INFO: ‚úÖ Generated 3 decision-makers (template-based)\n",
        "INFO: üìß Generating personalized outreach plan...\n",
        "INFO: ‚úÖ Outreach plan generated\n",
        "INFO:    Target: PLACEHOLDER - Sales 1\n",
        "INFO:    Channel: linkedin\n",
        "INFO:    Messages: 3 drafts\n",
        "INFO: üìÑ Generating lead research report and outreach plan...\n",
        "INFO: Rendering research report template...\n",
        "INFO: Rendering outreach plan template...\n",
        "INFO: Saving research report to lead_research_Target_20251103_171559.md...\n",
        "INFO: Saving outreach plan to outreach_plan_Target_20251103_171559.md...\n",
        "INFO: ‚úÖ Reports generated successfully\n",
        "INFO:    Research report: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_012/sales_reports/lead_research_Target_20251103_171559.md\n",
        "INFO:    Outreach plan: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_012/sales_reports/outreach_plan_Target_20251103_171559.md\n",
        "INFO: ‚úÖ Agent completed for Target\n",
        "‚úÖ run_agent() function works correctly\n",
        "(.venv) micahshull@Micahs-iMac LG_Cursor_012 %"
      ],
      "metadata": {
        "id": "-arXW171zC57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangGraph workflow is working end-to-end.\n",
        "\n",
        "## MVP complete\n",
        "\n",
        "The integration test passed:\n",
        "- All 6 nodes executed in sequence via LangGraph\n",
        "- Real Tavily research (12 sources, 5 pain points, 2 buying signals)\n",
        "- LLM extraction working\n",
        "- Fit score: 74/100 (high priority)\n",
        "- Reports generated successfully\n",
        "- Zero errors\n",
        "\n",
        "## What you've built\n",
        "\n",
        "A B2B Sales Orchestrator Agent that:\n",
        "1. Researches companies using Tavily web search\n",
        "2. Extracts structured data with LLM\n",
        "3. Calculates ICP fit scores\n",
        "4. Generates decision-makers (template-based for MVP)\n",
        "5. Creates personalized outreach plans\n",
        "6. Produces markdown reports\n",
        "\n"
      ],
      "metadata": {
        "id": "5ehpJjJOzKuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B2B Sales Orchestrator Agent - Build Reflection\n",
        "\n",
        "**Date:** Build completed successfully  \n",
        "**Agent:** B2B Sales Orchestrator (6-node linear workflow)  \n",
        "**Status:** MVP complete, fully functional\n",
        "\n",
        "---\n",
        "\n",
        "## What Worked Exceptionally Well\n",
        "\n",
        "### 1. **Scaffold Planning in Plain English First** ‚≠ê‚≠ê‚≠ê\n",
        "**What:** Created comprehensive scaffold plan before coding  \n",
        "**Impact:**\n",
        "- Avoided architectural mistakes\n",
        "- Clear understanding of node responsibilities\n",
        "- Defined state schema upfront\n",
        "- Made implementation decisions explicit (templates, dummy data, MVP approach)\n",
        "\n",
        "**Why it worked:**\n",
        "- Forced us to think through the entire flow before coding\n",
        "- Caught potential issues early (like \"should we use templates or LLM for decision-makers?\")\n",
        "- Made the conversation about architecture, not code syntax\n",
        "\n",
        "**Example:** We decided on \"fixed template for decision-makers\" vs \"LLM-generated\" upfront, which saved time and kept focus on orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Incremental Dummy Data Approach** ‚≠ê‚≠ê‚≠ê\n",
        "**What:** Started with templates/defaults/dummy data, then replaced incrementally  \n",
        "**Impact:**\n",
        "- Got orchestration working end-to-end quickly\n",
        "- Could test each node independently\n",
        "- Isolated issues easily (knew exactly which node had problems)\n",
        "- Built confidence progressively\n",
        "\n",
        "**Why it worked:**\n",
        "- Testing orchestration separately from data quality\n",
        "- Could verify state contracts work before adding complexity\n",
        "- Made debugging easier (if orchestration breaks, we knew it wasn't the data)\n",
        "\n",
        "**Example:** We got all 6 nodes working with dummy data, THEN added real Tavily research. When research worked, we knew the issue wasn't in orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Smoke Test Pattern (Before LangGraph)** ‚≠ê‚≠ê‚≠ê\n",
        "**What:** Tested nodes manually in sequence before wiring into LangGraph  \n",
        "**Impact:**\n",
        "- Caught import path issues immediately\n",
        "- Verified state contracts work correctly\n",
        "- Tested each node independently\n",
        "- Caught 90% of issues before graph complexity\n",
        "\n",
        "**Why it worked:**\n",
        "- Simpler debugging (just Python function calls, not graph execution)\n",
        "- Faster iteration (no need to recompile graph)\n",
        "- Clear visibility into what each node does\n",
        "\n",
        "**Example:** When we tested `research_node`, we immediately saw Tavily API key was missing. Caught it before wiring into LangGraph.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Implementation Order (Simplest ‚Üí Most Complex)** ‚≠ê‚≠ê\n",
        "**What:** Implemented nodes in order: goal ‚Üí planning ‚Üí analyze ‚Üí outreach ‚Üí report ‚Üí research  \n",
        "**Impact:**\n",
        "- Built momentum (easy wins first)\n",
        "- Each node tested before dependencies\n",
        "- Natural progression of complexity\n",
        "\n",
        "**Why it worked:**\n",
        "- Goal/planning nodes were simple (template-based, no APIs)\n",
        "- Could test immediately\n",
        "- Research node (most complex) came last, when we had confidence\n",
        "\n",
        "**Note:** We actually did: goal ‚Üí planning ‚Üí analyze ‚Üí outreach ‚Üí report ‚Üí research (research was last because it needed Tavily setup). This still worked because research doesn't depend on other nodes.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **State Schema Defined Upfront** ‚≠ê‚≠ê\n",
        "**What:** Created complete TypedDict with all fields before implementing nodes  \n",
        "**Impact:**\n",
        "- Clear contract for each node (what it reads/writes)\n",
        "- Type safety from the start\n",
        "- Documented field purposes in comments\n",
        "\n",
        "**Why it worked:**\n",
        "- Prevented state schema mismatches\n",
        "- Each node knew exactly what fields to expect\n",
        "- Made it easy to see data flow\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **PROJECT_REQUIREMENTS.md Pattern** ‚≠ê‚≠ê\n",
        "**What:** Centralized all project decisions in one place  \n",
        "**Impact:**\n",
        "- Avoided repeated questions\n",
        "- Clear \"Quick Reference\" for decisions\n",
        "- Standard patterns documented\n",
        "\n",
        "**Why it worked:**\n",
        "- Single source of truth\n",
        "- Fast decisions (look it up, don't ask)\n",
        "- Consistent patterns across the build\n",
        "\n",
        "---\n",
        "\n",
        "## What Was Helpful But Could Be Improved\n",
        "\n",
        "### 1. **Folder Structure Timing**\n",
        "**What:** Guide mentioned folder structure, but we created it mid-way  \n",
        "**Impact:**\n",
        "- Had to reorganize files slightly\n",
        "- Slightly unclear where files should go initially\n",
        "\n",
        "**Improvement:** Create folder structure FIRST (step 3), before any code. Make it a concrete checklist item.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Dependency Management**\n",
        "**What:** We added `tavily-python` to requirements.txt, but didn't install until later  \n",
        "**Impact:**\n",
        "- Could have caught import errors earlier\n",
        "- Had to remember to install dependencies\n",
        "\n",
        "**Improvement:** Add a checklist item: \"Install all dependencies from requirements.txt before testing\"\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Virtual Environment Awareness**\n",
        "**What:** User wasn't sure if `(.venv)` meant they were in venv  \n",
        "**Impact:**\n",
        "- Brief confusion about where packages were installed\n",
        "- Could have installed globally by mistake\n",
        "\n",
        "**Improvement:** Add explicit note: \"`(.venv)` in prompt = virtual environment active. Always check with `which python` if unsure.\"\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **API Key Setup Timing**\n",
        "**What:** Tavily API key needed to be added, but we didn't check until research_node  \n",
        "**Impact:**\n",
        "- Could have set it up earlier\n",
        "- Not critical, but could streamline\n",
        "\n",
        "**Improvement:** Add checklist: \"Verify all API keys exist in API_KEYS.env before implementing nodes that need them\"\n",
        "\n",
        "---\n",
        "\n",
        "## What Didn't Work or Was Confusing\n",
        "\n",
        "### 1. **Import Path Issues (Minor)**\n",
        "**What:** Test file couldn't import config/nodes initially  \n",
        "**Impact:**\n",
        "- Had to fix import paths (adding sys.path)\n",
        "- Minor friction\n",
        "\n",
        "**Why it happened:** Guide mentioned this, but we didn't check test file structure first  \n",
        "**Fix:** Guide already mentions this in \"Common Gotchas\" - this is fine, just caught it early.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Node Dependencies Clarity**\n",
        "**What:** Guide says \"setup node\" before \"analyze node\", but we had different node types  \n",
        "**Impact:**\n",
        "- Slightly confusing when nodes don't match the pattern\n",
        "- Had to adapt the order\n",
        "\n",
        "**Why it happened:** Our agent structure was different (research_node vs setup_node)  \n",
        "**Fix:** Guide's order is a pattern, not a rule. Adapt as needed. This is fine.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Template vs LLM Decision**\n",
        "**What:** Guide mentions \"template-based\" but doesn't explicitly say when to use templates vs LLM  \n",
        "**Impact:**\n",
        "- Had to discuss/debate this during scaffold\n",
        "- Not a problem, but could be clearer\n",
        "\n",
        "**Fix:** Guide is actually good here - it says \"start simple, add complexity later.\" Our incremental approach followed this.\n",
        "\n",
        "---\n",
        "\n",
        "## What I Would Do Differently (If Starting Over)\n",
        "\n",
        "### 1. **Create Folder Structure Immediately** (After scaffold)\n",
        "**Rationale:**\n",
        "- Clearer organization from the start\n",
        "- Know where files go before writing code\n",
        "- Prevents reorganizing later\n",
        "\n",
        "**Action:** Add to checklist: \"Step 3: Create complete folder structure (all directories, __init__.py files)\"\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Install Dependencies Early** (Before any imports)\n",
        "**Rationale:**\n",
        "- Catch import errors immediately\n",
        "- Know what's available\n",
        "- Fail fast if dependencies are missing\n",
        "\n",
        "**Action:** Add to checklist: \"Step 4: Install all dependencies: `pip install -r requirements.txt`\"\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Verify API Keys Before Implementation**\n",
        "**Rationale:**\n",
        "- Know what's available before coding\n",
        "- Set up API keys early\n",
        "- Fail fast if keys are missing\n",
        "\n",
        "**Action:** Add to checklist: \"Step 5: Verify all API keys exist in API_KEYS.env (list required keys)\"\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Create State Schema AND Config Together**\n",
        "**Rationale:**\n",
        "- Config depends on state schema\n",
        "- Keep related code together\n",
        "- Clearer dependencies\n",
        "\n",
        "**Action:** Combine steps: \"Create state schema + config together in config.py\"\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Test Each Node Immediately After Implementation**\n",
        "**Rationale:**\n",
        "- Catch issues while code is fresh\n",
        "- Don't accumulate multiple issues\n",
        "- Faster feedback loop\n",
        "\n",
        "**What we did:** We tested after implementing 2 nodes, which worked but could be even tighter  \n",
        "**Action:** Test each node as you implement it (update smoke test incrementally)\n",
        "\n",
        "---\n",
        "\n",
        "## Overall Assessment\n",
        "\n",
        "### Strengths of Your Guidelines ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê\n",
        "\n",
        "1. **Incremental approach** - This was the MVP's secret weapon\n",
        "2. **Smoke test pattern** - Saved significant debugging time\n",
        "3. **Scaffold planning** - Prevented architectural mistakes\n",
        "4. **Start simple** - Avoided over-engineering\n",
        "5. **Clear state contracts** - Made debugging straightforward\n",
        "\n",
        "### Areas for Enhancement\n",
        "\n",
        "1. **More explicit checklist format** - Some steps are buried in paragraphs\n",
        "2. **Dependency management** - Add explicit \"install dependencies\" step\n",
        "3. **Environment setup** - Add \"verify API keys\" checklist item\n",
        "4. **Folder structure** - Make it step 3, not implied\n",
        "5. **Test incrementally** - Test each node as you build it (tighter loop)\n",
        "\n",
        "---\n",
        "\n",
        "## Suggested Improvements to Guide\n",
        "\n",
        "### 1. **Add \"Quick Start Checklist\" Section**\n",
        "```\n",
        "‚ñ° Read PROJECT_REQUIREMENTS.md\n",
        "‚ñ° Create scaffold plan (plain English)\n",
        "‚ñ° Create folder structure (all directories + __init__.py)\n",
        "‚ñ° Install dependencies: pip install -r requirements.txt\n",
        "‚ñ° Verify API keys in API_KEYS.env\n",
        "‚ñ° Create state schema in config.py\n",
        "‚ñ° Create minimal node stubs\n",
        "‚ñ° Update smoke test incrementally (test as you build)\n",
        "‚ñ° Wire into LangGraph after smoke test passes\n",
        "```\n",
        "\n",
        "### 2. **Add \"Environment Setup Verification\" Section**\n",
        "- Check venv activation: `which python` should show `.venv/bin/python`\n",
        "- Verify API keys: List all required keys upfront\n",
        "- Check dependencies: `pip list | grep <package>`\n",
        "\n",
        "### 3. **Clarify \"Implementation Order\"**\n",
        "- Make it clear this is a pattern, not a rule\n",
        "- Emphasize: \"Simplest ‚Üí Most Complex\"\n",
        "- Note: Adapt based on your specific node types\n",
        "\n",
        "### 4. **Add \"Test Incrementally\" Pattern**\n",
        "- Test each node as you implement it\n",
        "- Update smoke test after each node\n",
        "- Don't wait until all nodes are done\n",
        "\n",
        "---\n",
        "\n",
        "## Key Insights\n",
        "\n",
        "### What Made This Build Fast and Efficient\n",
        "\n",
        "1. **Scaffold planning** - 90% of decisions made before coding\n",
        "2. **Incremental approach** - Could test orchestration separately from data quality\n",
        "3. **Smoke test** - Caught issues early, before graph complexity\n",
        "4. **Clear state contracts** - Each node knew exactly what to expect\n",
        "5. **Dummy data first** - Got end-to-end flow working, then improved data quality\n",
        "\n",
        "### What Made This Build Smooth\n",
        "\n",
        "1. **No over-engineering** - Started simple, added complexity only when needed\n",
        "2. **Clear error handling** - Defined strategies upfront\n",
        "3. **Good logging** - Easy to see what each node was doing\n",
        "4. **Type safety** - TypedDict caught issues early\n",
        "\n",
        "---\n",
        "\n",
        "## Final Verdict\n",
        "\n",
        "**Your guidelines were EXCELLENT** for building this agent quickly and efficiently.\n",
        "\n",
        "### Rating: 9/10\n",
        "\n",
        "**What worked:**\n",
        "- Incremental approach (MVP with dummy data)\n",
        "- Smoke test pattern\n",
        "- Scaffold planning\n",
        "- Start simple principle\n",
        "- Clear state contracts\n",
        "\n",
        "**What could be improved:**\n",
        "- Make checklist format more explicit\n",
        "- Add dependency installation step\n",
        "- Add API key verification step\n",
        "- Test each node incrementally (tighter loop)\n",
        "\n",
        "**Overall:** The guidelines helped us build a complete, working agent efficiently. The incremental approach was the MVP's secret weapon. With minor additions (checklist format, dependency management), it would be even better.\n",
        "\n",
        "---\n",
        "\n",
        "## Recommendation\n",
        "\n",
        "**Update your guide with:**\n",
        "1. Quick Start Checklist (1-page format)\n",
        "2. Environment Setup Verification section\n",
        "3. Test Incrementally pattern (test each node as you build)\n",
        "4. Dependency Management section (install early, verify before imports)\n",
        "\n",
        "**Keep these sections (they're perfect):**\n",
        "- Scaffold planning\n",
        "- Smoke test pattern\n",
        "- Incremental approach\n",
        "- Start simple principle\n",
        "- State schema patterns\n",
        "\n",
        "---\n",
        "\n",
        "*This reflection captured after successfully building the B2B Sales Orchestrator Agent MVP.*\n",
        "\n"
      ],
      "metadata": {
        "id": "Md6jsVIK1yaT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fYL0kO0WzSo1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}