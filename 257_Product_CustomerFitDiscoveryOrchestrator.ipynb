{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJmo7zdlRT4cdPF/dev3DR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/257_Product_CustomerFitDiscoveryOrchestrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthesis utilities for Product-Customer Fit Discovery Orchestrator\n",
        "\n",
        "This final set of utilities, the **Synthesis Agent (Step 6)**, is the ultimate goal of your entire orchestrator. Its role is to take the disparate analytical outputs from all previous agentsâ€”the clusters, the rules, the motifs, and the scoresâ€”and **synthesize** them into a unified list of **actionable, ranked business opportunities.**\n",
        "\n",
        "This is where the raw data is finally transformed into the final, consumable **strategy**.\n",
        "\n",
        "***\n",
        "\n",
        "## ðŸ§  Core Agent Architecture: Cross-Agent Validation and Strategic Scoring\n",
        "\n",
        "The module's power comes from its ability to validate findings across multiple analytical methods and score them based on business value.\n",
        "\n",
        "### 1. The Synthesis Engine (`combine_insights`)\n",
        "\n",
        "This function is the strategic core, using pre-defined **business heuristics** to generate opportunities from the combined evidence.\n",
        "\n",
        "| Opportunity Type | Evidence Source (Agent) | Strategic Goal |\n",
        "| :--- | :--- | :--- |\n",
        "| **Product Gap** | Customer Clusters (Segmentation) | Identify **Cross-Sell** opportunities to fill gaps in a specific customer segment's purchasing profile. |\n",
        "| **Bundle Opportunity** | Product Clusters + Association Rules | **Cross-Validation:** Confirms that products that *cluster* together are also *statistically associated* in purchase history. |\n",
        "| **Cross-Sell** | Association Rules (Pattern Mining) | Direct translation of high-confidence purchase dependencies into **Targeted Marketing** actions. |\n",
        "| **Market Gap** | Graph Motifs/Centrality (Isolated Products) | **Flagging Structural Failure:** Explicitly identifies products that are failing to connect with the market (Ghost Demand), leading to investigation actions. |\n",
        "\n",
        "**Output Structure:** Crucially, every generated insight includes an `evidence` dictionary that explicitly tracks which agent (clustering, patterns, graph) contributed to the finding.\n",
        "\n",
        "***\n",
        "\n",
        "### 2. Validation and Ranking for Robustness\n",
        "\n",
        "The latter functions ensure that the final list of strategies is robust, ranked, and ready for execution.\n",
        "\n",
        "| Function | Purpose | Strategic Implication |\n",
        "| :--- | :--- | :--- |\n",
        "| **`validate_insights`** | Requires **Cross-Agent Evidence**. Sets `validated=True` only if an insight is supported by two or more independent analytical agents. | **Mitigates Risk:** Prevents the agent from acting on a noisy signal from a single source. Only robust, multi-perspective findings are confirmed. |\n",
        "| **`score_opportunities`** | Calculates the **Composite Score**. This score is a weighted blend of: **Confidence** ($\\text{40\\%}$), **Business Value** ($\\text{30\\%}$), **Feasibility** ($\\text{20\\%}$), and **Evidence Strength** ($\\text{10\\%}$). | **Prioritizes Action:** Embeds the business's priorities (confidence is key) into the final metric, ensuring the agent recommends high-quality, executable ideas. |\n",
        "| **`rank_opportunities`** | Ranks the final list by prioritizing **Validated** insights first, then by the **Composite Score**. | **Final Playbook:** Creates a definitive, ordered list of the top business strategies, maximizing the impact of the analysis. |\n",
        "\n",
        "***\n",
        "\n",
        "## âœ¨ Differentiation: The Final Strategic Playbook\n",
        "\n",
        "This module is the definitive component that transforms your system into a **Strategic Discovery Orchestrator**\n",
        "\n",
        "[Image of a Data Pipeline Flow]\n",
        ".\n",
        "\n",
        "* **Autonomous Strategy:** The agent produces a complete, ranked list of **recommended actions** and flags them with a confidence level and feasibility score. No human intervention is needed to translate the data science output into a sales strategy.\n",
        "* **The \"Ghost Demand\" Resolution:** By generating and prioritizing **Market Gap** and **Product Gap** insights, the agent fulfills its core mission: to identify and quantify the specific, actionable opportunities represented by the unseen market potential.\n",
        "* **Self-Correction:** The mandatory **cross-validation step** gives the agent an internal self-correction mechanism, ensuring the strategic recommendations are the most reliable outcome of the entire 6-step analytical process."
      ],
      "metadata": {
        "id": "OvlOMjBSqMMY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqzuW3PjpyNE"
      },
      "outputs": [],
      "source": [
        "\"\"\"Synthesis utilities for Product-Customer Fit Discovery Orchestrator\"\"\"\n",
        "\n",
        "from typing import List, Dict, Any, Set\n",
        "from collections import defaultdict, Counter\n",
        "import uuid\n",
        "\n",
        "\n",
        "def combine_insights(\n",
        "    customer_clusters: List[Dict[str, Any]],\n",
        "    product_clusters: List[Dict[str, Any]],\n",
        "    association_rules: List[Dict[str, Any]],\n",
        "    sequential_patterns: List[Dict[str, Any]],\n",
        "    graph_motifs: List[Dict[str, Any]],\n",
        "    centrality_metrics: Dict[str, Any],\n",
        "    preprocessed_data: Dict[str, Any]\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Combine insights from all analysis agents into unified opportunities.\n",
        "\n",
        "    Args:\n",
        "        customer_clusters: Customer segmentation results\n",
        "        product_clusters: Product bundling results\n",
        "        association_rules: Product association rules\n",
        "        sequential_patterns: Purchase sequence patterns\n",
        "        graph_motifs: Network motif patterns\n",
        "        centrality_metrics: Centrality analysis results\n",
        "        preprocessed_data: Preprocessed data for context\n",
        "\n",
        "    Returns:\n",
        "        List of synthesized insight dictionaries\n",
        "    \"\"\"\n",
        "    insights = []\n",
        "\n",
        "    # Get derived features for context\n",
        "    derived_features = preprocessed_data.get(\"derived_features\", {})\n",
        "    customer_engagement = derived_features.get(\"customer_engagement\", {})\n",
        "    product_popularity = derived_features.get(\"product_popularity\", {})\n",
        "\n",
        "    # 1. Product Gap Opportunities (from clustering)\n",
        "    for cluster in customer_clusters:\n",
        "        underserved_products = cluster.get(\"underserved_products\", [])\n",
        "        if underserved_products:\n",
        "            for product_id in underserved_products[:3]:  # Top 3 per cluster\n",
        "                insight = {\n",
        "                    \"insight_id\": str(uuid.uuid4())[:8],\n",
        "                    \"insight_type\": \"product_gap\",\n",
        "                    \"title\": f\"Untapped Product: {product_id} for {cluster['cluster_label']}\",\n",
        "                    \"description\": f\"Customer segment {cluster['cluster_label']} ({cluster['size']} customers) doesn't use {product_id}, representing a cross-sell opportunity\",\n",
        "                    \"confidence\": 0.7,  # Medium confidence\n",
        "                    \"business_value\": cluster.get(\"business_value\", 0.0) * 0.1,  # Estimate\n",
        "                    \"evidence\": {\n",
        "                        \"from_clustering\": [f\"Segment {cluster['cluster_label']} missing {product_id}\"],\n",
        "                        \"from_patterns\": [],\n",
        "                        \"from_graph\": []\n",
        "                    },\n",
        "                    \"recommended_actions\": [\n",
        "                        f\"Target {cluster['cluster_label']} with {product_id} marketing\",\n",
        "                        f\"Create bundle including {product_id} for this segment\"\n",
        "                    ],\n",
        "                    \"implementation_feasibility\": \"medium\"\n",
        "                }\n",
        "                insights.append(insight)\n",
        "\n",
        "    # 2. Bundle Opportunities (from product clustering + association rules)\n",
        "    for cluster in product_clusters:\n",
        "        if cluster.get(\"bundle_potential\", 0) > 0.5:\n",
        "            product_ids = cluster.get(\"entity_ids\", [])\n",
        "            if len(product_ids) >= 2:\n",
        "                # Check if association rules support this bundle\n",
        "                supporting_rules = [\n",
        "                    r for r in association_rules\n",
        "                    if set(r.get(\"antecedent\", [])).issubset(set(product_ids)) or\n",
        "                       set(r.get(\"consequent\", [])).issubset(set(product_ids))\n",
        "                ]\n",
        "\n",
        "                insight = {\n",
        "                    \"insight_id\": str(uuid.uuid4())[:8],\n",
        "                    \"insight_type\": \"bundle_opportunity\",\n",
        "                    \"title\": f\"Natural Product Bundle: {', '.join(product_ids[:3])}\",\n",
        "                    \"description\": f\"Products {', '.join(product_ids)} naturally cluster together with bundle potential {cluster.get('bundle_potential', 0):.2f}\",\n",
        "                    \"confidence\": 0.8 if supporting_rules else 0.6,\n",
        "                    \"business_value\": cluster.get(\"bundle_potential\", 0.0) * 1000,  # Estimate\n",
        "                    \"evidence\": {\n",
        "                        \"from_clustering\": [f\"Product cluster {cluster['cluster_label']}\"],\n",
        "                        \"from_patterns\": [f\"{len(supporting_rules)} supporting association rules\"] if supporting_rules else [],\n",
        "                        \"from_graph\": []\n",
        "                    },\n",
        "                    \"recommended_actions\": [\n",
        "                        f\"Create bundle package: {', '.join(product_ids)}\",\n",
        "                        \"Test bundle pricing strategy\"\n",
        "                    ],\n",
        "                    \"implementation_feasibility\": \"high\"\n",
        "                }\n",
        "                insights.append(insight)\n",
        "\n",
        "    # 3. Cross-Sell Opportunities (from association rules)\n",
        "    cross_sell_rules = [r for r in association_rules if r.get(\"rule_type\") == \"cross_sell\"]\n",
        "    for rule in cross_sell_rules[:10]:  # Top 10 cross-sell rules\n",
        "        antecedent = rule.get(\"antecedent\", [])\n",
        "        consequent = rule.get(\"consequent\", [])\n",
        "        confidence = rule.get(\"confidence\", 0.0)\n",
        "\n",
        "        if confidence >= 0.5:  # High confidence only\n",
        "            insight = {\n",
        "                \"insight_id\": str(uuid.uuid4())[:8],\n",
        "                \"insight_type\": \"cross_sell\",\n",
        "                \"title\": f\"Cross-Sell: {', '.join(antecedent)} â†’ {', '.join(consequent)}\",\n",
        "                \"description\": f\"Customers with {', '.join(antecedent)} have {confidence:.0%} probability of also using {', '.join(consequent)}\",\n",
        "                \"confidence\": confidence,\n",
        "                \"business_value\": rule.get(\"business_value\", 0.0),\n",
        "                \"evidence\": {\n",
        "                    \"from_clustering\": [],\n",
        "                    \"from_patterns\": [f\"Association rule: {confidence:.0%} confidence, {rule.get('support', 0):.0%} support\"],\n",
        "                    \"from_graph\": []\n",
        "                },\n",
        "                \"recommended_actions\": [\n",
        "                    f\"Recommend {', '.join(consequent)} to customers with {', '.join(antecedent)}\",\n",
        "                    \"Create automated cross-sell campaign\"\n",
        "                ],\n",
        "                \"implementation_feasibility\": \"high\"\n",
        "            }\n",
        "            insights.append(insight)\n",
        "\n",
        "    # 4. Market Gap Opportunities (from graph analysis - isolated products)\n",
        "    isolated_products = centrality_metrics.get(\"isolated_products\", [])\n",
        "    for product_id in isolated_products[:5]:  # Top 5 isolated products\n",
        "        popularity = product_popularity.get(product_id, {})\n",
        "        popularity_score = popularity.get(\"popularity_score\", 0.0)\n",
        "\n",
        "        insight = {\n",
        "            \"insight_id\": str(uuid.uuid4())[:8],\n",
        "            \"insight_type\": \"market_gap\",\n",
        "            \"title\": f\"Underutilized Product: {product_id}\",\n",
        "            \"description\": f\"Product {product_id} has low network connectivity (isolated) but may represent untapped market potential\",\n",
        "            \"confidence\": 0.6,\n",
        "            \"business_value\": (1.0 - popularity_score) * 500,  # Inverse of popularity\n",
        "            \"evidence\": {\n",
        "                \"from_clustering\": [],\n",
        "                \"from_patterns\": [],\n",
        "                \"from_graph\": [f\"Low centrality: isolated product in network\"]\n",
        "            },\n",
        "            \"recommended_actions\": [\n",
        "                f\"Investigate why {product_id} has low adoption\",\n",
        "                \"Consider targeted marketing campaign for {product_id}\",\n",
        "                \"Review product positioning and messaging\"\n",
        "            ],\n",
        "            \"implementation_feasibility\": \"medium\"\n",
        "        }\n",
        "        insights.append(insight)\n",
        "\n",
        "    # 5. Customer Segment Opportunities (from clustering + patterns)\n",
        "    for cluster in customer_clusters:\n",
        "        characteristics = cluster.get(\"characteristics\", {})\n",
        "        top_products = characteristics.get(\"top_products\", [])\n",
        "\n",
        "        # Find association rules relevant to this segment's products\n",
        "        segment_rules = [\n",
        "            r for r in association_rules\n",
        "            if any(p in r.get(\"antecedent\", []) + r.get(\"consequent\", []) for p in top_products)\n",
        "        ]\n",
        "\n",
        "        if segment_rules and cluster.get(\"size\", 0) > 10:  # Significant segment\n",
        "            insight = {\n",
        "                \"insight_id\": str(uuid.uuid4())[:8],\n",
        "                \"insight_type\": \"customer_segment\",\n",
        "                \"title\": f\"High-Value Segment: {cluster['cluster_label']}\",\n",
        "                \"description\": f\"Segment {cluster['cluster_label']} ({cluster['size']} customers) shows strong product patterns with {len(segment_rules)} relevant association rules\",\n",
        "                \"confidence\": 0.75,\n",
        "                \"business_value\": cluster.get(\"business_value\", 0.0),\n",
        "                \"evidence\": {\n",
        "                    \"from_clustering\": [f\"Segment size: {cluster['size']} customers\"],\n",
        "                    \"from_patterns\": [f\"{len(segment_rules)} relevant association rules\"],\n",
        "                    \"from_graph\": []\n",
        "                },\n",
        "                \"recommended_actions\": [\n",
        "                    f\"Develop segment-specific marketing for {cluster['cluster_label']}\",\n",
        "                    f\"Create personalized product recommendations\"\n",
        "                ],\n",
        "                \"implementation_feasibility\": \"high\"\n",
        "            }\n",
        "            insights.append(insight)\n",
        "\n",
        "    return insights\n",
        "\n",
        "\n",
        "def score_opportunities(insights: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Score opportunities based on business value, confidence, and feasibility.\n",
        "\n",
        "    Args:\n",
        "        insights: List of insight dictionaries\n",
        "\n",
        "    Returns:\n",
        "        List of insights with added scores, sorted by score\n",
        "    \"\"\"\n",
        "    scored = []\n",
        "\n",
        "    for insight in insights:\n",
        "        confidence = insight.get(\"confidence\", 0.0)\n",
        "        business_value = insight.get(\"business_value\", 0.0)\n",
        "        feasibility = insight.get(\"implementation_feasibility\", \"low\")\n",
        "\n",
        "        # Feasibility score\n",
        "        feasibility_scores = {\"high\": 1.0, \"medium\": 0.7, \"low\": 0.4}\n",
        "        feasibility_score = feasibility_scores.get(feasibility, 0.5)\n",
        "\n",
        "        # Evidence strength (number of supporting sources)\n",
        "        evidence = insight.get(\"evidence\", {})\n",
        "        evidence_count = sum(len(v) for v in evidence.values())\n",
        "        evidence_strength = min(1.0, evidence_count / 3.0)  # Normalize to 0-1\n",
        "\n",
        "        # Composite score\n",
        "        composite_score = (\n",
        "            confidence * 0.4 +\n",
        "            min(1.0, business_value / 1000.0) * 0.3 +  # Normalize business value\n",
        "            feasibility_score * 0.2 +\n",
        "            evidence_strength * 0.1\n",
        "        )\n",
        "\n",
        "        insight_copy = insight.copy()\n",
        "        insight_copy[\"composite_score\"] = composite_score\n",
        "        scored.append(insight_copy)\n",
        "\n",
        "    # Sort by composite score (descending)\n",
        "    scored.sort(key=lambda x: x[\"composite_score\"], reverse=True)\n",
        "\n",
        "    return scored\n",
        "\n",
        "\n",
        "def validate_insights(\n",
        "    insights: List[Dict[str, Any]],\n",
        "    require_cross_validation: bool = True\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Validate insights by checking for cross-agent evidence.\n",
        "\n",
        "    Args:\n",
        "        insights: List of insight dictionaries\n",
        "        require_cross_validation: Whether to require evidence from multiple agents\n",
        "\n",
        "    Returns:\n",
        "        List of validated insights with validation flags\n",
        "    \"\"\"\n",
        "    validated = []\n",
        "\n",
        "    for insight in insights:\n",
        "        evidence = insight.get(\"evidence\", {})\n",
        "\n",
        "        # Count evidence sources\n",
        "        sources = sum(1 for v in evidence.values() if v)\n",
        "\n",
        "        if require_cross_validation:\n",
        "            is_validated = sources >= 2  # Need evidence from at least 2 agents\n",
        "        else:\n",
        "            is_validated = sources >= 1\n",
        "\n",
        "        insight_copy = insight.copy()\n",
        "        insight_copy[\"validated\"] = is_validated\n",
        "        insight_copy[\"evidence_sources\"] = sources\n",
        "\n",
        "        validated.append(insight_copy)\n",
        "\n",
        "    return validated\n",
        "\n",
        "\n",
        "def rank_opportunities(\n",
        "    insights: List[Dict[str, Any]],\n",
        "    top_n: int = 10\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Rank opportunities by composite score and validation status.\n",
        "\n",
        "    Args:\n",
        "        insights: List of validated insight dictionaries\n",
        "        top_n: Number of top opportunities to return\n",
        "\n",
        "    Returns:\n",
        "        Top N ranked opportunities\n",
        "    \"\"\"\n",
        "    # Sort by: validated first, then composite score\n",
        "    ranked = sorted(\n",
        "        insights,\n",
        "        key=lambda x: (x.get(\"validated\", False), x.get(\"composite_score\", 0.0)),\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    return ranked[:top_n]\n",
        "\n",
        "\n",
        "def create_synthesis_summary(\n",
        "    insights: List[Dict[str, Any]],\n",
        "    validated_insights: List[Dict[str, Any]],\n",
        "    ranked_opportunities: List[Dict[str, Any]]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Create summary of synthesis results.\n",
        "\n",
        "    Args:\n",
        "        insights: All insights\n",
        "        validated_insights: Validated insights\n",
        "        ranked_opportunities: Top ranked opportunities\n",
        "\n",
        "    Returns:\n",
        "        Summary dictionary\n",
        "    \"\"\"\n",
        "    # Count by type\n",
        "    insights_by_type = Counter(i.get(\"insight_type\", \"unknown\") for i in insights)\n",
        "\n",
        "    # Calculate total potential value\n",
        "    total_value = sum(i.get(\"business_value\", 0.0) for i in ranked_opportunities)\n",
        "\n",
        "    # Count validated\n",
        "    validated_count = sum(1 for i in validated_insights if i.get(\"validated\", False))\n",
        "\n",
        "    # Top opportunity types\n",
        "    top_types = [insight_type for insight_type, _ in insights_by_type.most_common(3)]\n",
        "\n",
        "    return {\n",
        "        \"total_insights\": len(insights),\n",
        "        \"high_confidence_insights\": sum(1 for i in insights if i.get(\"confidence\", 0) >= 0.7),\n",
        "        \"total_potential_value\": float(total_value),\n",
        "        \"insights_by_type\": dict(insights_by_type),\n",
        "        \"cross_validated_insights\": validated_count,\n",
        "        \"top_opportunity_types\": top_types\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for synthesis utilities"
      ],
      "metadata": {
        "id": "MtRIPEBxtBuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Tests for synthesis utilities\"\"\"\n",
        "\n",
        "import pytest\n",
        "from tools.synthesis import (\n",
        "    combine_insights,\n",
        "    score_opportunities,\n",
        "    validate_insights,\n",
        "    rank_opportunities,\n",
        "    create_synthesis_summary\n",
        ")\n",
        "\n",
        "\n",
        "def test_combine_insights():\n",
        "    \"\"\"Test combining insights from all agents\"\"\"\n",
        "    customer_clusters = [\n",
        "        {\n",
        "            \"cluster_id\": 0,\n",
        "            \"cluster_label\": \"Segment 1\",\n",
        "            \"entity_ids\": [\"C001\", \"C002\"],\n",
        "            \"size\": 2,\n",
        "            \"underserved_products\": [\"P10\"],\n",
        "            \"business_value\": 100.0,\n",
        "            \"characteristics\": {\"top_products\": [\"P01\", \"P02\"]}\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    product_clusters = [\n",
        "        {\n",
        "            \"cluster_id\": 0,\n",
        "            \"cluster_label\": \"Bundle 1\",\n",
        "            \"entity_ids\": [\"P01\", \"P02\"],\n",
        "            \"size\": 2,\n",
        "            \"bundle_potential\": 0.8\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    association_rules = [\n",
        "        {\n",
        "            \"antecedent\": [\"P01\"],\n",
        "            \"consequent\": [\"P02\"],\n",
        "            \"confidence\": 0.75,\n",
        "            \"support\": 0.5,\n",
        "            \"rule_type\": \"cross_sell\",\n",
        "            \"business_value\": 50.0\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    sequential_patterns = []\n",
        "    graph_motifs = []\n",
        "    centrality_metrics = {\"isolated_products\": [\"P20\"]}\n",
        "    preprocessed_data = {\n",
        "        \"derived_features\": {\n",
        "            \"customer_engagement\": {},\n",
        "            \"product_popularity\": {\"P20\": {\"popularity_score\": 0.2}}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    insights = combine_insights(\n",
        "        customer_clusters,\n",
        "        product_clusters,\n",
        "        association_rules,\n",
        "        sequential_patterns,\n",
        "        graph_motifs,\n",
        "        centrality_metrics,\n",
        "        preprocessed_data\n",
        "    )\n",
        "\n",
        "    assert len(insights) > 0\n",
        "    assert all(\"insight_id\" in i for i in insights)\n",
        "    assert all(\"insight_type\" in i for i in insights)\n",
        "    assert all(\"confidence\" in i for i in insights)\n",
        "\n",
        "\n",
        "def test_score_opportunities():\n",
        "    \"\"\"Test scoring opportunities\"\"\"\n",
        "    insights = [\n",
        "        {\n",
        "            \"insight_id\": \"test1\",\n",
        "            \"confidence\": 0.8,\n",
        "            \"business_value\": 500.0,\n",
        "            \"implementation_feasibility\": \"high\",\n",
        "            \"evidence\": {\"from_clustering\": [\"test\"], \"from_patterns\": [\"test\"]}\n",
        "        },\n",
        "        {\n",
        "            \"insight_id\": \"test2\",\n",
        "            \"confidence\": 0.5,\n",
        "            \"business_value\": 200.0,\n",
        "            \"implementation_feasibility\": \"low\",\n",
        "            \"evidence\": {\"from_clustering\": []}\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    scored = score_opportunities(insights)\n",
        "\n",
        "    assert len(scored) == 2\n",
        "    assert all(\"composite_score\" in s for s in scored)\n",
        "    assert scored[0][\"composite_score\"] >= scored[1][\"composite_score\"]  # Should be sorted\n",
        "\n",
        "\n",
        "def test_validate_insights():\n",
        "    \"\"\"Test validating insights\"\"\"\n",
        "    insights = [\n",
        "        {\n",
        "            \"insight_id\": \"test1\",\n",
        "            \"evidence\": {\n",
        "                \"from_clustering\": [\"evidence1\"],\n",
        "                \"from_patterns\": [\"evidence2\"],\n",
        "                \"from_graph\": []\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"insight_id\": \"test2\",\n",
        "            \"evidence\": {\n",
        "                \"from_clustering\": [\"evidence1\"],\n",
        "                \"from_patterns\": [],\n",
        "                \"from_graph\": []\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    validated = validate_insights(insights, require_cross_validation=True)\n",
        "\n",
        "    assert len(validated) == 2\n",
        "    assert all(\"validated\" in v for v in validated)\n",
        "    assert all(\"evidence_sources\" in v for v in validated)\n",
        "    assert validated[0][\"validated\"] is True  # Has 2 sources\n",
        "    assert validated[1][\"validated\"] is False  # Has only 1 source\n",
        "\n",
        "\n",
        "def test_rank_opportunities():\n",
        "    \"\"\"Test ranking opportunities\"\"\"\n",
        "    insights = [\n",
        "        {\n",
        "            \"insight_id\": \"test1\",\n",
        "            \"validated\": True,\n",
        "            \"composite_score\": 0.8\n",
        "        },\n",
        "        {\n",
        "            \"insight_id\": \"test2\",\n",
        "            \"validated\": False,\n",
        "            \"composite_score\": 0.9\n",
        "        },\n",
        "        {\n",
        "            \"insight_id\": \"test3\",\n",
        "            \"validated\": True,\n",
        "            \"composite_score\": 0.7\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    ranked = rank_opportunities(insights, top_n=2)\n",
        "\n",
        "    assert len(ranked) == 2\n",
        "    # Validated should come first\n",
        "    assert ranked[0][\"validated\"] is True\n",
        "    assert ranked[1][\"validated\"] is True\n",
        "\n",
        "\n",
        "def test_create_synthesis_summary():\n",
        "    \"\"\"Test creating synthesis summary\"\"\"\n",
        "    insights = [\n",
        "        {\"insight_type\": \"product_gap\", \"confidence\": 0.8, \"business_value\": 100.0},\n",
        "        {\"insight_type\": \"bundle_opportunity\", \"confidence\": 0.7, \"business_value\": 200.0},\n",
        "        {\"insight_type\": \"product_gap\", \"confidence\": 0.6, \"business_value\": 50.0}\n",
        "    ]\n",
        "\n",
        "    validated = [\n",
        "        {\"validated\": True},\n",
        "        {\"validated\": True},\n",
        "        {\"validated\": False}\n",
        "    ]\n",
        "\n",
        "    ranked = [\n",
        "        {\"business_value\": 200.0},\n",
        "        {\"business_value\": 100.0}\n",
        "    ]\n",
        "\n",
        "    summary = create_synthesis_summary(insights, validated, ranked)\n",
        "\n",
        "    assert \"total_insights\" in summary\n",
        "    assert \"high_confidence_insights\" in summary\n",
        "    assert \"total_potential_value\" in summary\n",
        "    assert \"insights_by_type\" in summary\n",
        "    assert summary[\"total_insights\"] == 3\n",
        "    assert summary[\"cross_validated_insights\"] == 2\n",
        "\n",
        "\n",
        "def test_combine_insights_product_gap():\n",
        "    \"\"\"Test product gap insights are created\"\"\"\n",
        "    customer_clusters = [\n",
        "        {\n",
        "            \"cluster_id\": 0,\n",
        "            \"cluster_label\": \"Test Segment\",\n",
        "            \"entity_ids\": [\"C001\"],\n",
        "            \"size\": 1,\n",
        "            \"underserved_products\": [\"P10\", \"P11\"],\n",
        "            \"business_value\": 100.0,\n",
        "            \"characteristics\": {}\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    insights = combine_insights(\n",
        "        customer_clusters,\n",
        "        [],\n",
        "        [],\n",
        "        [],\n",
        "        [],\n",
        "        {},\n",
        "        {\"derived_features\": {}}\n",
        "    )\n",
        "\n",
        "    # Should have product gap insights\n",
        "    product_gaps = [i for i in insights if i[\"insight_type\"] == \"product_gap\"]\n",
        "    assert len(product_gaps) > 0\n",
        "\n",
        "\n",
        "def test_combine_insights_bundle_opportunity():\n",
        "    \"\"\"Test bundle opportunity insights are created\"\"\"\n",
        "    product_clusters = [\n",
        "        {\n",
        "            \"cluster_id\": 0,\n",
        "            \"cluster_label\": \"Test Bundle\",\n",
        "            \"entity_ids\": [\"P01\", \"P02\", \"P03\"],\n",
        "            \"size\": 3,\n",
        "            \"bundle_potential\": 0.9\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    insights = combine_insights(\n",
        "        [],\n",
        "        product_clusters,\n",
        "        [],\n",
        "        [],\n",
        "        [],\n",
        "        {},\n",
        "        {\"derived_features\": {}}\n",
        "    )\n",
        "\n",
        "    # Should have bundle opportunity insights\n",
        "    bundles = [i for i in insights if i[\"insight_type\"] == \"bundle_opportunity\"]\n",
        "    assert len(bundles) > 0\n",
        "\n",
        "\n",
        "def test_combine_insights_cross_sell():\n",
        "    \"\"\"Test cross-sell insights are created\"\"\"\n",
        "    association_rules = [\n",
        "        {\n",
        "            \"antecedent\": [\"P01\"],\n",
        "            \"consequent\": [\"P02\"],\n",
        "            \"confidence\": 0.8,\n",
        "            \"support\": 0.4,\n",
        "            \"rule_type\": \"cross_sell\",\n",
        "            \"business_value\": 100.0\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    insights = combine_insights(\n",
        "        [],\n",
        "        [],\n",
        "        association_rules,\n",
        "        [],\n",
        "        [],\n",
        "        {},\n",
        "        {\"derived_features\": {}}\n",
        "    )\n",
        "\n",
        "    # Should have cross-sell insights\n",
        "    cross_sells = [i for i in insights if i[\"insight_type\"] == \"cross_sell\"]\n",
        "    assert len(cross_sells) > 0\n",
        "\n"
      ],
      "metadata": {
        "id": "jurIwRIQs_EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "bDCluZCetJGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac LG_Cursor_035_Product-CustomerFitDiscoveryOrchestrator % python3 -m pytest tests/test_synthesis.py -v\n",
        "============================================================ test session starts ============================================================\n",
        "platform darwin -- Python 3.13.7, pytest-9.0.1, pluggy-1.6.0 -- /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_035_Product-CustomerFitDiscoveryOrchestrator/.venv/bin/python3\n",
        "cachedir: .pytest_cache\n",
        "rootdir: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_035_Product-CustomerFitDiscoveryOrchestrator\n",
        "plugins: langsmith-0.4.53, anyio-4.12.0, asyncio-1.3.0, cov-7.0.0\n",
        "asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n",
        "collected 8 items\n",
        "\n",
        "tests/test_synthesis.py::test_combine_insights PASSED                                                                                 [ 12%]\n",
        "tests/test_synthesis.py::test_score_opportunities PASSED                                                                              [ 25%]\n",
        "tests/test_synthesis.py::test_validate_insights PASSED                                                                                [ 37%]\n",
        "tests/test_synthesis.py::test_rank_opportunities PASSED                                                                               [ 50%]\n",
        "tests/test_synthesis.py::test_create_synthesis_summary PASSED                                                                         [ 62%]\n",
        "tests/test_synthesis.py::test_combine_insights_product_gap PASSED                                                                     [ 75%]\n",
        "tests/test_synthesis.py::test_combine_insights_bundle_opportunity PASSED                                                              [ 87%]\n",
        "tests/test_synthesis.py::test_combine_insights_cross_sell PASSED                                                                      [100%]\n",
        "\n",
        "============================================================= 8 passed in 0.02s =============================================================\n"
      ],
      "metadata": {
        "id": "YH0J2tg5tKlq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}