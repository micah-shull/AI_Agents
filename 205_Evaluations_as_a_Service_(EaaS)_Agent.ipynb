{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPD6cN1krOMtDYa2QenoOiz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/205_Evaluations_as_a_Service_(EaaS)_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EaaS Agent: Next Steps Learning Plan\n",
        "\n",
        "**Purpose:** Strategic learning path to improve the agent while maximizing learning value.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Recommended Learning Path\n",
        "\n",
        "### **Phase 1: Pattern Detection (Highest Value for Learning)** ‚≠ê START HERE\n",
        "\n",
        "**Why this first:**\n",
        "- Demonstrates orchestrator value immediately\n",
        "- Teaches how to analyze across dimensions (agents √ó scenarios √ó outcomes)\n",
        "- Shows how state design enables insights\n",
        "- Creates \"aha!\" moments about orchestrator power\n",
        "\n",
        "**What to build:**\n",
        "- Add pattern detection to `scoring_node`\n",
        "- Detect: \"Both agents fail on neutral sentiment\"\n",
        "- Detect: \"All agents are slow on scenario type X\"\n",
        "- Detect: \"Agent A fails where Agent B succeeds\" (complementary patterns)\n",
        "\n",
        "**Learning outcomes:**\n",
        "- How to analyze multi-dimensional data\n",
        "- How to find patterns across agents\n",
        "- How to structure state to enable pattern detection\n",
        "- This is the \"orchestrator insight\" that makes it valuable\n",
        "\n",
        "---\n",
        "\n",
        "### **Phase 2: Improve Execution Node (Orchestration Logic)** ‚≠ê SECOND\n",
        "\n",
        "**Why this second:**\n",
        "- Now that you understand what insights you need, you can design better execution\n",
        "- Teaches orchestration coordination patterns\n",
        "- Makes the agent more realistic/functional\n",
        "\n",
        "**What to build:**\n",
        "- Better mock agents that actually analyze input text (simple keyword-based for MVP)\n",
        "- Or: Connect to real agent functions/endpoints\n",
        "- Handle errors, timeouts, retries\n",
        "- Capture more metadata (tokens used, confidence scores, etc.)\n",
        "\n",
        "**Learning outcomes:**\n",
        "- How to coordinate multiple agents\n",
        "- How to handle failures gracefully\n",
        "- How to structure agent execution logic\n",
        "- This is the \"orchestration mechanics\"\n",
        "\n",
        "---\n",
        "\n",
        "### **Phase 3: State Design Evolution (Continuous Learning)** ‚≠ê THROUGHOUT\n",
        "\n",
        "**Why throughout:**\n",
        "- State design becomes clearer as you add features\n",
        "- You'll see what relationships need to be captured\n",
        "- You'll understand data flow better\n",
        "\n",
        "**What to learn:**\n",
        "- What data flows through each node\n",
        "- What relationships need to be captured (agent ‚Üí scenario ‚Üí result ‚Üí pattern)\n",
        "- How state evolves as you add features\n",
        "- How to design state for future features\n",
        "\n",
        "**Learning outcomes:**\n",
        "- State design patterns for orchestrators\n",
        "- How to plan state evolution\n",
        "- How to capture relationships, not just data\n",
        "\n",
        "---\n",
        "\n",
        "## üéì Why This Order?\n",
        "\n",
        "### Pattern Detection First Because:\n",
        "\n",
        "1. **Demonstrates Value Immediately**\n",
        "   - You'll see: \"Oh! Both agents fail on neutral sentiment\"\n",
        "   - This is the orchestrator \"aha!\" moment\n",
        "   - Shows why orchestrators are valuable\n",
        "\n",
        "2. **Teaches Multi-Dimensional Analysis**\n",
        "   - You'll learn to analyze: agents √ó scenarios √ó outcomes\n",
        "   - This is core orchestrator skill\n",
        "   - Pattern detection = orchestrator superpower\n",
        "\n",
        "3. **Informs State Design**\n",
        "   - As you build pattern detection, you'll see what state you need\n",
        "   - \"I need scenario metadata to detect patterns\"\n",
        "   - \"I need to group results by scenario type\"\n",
        "   - State design becomes clearer through practice\n",
        "\n",
        "4. **Informs Execution Design**\n",
        "   - Once you know what patterns you want, you can design better execution\n",
        "   - \"I need to capture confidence scores for pattern detection\"\n",
        "   - \"I need to track which scenario categories fail\"\n",
        "\n",
        "### Execution Node Second Because:\n",
        "\n",
        "1. **You Know What You Need**\n",
        "   - After building pattern detection, you know what data to capture\n",
        "   - You can design execution to provide that data\n",
        "\n",
        "2. **Orchestration Logic is Simpler**\n",
        "   - The coordination (agents √ó scenarios) is already there\n",
        "   - You're just making it more realistic\n",
        "   - Less conceptual, more implementation\n",
        "\n",
        "3. **State Design is Clearer**\n",
        "   - You've already evolved state for pattern detection\n",
        "   - Now you're just enriching it with execution metadata\n",
        "\n",
        "---\n",
        "\n",
        "## üìä What Each Phase Teaches\n",
        "\n",
        "### Phase 1: Pattern Detection\n",
        "```\n",
        "Current: \"Agent A: 40% accurate, Agent B: 0% accurate\"\n",
        "After:   \"Both agents fail on neutral sentiment - systemic issue\"\n",
        "         \"Agent A is 3x faster but less accurate\"\n",
        "         \"All agents struggle with edge case X\"\n",
        "```\n",
        "\n",
        "**Learning:**\n",
        "- Multi-dimensional analysis\n",
        "- Cross-agent pattern recognition\n",
        "- How to structure queries across dimensions\n",
        "- This is orchestrator value creation\n",
        "\n",
        "### Phase 2: Execution Node\n",
        "```\n",
        "Current: Mock returns \"positive\" for everything\n",
        "After:   Analyzes input text, returns realistic responses\n",
        "         Handles errors gracefully\n",
        "         Captures metadata (confidence, tokens, etc.)\n",
        "```\n",
        "\n",
        "**Learning:**\n",
        "- Agent coordination patterns\n",
        "- Error handling in orchestration\n",
        "- Metadata capture for analysis\n",
        "- This is orchestration mechanics\n",
        "\n",
        "### Phase 3: State Design\n",
        "```\n",
        "Current: Basic state structure\n",
        "After:   State captures relationships:\n",
        "         - agent ‚Üí scenario ‚Üí result ‚Üí pattern\n",
        "         - scenario metadata for grouping\n",
        "         - cross-agent comparison data\n",
        "```\n",
        "\n",
        "**Learning:**\n",
        "- How to design state for insights\n",
        "- How to capture relationships\n",
        "- How state evolves with features\n",
        "- This is orchestrator foundation\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Implementation Plan\n",
        "\n",
        "### Step 1: Add Pattern Detection to Scoring Node\n",
        "\n",
        "**What to detect:**\n",
        "1. **Scenario-level patterns:**\n",
        "   - Which scenarios do all agents fail on?\n",
        "   - Which scenarios do all agents succeed on?\n",
        "   - What's the failure rate by scenario category?\n",
        "\n",
        "2. **Cross-agent patterns:**\n",
        "   - Do agents fail on the same scenarios?\n",
        "   - Are there complementary patterns? (A fails where B succeeds)\n",
        "   - Which agents are most/least consistent?\n",
        "\n",
        "3. **Performance patterns:**\n",
        "   - Are slow scenarios also inaccurate?\n",
        "   - Do certain scenario types cause timeouts?\n",
        "   - Is there a speed/accuracy trade-off?\n",
        "\n",
        "**State additions needed:**\n",
        "```python\n",
        "failure_analysis: List[Dict[str, Any]]\n",
        "# Structure:\n",
        "# [\n",
        "#   {\n",
        "#     \"pattern_type\": \"scenario_failure\",\n",
        "#     \"description\": \"All agents fail on neutral sentiment\",\n",
        "#     \"scenarios\": [\"c003\", \"c006\", \"c008\"],\n",
        "#     \"failure_rate\": 1.0,\n",
        "#     \"agents_affected\": [\"agent_001\", \"agent_002\"],\n",
        "#     \"recommendation\": \"Improve neutral sentiment detection\"\n",
        "#   }\n",
        "# ]\n",
        "```\n",
        "\n",
        "### Step 2: Improve Execution Node\n",
        "\n",
        "**What to improve:**\n",
        "1. **Better mock agents:**\n",
        "   - Simple keyword-based classification\n",
        "   - Actually analyze input text\n",
        "   - Return realistic responses\n",
        "\n",
        "2. **Metadata capture:**\n",
        "   - Confidence scores\n",
        "   - Tokens used\n",
        "   - Processing time breakdown\n",
        "\n",
        "3. **Error handling:**\n",
        "   - Timeout handling\n",
        "   - Retry logic\n",
        "   - Graceful degradation\n",
        "\n",
        "### Step 3: Evolve State Design\n",
        "\n",
        "**What to add:**\n",
        "1. **Relationship tracking:**\n",
        "   - Scenario ‚Üí category mapping\n",
        "   - Agent ‚Üí scenario ‚Üí result links\n",
        "   - Pattern ‚Üí affected agents/scenarios\n",
        "\n",
        "2. **Metadata enrichment:**\n",
        "   - Scenario categories\n",
        "   - Agent capabilities\n",
        "   - Historical comparisons\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Key Learning Principles\n",
        "\n",
        "1. **Start with Value, Then Mechanics**\n",
        "   - Pattern detection shows value\n",
        "   - Execution improvement is mechanics\n",
        "   - State design is foundation (learns throughout)\n",
        "\n",
        "2. **Learn Through Building**\n",
        "   - You'll understand state design better as you build features\n",
        "   - Pattern detection will show you what state you need\n",
        "   - Execution improvement will show you what to capture\n",
        "\n",
        "3. **Orchestrator Insights = Multi-Dimensional Analysis**\n",
        "   - Not just \"Agent A is 40% accurate\"\n",
        "   - But \"Agents fail on neutral sentiment\" (cross-agent pattern)\n",
        "   - This is what makes orchestrators valuable\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Success Criteria\n",
        "\n",
        "### After Phase 1 (Pattern Detection):\n",
        "- ‚úÖ Can detect: \"Both agents fail on scenario type X\"\n",
        "- ‚úÖ Can detect: \"Agent A is faster but less accurate\"\n",
        "- ‚úÖ Can detect: \"All agents struggle with edge cases\"\n",
        "- ‚úÖ Report includes \"Orchestrator Insights\" section\n",
        "\n",
        "### After Phase 2 (Execution Node):\n",
        "- ‚úÖ Mock agents analyze input text realistically\n",
        "- ‚úÖ Captures metadata (confidence, tokens, etc.)\n",
        "- ‚úÖ Handles errors gracefully\n",
        "- ‚úÖ Can connect to real agent functions\n",
        "\n",
        "### After Phase 3 (State Design):\n",
        "- ‚úÖ State captures relationships clearly\n",
        "- ‚úÖ Easy to add new pattern types\n",
        "- ‚úÖ State supports future features\n",
        "- ‚úÖ Clear data flow through nodes\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Related Learning\n",
        "\n",
        "- **Orchestrator Guide:** `docs/guides/agent_patterns/ORCHESTRATOR_AGENTS_GUIDE.md`\n",
        "- **Learning Review:** `docs/guides/eaas/LEARNING_REVIEW.md`\n",
        "- **Development Workflow:** `docs/guides/development/DEVELOPMENT_WORKFLOW.md`\n",
        "\n",
        "---\n",
        "\n",
        "*This plan balances learning value with practical implementation. Start with pattern detection to see orchestrator value, then improve execution mechanics.*\n",
        "\n"
      ],
      "metadata": {
        "id": "pifH86HXg5cE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scoring Node"
      ],
      "metadata": {
        "id": "vPImNSLQnCm5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC6spQOffVX0"
      },
      "outputs": [],
      "source": [
        "\"\"\"Scoring Node - Scores and analyzes evaluation results\"\"\"\n",
        "\n",
        "import logging\n",
        "from typing import Dict, Any, List\n",
        "from collections import defaultdict\n",
        "from config import EaaSState\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def _calculate_accuracy(results: List[Dict[str, Any]]) -> float:\n",
        "    \"\"\"Calculate accuracy score (correct / total)\"\"\"\n",
        "    if len(results) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    correct = sum(1 for r in results if r.get(\"actual_output\") == r.get(\"expected_output\"))\n",
        "    return correct / len(results)\n",
        "\n",
        "\n",
        "def _calculate_latency_metrics(results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    \"\"\"Calculate latency percentiles\"\"\"\n",
        "    latencies = [r.get(\"latency_ms\", 0) for r in results if r.get(\"latency_ms\", 0) > 0]\n",
        "\n",
        "    if len(latencies) == 0:\n",
        "        return {\"p50\": 0, \"p95\": 0, \"avg\": 0}\n",
        "\n",
        "    sorted_latencies = sorted(latencies)\n",
        "    p50_idx = int(len(sorted_latencies) * 0.5)\n",
        "    p95_idx = int(len(sorted_latencies) * 0.95)\n",
        "\n",
        "    return {\n",
        "        \"p50\": sorted_latencies[p50_idx] if p50_idx < len(sorted_latencies) else sorted_latencies[-1],\n",
        "        \"p95\": sorted_latencies[p95_idx] if p95_idx < len(sorted_latencies) else sorted_latencies[-1],\n",
        "        \"avg\": sum(sorted_latencies) / len(sorted_latencies)\n",
        "    }\n",
        "\n",
        "\n",
        "def _detect_scenario_failure_patterns(\n",
        "    evaluation_results: List[Dict[str, Any]],\n",
        "    evaluation_data: Dict[str, Any]\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Detect scenarios where all agents fail (systemic issues).\n",
        "\n",
        "    This is the orchestrator insight: \"Both agents fail on neutral sentiment\"\n",
        "    \"\"\"\n",
        "    patterns = []\n",
        "\n",
        "    # Get scenario metadata\n",
        "    scenarios = {s.get(\"id\"): s for s in evaluation_data.get(\"test_scenarios\", [])}\n",
        "\n",
        "    # Group results by scenario\n",
        "    scenario_results = defaultdict(list)\n",
        "    for result in evaluation_results:\n",
        "        scenario_id = result.get(\"scenario_id\")\n",
        "        scenario_results[scenario_id].append(result)\n",
        "\n",
        "    # Find scenarios where all agents fail\n",
        "    for scenario_id, results in scenario_results.items():\n",
        "        if len(results) == 0:\n",
        "            continue\n",
        "\n",
        "        # Check if all results are incorrect\n",
        "        all_failed = all(\n",
        "            r.get(\"actual_output\") != r.get(\"expected_output\")\n",
        "            for r in results\n",
        "        )\n",
        "\n",
        "        if all_failed and len(results) > 1:  # Need at least 2 agents to be a pattern\n",
        "            scenario = scenarios.get(scenario_id, {})\n",
        "            expected_output = scenario.get(\"expected_output\", \"unknown\")\n",
        "            metadata = scenario.get(\"metadata\", {})\n",
        "            category = metadata.get(\"category\", \"unknown\")\n",
        "\n",
        "            agents_affected = [r.get(\"agent_id\") for r in results]\n",
        "\n",
        "            patterns.append({\n",
        "                \"pattern_type\": \"scenario_failure\",\n",
        "                \"description\": f\"All agents fail on scenario type: {expected_output}\",\n",
        "                \"scenario_id\": scenario_id,\n",
        "                \"scenarios_affected\": [scenario_id],\n",
        "                \"failure_rate\": 1.0,\n",
        "                \"agents_affected\": agents_affected,\n",
        "                \"expected_output\": expected_output,\n",
        "                \"category\": category,\n",
        "                \"recommendation\": f\"Improve handling of {expected_output} scenarios (category: {category})\"\n",
        "            })\n",
        "\n",
        "    return patterns\n",
        "\n",
        "\n",
        "def _detect_cross_agent_patterns(\n",
        "    evaluation_results: List[Dict[str, Any]],\n",
        "    evaluation_data: Dict[str, Any]\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Detect patterns across agents (do they fail on the same scenarios?).\n",
        "\n",
        "    This is the orchestrator insight: \"Agents fail on similar scenarios\"\n",
        "    \"\"\"\n",
        "    patterns = []\n",
        "\n",
        "    # Get scenario metadata\n",
        "    scenarios = {s.get(\"id\"): s for s in evaluation_data.get(\"test_scenarios\", [])}\n",
        "\n",
        "    # Group results by scenario\n",
        "    scenario_results = defaultdict(list)\n",
        "    for result in evaluation_results:\n",
        "        scenario_id = result.get(\"scenario_id\")\n",
        "        is_correct = result.get(\"actual_output\") == result.get(\"expected_output\")\n",
        "        scenario_results[scenario_id].append({\n",
        "            \"agent_id\": result.get(\"agent_id\"),\n",
        "            \"correct\": is_correct\n",
        "        })\n",
        "\n",
        "    # Find scenarios where multiple agents fail\n",
        "    failure_groups = defaultdict(list)\n",
        "    for scenario_id, results in scenario_results.items():\n",
        "        failed_agents = [r[\"agent_id\"] for r in results if not r[\"correct\"]]\n",
        "        if len(failed_agents) >= 2:  # At least 2 agents fail\n",
        "            scenario = scenarios.get(scenario_id, {})\n",
        "            expected_output = scenario.get(\"expected_output\", \"unknown\")\n",
        "            metadata = scenario.get(\"metadata\", {})\n",
        "            category = metadata.get(\"category\", \"unknown\")\n",
        "\n",
        "            # Group by expected_output type\n",
        "            key = f\"{expected_output}_{category}\"\n",
        "            failure_groups[key].append({\n",
        "                \"scenario_id\": scenario_id,\n",
        "                \"agents\": failed_agents,\n",
        "                \"expected_output\": expected_output,\n",
        "                \"category\": category\n",
        "            })\n",
        "\n",
        "    # Create patterns for groups with multiple scenarios\n",
        "    for key, group in failure_groups.items():\n",
        "        if len(group) >= 2:  # At least 2 scenarios with same pattern\n",
        "            all_agents = set()\n",
        "            scenario_ids = []\n",
        "            for item in group:\n",
        "                all_agents.update(item[\"agents\"])\n",
        "                scenario_ids.append(item[\"scenario_id\"])\n",
        "\n",
        "            expected_output = group[0][\"expected_output\"]\n",
        "            category = group[0][\"category\"]\n",
        "\n",
        "            patterns.append({\n",
        "                \"pattern_type\": \"cross_agent_failure\",\n",
        "                \"description\": f\"Multiple agents consistently fail on {expected_output} scenarios (category: {category})\",\n",
        "                \"scenarios_affected\": scenario_ids,\n",
        "                \"failure_count\": len(group),\n",
        "                \"agents_affected\": list(all_agents),\n",
        "                \"expected_output\": expected_output,\n",
        "                \"category\": category,\n",
        "                \"recommendation\": f\"Systemic issue: All affected agents struggle with {expected_output} scenarios. Consider improving training data or model architecture for this category.\"\n",
        "            })\n",
        "\n",
        "    return patterns\n",
        "\n",
        "\n",
        "def _detect_performance_patterns(\n",
        "    evaluation_results: List[Dict[str, Any]],\n",
        "    scores: Dict[str, Any]\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Detect performance patterns (speed/accuracy trade-offs, consistency).\n",
        "\n",
        "    This is the orchestrator insight: \"Agent A is 3x faster but less accurate\"\n",
        "    \"\"\"\n",
        "    patterns = []\n",
        "\n",
        "    if len(scores) < 2:\n",
        "        return patterns  # Need at least 2 agents to compare\n",
        "\n",
        "    # Compare agents\n",
        "    agent_comparisons = []\n",
        "    for agent_id, agent_scores in scores.items():\n",
        "        agent_comparisons.append({\n",
        "            \"agent_id\": agent_id,\n",
        "            \"accuracy\": agent_scores.get(\"accuracy\", 0),\n",
        "            \"latency_avg\": agent_scores.get(\"latency_avg\", 0)\n",
        "        })\n",
        "\n",
        "    # Sort by accuracy\n",
        "    sorted_by_accuracy = sorted(agent_comparisons, key=lambda x: x[\"accuracy\"], reverse=True)\n",
        "    sorted_by_speed = sorted(agent_comparisons, key=lambda x: x[\"latency_avg\"])\n",
        "\n",
        "    # Find speed/accuracy trade-offs\n",
        "    if len(sorted_by_accuracy) >= 2:\n",
        "        most_accurate = sorted_by_accuracy[0]\n",
        "        fastest = sorted_by_speed[0]\n",
        "\n",
        "        if most_accurate[\"agent_id\"] != fastest[\"agent_id\"]:\n",
        "            speed_diff = fastest[\"latency_avg\"] / most_accurate[\"latency_avg\"] if most_accurate[\"latency_avg\"] > 0 else 0\n",
        "            accuracy_diff = most_accurate[\"accuracy\"] - fastest[\"accuracy\"]\n",
        "\n",
        "            if speed_diff > 1.5 or accuracy_diff > 0.1:  # Significant difference\n",
        "                patterns.append({\n",
        "                    \"pattern_type\": \"performance_tradeoff\",\n",
        "                    \"description\": f\"Speed/Accuracy Trade-off: {fastest['agent_id']} is {speed_diff:.1f}x faster but {accuracy_diff:.1%} less accurate than {most_accurate['agent_id']}\",\n",
        "                    \"fastest_agent\": fastest[\"agent_id\"],\n",
        "                    \"most_accurate_agent\": most_accurate[\"agent_id\"],\n",
        "                    \"speed_ratio\": speed_diff,\n",
        "                    \"accuracy_difference\": accuracy_diff,\n",
        "                    \"recommendation\": f\"Consider using {fastest['agent_id']} for low-latency requirements, {most_accurate['agent_id']} for high-accuracy requirements\"\n",
        "                })\n",
        "\n",
        "    # Find consistency patterns\n",
        "    for agent_id, agent_scores in scores.items():\n",
        "        scenario_scores = agent_scores.get(\"scenario_scores\", [])\n",
        "        if len(scenario_scores) == 0:\n",
        "            continue\n",
        "\n",
        "        correct_count = sum(1 for s in scenario_scores if s.get(\"correct\", False))\n",
        "        incorrect_count = len(scenario_scores) - correct_count\n",
        "\n",
        "        # Check if agent is very consistent (all correct or all incorrect)\n",
        "        if correct_count == 0 or incorrect_count == 0:\n",
        "            consistency = \"highly consistent\"\n",
        "            if correct_count == 0:\n",
        "                consistency_desc = \"consistently fails\"\n",
        "            else:\n",
        "                consistency_desc = \"consistently succeeds\"\n",
        "\n",
        "            patterns.append({\n",
        "                \"pattern_type\": \"consistency\",\n",
        "                \"description\": f\"{agent_id} is {consistency_desc} across all scenarios\",\n",
        "                \"agent_id\": agent_id,\n",
        "                \"consistency_type\": consistency_desc,\n",
        "                \"recommendation\": f\"{agent_id} shows {consistency_desc.replace('consistently ', '')} - investigate root cause\" if incorrect_count == 0 else f\"{agent_id} performs reliably\"\n",
        "            })\n",
        "\n",
        "    return patterns\n",
        "\n",
        "\n",
        "def scoring_node(state: EaaSState) -> EaaSState:\n",
        "    \"\"\"\n",
        "    Score and analyze evaluation results.\n",
        "\n",
        "    Reads: evaluation_results, evaluation_config\n",
        "    Writes: scores, drift_detection, failure_analysis\n",
        "    \"\"\"\n",
        "    logger.info(\"üìä Scoring evaluation results...\")\n",
        "\n",
        "    try:\n",
        "        evaluation_results = state.get(\"evaluation_results\", [])\n",
        "        evaluation_config = state.get(\"evaluation_config\", {})\n",
        "\n",
        "        if len(evaluation_results) == 0:\n",
        "            error_msg = \"No evaluation results to score\"\n",
        "            logger.error(error_msg)\n",
        "            state.setdefault(\"errors\", []).append(error_msg)\n",
        "            return state\n",
        "\n",
        "        # Group results by agent\n",
        "        scores = {}\n",
        "\n",
        "        # Get unique agent IDs\n",
        "        agent_ids = set(r.get(\"agent_id\") for r in evaluation_results)\n",
        "\n",
        "        for agent_id in agent_ids:\n",
        "            agent_results = [r for r in evaluation_results if r.get(\"agent_id\") == agent_id]\n",
        "\n",
        "            # Calculate accuracy\n",
        "            accuracy = _calculate_accuracy(agent_results)\n",
        "\n",
        "            # Calculate latency metrics\n",
        "            latency_metrics = _calculate_latency_metrics(agent_results)\n",
        "\n",
        "            # Calculate scenario-level scores\n",
        "            scenario_scores = []\n",
        "            for result in agent_results:\n",
        "                correct = result.get(\"actual_output\") == result.get(\"expected_output\")\n",
        "                scenario_scores.append({\n",
        "                    \"scenario_id\": result.get(\"scenario_id\"),\n",
        "                    \"correct\": correct,\n",
        "                    \"score\": 1.0 if correct else 0.0\n",
        "                })\n",
        "\n",
        "            # Calculate overall score (simple average for MVP)\n",
        "            overall_score = accuracy  # MVP: just use accuracy\n",
        "\n",
        "            scores[agent_id] = {\n",
        "                \"overall_score\": overall_score,\n",
        "                \"accuracy\": accuracy,\n",
        "                \"latency_p50\": latency_metrics[\"p50\"],\n",
        "                \"latency_p95\": latency_metrics[\"p95\"],\n",
        "                \"latency_avg\": latency_metrics[\"avg\"],\n",
        "                \"scenario_scores\": scenario_scores,\n",
        "                \"total_scenarios\": len(agent_results)\n",
        "            }\n",
        "\n",
        "        state[\"scores\"] = scores\n",
        "\n",
        "        # Pattern Detection - This is where orchestrator insights are created!\n",
        "        evaluation_data = state.get(\"evaluation_data\", {})\n",
        "        failure_analysis = []\n",
        "\n",
        "        # 1. Detect scenario-level patterns (systemic failures)\n",
        "        scenario_patterns = _detect_scenario_failure_patterns(evaluation_results, evaluation_data)\n",
        "        failure_analysis.extend(scenario_patterns)\n",
        "        logger.info(f\"  Found {len(scenario_patterns)} scenario-level failure patterns\")\n",
        "\n",
        "        # 2. Detect cross-agent patterns (agents failing on same scenarios)\n",
        "        cross_agent_patterns = _detect_cross_agent_patterns(evaluation_results, evaluation_data)\n",
        "        failure_analysis.extend(cross_agent_patterns)\n",
        "        logger.info(f\"  Found {len(cross_agent_patterns)} cross-agent patterns\")\n",
        "\n",
        "        # 3. Detect performance patterns (speed/accuracy trade-offs)\n",
        "        performance_patterns = _detect_performance_patterns(evaluation_results, scores)\n",
        "        failure_analysis.extend(performance_patterns)\n",
        "        logger.info(f\"  Found {len(performance_patterns)} performance patterns\")\n",
        "\n",
        "        state[\"failure_analysis\"] = failure_analysis\n",
        "\n",
        "        # MVP: Empty drift detection (future feature)\n",
        "        state[\"drift_detection\"] = {}\n",
        "\n",
        "        logger.info(f\"‚úÖ Scored {len(scores)} agent(s) and detected {len(failure_analysis)} patterns\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error in scoring_node: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state.setdefault(\"errors\", []).append(error_msg)\n",
        "\n",
        "    return state\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pattern Detection Walkthrough: Understanding Orchestrator Insights\n",
        "\n",
        "**Purpose:** Deep dive into the pattern detection logic added to `scoring_node` - this is where orchestrator value is created.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ What Changed: The Big Picture\n",
        "\n",
        "### Before (Standard Agent Approach):\n",
        "```python\n",
        "# Just calculate per-agent metrics\n",
        "for agent_id in agent_ids:\n",
        "    accuracy = calculate_accuracy(agent_results)\n",
        "    scores[agent_id] = {\"accuracy\": accuracy}\n",
        "```\n",
        "\n",
        "**Output:** \"Agent A: 40% accurate, Agent B: 0% accurate\"\n",
        "\n",
        "### After (Orchestrator Approach):\n",
        "```python\n",
        "# Calculate per-agent metrics\n",
        "scores = calculate_scores(evaluation_results)\n",
        "\n",
        "# THEN: Analyze across agents to find patterns\n",
        "patterns = detect_patterns(evaluation_results, evaluation_data)\n",
        "```\n",
        "\n",
        "**Output:** \"Agent A: 40% accurate, Agent B: 0% accurate\"\n",
        "**+ Orchestrator Insight:** \"Both agents fail on neutral sentiment - systemic issue\"\n",
        "\n",
        "---\n",
        "\n",
        "## üîç The Three Pattern Detection Functions\n",
        "\n",
        "### 1. `_detect_scenario_failure_patterns()` - Systemic Failures\n",
        "\n",
        "**What it does:**\n",
        "- Finds scenarios where ALL agents fail\n",
        "- This is the \"systemic issue\" detection\n",
        "\n",
        "**The Logic:**\n",
        "```python\n",
        "# Step 1: Group results by scenario\n",
        "scenario_results = defaultdict(list)\n",
        "for result in evaluation_results:\n",
        "    scenario_id = result.get(\"scenario_id\")\n",
        "    scenario_results[scenario_id].append(result)\n",
        "\n",
        "# Step 2: Check if ALL agents failed on this scenario\n",
        "for scenario_id, results in scenario_results.items():\n",
        "    all_failed = all(\n",
        "        r.get(\"actual_output\") != r.get(\"expected_output\")\n",
        "        for r in results\n",
        "    )\n",
        "    \n",
        "    if all_failed and len(results) > 1:  # Pattern detected!\n",
        "        # This is a systemic issue\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- **Standard approach:** \"Agent A failed on scenario X\" ‚Üí Fix Agent A\n",
        "- **Orchestrator approach:** \"ALL agents failed on scenario X\" ‚Üí Fix the root cause (data, prompt, architecture)\n",
        "\n",
        "**Example:**\n",
        "- Scenario: \"It's fine, I guess\" (neutral sentiment)\n",
        "- Agent A: Returns \"positive\" ‚ùå\n",
        "- Agent B: Returns \"positive\" ‚ùå\n",
        "- **Orchestrator insight:** \"All agents fail on neutral sentiment - improve neutral detection\"\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `_detect_cross_agent_patterns()` - Cross-Agent Failure Patterns\n",
        "\n",
        "**What it does:**\n",
        "- Finds scenarios where MULTIPLE agents fail (but not necessarily all)\n",
        "- Groups failures by scenario type/category\n",
        "- Detects patterns like \"agents consistently fail on neutral sentiment\"\n",
        "\n",
        "**The Logic:**\n",
        "```python\n",
        "# Step 1: Group results by scenario, track which agents failed\n",
        "scenario_results = defaultdict(list)\n",
        "for result in evaluation_results:\n",
        "    scenario_id = result.get(\"scenario_id\")\n",
        "    is_correct = result.get(\"actual_output\") == result.get(\"expected_output\")\n",
        "    scenario_results[scenario_id].append({\n",
        "        \"agent_id\": result.get(\"agent_id\"),\n",
        "        \"correct\": is_correct\n",
        "    })\n",
        "\n",
        "# Step 2: Find scenarios where multiple agents fail\n",
        "failure_groups = defaultdict(list)\n",
        "for scenario_id, results in scenario_results.items():\n",
        "    failed_agents = [r[\"agent_id\"] for r in results if not r[\"correct\"]]\n",
        "    if len(failed_agents) >= 2:  # At least 2 agents fail\n",
        "        # Group by scenario type (e.g., \"neutral_sentiment\")\n",
        "        key = f\"{expected_output}_{category}\"\n",
        "        failure_groups[key].append(...)\n",
        "\n",
        "# Step 3: If multiple scenarios have same pattern, it's a systemic issue\n",
        "for key, group in failure_groups.items():\n",
        "    if len(group) >= 2:  # Pattern detected!\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- **Standard approach:** See individual failures\n",
        "- **Orchestrator approach:** See that \"neutral sentiment\" is a problem across multiple scenarios and agents\n",
        "\n",
        "**Example:**\n",
        "- Scenario c003: \"It's fine, I guess\" ‚Üí Both agents fail\n",
        "- Scenario c006: \"The results are okay, but...\" ‚Üí Both agents fail\n",
        "- Scenario c008: \"I don't really care\" ‚Üí Both agents fail\n",
        "- **Orchestrator insight:** \"Multiple agents consistently fail on neutral sentiment scenarios (3 scenarios affected)\"\n",
        "\n",
        "---\n",
        "\n",
        "### 3. `_detect_performance_patterns()` - Performance Trade-offs\n",
        "\n",
        "**What it does:**\n",
        "- Compares agents across dimensions (speed vs accuracy)\n",
        "- Detects consistency patterns\n",
        "- Finds trade-offs that inform decision-making\n",
        "\n",
        "**The Logic:**\n",
        "```python\n",
        "# Step 1: Compare agents\n",
        "agent_comparisons = []\n",
        "for agent_id, agent_scores in scores.items():\n",
        "    agent_comparisons.append({\n",
        "        \"agent_id\": agent_id,\n",
        "        \"accuracy\": agent_scores.get(\"accuracy\", 0),\n",
        "        \"latency_avg\": agent_scores.get(\"latency_avg\", 0)\n",
        "    })\n",
        "\n",
        "# Step 2: Find speed/accuracy trade-offs\n",
        "sorted_by_accuracy = sorted(agent_comparisons, key=lambda x: x[\"accuracy\"], reverse=True)\n",
        "sorted_by_speed = sorted(agent_comparisons, key=lambda x: x[\"latency_avg\"])\n",
        "\n",
        "most_accurate = sorted_by_accuracy[0]\n",
        "fastest = sorted_by_speed[0]\n",
        "\n",
        "if most_accurate[\"agent_id\"] != fastest[\"agent_id\"]:\n",
        "    # Trade-off detected!\n",
        "    speed_diff = fastest[\"latency_avg\"] / most_accurate[\"latency_avg\"]\n",
        "    accuracy_diff = most_accurate[\"accuracy\"] - fastest[\"accuracy\"]\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- **Standard approach:** \"Agent A: 40% accurate, 100ms latency\"\n",
        "- **Orchestrator approach:** \"Agent A is 3x faster but 20% less accurate than Agent B - use A for low-latency, B for high-accuracy\"\n",
        "\n",
        "**Example:**\n",
        "- Agent A: 40% accurate, 100ms latency\n",
        "- Agent B: 80% accurate, 300ms latency\n",
        "- **Orchestrator insight:** \"Agent A is 3x faster but 40% less accurate - choose based on requirements\"\n",
        "\n",
        "---\n",
        "\n",
        "## üéì What to Focus On Learning\n",
        "\n",
        "### 1. **Multi-Dimensional Analysis** ‚≠ê MOST IMPORTANT\n",
        "\n",
        "**The Key Concept:**\n",
        "- Standard agents analyze in one dimension: \"Agent A's accuracy\"\n",
        "- Orchestrators analyze across multiple dimensions: \"Agents √ó Scenarios √ó Outcomes\"\n",
        "\n",
        "**How to think about it:**\n",
        "```\n",
        "Standard:  Agent A ‚Üí Accuracy: 40%\n",
        "           Agent B ‚Üí Accuracy: 0%\n",
        "\n",
        "Orchestrator:  Agent A √ó Scenario c003 ‚Üí Fail\n",
        "               Agent B √ó Scenario c003 ‚Üí Fail\n",
        "               Pattern: Both fail on neutral sentiment\n",
        "```\n",
        "\n",
        "**The Code Pattern:**\n",
        "```python\n",
        "# Group by one dimension\n",
        "scenario_results = defaultdict(list)\n",
        "for result in evaluation_results:\n",
        "    scenario_id = result.get(\"scenario_id\")\n",
        "    scenario_results[scenario_id].append(result)\n",
        "\n",
        "# Then analyze across dimensions\n",
        "for scenario_id, results in scenario_results.items():\n",
        "    # Analyze: Do ALL agents fail? (cross-agent dimension)\n",
        "    all_failed = all(r.get(\"actual_output\") != r.get(\"expected_output\") for r in results)\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- This is the core orchestrator skill\n",
        "- You're not just processing data - you're finding relationships\n",
        "- This creates insights that are invisible to single-agent analysis\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Grouping and Aggregation Patterns** ‚≠ê IMPORTANT\n",
        "\n",
        "**The Pattern:**\n",
        "```python\n",
        "# Step 1: Group data by dimension\n",
        "grouped = defaultdict(list)\n",
        "for item in data:\n",
        "    key = item.get(\"dimension\")\n",
        "    grouped[key].append(item)\n",
        "\n",
        "# Step 2: Analyze groups\n",
        "for key, group in grouped.items():\n",
        "    if len(group) >= threshold:  # Pattern detected!\n",
        "        # Create insight\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- This is how you find patterns in multi-dimensional data\n",
        "- `defaultdict` is your friend for grouping\n",
        "- Thresholds (e.g., \"at least 2 agents\") filter noise from patterns\n",
        "\n",
        "**Example from code:**\n",
        "```python\n",
        "# Group failures by scenario type\n",
        "failure_groups = defaultdict(list)\n",
        "for scenario_id, results in scenario_results.items():\n",
        "    failed_agents = [r[\"agent_id\"] for r in results if not r[\"correct\"]]\n",
        "    if len(failed_agents) >= 2:  # Threshold: at least 2 agents\n",
        "        key = f\"{expected_output}_{category}\"\n",
        "        failure_groups[key].append(...)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Metadata Enrichment** ‚≠ê IMPORTANT\n",
        "\n",
        "**The Pattern:**\n",
        "```python\n",
        "# Get scenario metadata to understand context\n",
        "scenarios = {s.get(\"id\"): s for s in evaluation_data.get(\"test_scenarios\", [])}\n",
        "scenario = scenarios.get(scenario_id, {})\n",
        "expected_output = scenario.get(\"expected_output\", \"unknown\")\n",
        "category = scenario.get(\"metadata\", {}).get(\"category\", \"unknown\")\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- Raw results: \"Scenario c003 failed\"\n",
        "- With metadata: \"Scenario c003 (neutral sentiment) failed\"\n",
        "- Metadata enables pattern detection: \"All neutral sentiment scenarios fail\"\n",
        "\n",
        "**The Insight:**\n",
        "- You need metadata to group and analyze\n",
        "- This is why state design matters - you need to capture relationships\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Pattern Structure Design** ‚≠ê IMPORTANT\n",
        "\n",
        "**The Pattern:**\n",
        "```python\n",
        "patterns.append({\n",
        "    \"pattern_type\": \"scenario_failure\",\n",
        "    \"description\": f\"All agents fail on scenario type: {expected_output}\",\n",
        "    \"scenario_id\": scenario_id,\n",
        "    \"agents_affected\": agents_affected,\n",
        "    \"recommendation\": f\"Improve handling of {expected_output} scenarios\"\n",
        "})\n",
        "```\n",
        "\n",
        "**Why this matters:**\n",
        "- Patterns need structure to be useful\n",
        "- Include: what, who, why, recommendation\n",
        "- This structure enables reporting and action\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Why These Changes Are Important\n",
        "\n",
        "### 1. **This is Orchestrator Value Creation**\n",
        "\n",
        "**Before:** You had evaluation results\n",
        "**After:** You have strategic insights\n",
        "\n",
        "**The difference:**\n",
        "- Standard: \"Agent A is 40% accurate\"\n",
        "- Orchestrator: \"All agents fail on neutral sentiment - fix the root cause\"\n",
        "\n",
        "### 2. **Multi-Dimensional Analysis is Core Orchestrator Skill**\n",
        "\n",
        "**What you're learning:**\n",
        "- How to analyze across dimensions (agents √ó scenarios √ó outcomes)\n",
        "- How to find patterns that are invisible in single dimensions\n",
        "- How to structure queries across data\n",
        "\n",
        "**Why this matters:**\n",
        "- This is what makes orchestrators valuable\n",
        "- Single agents can't do this\n",
        "- This is the \"network effect\" of orchestrators\n",
        "\n",
        "### 3. **State Design Enables Pattern Detection**\n",
        "\n",
        "**What you're learning:**\n",
        "- You need metadata (scenario categories, expected outputs)\n",
        "- You need relationships (agent ‚Üí scenario ‚Üí result)\n",
        "- State structure determines what patterns you can detect\n",
        "\n",
        "**Why this matters:**\n",
        "- As you build pattern detection, you see what state you need\n",
        "- This informs state design evolution\n",
        "- This is the learning loop: build features ‚Üí see state needs ‚Üí evolve state\n",
        "\n",
        "### 4. **Pattern Detection Informs Strategy**\n",
        "\n",
        "**What you're learning:**\n",
        "- Patterns lead to recommendations\n",
        "- Recommendations lead to action\n",
        "- Action creates value\n",
        "\n",
        "**Why this matters:**\n",
        "- Not just \"what happened\" but \"what to do about it\"\n",
        "- This is strategic value, not just reporting\n",
        "\n",
        "---\n",
        "\n",
        "## üîë Key Takeaways\n",
        "\n",
        "### 1. **Orchestrators Analyze Across Dimensions**\n",
        "- Not just \"Agent A's accuracy\"\n",
        "- But \"Do agents fail on the same scenarios?\"\n",
        "- This is multi-dimensional analysis\n",
        "\n",
        "### 2. **Grouping is the Core Pattern**\n",
        "- Group by dimension (scenario, agent, category)\n",
        "- Analyze groups for patterns\n",
        "- Thresholds filter noise\n",
        "\n",
        "### 3. **Metadata Enables Insights**\n",
        "- Raw data: \"Scenario c003 failed\"\n",
        "- With metadata: \"Neutral sentiment scenarios fail\"\n",
        "- Metadata is what makes patterns visible\n",
        "\n",
        "### 4. **Pattern Structure Enables Action**\n",
        "- Patterns need: what, who, why, recommendation\n",
        "- This structure enables reporting and decision-making\n",
        "\n",
        "### 5. **This is Where Orchestrator Value Lives**\n",
        "- Pattern detection = orchestrator superpower\n",
        "- This is what makes orchestrators valuable\n",
        "- This is what single agents can't do\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Next Steps for Learning\n",
        "\n",
        "1. **Study the grouping patterns** - How data is grouped by dimension\n",
        "2. **Study the threshold logic** - How patterns are filtered from noise\n",
        "3. **Study the metadata usage** - How metadata enables pattern detection\n",
        "4. **Experiment with new patterns** - Try detecting different types of patterns\n",
        "5. **Understand state requirements** - See what state you need for pattern detection\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Visual Summary\n",
        "\n",
        "```\n",
        "Standard Agent Analysis:\n",
        "Agent A ‚Üí Accuracy: 40%\n",
        "Agent B ‚Üí Accuracy: 0%\n",
        "\n",
        "Orchestrator Analysis:\n",
        "Agent A √ó Scenario c003 ‚Üí Fail\n",
        "Agent B √ó Scenario c003 ‚Üí Fail\n",
        "  ‚Üì\n",
        "Pattern: Both agents fail on neutral sentiment\n",
        "  ‚Üì\n",
        "Insight: Systemic issue - improve neutral detection\n",
        "  ‚Üì\n",
        "Recommendation: Fix root cause, not individual agents\n",
        "```\n",
        "\n",
        "**This is the orchestrator value!**\n",
        "\n",
        "---\n",
        "\n",
        "*This walkthrough explains the pattern detection logic that creates orchestrator insights. Focus on understanding multi-dimensional analysis - this is the core orchestrator skill.*\n",
        "\n"
      ],
      "metadata": {
        "id": "DrR32POun2nU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report Node"
      ],
      "metadata": {
        "id": "5wdRy76WnXCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Report Node - Generates evaluation report\"\"\"\n",
        "\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, Any\n",
        "from config import EaaSState, EaaSConfig\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Initialize config\n",
        "config = EaaSConfig()\n",
        "\n",
        "\n",
        "def report_node(state: EaaSState) -> EaaSState:\n",
        "    \"\"\"\n",
        "    Generate evaluation report.\n",
        "\n",
        "    Reads: scores, evaluation_results, goal\n",
        "    Writes: evaluation_report, report_file_path\n",
        "    \"\"\"\n",
        "    logger.info(\"üìù Generating evaluation report...\")\n",
        "\n",
        "    try:\n",
        "        scores = state.get(\"scores\", {})\n",
        "        evaluation_results = state.get(\"evaluation_results\", [])\n",
        "        goal = state.get(\"goal\", {})\n",
        "        failure_analysis = state.get(\"failure_analysis\", [])\n",
        "\n",
        "        # MVP: Simple markdown report (no template for now)\n",
        "        report_lines = [\n",
        "            \"# Evaluation Report\",\n",
        "            \"\",\n",
        "            f\"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "            \"\",\n",
        "            \"## Summary\",\n",
        "            \"\",\n",
        "            f\"Evaluated **{len(scores)} agent(s)** across **{len(evaluation_results)} test scenario(s)**.\",\n",
        "            f\"Detected **{len(failure_analysis)} orchestrator insight(s)**.\",\n",
        "            \"\",\n",
        "            \"## Agent Scores\",\n",
        "            \"\"\n",
        "        ]\n",
        "\n",
        "        # Add scores for each agent\n",
        "        for agent_id, agent_scores in scores.items():\n",
        "            report_lines.extend([\n",
        "                f\"### {agent_id}\",\n",
        "                \"\",\n",
        "                f\"- **Overall Score:** {agent_scores.get('overall_score', 0):.2%}\",\n",
        "                f\"- **Accuracy:** {agent_scores.get('accuracy', 0):.2%}\",\n",
        "                f\"- **Latency (P50):** {agent_scores.get('latency_p50', 0)}ms\",\n",
        "                f\"- **Latency (P95):** {agent_scores.get('latency_p95', 0)}ms\",\n",
        "                f\"- **Total Scenarios:** {agent_scores.get('total_scenarios', 0)}\",\n",
        "                \"\"\n",
        "            ])\n",
        "\n",
        "        report_lines.extend([\n",
        "            \"## Detailed Results\",\n",
        "            \"\",\n",
        "            \"| Agent | Scenario | Input | Expected | Actual | Correct |\",\n",
        "            \"|-------|----------|-------|----------|--------|---------|\"\n",
        "        ])\n",
        "\n",
        "        # Add detailed results (limit to first 10 for readability)\n",
        "        for result in evaluation_results[:10]:\n",
        "            agent_id = result.get(\"agent_id\", \"unknown\")\n",
        "            scenario_id = result.get(\"scenario_id\", \"unknown\")\n",
        "            input_text = result.get(\"input\", \"\")[:50] + \"...\" if len(result.get(\"input\", \"\")) > 50 else result.get(\"input\", \"\")\n",
        "            expected = result.get(\"expected_output\", \"\")\n",
        "            actual = result.get(\"actual_output\", \"\")\n",
        "            correct = \"‚úÖ\" if expected == actual else \"‚ùå\"\n",
        "\n",
        "            report_lines.append(\n",
        "                f\"| {agent_id} | {scenario_id} | {input_text} | {expected} | {actual} | {correct} |\"\n",
        "            )\n",
        "\n",
        "        if len(evaluation_results) > 10:\n",
        "            report_lines.append(f\"\\n*... and {len(evaluation_results) - 10} more results*\")\n",
        "\n",
        "        # Add Orchestrator Insights Section - This is the key value!\n",
        "        if len(failure_analysis) > 0:\n",
        "            report_lines.extend([\n",
        "                \"\",\n",
        "                \"## üéØ Orchestrator Insights\",\n",
        "                \"\",\n",
        "                \"*These insights are only visible when evaluating multiple agents together - this is the orchestrator value!*\",\n",
        "                \"\"\n",
        "            ])\n",
        "\n",
        "            # Group patterns by type\n",
        "            pattern_groups = {}\n",
        "            for pattern in failure_analysis:\n",
        "                pattern_type = pattern.get(\"pattern_type\", \"unknown\")\n",
        "                if pattern_type not in pattern_groups:\n",
        "                    pattern_groups[pattern_type] = []\n",
        "                pattern_groups[pattern_type].append(pattern)\n",
        "\n",
        "            # Display each pattern type\n",
        "            for pattern_type, patterns in pattern_groups.items():\n",
        "                if pattern_type == \"scenario_failure\":\n",
        "                    report_lines.append(\"### üî¥ Systemic Failures (All Agents Fail)\")\n",
        "                    report_lines.append(\"\")\n",
        "                    for pattern in patterns:\n",
        "                        report_lines.extend([\n",
        "                            f\"**{pattern.get('description', 'Unknown pattern')}**\",\n",
        "                            f\"- Scenario: {pattern.get('scenario_id', 'unknown')}\",\n",
        "                            f\"- Agents affected: {', '.join(pattern.get('agents_affected', []))}\",\n",
        "                            f\"- Category: {pattern.get('category', 'unknown')}\",\n",
        "                            f\"- üí° Recommendation: {pattern.get('recommendation', 'N/A')}\",\n",
        "                            \"\"\n",
        "                        ])\n",
        "\n",
        "                elif pattern_type == \"cross_agent_failure\":\n",
        "                    report_lines.append(\"### ‚ö†Ô∏è Cross-Agent Failure Patterns\")\n",
        "                    report_lines.append(\"\")\n",
        "                    for pattern in patterns:\n",
        "                        report_lines.extend([\n",
        "                            f\"**{pattern.get('description', 'Unknown pattern')}**\",\n",
        "                            f\"- Scenarios affected: {len(pattern.get('scenarios_affected', []))} scenarios\",\n",
        "                            f\"- Agents affected: {', '.join(pattern.get('agents_affected', []))}\",\n",
        "                            f\"- Failure count: {pattern.get('failure_count', 0)}\",\n",
        "                            f\"- üí° Recommendation: {pattern.get('recommendation', 'N/A')}\",\n",
        "                            \"\"\n",
        "                        ])\n",
        "\n",
        "                elif pattern_type == \"performance_tradeoff\":\n",
        "                    report_lines.append(\"### ‚ö° Performance Trade-offs\")\n",
        "                    report_lines.append(\"\")\n",
        "                    for pattern in patterns:\n",
        "                        report_lines.extend([\n",
        "                            f\"**{pattern.get('description', 'Unknown pattern')}**\",\n",
        "                            f\"- üí° Recommendation: {pattern.get('recommendation', 'N/A')}\",\n",
        "                            \"\"\n",
        "                        ])\n",
        "\n",
        "                elif pattern_type == \"consistency\":\n",
        "                    report_lines.append(\"### üìä Consistency Patterns\")\n",
        "                    report_lines.append(\"\")\n",
        "                    for pattern in patterns:\n",
        "                        report_lines.extend([\n",
        "                            f\"**{pattern.get('description', 'Unknown pattern')}**\",\n",
        "                            f\"- üí° Recommendation: {pattern.get('recommendation', 'N/A')}\",\n",
        "                            \"\"\n",
        "                        ])\n",
        "        else:\n",
        "            report_lines.extend([\n",
        "                \"\",\n",
        "                \"## üéØ Orchestrator Insights\",\n",
        "                \"\",\n",
        "                \"*No patterns detected. This may indicate:*\",\n",
        "                \"- Agents are performing well across all scenarios\",\n",
        "                \"- Need more agents or scenarios to detect patterns\",\n",
        "                \"- Evaluation data may need more diversity\",\n",
        "                \"\"\n",
        "            ])\n",
        "\n",
        "        report_markdown = \"\\n\".join(report_lines)\n",
        "        state[\"evaluation_report\"] = report_markdown\n",
        "\n",
        "        # Save report to file\n",
        "        reports_dir = Path(config.evaluation_reports_dir)\n",
        "        reports_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        report_file = reports_dir / f\"evaluation_report_{timestamp}.md\"\n",
        "        report_file.write_text(report_markdown)\n",
        "\n",
        "        state[\"report_file_path\"] = str(report_file)\n",
        "        logger.info(f\"‚úÖ Report generated: {report_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error in report_node: {str(e)}\"\n",
        "        logger.error(error_msg)\n",
        "        state.setdefault(\"errors\", []).append(error_msg)\n",
        "\n",
        "    return state\n",
        "\n"
      ],
      "metadata": {
        "id": "GcemQK-KnYQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "5FZxuEJLq0l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac LG_Cursor_026 % python3 tests/test_mvp_runner.py\n",
        "\n",
        "============================================================\n",
        "üß™ EaaS Agent Smoke Test\n",
        "============================================================\n",
        "\n",
        "1Ô∏è‚É£ Testing goal_node...\n",
        "INFO: üéØ Defining evaluation goal...\n",
        "INFO: ‚úÖ Goal defined for 2 agent(s) with criteria: ['accuracy', 'safety', 'latency']\n",
        "   ‚úÖ Goal defined: Evaluate target agents against test scenarios\n",
        "\n",
        "2Ô∏è‚É£ Testing planning_node...\n",
        "INFO: üìã Creating execution plan...\n",
        "INFO: ‚úÖ Plan created with 5 steps\n",
        "   ‚úÖ Plan created with 5 steps\n",
        "\n",
        "3Ô∏è‚É£ Testing data_ingestion_node...\n",
        "INFO: üì• Ingesting evaluation data...\n",
        "INFO: ‚úÖ Loaded 10 test scenarios (types: ['classification'])\n",
        "   ‚úÖ Loaded 10 test scenarios\n",
        "\n",
        "4Ô∏è‚É£ Testing scenario_generation_node...\n",
        "INFO: üîß Generating additional scenarios...\n",
        "INFO: ‚úÖ Test data provided, skipping scenario generation (MVP)\n",
        "   ‚úÖ Scenario generation complete\n",
        "\n",
        "5Ô∏è‚É£ Testing evaluation_execution_node...\n",
        "INFO: üöÄ Executing evaluations...\n",
        "INFO:   Evaluating agent: agent_001\n",
        "INFO:   Evaluating agent: agent_002\n",
        "INFO: ‚úÖ Executed 20 evaluations across 2 agent(s)\n",
        "   ‚úÖ Executed 20 evaluations\n",
        "\n",
        "6Ô∏è‚É£ Testing scoring_node...\n",
        "INFO: üìä Scoring evaluation results...\n",
        "INFO:   Found 6 scenario-level failure patterns\n",
        "INFO:   Found 2 cross-agent patterns\n",
        "INFO:   Found 2 performance patterns\n",
        "INFO: ‚úÖ Scored 2 agent(s) and detected 10 patterns\n",
        "   ‚úÖ Scored 2 agent(s)\n",
        "\n",
        "   üìä agent_001:\n",
        "      Accuracy: 40.00%\n",
        "      Overall: 40.00%\n",
        "   üìä agent_002:\n",
        "      Accuracy: 0.00%\n",
        "      Overall: 0.00%\n",
        "\n",
        "7Ô∏è‚É£ Testing report_node...\n",
        "INFO: üìù Generating evaluation report...\n",
        "INFO: ‚úÖ Report generated: output/evaluation_reports/evaluation_report_20251117_161413.md\n",
        "   ‚úÖ Report generated: output/evaluation_reports/evaluation_report_20251117_161413.md\n",
        "\n",
        "============================================================\n",
        "‚úÖ All nodes passed smoke test!\n",
        "============================================================\n",
        "\n",
        "üìÑ Report saved to: output/evaluation_reports/evaluation_report_20251117_161413.md\n",
        "\n",
        "‚ú® No errors encountered!\n",
        "\n",
        "üéâ Smoke test completed successfully!\n"
      ],
      "metadata": {
        "id": "cDoKxgiqq14_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Report\n",
        "\n",
        "**Generated:** 2025-11-17 16:14:13\n",
        "\n",
        "## Summary\n",
        "\n",
        "Evaluated **2 agent(s)** across **20 test scenario(s)**.\n",
        "Detected **10 orchestrator insight(s)**.\n",
        "\n",
        "## Agent Scores\n",
        "\n",
        "### agent_001\n",
        "\n",
        "- **Overall Score:** 40.00%\n",
        "- **Accuracy:** 40.00%\n",
        "- **Latency (P50):** 105ms\n",
        "- **Latency (P95):** 105ms\n",
        "- **Total Scenarios:** 10\n",
        "\n",
        "### agent_002\n",
        "\n",
        "- **Overall Score:** 0.00%\n",
        "- **Accuracy:** 0.00%\n",
        "- **Latency (P50):** 105ms\n",
        "- **Latency (P95):** 105ms\n",
        "- **Total Scenarios:** 10\n",
        "\n",
        "## Detailed Results\n",
        "\n",
        "| Agent | Scenario | Input | Expected | Actual | Correct |\n",
        "|-------|----------|-------|----------|--------|---------|\n",
        "| agent_001 | c001 | I absolutely loved the new dashboard ‚Äì it‚Äôs so muc... | positive | positive | ‚úÖ |\n",
        "| agent_001 | c002 | This update is terrible, nothing works the way it ... | negative | positive | ‚ùå |\n",
        "| agent_001 | c003 | It‚Äôs fine, I guess. Not really better or worse tha... | neutral | positive | ‚ùå |\n",
        "| agent_001 | c004 | Thank you so much for fixing this so quickly, I re... | positive | positive | ‚úÖ |\n",
        "| agent_001 | c005 | I‚Äôm really frustrated that I keep getting logged o... | negative | positive | ‚ùå |\n",
        "| agent_001 | c006 | The results are okay, but there‚Äôs still room for i... | neutral | positive | ‚ùå |\n",
        "| agent_001 | c007 | This new feature saves me at least an hour every d... | positive | positive | ‚úÖ |\n",
        "| agent_001 | c008 | I don‚Äôt really care about this change. | neutral | positive | ‚ùå |\n",
        "| agent_001 | c009 | This is completely unusable; I‚Äôm going back to the... | negative | positive | ‚ùå |\n",
        "| agent_001 | c010 | Nice job on the redesign ‚Äì it looks clean and intu... | positive | positive | ‚úÖ |\n",
        "\n",
        "*... and 10 more results*\n",
        "\n",
        "## üéØ Orchestrator Insights\n",
        "\n",
        "*These insights are only visible when evaluating multiple agents together - this is the orchestrator value!*\n",
        "\n",
        "### üî¥ Systemic Failures (All Agents Fail)\n",
        "\n",
        "**All agents fail on scenario type: negative**\n",
        "- Scenario: c002\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Category: sentiment\n",
        "- üí° Recommendation: Improve handling of negative scenarios (category: sentiment)\n",
        "\n",
        "**All agents fail on scenario type: neutral**\n",
        "- Scenario: c003\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Category: sentiment\n",
        "- üí° Recommendation: Improve handling of neutral scenarios (category: sentiment)\n",
        "\n",
        "**All agents fail on scenario type: negative**\n",
        "- Scenario: c005\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Category: sentiment\n",
        "- üí° Recommendation: Improve handling of negative scenarios (category: sentiment)\n",
        "\n",
        "**All agents fail on scenario type: neutral**\n",
        "- Scenario: c006\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Category: sentiment\n",
        "- üí° Recommendation: Improve handling of neutral scenarios (category: sentiment)\n",
        "\n",
        "**All agents fail on scenario type: neutral**\n",
        "- Scenario: c008\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Category: sentiment\n",
        "- üí° Recommendation: Improve handling of neutral scenarios (category: sentiment)\n",
        "\n",
        "**All agents fail on scenario type: negative**\n",
        "- Scenario: c009\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Category: sentiment\n",
        "- üí° Recommendation: Improve handling of negative scenarios (category: sentiment)\n",
        "\n",
        "### ‚ö†Ô∏è Cross-Agent Failure Patterns\n",
        "\n",
        "**Multiple agents consistently fail on negative scenarios (category: sentiment)**\n",
        "- Scenarios affected: 3 scenarios\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Failure count: 3\n",
        "- üí° Recommendation: Systemic issue: All affected agents struggle with negative scenarios. Consider improving training data or model architecture for this category.\n",
        "\n",
        "**Multiple agents consistently fail on neutral scenarios (category: sentiment)**\n",
        "- Scenarios affected: 3 scenarios\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Failure count: 3\n",
        "- üí° Recommendation: Systemic issue: All affected agents struggle with neutral scenarios. Consider improving training data or model architecture for this category.\n",
        "\n",
        "### ‚ö° Performance Trade-offs\n",
        "\n",
        "**Speed/Accuracy Trade-off: agent_002 is 1.0x faster but 40.0% less accurate than agent_001**\n",
        "- üí° Recommendation: Consider using agent_002 for low-latency requirements, agent_001 for high-accuracy requirements\n",
        "\n",
        "### üìä Consistency Patterns\n",
        "\n",
        "**agent_002 is consistently fails across all scenarios**\n",
        "- üí° Recommendation: agent_002 performs reliably\n"
      ],
      "metadata": {
        "id": "tvJhbFUPrCfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Strategic Recommendation: What to Focus On Next\n",
        "\n",
        "**Based on:** Evaluation report showing orchestrator insights working perfectly!\n",
        "\n",
        "---\n",
        "\n",
        "## üéâ What's Working Great\n",
        "\n",
        "### Pattern Detection is Perfect!\n",
        "- ‚úÖ Detected 6 scenario-level failures\n",
        "- ‚úÖ Detected 2 cross-agent patterns (systemic issues)\n",
        "- ‚úÖ Detected performance trade-offs\n",
        "- ‚úÖ Detected consistency patterns\n",
        "\n",
        "**The orchestrator insights are clear:**\n",
        "- \"Multiple agents consistently fail on negative scenarios\"\n",
        "- \"Multiple agents consistently fail on neutral scenarios\"\n",
        "- This is exactly the orchestrator value we wanted!\n",
        "\n",
        "---\n",
        "\n",
        "## üîç What We're Seeing\n",
        "\n",
        "### Current Situation:\n",
        "- **Agent 001:** 40% accurate (correct on 4 positive scenarios, wrong on 6 negative/neutral)\n",
        "- **Agent 002:** 0% accurate (returns \"safe\" for everything, which never matches classification labels)\n",
        "\n",
        "### The Pattern Detection Revealed:\n",
        "- **Systemic Issue:** Both agents fail on negative and neutral sentiment\n",
        "- **Root Cause:** Mock agents are too simple (just return \"positive\" or \"safe\")\n",
        "- **Orchestrator Insight:** \"This is a systemic issue, not individual agent problems\"\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Strategic Recommendation\n",
        "\n",
        "### **Option A: Improve Mock Agents (Recommended Next Step)** ‚≠ê\n",
        "\n",
        "**Why:**\n",
        "1. **Pattern detection is working** - we've proven orchestrator value\n",
        "2. **Better mocks = more realistic patterns** - we'll see more nuanced insights\n",
        "3. **Aligns with Phase 2** of learning plan (improve execution node)\n",
        "4. **Teaches orchestration mechanics** - how to coordinate real agents\n",
        "\n",
        "**What to do:**\n",
        "- Make mock agents analyze input text (simple keyword-based classification)\n",
        "- Agent 001: Actually classify sentiment (positive/negative/neutral)\n",
        "- Agent 002: Actually check safety (safe/unsafe)\n",
        "- This will show more realistic patterns and insights\n",
        "\n",
        "**Learning Value:**\n",
        "- How to structure agent execution\n",
        "- How to handle different agent types\n",
        "- How to capture metadata for pattern detection\n",
        "\n",
        "---\n",
        "\n",
        "### **Option B: Focus on Training Data**\n",
        "\n",
        "**Why this might make sense:**\n",
        "- The pattern detection is showing \"systemic issues\" with negative/neutral sentiment\n",
        "- This could indicate training data problems\n",
        "\n",
        "**Why this is less valuable right now:**\n",
        "- The \"systemic issues\" are because mock agents are too simple\n",
        "- Real training data issues would only be visible with real agents\n",
        "- We're still in MVP/learning phase\n",
        "\n",
        "**When to do this:**\n",
        "- After we have realistic agents\n",
        "- When we see patterns with real agent behavior\n",
        "- When we want to improve actual agent performance\n",
        "\n",
        "---\n",
        "\n",
        "### **Option C: Add More Pattern Types**\n",
        "\n",
        "**Why this might make sense:**\n",
        "- Pattern detection is working, let's expand it\n",
        "- Could detect more sophisticated patterns\n",
        "\n",
        "**Why this is less valuable right now:**\n",
        "- We've proven orchestrator value\n",
        "- Better to improve execution first, then see what patterns emerge\n",
        "- More patterns = more complexity, but we want to learn fundamentals first\n",
        "\n",
        "**When to do this:**\n",
        "- After we have realistic agents\n",
        "- When we see what patterns real agents produce\n",
        "- When we understand what patterns are most valuable\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ My Recommendation: Improve Mock Agents (Option A)\n",
        "\n",
        "### Why This is the Best Next Step:\n",
        "\n",
        "1. **Pattern Detection is Proven**\n",
        "   - We've shown orchestrator value works\n",
        "   - We can detect systemic issues\n",
        "   - The architecture is solid\n",
        "\n",
        "2. **Better Mocks = Better Learning**\n",
        "   - More realistic patterns to detect\n",
        "   - See how pattern detection works with varied data\n",
        "   - Learn orchestration mechanics\n",
        "\n",
        "3. **Aligns with Learning Plan**\n",
        "   - Phase 1 (Pattern Detection): ‚úÖ Complete\n",
        "   - Phase 2 (Execution Node): Next step\n",
        "   - This is the natural progression\n",
        "\n",
        "4. **Teaches Core Skills**\n",
        "   - How to structure agent execution\n",
        "   - How to handle different agent types\n",
        "   - How to capture metadata for analysis\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Implementation Plan\n",
        "\n",
        "### Step 1: Improve Mock Classification Agent\n",
        "```python\n",
        "def _run_classification_agent(input_text: str) -> str:\n",
        "    \"\"\"Simple keyword-based sentiment classification\"\"\"\n",
        "    input_lower = input_text.lower()\n",
        "    \n",
        "    # Positive keywords\n",
        "    if any(word in input_lower for word in [\"love\", \"great\", \"awesome\", \"thank\", \"appreciate\", \"nice\"]):\n",
        "        return \"positive\"\n",
        "    \n",
        "    # Negative keywords\n",
        "    if any(word in input_lower for word in [\"terrible\", \"frustrated\", \"unusable\", \"hate\", \"bad\"]):\n",
        "        return \"negative\"\n",
        "    \n",
        "    # Neutral (default)\n",
        "    return \"neutral\"\n",
        "```\n",
        "\n",
        "### Step 2: Improve Mock Safety Agent\n",
        "```python\n",
        "def _run_safety_agent(input_text: str) -> str:\n",
        "    \"\"\"Simple keyword-based safety check\"\"\"\n",
        "    input_lower = input_text.lower()\n",
        "    \n",
        "    # Unsafe keywords\n",
        "    if any(word in input_lower for word in [\"hack\", \"dangerous\", \"harm\", \"illegal\"]):\n",
        "        return \"unsafe\"\n",
        "    \n",
        "    # Safe (default)\n",
        "    return \"safe\"\n",
        "```\n",
        "\n",
        "### Step 3: Test Again\n",
        "- Run evaluation with improved mocks\n",
        "- See more realistic patterns\n",
        "- Verify pattern detection still works\n",
        "- Learn how orchestration mechanics work\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Expected Outcomes\n",
        "\n",
        "### With Improved Mocks:\n",
        "- **More realistic accuracy** (agents will actually analyze text)\n",
        "- **More nuanced patterns** (some scenarios will pass, some will fail)\n",
        "- **Better insights** (patterns will reflect actual behavior, not just mock limitations)\n",
        "- **Learning value** (understand orchestration mechanics)\n",
        "\n",
        "### What We'll Learn:\n",
        "- How to structure agent execution\n",
        "- How different agent types work\n",
        "- How to capture metadata for pattern detection\n",
        "- How orchestration coordinates multiple agents\n",
        "\n",
        "---\n",
        "\n",
        "## üéì Learning Focus\n",
        "\n",
        "### What to Focus On:\n",
        "1. **Agent Execution Structure** - How to run different agent types\n",
        "2. **Metadata Capture** - What data to capture for pattern detection\n",
        "3. **Error Handling** - How to handle agent failures gracefully\n",
        "4. **Orchestration Mechanics** - How coordination works\n",
        "\n",
        "### Why This Matters:\n",
        "- This is the \"orchestration mechanics\" part of orchestrators\n",
        "- Pattern detection is the \"insights\" part\n",
        "- You need both to understand orchestrators fully\n",
        "\n",
        "---\n",
        "\n",
        "## üí≠ Alternative: Keep Current Mocks, Focus on State Design\n",
        "\n",
        "If you want to focus on state design instead:\n",
        "\n",
        "**Why:**\n",
        "- Pattern detection revealed what state we need\n",
        "- We could refine state structure based on patterns\n",
        "- This teaches state design for orchestrators\n",
        "\n",
        "**What to do:**\n",
        "- Analyze what metadata pattern detection needs\n",
        "- Refine state structure to capture relationships better\n",
        "- Plan state evolution for future features\n",
        "\n",
        "**When to do this:**\n",
        "- If you want to understand state design deeply\n",
        "- If you want to plan for future features\n",
        "- If you want to optimize current architecture\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Final Recommendation\n",
        "\n",
        "**Improve Mock Agents (Option A)** because:\n",
        "1. ‚úÖ Pattern detection is proven - we've shown orchestrator value\n",
        "2. ‚úÖ Natural next step in learning plan\n",
        "3. ‚úÖ Teaches orchestration mechanics\n",
        "4. ‚úÖ Will reveal more realistic patterns\n",
        "5. ‚úÖ Better foundation for future improvements\n",
        "\n",
        "**Then:**\n",
        "- After improved mocks, we can see what patterns emerge\n",
        "- We can refine pattern detection based on real behavior\n",
        "- We can improve state design based on what we learn\n",
        "- We can add more sophisticated features\n",
        "\n",
        "---\n",
        "\n",
        "*This recommendation balances learning value with practical progress. Improving mocks teaches orchestration mechanics while keeping pattern detection working.*\n",
        "\n"
      ],
      "metadata": {
        "id": "j7_TspaFsARd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation Report\n",
        "\n",
        "**Generated:** 2025-11-17 16:21:51\n",
        "\n",
        "## Summary\n",
        "\n",
        "Evaluated **2 agent(s)** across **20 test scenario(s)**.\n",
        "Detected **2 orchestrator insight(s)**.\n",
        "\n",
        "## Agent Scores\n",
        "\n",
        "### agent_001\n",
        "\n",
        "- **Overall Score:** 90.00%\n",
        "- **Accuracy:** 90.00%\n",
        "- **Latency (P50):** 105ms\n",
        "- **Latency (P95):** 105ms\n",
        "- **Total Scenarios:** 10\n",
        "\n",
        "### agent_002\n",
        "\n",
        "- **Overall Score:** 0.00%\n",
        "- **Accuracy:** 0.00%\n",
        "- **Latency (P50):** 105ms\n",
        "- **Latency (P95):** 105ms\n",
        "- **Total Scenarios:** 10\n",
        "\n",
        "## Detailed Results\n",
        "\n",
        "| Agent | Scenario | Input | Expected | Actual | Correct |\n",
        "|-------|----------|-------|----------|--------|---------|\n",
        "| agent_001 | c001 | I absolutely loved the new dashboard ‚Äì it‚Äôs so muc... | positive | positive | ‚úÖ |\n",
        "| agent_001 | c002 | This update is terrible, nothing works the way it ... | negative | negative | ‚úÖ |\n",
        "| agent_001 | c003 | It‚Äôs fine, I guess. Not really better or worse tha... | neutral | positive | ‚ùå |\n",
        "| agent_001 | c004 | Thank you so much for fixing this so quickly, I re... | positive | positive | ‚úÖ |\n",
        "| agent_001 | c005 | I‚Äôm really frustrated that I keep getting logged o... | negative | negative | ‚úÖ |\n",
        "| agent_001 | c006 | The results are okay, but there‚Äôs still room for i... | neutral | neutral | ‚úÖ |\n",
        "| agent_001 | c007 | This new feature saves me at least an hour every d... | positive | positive | ‚úÖ |\n",
        "| agent_001 | c008 | I don‚Äôt really care about this change. | neutral | neutral | ‚úÖ |\n",
        "| agent_001 | c009 | This is completely unusable; I‚Äôm going back to the... | negative | negative | ‚úÖ |\n",
        "| agent_001 | c010 | Nice job on the redesign ‚Äì it looks clean and intu... | positive | positive | ‚úÖ |\n",
        "\n",
        "*... and 10 more results*\n",
        "\n",
        "## üéØ Orchestrator Insights\n",
        "\n",
        "*These insights are only visible when evaluating multiple agents together - this is the orchestrator value!*\n",
        "\n",
        "### üî¥ Systemic Failures (All Agents Fail)\n",
        "\n",
        "**All agents fail on scenario type: neutral**\n",
        "- Scenario: c003\n",
        "- Agents affected: agent_001, agent_002\n",
        "- Category: sentiment\n",
        "- üí° Recommendation: Improve handling of neutral scenarios (category: sentiment)\n",
        "\n",
        "### üìä Consistency Patterns\n",
        "\n",
        "**agent_002 is consistently fails across all scenarios**\n",
        "- üí° Recommendation: agent_002 performs reliably\n"
      ],
      "metadata": {
        "id": "rBckHv80snhs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcsyQksjrbkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}