{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBW2hY9IBOJS7UUUUzKnA5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/071_Clean_AI_Tools_with_Dependency_Injection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# ðŸ§¼ Clean AI Tools with Dependency Injection\n",
        "\n",
        "## Why This Pattern Matters\n",
        "\n",
        "By using `ActionContext`, we solve several key challenges in AI tool and agent architecture:\n",
        "\n",
        "* âœ… Tools can access **conversation history** without being tightly coupled to the agent implementation\n",
        "* ðŸ” **Authentication** and other request-specific info can be injected where needed\n",
        "* ðŸ§ª Tools remain **independent and testable**, thanks to explicit dependency declarations\n",
        "* ðŸ”„ Agents can provide **different contexts** for development, testing, or production environments\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ’¡ What Is `ActionContext`?\n",
        "\n",
        "Weâ€™ve already been using `ActionContext` throughout our tools, but we havenâ€™t talked about why it's so important. It's a powerful architectural pattern that enables **dependency injection** and **decouples tools** from the core agent logic.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Real-World Example: Code Development & Review Agent\n",
        "\n",
        "Imagine building an AI agent that:\n",
        "\n",
        "1. First acts as a developer to write code based on requirements\n",
        "2. Later acts as a reviewer to critique its own work\n",
        "\n",
        "Seems simple, right? But here's the architectural catch:\n",
        "\n",
        "* For a code review to be effective, the LLM must understand the **entire context** of how the code was created:\n",
        "\n",
        "  * What requirements were discussed?\n",
        "  * What constraints were raised?\n",
        "  * What tradeoffs were considered?\n",
        "\n",
        "That history is in the **agent memory** â€” so how do we give the tool access to it **without tightly coupling** it to the agent itself?\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ¤¯ The Problem Without ActionContext\n",
        "\n",
        "Hereâ€™s a naive version of the tool:\n",
        "\n",
        "```python\n",
        "@register_tool(description=\"Analyze code quality and suggest improvements\")\n",
        "def analyze_code_quality(code: str) -> str:\n",
        "    return prompt_expert(\n",
        "        description_of_expert=\"Senior software architect reviewing code quality\",\n",
        "        prompt=f\"Review this code:\\n{code}\"\n",
        "    )\n",
        "```\n",
        "\n",
        "The problem?\n",
        "ðŸ”— This tool has **no access to memory** â€” so it canâ€™t consider **how** the code was developed, only **what** it looks like now.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© The Solution: Injecting Memory via `ActionContext`\n",
        "\n",
        "We fix this with dependency injection:\n",
        "\n",
        "```python\n",
        "@register_tool(description=\"Analyze code quality and suggest improvements\")\n",
        "def analyze_code_quality(action_context: ActionContext, code: str) -> str:\n",
        "    memory = action_context.get_memory()\n",
        "\n",
        "    development_context = []\n",
        "    for mem in memory.get_memories():\n",
        "        if mem[\"type\"] == \"user\":\n",
        "            development_context.append(f\"User: {mem['content']}\")\n",
        "        elif mem[\"type\"] == \"assistant\" and \"Here's the implementation\" in mem[\"content\"]:\n",
        "            development_context.append(f\"Implementation Decision: {mem['content']}\")\n",
        "\n",
        "    review_prompt = f\"\"\"Review this code in the context of its development history:\n",
        "\n",
        "Development History:\n",
        "{'\\n'.join(development_context)}\n",
        "\n",
        "Current Implementation:\n",
        "{code}\n",
        "\n",
        "Analyze:\n",
        "1. Does the implementation meet all stated requirements?\n",
        "2. Are all constraints and considerations from the discussion addressed?\n",
        "3. Have any requirements or constraints been overlooked?\n",
        "4. What improvements could make the code better while staying within the discussed parameters?\n",
        "\"\"\"\n",
        "\n",
        "    generate_response = action_context.get(\"llm\")\n",
        "    return generate_response(review_prompt)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "âœ… Now this tool is **context-aware**\n",
        "âœ… But still **modular and testable**\n",
        "âœ… And can be used **across agents, pipelines, or environments**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OIl0_qRpqPsI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhokE8LOpjIm"
      },
      "outputs": [],
      "source": [
        "@register_tool(\n",
        "    description=\"Analyze code quality and suggest improvements\",\n",
        "    tags=[\"code_quality\"]\n",
        ")\n",
        "def analyze_code_quality(code: str) -> str:\n",
        "    \"\"\"Review code quality and suggest improvements.\"\"\"\n",
        "    # But how do we access the conversation history?\n",
        "    # We can't just import the agent instance - that would create tight coupling\n",
        "\n",
        "    return prompt_expert(\n",
        "        description_of_expert=\"\"\"\n",
        "        Senior software architect reviewing code quality\n",
        "        \"\"\",\n",
        "        prompt=f\"Review this code:\\n{code}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ðŸ§© **The General Workflow**\n",
        "\n",
        "#### 1. **User Input**\n",
        "\n",
        "The user initiates the process:\n",
        "\n",
        "> *\"Please write a function that parses CSV data and handles malformed rows gracefully.\"*\n",
        "\n",
        "#### 2. **Code Generation Agent**\n",
        "\n",
        "The agent:\n",
        "\n",
        "* Reads the user input.\n",
        "* Writes an initial implementation.\n",
        "* Saves this to memory along with reasoning and user requirements.\n",
        "* Returns the **first draft** of the code to the user.\n",
        "\n",
        "#### 3. **Review Trigger**\n",
        "\n",
        "At this point:\n",
        "\n",
        "* Either the agent or user can trigger the **code review** tool (e.g., `analyze_code_quality`).\n",
        "* The tool reads memory (requirements + code) and uses an LLM to generate **feedback**:\n",
        "\n",
        "  * Missed requirements\n",
        "  * Logic bugs\n",
        "  * Suggestions for improvement\n",
        "\n",
        "#### 4. **Result Options**\n",
        "\n",
        "The agent/system might now:\n",
        "\n",
        "* âœ… Return **only** the review (for user to manually revise).\n",
        "* ðŸ” Automatically attempt a **revised version** using feedback.\n",
        "* ðŸ§  Present **both** the review and the revision for user review.\n",
        "\n",
        "#### 5. **User Review & Iteration**\n",
        "\n",
        "The user might then:\n",
        "\n",
        "* Accept the revision.\n",
        "* Add clarification (e.g., *â€œActually, can it also validate column types?â€*)\n",
        "* Request further changes.\n",
        "* Ask the agent to **re-run the review** with the new context.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” **Feedback Loop Summary**\n",
        "\n",
        "```text\n",
        "User â†’ Agent â†’ Code\n",
        "             â†˜\n",
        "           Review Agent\n",
        "             â†˜\n",
        "           Feedback â†’ Revised Code\n",
        "                     â†˜\n",
        "                  User Feedback\n",
        "                        â†˜\n",
        "                 Restart or Accept\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Why This Matters\n",
        "\n",
        "This pattern:\n",
        "\n",
        "* Mirrors how humans work: draft â†’ review â†’ revise â†’ approval.\n",
        "* Lets agents stay modular (creator vs reviewer).\n",
        "* Enables **safe, testable, traceable** development cycles.\n",
        "* Builds trust by **exposing rationale**, not just results.\n",
        "\n"
      ],
      "metadata": {
        "id": "8JdcCjZD1tY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ðŸ§  What the Tool Is Doing\n",
        "\n",
        "When the tool performs a **code review**, it wants to **simulate how a senior engineer would think**:\n",
        "\n",
        "> *\"Before I judge this code, I need to understand what the requirements were and how the solution came about.\"*\n",
        "\n",
        "So it:\n",
        "\n",
        "1. **Pulls memory** from `action_context` â€” this includes the full conversation history (user prompts, LLM responses, etc.).\n",
        "\n",
        "2. **Filters** those memories to:\n",
        "\n",
        "   * âœ… Capture the **userâ€™s original instructions**, like:\n",
        "\n",
        "     > \"Write a function that parses a CSV and summarizes data by region.\"\n",
        "   * âœ… Capture relevant **LLM responses**, such as:\n",
        "\n",
        "     > \"Hereâ€™s the implementation that does what you asked.\"\n",
        "\n",
        "3. **Combines**:\n",
        "\n",
        "   * The **intent** from the user\n",
        "   * The **decisions made by the LLM**\n",
        "   * The **final code snippet**\n",
        "\n",
        "4. **Constructs a prompt** that gives the LLM this full development history for a **context-rich review**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Why This Matters\n",
        "\n",
        "Without this memory injection:\n",
        "\n",
        "* The LLM would only see the **final code**, not the *why* behind it.\n",
        "* Thatâ€™s like asking someone to critique a building without telling them what kind of building itâ€™s supposed to be.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Summary\n",
        "\n",
        "> **Yes â€” you're absolutely right.**\n",
        "> It captures both the **intent** (user input) and the **response** (generated code) so the final review can assess whether the code **meets the original goals**, **respects constraints**, and **offers room for improvement**.\n"
      ],
      "metadata": {
        "id": "S4bRchN4w-4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ðŸ§© What Does \"Tightly Coupled\" Mean?\n",
        "\n",
        "When two components are **tightly coupled**, it means:\n",
        "\n",
        "* One **directly depends** on the inner workings of the other\n",
        "* If you change one, youâ€™re **forced to change the other**\n",
        "* They **canâ€™t function independently**\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“¦ In the Agent Context\n",
        "\n",
        "Letâ€™s say you have a tool like:\n",
        "\n",
        "```python\n",
        "def review_code():\n",
        "    memory = my_agent.memory\n",
        "    llm = my_agent.llm\n",
        "    ...\n",
        "```\n",
        "\n",
        "That tool is now **tightly coupled** to `my_agent` because:\n",
        "\n",
        "* It assumes the existence of a specific agent object\n",
        "* It pulls memory and LLM references directly from that agent\n",
        "* You **can't reuse** this tool in another context or test it easily\n",
        "\n",
        "If the agent changes its structure or API, this tool **breaks**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ›  Why This Is a Problem\n",
        "\n",
        "* âŒ You **canâ€™t reuse** tools across agents\n",
        "* âŒ You **canâ€™t unit test** tools in isolation\n",
        "* âŒ You **canâ€™t swap** agents or LLMs easily\n",
        "* âŒ It violates the **Separation of Concerns** principle\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… What ActionContext Enables\n",
        "\n",
        "By injecting dependencies like this:\n",
        "\n",
        "```python\n",
        "def review_code(action_context: ActionContext):\n",
        "    memory = action_context.get_memory()\n",
        "    llm = action_context.get(\"llm\")\n",
        "```\n",
        "\n",
        "You get:\n",
        "\n",
        "* âœ” **Loose coupling** (no hardcoded references)\n",
        "* âœ” **Testability** (inject mocks or stubs)\n",
        "* âœ” **Portability** (use the same tool in different agents or environments)\n",
        "* âœ” **Encapsulation** (tools donâ€™t care *who* the agent is, only that they get the data they need)\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Analogy\n",
        "\n",
        "> Tightly coupled = You wrote a tool that only works in *your* kitchen\n",
        "> Loosely coupled = You wrote a tool that works in *any* kitchen, as long as thereâ€™s a fridge and a stove\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bd08-EBjxWgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ§° `action_context`: Decoupling Tools from Agents\n",
        "\n",
        "We face an immediate problem:\n",
        "Our tool needs access to the **conversation history** stored in memory â€” but we canâ€™t simply import the agent instance or directly reference its memory.\n",
        "\n",
        "### âŒ Why Thatâ€™s a Problem\n",
        "\n",
        "Directly accessing agent memory would:\n",
        "\n",
        "* **Tightly couple** the tool to a specific agent implementation\n",
        "* Make tools **harder to reuse** across different agents\n",
        "* Complicate **testing** and **modularity**\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… The Solution: `ActionContext` Pattern\n",
        "\n",
        "The `ActionContext` pattern solves this by acting as a **dependency injection container** â€” it passes in only what the tool needs to function.\n",
        "\n",
        "> Think of it as a backpack the agent gives to the tool, containing just the right supplies (like memory, LLM, APIs, etc.)\n",
        "\n",
        "This allows:\n",
        "\n",
        "* Tools to access memory **without knowing where it came from**\n",
        "* Tools to remain **independent, testable, and portable**\n",
        "* A clean architecture where **tools donâ€™t import agents or global state**\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  Why It Matters\n",
        "\n",
        "`ActionContext` creates a separation between:\n",
        "\n",
        "* **Business logic** (what the tool does)\n",
        "* **Execution environment** (what memory/LLM/resources are available)\n",
        "\n",
        "This makes tools safer, more robust, and easy to scale across multiple agent workflows.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R7NGyzHKy0bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ðŸ” Understanding the `ActionContext` Class\n",
        "\n",
        "```python\n",
        "class ActionContext:\n",
        "    def __init__(self, properties: Dict = None):\n",
        "        self.context_id = str(uuid.uuid4())\n",
        "        self.properties = properties or {}\n",
        "\n",
        "    def get(self, key: str, default=None):\n",
        "        return self.properties.get(key, default)\n",
        "\n",
        "    def get_memory(self):\n",
        "        return self.properties.get(\"memory\", None)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§± What's Happening Here?\n",
        "\n",
        "| Line / Concept | What It Does                                                                  | Why It Matters                                                                                                    |\n",
        "| -------------- | ----------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
        "| `__init__`     | Creates a new `ActionContext` with a unique ID and a dictionary of resources. | This allows any tool to be passed context-specific data (e.g., memory, LLM, tokens, APIs) without tight coupling. |\n",
        "| `context_id`   | Unique ID for the context session.                                            | Helpful for tracking/debugging tool runs in complex systems.                                                      |\n",
        "| `properties`   | A flexible dictionary of all available injected dependencies.                 | Keeps things modular. Add what you need, ignore what you donâ€™t.                                                   |\n",
        "| `get(key)`     | General-purpose accessor for context data.                                    | Use this when you want to access something like `\"llm\"`, `\"api_key\"`, etc.                                        |\n",
        "| `get_memory()` | Specialized helper to retrieve the memory object.                             | Frequently used by tools that need to read past conversation history.                                             |\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“¦ What Kind of Things Go Into `properties`?\n",
        "\n",
        "You might inject any of the following:\n",
        "\n",
        "* `memory`: An object that holds conversation history\n",
        "* `llm`: A function that wraps LLM calls (like `generate_response(prompt)`)\n",
        "* `agent_registry`: Used for agent-to-agent calls\n",
        "* `api_keys`: Tokens for calendar, email, etc.\n",
        "* `user_id`, `session_id`, etc.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Benefits Recap\n",
        "\n",
        "* **Testable:** Tools donâ€™t need global state\n",
        "* **Reusable:** Use the same tool across agents/systems\n",
        "* **Flexible:** Context can be tailored per environment (e.g., dev vs. prod)\n",
        "* **Safe:** Tools don't reach outside their scope\n",
        "\n"
      ],
      "metadata": {
        "id": "rwDLHAFtzN1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This second half of the code introduces **the real power of `ActionContext`** â€” and there are a few *key architectural principles and design patterns* you should focus on. Letâ€™s break them down:\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” What You Should Focus On\n",
        "\n",
        "### 1. **The Role of `ActionContext`: Dependency Injection**\n",
        "\n",
        "```python\n",
        "def analyze_code_quality(action_context: ActionContext, code: str) -> str:\n",
        "```\n",
        "\n",
        "* Instead of accessing global objects, the tool receives **everything it needs** through `action_context`.\n",
        "* âœ… This makes the tool **reusable, testable, and decoupled** from the environment it's running in.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Accessing Memory Through Context (Not Agent)**\n",
        "\n",
        "```python\n",
        "memory = action_context.get_memory()\n",
        "```\n",
        "\n",
        "* This is **clean dependency injection**.\n",
        "* Youâ€™re not importing or hardcoding any `Agent` object â€” the memory could come from *any* source (mock, live agent, simulated test).\n",
        "* ðŸ“Œ This solves the tight coupling problem.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Selective Memory Parsing for Relevant Context**\n",
        "\n",
        "```python\n",
        "for mem in memory.get_memories():\n",
        "    if mem[\"type\"] == \"user\":\n",
        "        ...\n",
        "    elif mem[\"type\"] == \"assistant\" and \"Here's the implementation\" in mem[\"content\"]:\n",
        "        ...\n",
        "```\n",
        "\n",
        "* Youâ€™re building a **development history context** based on conversation types.\n",
        "* This lets the tool **reconstruct the narrative** of the codeâ€™s origin: what was asked, what was built.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Context-Aware Prompt Engineering**\n",
        "\n",
        "```python\n",
        "review_prompt = f\"\"\"Review this code in the context of its development history:\n",
        "...\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "* Instead of just dumping code into the LLM, you provide **historical context** that helps it reason more effectively.\n",
        "* ðŸ§  Youâ€™re helping the model understand *why* the code was written the way it was â€” just like a human reviewer would.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **LLM Access Through Context (Not Direct Call)**\n",
        "\n",
        "```python\n",
        "generate_response = action_context.get(\"llm\")\n",
        "return generate_response(review_prompt)\n",
        "```\n",
        "\n",
        "* Again, youâ€™re not hardcoding `openai.ChatCompletion.create()` or anything vendor-specific.\n",
        "* This makes it easy to swap in another LLM, mock it for testing, or route it through a review system.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  What You're Learning\n",
        "\n",
        "* **Architectural clean code**: Tools should be dumb. Context should be smart.\n",
        "* **Tool portability**: This review tool could now be dropped into *any* codebase with any memory and LLM backend.\n",
        "* **Scalability**: This pattern supports plugin systems, multi-agent systems, and runtime configuration.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Why This Matters\n",
        "\n",
        "| Principle                  | Why It Matters                             |\n",
        "| -------------------------- | ------------------------------------------ |\n",
        "| **Loose coupling**         | Easier to reuse and modify tools           |\n",
        "| **Separation of concerns** | Tools focus only on logic, not environment |\n",
        "| **Testability**            | You can unit test tools in isolation       |\n",
        "| **Context awareness**      | LLMs perform better with relevant context  |\n",
        "| **Vendor agnostic**        | Works with OpenAI, Anthropic, etc.         |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GFS7lPJKyZYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@register_tool(\n",
        "    description=\"Analyze code quality and suggest improvements\",\n",
        "    tags=[\"code_quality\"]\n",
        ")\n",
        "def analyze_code_quality(action_context: ActionContext, code: str) -> str:\n",
        "    \"\"\"Review code quality and suggest improvements.\"\"\"\n",
        "    # Get memory to understand the code's context\n",
        "    memory = action_context.get_memory()\n",
        "\n",
        "    # Extract relevant history\n",
        "    development_context = []\n",
        "    for mem in memory.get_memories():\n",
        "        if mem[\"type\"] == \"user\":\n",
        "            development_context.append(f\"User: {mem['content']}\")\n",
        "        # Hypotethical scenario where our agent includes the phrase \"Here's the implementation\" when it generates code\n",
        "        elif mem[\"type\"] == \"assistant\" and \"Here's the implementation\" in mem[\"content\"]:\n",
        "            development_context.append(f\"Implementation Decision: {mem['content']}\")\n",
        "\n",
        "    # Create review prompt with full context\n",
        "    review_prompt = f\"\"\"Review this code in the context of its development history:\n",
        "\n",
        "Development History:\n",
        "{'\\n'.join(development_context)}\n",
        "\n",
        "Current Implementation:\n",
        "{code}\n",
        "\n",
        "Analyze:\n",
        "1. Does the implementation meet all stated requirements?\n",
        "2. Are all constraints and considerations from the discussion addressed?\n",
        "3. Have any requirements or constraints been overlooked?\n",
        "4. What improvements could make the code better while staying within the discussed parameters?\n",
        "\"\"\"\n",
        "\n",
        "    generate_response = action_context.get(\"llm\")\n",
        "    return generate_response(review_prompt)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CCiXVzzixBn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a great example of how clean, decoupled tool design can empower complex AI behaviors. Letâ€™s break it down step by step and highlight what you should focus on and **why** it matters.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Key Purpose of This Tool\n",
        "\n",
        "The `analyze_code_quality` tool:\n",
        "\n",
        "* **Reviews code intelligently**, based not just on the code itself but also on the **conversation history** (requirements, decisions, trade-offs).\n",
        "* Demonstrates how to use the `ActionContext` to **inject dependencies** cleanly (like memory and the LLM function).\n",
        "* Makes the tool testable, reusable, and modular.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ” What to Focus On and Why\n",
        "\n",
        "| Code Block                                      | ðŸ” What to Focus On                                                            | ðŸ’¡ Why It Matters                                                                                                                                  |\n",
        "| ----------------------------------------------- | ------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| `action_context.get_memory()`                   | Memory access is abstracted through the context.                               | Tool doesnâ€™t need to know how or where memory is stored â€” itâ€™s injected. This is key to **decoupling**.                                            |\n",
        "| `memory.get_memories()`                         | Retrieves the full conversation history.                                       | Enables the tool to reconstruct the **development process** that led to the current code.                                                          |\n",
        "| Conditional logic: `if mem[\"type\"] == ...`      | Selectively extracts relevant history (user input, assistant code generation). | Reduces token usage and improves relevance â€” donâ€™t dump the whole memory, just the important parts.                                                |\n",
        "| `\"Here's the implementation\" in mem[\"content\"]` | Using a **heuristic** to identify code-generation messages.                    | Demonstrates lightweight, human-readable methods to tag or extract agent actions.                                                                  |\n",
        "| `review_prompt = f\"\"\"...\"\"\"`                    | Builds a custom LLM prompt using **dynamic context**.                          | This is where the tool becomes smart. It combines memory and current input to produce an informed, context-aware review request.                   |\n",
        "| `generate_response = action_context.get(\"llm\")` | LLM is injected, not hardcoded.                                                | You could swap in a different model (e.g., GPT-4 vs Claude) just by changing the context â€” great for testing or different deployment environments. |\n",
        "| `return generate_response(review_prompt)`       | Tool calls the LLM with a structured, scoped task.                             | Clean separation: **tool defines behavior**, **LLM executes it**. No entanglement with the tool internals.                                         |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© Summary: What You're Learning\n",
        "\n",
        "This tool teaches you:\n",
        "\n",
        "âœ… How to use memory to provide intelligent context\n",
        "âœ… How to build clean, testable tools with **dependency injection**\n",
        "âœ… How to combine current input + past conversation to produce better LLM prompts\n",
        "âœ… How to keep tools **modular** without losing power or flexibility\n",
        "\n",
        "This is *exactly* the kind of design that scales well, remains safe, and keeps agents reliable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cUgaTAxrz9PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#===============================\n",
        "# V1: Naive version (Tightly Coupled)\n",
        "#===============================\n",
        "\n",
        "@register_tool(\n",
        "    description=\"Analyze code quality and suggest improvements\",\n",
        "    tags=[\"code_quality\"]\n",
        ")\n",
        "def analyze_code_quality(code: str) -> str:\n",
        "    \"\"\"Review code quality and suggest improvements.\"\"\"\n",
        "\n",
        "    # â—ï¸Problem: This version lacks context about how the code was written\n",
        "    # It assumes that code alone is enough, but good review needs to understand requirements, goals, and trade-offs\n",
        "\n",
        "    # â—ï¸Also: No memory or external resources can be injected â€” this makes it hard to test or adapt\n",
        "\n",
        "    return prompt_expert(\n",
        "        description_of_expert=\"\"\"\n",
        "        Senior software architect reviewing code quality\n",
        "        \"\"\",\n",
        "        prompt=f\"Review this code:\\n{code}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "wnG6QaP50AqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#===============================\n",
        "# ActionContext Utility Class\n",
        "#===============================\n",
        "\n",
        "class ActionContext:\n",
        "    def __init__(self, properties: Dict=None):\n",
        "        self.context_id = str(uuid.uuid4())  # Unique ID for traceability/debugging\n",
        "        self.properties = properties or {}   # Store injected dependencies or state\n",
        "\n",
        "    def get(self, key: str, default=None):\n",
        "        # Generic getter â€” flexible and extendable\n",
        "        return self.properties.get(key, default)\n",
        "\n",
        "    def get_memory(self):\n",
        "        # Memory accessor â€” useful abstraction\n",
        "        return self.properties.get(\"memory\", None)\n",
        "\n",
        "#===============================\n",
        "# V2: Context-Aware Tool (Decoupled)\n",
        "#===============================\n",
        "\n",
        "@register_tool(\n",
        "    description=\"Analyze code quality and suggest improvements\",\n",
        "    tags=[\"code_quality\"]\n",
        ")\n",
        "def analyze_code_quality(action_context: ActionContext, code: str) -> str:\n",
        "    \"\"\"Review code quality and suggest improvements.\"\"\"\n",
        "\n",
        "    # âœ… Dependency injection: Tool does not assume where memory comes from\n",
        "    memory = action_context.get_memory()\n",
        "\n",
        "    # Extract relevant development history from memory\n",
        "    development_context = []\n",
        "    for mem in memory.get_memories():\n",
        "        if mem[\"type\"] == \"user\":\n",
        "            # Capture user input (e.g. requirements or constraints)\n",
        "            development_context.append(f\"User: {mem['content']}\")\n",
        "\n",
        "        elif mem[\"type\"] == \"assistant\" and \"Here's the implementation\" in mem[\"content\"]:\n",
        "            # Heuristic: Capture key assistant responses that signal code generation\n",
        "            development_context.append(f\"Implementation Decision: {mem['content']}\")\n",
        "\n",
        "    # ðŸ§  We are building a prompt that includes both the code and the *story* of how it was created\n",
        "    review_prompt = f\"\"\"Review this code in the context of its development history:\n",
        "\n",
        "Development History:\n",
        "{'\\n'.join(development_context)}\n",
        "\n",
        "Current Implementation:\n",
        "{code}\n",
        "\n",
        "Analyze:\n",
        "1. Does the implementation meet all stated requirements?\n",
        "2. Are all constraints and considerations from the discussion addressed?\n",
        "3. Have any requirements or constraints been overlooked?\n",
        "4. What improvements could make the code better while staying within the discussed parameters?\n",
        "\"\"\"\n",
        "\n",
        "    # Injected LLM function â€” you could swap models just by changing the context\n",
        "    generate_response = action_context.get(\"llm\")\n",
        "\n",
        "    # Return the LLM's analysis\n",
        "    return generate_response(review_prompt)\n"
      ],
      "metadata": {
        "id": "cKK4wWKL0iTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Summary of What You Should Learn from This\n",
        "\n",
        "### ðŸ”§ Architectural Takeaways:\n",
        "\n",
        "* **Decouple tools from agents** using `ActionContext`\n",
        "* **Inject dependencies** instead of importing or assuming them\n",
        "* **Enable testing and reuse** by keeping tools stateless and parameterized\n",
        "\n",
        "### ðŸ¤– AI-Specific Insights:\n",
        "\n",
        "* Context matters â€” LLMs perform better with structured, relevant memory\n",
        "* Design prompts to include history, decisions, and intent â€” not just code\n",
        "* Use heuristics (like `\"Here's the implementation\"`) to extract key memory entries\n",
        "\n",
        "### ðŸ§ª Why This Scales:\n",
        "\n",
        "This design makes your tools:\n",
        "\n",
        "* Easier to test\n",
        "* More maintainable\n",
        "* Safer in production\n",
        "* More adaptable across different agents or environments"
      ],
      "metadata": {
        "id": "0_6Pm99H0qmL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89VGzUYc0twj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}