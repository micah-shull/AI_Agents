{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPvQAcBdTkfB+aRhd7JW5/L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/098_Research_Summarizer_Agent_aLittleLessDirty.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Code\n",
        "### Copy of completed code from preivous notebook"
      ],
      "metadata": {
        "id": "HmbBm21y2Us7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- LLM Summarization Helper (uses your OpenAI client outside the loop) ---\n",
        "def make_summarizer(openai_chat_fn: Callable[[List[Dict[str, str]]], str]):\n",
        "    \"\"\"Return a summarize_text(text, max_points, style) function using provided LLM call.\n",
        "    openai_chat_fn: function that takes messages=[...] and returns string content.\n",
        "    \"\"\"\n",
        "    def summarize_text(text: str, max_points: int = 5, style: str = \"bullet\") -> str:\n",
        "        system = (\n",
        "            \"You are a precise technical summarizer. Extract key points, preserve facts, \"\n",
        "            \"and avoid speculation. Keep it concise.\"\n",
        "        )\n",
        "        user = (\n",
        "            f\"Summarize the following text into at most {max_points} key points. \"\n",
        "            f\"Format: {'bullets' if style=='bullet' else 'short paragraphs'}.\\n\\n\" + text\n",
        "        )\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system},\n",
        "            {\"role\": \"user\", \"content\": user},\n",
        "        ]\n",
        "        return openai_chat_fn(messages)\n",
        "    return summarize_text\n",
        "\n",
        "# --- Wiring helper to build the registry for this agent ---\n",
        "def build_research_actions(env: ResearchEnvironment, summarizer_fn: Callable[[str, int, str], str]) -> ActionRegistry:\n",
        "    registry = ActionRegistry()\n",
        "\n",
        "    registry.register(Action(\n",
        "        name=\"list_txt_files\",\n",
        "        fn=lambda: env.list_txt_files(),\n",
        "        description=\"Return .txt file names from /content/files\",\n",
        "        parameters={\"type\":\"object\",\"properties\":{},\"required\":[]},\n",
        "    ))\n",
        "\n",
        "    registry.register(Action(\n",
        "        name=\"read_txt_file\",\n",
        "        fn=lambda file_name: env.read_txt_file(file_name),\n",
        "        description=\"Read a text file from /content/files\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "            \"required\": [\"file_name\"],\n",
        "        },\n",
        "    ))\n",
        "\n",
        "    registry.register(Action(\n",
        "        name=\"summarize_text\",\n",
        "        fn=lambda text, max_points=5, style=\"bullet\": summarizer_fn(text, max_points, style),\n",
        "        description=\"Summarize raw text into key points using the LLM\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"text\": {\"type\": \"string\"},\n",
        "                \"max_points\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 12},\n",
        "                \"style\": {\"type\": \"string\", \"enum\": [\"bullet\", \"paragraph\"]},\n",
        "            },\n",
        "            \"required\": [\"text\"],\n",
        "        },\n",
        "    ))\n",
        "\n",
        "    registry.register(Action(\n",
        "        name=\"write_summary_file\",\n",
        "        fn=lambda source_file, content: env.write_summary_file(source_file, content),\n",
        "        description=\"Write summary text to /content/summaries (auto-named from source)\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"source_file\": {\"type\": \"string\"},\n",
        "                \"content\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [\"source_file\", \"content\"],\n",
        "        },\n",
        "    ))\n",
        "\n",
        "    return registry\n",
        "\n",
        "\n",
        "# STEP 2 — Language & Prereqs (clean)\n",
        "# Put this ABOVE the wiring cell. Defines: Goal, Memory, AgentLanguage, SummarizerLanguage.\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# --- Minimal prereqs --------------------------------------------------------\n",
        "@dataclass(frozen=True)\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.items: List[Dict[str, Any]] = []\n",
        "    def add_memory(self, m: Dict[str, Any]):\n",
        "        self.items.append(m)\n",
        "    def get_memories(self, limit: int | None = None):\n",
        "        return self.items[-limit:] if limit else self.items\n",
        "\n",
        "# --- AgentLanguage base + concrete SummarizerLanguage ----------------------\n",
        "class AgentLanguage:\n",
        "    \"\"\"Build prompt for the LLM; parse the LLM's response (usually handled by generate_response).\"\"\"\n",
        "    def construct_prompt(self, actions: List[Any], environment: Any, goals: List[Goal], memory: Memory) -> Dict[str, Any]:\n",
        "        raise NotImplementedError\n",
        "    def parse_response(self, response: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        # Default: response already structured as {\"tool\": ..., \"args\": {...}}\n",
        "        return response\n",
        "\n",
        "class SummarizerLanguage(AgentLanguage):\n",
        "    \"\"\"Formats goals/memory for the summarizer agent. Tool-call parsing is done in generate_response().\"\"\"\n",
        "    def construct_prompt(self, actions, environment, goals: List[Goal], memory: Memory) -> Dict[str, Any]:\n",
        "        goals_text = (\n",
        "            \"You are a file summarizer. Follow these goals in order of priority:\\n\" +\n",
        "            \"\\n\".join(f\"- ({g.priority}) {g.name}: {g.description.strip()}\" for g in sorted(goals, key=lambda g: g.priority))\n",
        "        )\n",
        "        mem = memory.get_memories(8)\n",
        "        return {\"goals_text\": goals_text, \"memory\": mem, \"actions\": actions}\n",
        "\n",
        "# Research Summarizer — Orchestrator Wiring (function calling)\n",
        "# REQUIREMENTS (already defined earlier in your notebook):\n",
        "# - Agent (orchestrator template)\n",
        "# - Goal, Action, ActionRegistry\n",
        "# - ResearchEnvironment, make_summarizer, build_research_actions (from the previous cell)\n",
        "# - Memory class from your template\n",
        "#\n",
        "# This cell wires those pieces together, adds an AgentLanguage\n",
        "# and a generate_response() that uses OpenAI function calling.\n",
        "\n",
        "import os, json\n",
        "from typing import Dict, Any, List\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# ---------------- Load API key & client ----------------\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "# ---------------- Tools export helper ------------------\n",
        "def registry_to_openai_tools(registry: ActionRegistry) -> List[Dict[str, Any]]:\n",
        "    tools = []\n",
        "    for a in registry.get_actions():\n",
        "        tools.append({\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": a.name,\n",
        "                \"description\": a.description,\n",
        "                \"parameters\": a.parameters or {\"type\": \"object\", \"properties\": {}, \"required\": []},\n",
        "            },\n",
        "        })\n",
        "    return tools\n",
        "\n",
        "# ---------------- AgentLanguage ------------------------\n",
        "class SummarizerLanguage(AgentLanguage):\n",
        "    \"\"\"Formats goals/memory for the LLM; parse is handled in generate_response.\"\"\"\n",
        "    def construct_prompt(self, actions, environment, goals, memory):\n",
        "        goals_text = \"You are a file summarizer. Follow these goals in order of priority:\\n\" + \"\\n\".join(\n",
        "            f\"- ({g.priority}) {g.name}: {g.description.strip()}\" for g in sorted(goals, key=lambda g: g.priority)\n",
        "        )\n",
        "        # Keep a tight memory window\n",
        "        mem = memory.get_memories(8)\n",
        "        return {\"goals_text\": goals_text, \"memory\": mem, \"actions\": actions}\n",
        "\n",
        "# ------------- generate_response (OpenAI call) ---------\n",
        "# NOTE: This returns a structured dict {\"tool\": name, \"args\": {...}} for the orchestrator.\n",
        "\n",
        "def make_generate_response(registry: ActionRegistry):\n",
        "    tools_spec = registry_to_openai_tools(registry)\n",
        "\n",
        "    def build_messages(prompt_dict: Dict[str, Any]) -> List[Dict[str, str]]:\n",
        "        system = (\n",
        "            prompt_dict[\"goals_text\"]\n",
        "            + \"\\n\\nYou must use tools via function calling to make progress. \"\n",
        "            + \"Choose exactly one next tool per step. If you have saved all summaries, call a terminate tool if available; otherwise indicate completion.\"\n",
        "        )\n",
        "        # Replay memory if you'd like the model to see prior context (optional here)\n",
        "        memory_msgs = []\n",
        "        for m in prompt_dict[\"memory\"]:\n",
        "            role = m.get(\"role\") or m.get(\"type\") or \"user\"\n",
        "            content = m.get(\"content\")\n",
        "            # Coerce non-strings for safety\n",
        "            if not isinstance(content, str):\n",
        "                content = json.dumps(content)\n",
        "            memory_msgs.append({\"role\": role if role in (\"system\",\"user\",\"assistant\") else \"user\", \"content\": content})\n",
        "\n",
        "        # Nudge the model with a fresh user instruction\n",
        "        user_msg = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Pick the best next tool from the available functions to progress toward summarizing the files. \"\n",
        "                \"Return a function call, not prose.\"\n",
        "            ),\n",
        "        }\n",
        "        return [{\"role\": \"system\", \"content\": system}] + memory_msgs + [user_msg]\n",
        "\n",
        "    def _generate_response(prompt_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        messages = build_messages(prompt_dict)\n",
        "        resp = client.chat.completions.create(\n",
        "            model=MODEL,\n",
        "            messages=messages,\n",
        "            tools=tools_spec,\n",
        "            tool_choice=\"auto\",\n",
        "            temperature=0.2,\n",
        "        )\n",
        "        msg = resp.choices[0].message\n",
        "        # If the model chose a tool, parse it\n",
        "        if msg.tool_calls:\n",
        "            call = msg.tool_calls[0]\n",
        "            name = call.function.name\n",
        "            try:\n",
        "                args = json.loads(call.function.arguments or \"{}\")\n",
        "            except json.JSONDecodeError:\n",
        "                args = {}\n",
        "            return {\"tool\": name, \"args\": args}\n",
        "        # Fallback if no tool was called; gently kick off with list_txt_files\n",
        "        return {\"tool\": \"list_txt_files\", \"args\": {}}\n",
        "\n",
        "    return _generate_response\n",
        "\n",
        "# ---------------- Build environment & tools -------------\n",
        "env = ResearchEnvironment()\n",
        "\n",
        "# Summarizer uses your OpenAI client under the hood\n",
        "\n",
        "def openai_chat_fn(messages):\n",
        "    resp = client.chat.completions.create(model=MODEL, messages=messages)\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "summarizer = make_summarizer(openai_chat_fn)\n",
        "registry = build_research_actions(env, summarizer)\n",
        "\n",
        "# ---------------- Goals --------------------------------\n",
        "file_summary_goal = Goal(\n",
        "    priority=1,\n",
        "    name=\"file_summary\",\n",
        "    description=(\n",
        "        \"Summarize key points of text documents in /content/files.\\n\"\n",
        "        \"Steps: 1) list files, 2) read each file, 3) summarize to ≤5 bullets, 4) write to /content/summaries.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# ---------------- Orchestrator instance -----------------\n",
        "language = SummarizerLanguage()\n",
        "generate_response = make_generate_response(registry)\n",
        "\n",
        "agent = Agent(\n",
        "    goals=[file_summary_goal],\n",
        "    agent_language=language,\n",
        "    action_registry=registry,\n",
        "    generate_response=generate_response,\n",
        "    environment=env,\n",
        ")\n",
        "\n",
        "\n",
        "# STEP 1 — Base Orchestrator (GAME skeleton)\n",
        "# Run this cell first. It defines the core classes we'll reuse.\n",
        "from typing import List, Dict, Any, Optional, Callable\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# ---- G: Goals --------------------------------------------------------------\n",
        "@dataclass(frozen=True)\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "# ---- A: Actions + Registry -------------------------------------------------\n",
        "class Action:\n",
        "    def __init__(self, name: str, fn: Callable, description: str, parameters: Dict, terminal: bool=False):\n",
        "        self.name, self.fn = name, fn\n",
        "        self.description, self.parameters = description, parameters\n",
        "        self.terminal = terminal\n",
        "    def execute(self, **kwargs):\n",
        "        return self.fn(**kwargs)\n",
        "\n",
        "class ActionRegistry:\n",
        "    def __init__(self):\n",
        "        self._actions: Dict[str, Action] = {}\n",
        "    def register(self, action: Action):\n",
        "        if action.name in self._actions:\n",
        "            raise ValueError(f\"Action already registered: {action.name}\")\n",
        "        self._actions[action.name] = action\n",
        "    def get_action(self, name: str) -> Optional[Action]:\n",
        "        return self._actions.get(name)\n",
        "    def get_actions(self) -> List[Action]:\n",
        "        return list(self._actions.values())\n",
        "    def validate_args(self, action: Action, args: Dict[str, Any]) -> (bool, str):\n",
        "        schema = action.parameters or {\"type\":\"object\",\"properties\":{},\"required\":[]}\n",
        "        for key in schema.get(\"required\", []):\n",
        "            if key not in args:\n",
        "                return False, f\"Missing required arg: {key}\"\n",
        "        return True, \"ok\"\n",
        "\n",
        "# ---- M: Memory -------------------------------------------------------------\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.items: List[Dict[str, Any]] = []  # each item: {role, content}\n",
        "    def add_memory(self, m: Dict[str, Any]):\n",
        "        self.items.append(m)\n",
        "    def get_memories(self, limit: Optional[int]=None) -> List[Dict[str, Any]]:\n",
        "        return self.items[-limit:] if limit else self.items\n",
        "\n",
        "# ---- E: Environment --------------------------------------------------------\n",
        "class Environment:\n",
        "    def execute_action(self, action: Action, args: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        try:\n",
        "            result = action.execute(**args)\n",
        "            return {\"tool_executed\": True, \"result\": result}\n",
        "        except Exception as e:\n",
        "            return {\"tool_executed\": False, \"error\": str(e)}\n",
        "\n",
        "\n",
        "\n",
        "# ---- AgentLanguage (prompt builder + parser) ------------------------------\n",
        "class AgentLanguage:\n",
        "    def construct_prompt(self, actions: List[Action], environment: Environment, goals: List[Goal], memory: Memory) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"goals\": [g.description for g in sorted(goals, key=lambda g: g.priority)],\n",
        "            \"tools\": [a.name for a in actions],\n",
        "            \"memory\": memory.get_memories(6),\n",
        "        }\n",
        "    def parse_response(self, response: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        # Expect a structured dict: {\"tool\": name, \"args\": {...}}\n",
        "        return response\n",
        "\n",
        "# ---- Orchestrator (Agent) -------------------------------------------------\n",
        "class Agent:\n",
        "    def __init__(self, goals, agent_language, action_registry, generate_response, environment):\n",
        "        self.goals = goals\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.generate_response = generate_response  # Callable[prompt_dict] -> {tool,args}\n",
        "        self.environment = environment\n",
        "\n",
        "    def construct_prompt(self, goals, memory, actions):\n",
        "        return self.agent_language.construct_prompt(actions=actions.get_actions(),\n",
        "                                                    environment=self.environment,\n",
        "                                                    goals=goals,\n",
        "                                                    memory=memory)\n",
        "\n",
        "    def prompt_llm_for_action(self, full_prompt):\n",
        "        return self.generate_response(full_prompt)\n",
        "\n",
        "    def get_action(self, response):\n",
        "        invocation = self.agent_language.parse_response(response)\n",
        "        action = self.actions.get_action(invocation.get(\"tool\"))\n",
        "        return action, invocation\n",
        "\n",
        "    def should_terminate(self, response):\n",
        "        action_def, _ = self.get_action(response)\n",
        "        return bool(action_def and action_def.terminal)\n",
        "\n",
        "    def run(self, user_input: str, memory: Optional[Memory]=None, max_iterations: int=3, verbose: bool=True) -> Memory:\n",
        "        memory = memory or Memory()\n",
        "        memory.add_memory({\"role\": \"user\", \"content\": user_input})\n",
        "        for _ in range(max_iterations):\n",
        "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "            if verbose:\n",
        "                print(\"Prompt →\", prompt)\n",
        "            response = self.prompt_llm_for_action(prompt)\n",
        "            if verbose:\n",
        "                print(\"Decision ←\", response)\n",
        "            action, invocation = self.get_action(response)\n",
        "            if not action:\n",
        "                err = {\"tool_executed\": False, \"error\": f\"Unknown action: {invocation.get('tool')}\"}\n",
        "                memory.add_memory({\"role\": \"tool\", \"content\": err})\n",
        "                break\n",
        "            ok, msg = self.actions.validate_args(action, invocation.get(\"args\", {}))\n",
        "            if not ok:\n",
        "                err = {\"tool_executed\": False, \"error\": f\"Invalid args: {msg}\"}\n",
        "                memory.add_memory({\"role\": \"tool\", \"content\": err})\n",
        "                continue\n",
        "            result = self.environment.execute_action(action, invocation.get(\"args\", {}))\n",
        "            if verbose:\n",
        "                print(\"Result ←\", result)\n",
        "            memory.add_memory({\"role\": \"tool\", \"content\": result})\n",
        "            if not result.get(\"tool_executed\", False):\n",
        "                memory.add_memory({\"role\": \"assistant\", \"content\": \"Got an error; choosing another action next.\"})\n",
        "                continue\n",
        "            if self.should_terminate(response):\n",
        "                if verbose:\n",
        "                    print(\"Terminate signal: stopping loop.\")\n",
        "                break\n",
        "        return memory\n",
        "\n",
        "# ---- Smoke test (no OpenAI, no files) -------------------------------------\n",
        "# Define a tiny tool and a mock \"LLM\" that always selects it\n",
        "\n",
        "def hello_tool(name: str = \"world\"):\n",
        "    return f\"hello, {name}!\"\n",
        "\n",
        "reg = ActionRegistry()\n",
        "reg.register(Action(\n",
        "    name=\"hello_tool\",\n",
        "    fn=hello_tool,\n",
        "    description=\"Say hello\",\n",
        "    parameters={\"type\":\"object\",\"properties\":{\"name\":{\"type\":\"string\"}},\"required\":[]}\n",
        "))\n",
        "\n",
        "lang = AgentLanguage()\n",
        "\n",
        "def mock_generate_response(prompt_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    # Always choose hello_tool with no args\n",
        "    return {\"tool\": \"hello_tool\", \"args\": {}}\n",
        "\n",
        "env = Environment()\n",
        "goals = [Goal(1, \"demo\", \"Run a single tool to confirm wiring works.\")]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    agent = Agent(goals, lang, reg, mock_generate_response, env)\n",
        "    _ = agent.run(\"Say hi\", verbose=True)"
      ],
      "metadata": {
        "id": "07uoJMgMd04P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Agent Build Blueprint (GAME)\n",
        "\n",
        "Use this checklist **every time** you spin up a new agent. Treat it like a recipe.\n",
        "\n",
        "### 0) Idea → 1-paragraph spec\n",
        "\n",
        "* **What:** “Summarize key points”\n",
        "* **Why:** “Create concise notes to speed up review.”\n",
        "* **Inputs/Outputs:** Inputs: files in `/content/files`. Outputs: `.summary.txt` in `/content/summaries`.\n",
        "* **Success criteria:** At most 5 bullets per file, factual, saved to disk.\n",
        "\n",
        "### 1) G — Goals (what & how)\n",
        "\n",
        "Write 1–3 concise goals, ordered by priority.\n",
        "\n",
        "```python\n",
        "file_summary_goal = Goal(\n",
        "    priority=1,\n",
        "    name=\"file_summary\",\n",
        "    description=(\n",
        "        \"Summarize key points of text documents in /content/files.\\n\"\n",
        "        \"Steps: 1) list files  2) read each  3) summarize ≤5 bullets  4) save to /content/summaries.\"\n",
        "    ),\n",
        ")\n",
        "```\n",
        "\n",
        "### 2) E — Environment (the body)\n",
        "\n",
        "Encapsulate domain actions with **safe paths** and **uniform envelopes**. Keep side effects minimal and explicit.\n",
        "\n",
        "* `list_txt_files()` → list source docs\n",
        "* `read_txt_file(file_name)` → return `{file_name, content, truncated}`\n",
        "* `write_summary_file(source_file, content)` → return output path\n",
        "\n",
        "(You already have this; keep path safety and truncation guard.)\n",
        "\n",
        "### 3) A — Actions (tools) + Registry\n",
        "\n",
        "Register each environment method as an `Action` with JSON-Schema-like `parameters`. Keep tools **specific**.\n",
        "\n",
        "```python\n",
        "registry.register(Action(\n",
        "    name=\"read_txt_file\",\n",
        "    fn=lambda file_name: env.read_txt_file(file_name),\n",
        "    description=\"Read a text file from /content/files\",\n",
        "    parameters={\"type\":\"object\",\"properties\":{\"file_name\":{\"type\":\"string\"}},\"required\":[\"file_name\"]},\n",
        "))\n",
        "```\n",
        "\n",
        "Also register:\n",
        "\n",
        "* `list_txt_files` (no args)\n",
        "* `summarize_text` (DI-backed; see next step)\n",
        "* `write_summary_file` (source\\_file, content)\n",
        "* *(Optional)* `terminate` with `terminal=True`\n",
        "\n",
        "### 4) Inject dependencies (LLM) cleanly\n",
        "\n",
        "Use **dependency injection** so your action isn’t married to one model/provider.\n",
        "\n",
        "```python\n",
        "def make_summarizer(openai_chat_fn):\n",
        "    def summarize_text(text, max_points=5, style=\"bullet\"):\n",
        "        messages=[{\"role\":\"system\",\"content\":\"Precise technical summarizer.\"},\n",
        "                  {\"role\":\"user\",\"content\": f\"Summarize into ≤{max_points} key points, {style}.\\n\\n{text}\"}]\n",
        "        return openai_chat_fn(messages)\n",
        "    return summarize_text\n",
        "```\n",
        "\n",
        "### 5) M — Memory (what happened)\n",
        "\n",
        "Start simple: list of `{role, content}`. Keep the window tight (e.g., last 6–8 messages). Consider upgrade paths (summaries/chunk recall) later, but don’t complicate the MVP.\n",
        "\n",
        "### 6) AgentLanguage (prompt builder & response parsing)\n",
        "\n",
        "* **Construct prompt**: deterministic text; sort goals/actions; cap memory window.\n",
        "* **Parse response**: if you use **function calling**, parsing happens in `generate_response`; otherwise parse the model’s JSON/text here.\n",
        "\n",
        "### 7) Function calling driver\n",
        "\n",
        "Export registry to the API’s `tools` format and implement a `generate_response(prompt) -> {\"tool\": name, \"args\": {...}}`.\n",
        "\n",
        "* Use a **narrow system message** (“pick exactly one tool per step”).\n",
        "* If the model doesn’t call a tool, **default** to a safe starting tool (e.g., `list_txt_files`).\n",
        "\n",
        "### 8) Orchestrator (the glue)\n",
        "\n",
        "Keep the loop small and boring:\n",
        "\n",
        "1. Build prompt (G + A + M + E)\n",
        "2. Get decision (`generate_response`)\n",
        "3. Validate args; execute via Environment\n",
        "4. Write results/errors back to **memory**\n",
        "5. Respect `terminal=True` or `max_iterations`\n",
        "\n",
        "### 9) Observability (optional but helpful)\n",
        "\n",
        "Add simple hooks/prints: `Prompt →`, `Decision ←`, `Result ←`. Later, you can redirect to logs.\n",
        "\n",
        "### 10) Safety & guardrails\n",
        "\n",
        "* File size limits & truncation flags\n",
        "* JSON schema validation before execution\n",
        "* Timeouts or retry limits if you add network tools\n",
        "* Principle of least privilege (the env only exposes what’s needed)\n",
        "\n",
        "---\n",
        "\n",
        "## Skeleton you can copy between projects\n",
        "\n",
        "```python\n",
        "# 0) Spec: one paragraph (keep near the top of your notebook)\n",
        "\n",
        "# 1) Goals\n",
        "goals = [Goal(1, \"task_name\", \"Short, stepwise description…\")]\n",
        "\n",
        "# 2) Environment\n",
        "class MyEnv(Environment):\n",
        "    # domain-specific methods: list_*, read_*, write_*\n",
        "\n",
        "env = MyEnv()\n",
        "\n",
        "# 3) Actions & Registry\n",
        "registry = ActionRegistry()\n",
        "# registry.register(Action(...))  # repeat per tool\n",
        "\n",
        "# 4) DI-backed helpers (e.g., make_summarizer)\n",
        "# summarizer = make_summarizer(openai_chat_fn)\n",
        "\n",
        "# 5) Memory (from skeleton)\n",
        "memory = Memory()\n",
        "\n",
        "# 6) AgentLanguage\n",
        "class MyLanguage(AgentLanguage):\n",
        "    def construct_prompt(self, actions, environment, goals, memory):\n",
        "        # deterministic text + small memory window\n",
        "        return {\"goals_text\": \"...\", \"memory\": memory.get_memories(8), \"actions\": actions}\n",
        "\n",
        "language = MyLanguage()\n",
        "\n",
        "# 7) generate_response (function calling)\n",
        "generate_response = make_generate_response(registry)  # your FC driver\n",
        "\n",
        "# 8) Orchestrator\n",
        "agent = Agent(goals, language, registry, generate_response, env)\n",
        "_ = agent.run(\"Natural language task request here\", max_iterations=8, verbose=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Why this works well\n",
        "\n",
        "* **Separation of concerns (GAME):** brain/body split keeps cognitive load low (for you and the model).\n",
        "* **Stable interfaces:** you can swap any component without rewriting the loop.\n",
        "* **Schema-first tools:** fewer tool-call mistakes, easier recovery.\n",
        "* **DI:** easy to test offline; easy to switch models/providers.\n",
        "\n"
      ],
      "metadata": {
        "id": "DmkpaDt0Wlb4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s treat this like a **repeatable kitchen recipe** we’ll refine over 3–5 agents. Here’s a tight, reusable **Agent Recipe v1.0** plus a test plan you can run each time.\n",
        "\n",
        "# Agent Recipe v1.0 (GAME)\n",
        "\n",
        "## 0) One-paragraph spec (write first)\n",
        "\n",
        "* **What** (task), **Why** (value), **Inputs/Outputs**, **Done when** (acceptance).\n",
        "* Example: “Summarize key points from `.txt` files in `/content/files`; write `.summary.txt` to `/content/summaries`; ≤5 bullets, factual.”\n",
        "\n",
        "## 1) Goals (G)\n",
        "\n",
        "* 1–3 goals, prioritized, stepwise.\n",
        "\n",
        "```python\n",
        "goals = [Goal(1, \"file_summary\", \"1) list files 2) read 3) summarize ≤5 bullets 4) save\")]\n",
        "```\n",
        "\n",
        "## 2) Environment (E)\n",
        "\n",
        "* Domain verbs only (list/read/write/etc), **no business logic**.\n",
        "* Safety: path whitelist, size guard, deterministic outputs.\n",
        "* Uniform envelope returned by base `Environment.execute_action`.\n",
        "\n",
        "## 3) Actions (A) + Registry\n",
        "\n",
        "* One `Action` per Env verb (plus LLM helpers), **specific names**, JSON-schema params.\n",
        "* Optional `terminate` action (`terminal=True`).\n",
        "\n",
        "## 4) Dependency Injection (LLM helpers)\n",
        "\n",
        "* Wrap model calls (e.g., `make_summarizer(chat_fn)`), never hardcode clients.\n",
        "\n",
        "## 5) Memory (M)\n",
        "\n",
        "* `{role, content}` items; small window (6–8). Keep it dumb at first.\n",
        "\n",
        "## 6) AgentLanguage\n",
        "\n",
        "* Deterministic prompt constructor; sort goals/actions; cap memory.\n",
        "* If using function calling, parsing lives in `generate_response`.\n",
        "\n",
        "## 7) Function-Calling Driver\n",
        "\n",
        "* Export registry → `tools`.\n",
        "* `generate_response(prompt) -> {\"tool\": name, \"args\": {...}}`.\n",
        "* Safe default if no tool called (e.g., `list_*`).\n",
        "\n",
        "## 8) Orchestrator\n",
        "\n",
        "* Loop: prompt → decision → validate → execute → write result to memory → (terminate?).\n",
        "* Guardrails: `max_iterations`, schema validation, error envelopes.\n",
        "\n",
        "---\n",
        "\n",
        "# Test Plan v1.0 (run every agent)\n",
        "\n",
        "## A) Unit-ish checks (fast)\n",
        "\n",
        "* **Env**: `list_*` returns list; `read_*` returns `{content, truncated}`; writes land in expected folder.\n",
        "* **Registry**: missing required arg → validation error.\n",
        "* **LLM helper**: with a **fake chat\\_fn**, returns plausible summary (string).\n",
        "\n",
        "## B) Integration smoke\n",
        "\n",
        "* **Mock driver**: hardcode `{\"tool\": \"list_*\"}` once; ensure result envelope looks right.\n",
        "* **Function calling**: real model picks tools in expected order on a tiny dataset.\n",
        "\n",
        "## C) Acceptance (spec → done)\n",
        "\n",
        "* Produce outputs matching “Done when.” Fail if any file skipped or bullets > limit.\n",
        "\n",
        "---\n",
        "\n",
        "# Iteration Loop (how we improve the recipe)\n",
        "\n",
        "1. **Log**: Keep `Prompt →`, `Decision ←`, `Result ←` prints. Save last N messages.\n",
        "2. **Find pain**: Where did it stumble? (wrong tool? arg mistake? long file?)\n",
        "3. **Fix**:\n",
        "\n",
        "   * Tool too generic? split it.\n",
        "   * Error ambiguous? add `hint` in envelope.\n",
        "   * Prompt noisy? trim or sort more deterministically.\n",
        "   * Files too big? add `read_chunk` action.\n",
        "4. **Re-run acceptance** on the same dataset.\n",
        "5. **Update the recipe** (checklist + code stub) so the fix is reusable.\n",
        "\n",
        "---\n",
        "\n",
        "# Experiment Set (3–5 agents to validate the recipe)\n",
        "\n",
        "1. **Research Summarizer** (current): local `.txt` → summaries.\n",
        "2. **Task Planner**: goal → tasks CRUD (add/list/complete/remove).\n",
        "3. **CSV Explorer**: list/read csv → summarize columns → write simple report.\n",
        "4. **Code Snippet Finder**: list/read `.py` → search patterns → explain.\n",
        "5. **KB Q\\&A**: search markdown → answer with citations.\n",
        "\n",
        "Each uses the same **recipe**; only the **Environment + Actions** change.\n",
        "\n",
        "---\n",
        "\n",
        "# Portable Notebook Scaffold (sections)\n",
        "\n",
        "1. Spec\n",
        "2. STEP 1: GAME skeleton (import once per session)\n",
        "3. STEP 2: Environment (domain)\n",
        "4. STEP 3: Actions + Registry (+ optional terminate)\n",
        "5. STEP 4: DI helpers (LLM wrappers)\n",
        "6. STEP 5: AgentLanguage\n",
        "7. STEP 6: Function-calling driver\n",
        "8. STEP 7: Final wiring + run\n",
        "9. Tests: unit-ish, integration, acceptance\n",
        "10. Notes: issues found → recipe updates\n",
        "\n"
      ],
      "metadata": {
        "id": "SQ2F98Z9bg9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Agent Idea**\n",
        "\n",
        "##A file-summarizing assistant that:\n",
        "\n",
        "* Reads `.txt` (and optionally `.md`, `.docx`, or `.pdf` in later iterations) from a given folder.\n",
        "* Produces clear, concise bullet-point summaries.\n",
        "* Saves the summaries into an output folder.\n",
        "* Works in an iterative “plan → act → check” loop, calling the right tools in sequence without manual intervention.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Features**\n",
        "\n",
        "1. **File Management**\n",
        "\n",
        "   * List available text files in the input directory.\n",
        "   * Read file contents safely (with truncation for very large files).\n",
        "   * Write summaries to a separate output directory with sanitized filenames.\n",
        "\n",
        "2. **Summarization**\n",
        "\n",
        "   * Use an LLM to convert file content into ≤5 concise bullet points.\n",
        "   * Ensure summaries retain key facts and avoid fluff.\n",
        "\n",
        "3. **Action Orchestration**\n",
        "\n",
        "   * Automatically choose next steps (list → read → summarize → write) without hard-coding the order.\n",
        "   * Allow retrying or skipping files if an error occurs.\n",
        "\n",
        "4. **Memory & Context**\n",
        "\n",
        "   * Keep a rolling memory of the last N steps so the agent can track progress and avoid repeating work.\n",
        "   * Optionally include truncated file contents in memory for multi-step summarization.\n",
        "\n",
        "5. **Extensibility**\n",
        "\n",
        "   * Easy to add new actions (e.g., translate summary, create PDF version).\n",
        "   * Portable “plug-and-play” environment so the same code can be used for other agent ideas.\n",
        "\n",
        "6. **Safety & Robustness**\n",
        "\n",
        "   * Path sanitization to prevent unsafe file access.\n",
        "   * Graceful handling of missing files or bad inputs.\n",
        "   * JSON-schema-like argument validation before tool execution.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k46vggX2cdOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Who Does What — Brain vs Body**\n",
        "\n",
        "### **1) File Management — Body**\n",
        "\n",
        "* **List files** → **Body**\n",
        "  Python: `list_txt_files()` → `[\"a.txt\", \"b.txt\", ...]`.\n",
        "* **Read file contents (with truncation)** → **Body**\n",
        "  Python: `read_txt_file(file_name)` → `{file_name, content, truncated: bool}`.\n",
        "* **Write sanitized summaries to output** → **Body**\n",
        "  Python: `write_summary_file(source_file, content)` → `\"/content/summaries/a.summary.txt\"`.\n",
        "\n",
        "---\n",
        "\n",
        "### **2) Summarization — Brain**\n",
        "\n",
        "* **Convert content to ≤5 bullet points** → **Brain**\n",
        "  LLM: `summarize_text(text, max_points=5, style=\"bullet\")` (via dependency injection).\n",
        "* **Maintain tone/quality (“concise, factual, no fluff”)** → **Brain**\n",
        "  System prompt ensures style compliance.\n",
        "\n",
        "---\n",
        "\n",
        "### **3) Action Orchestration — Brain + Body**\n",
        "\n",
        "* **Choose next tool (list → read → summarize → write)** → **Brain**\n",
        "  LLM planning via function calling.\n",
        "* **Validate args & execute tool** → **Body**\n",
        "  Python: schema checks + `Environment.execute_action(...)`.\n",
        "* **Handle failures (retry/skip)** → **Both**\n",
        "  **Body**: returns structured error.\n",
        "  **Brain**: decides next action.\n",
        "\n",
        "---\n",
        "\n",
        "### **4) Memory & Context — Brain + Body**\n",
        "\n",
        "* **Store outcomes & last N steps** → **Body**\n",
        "  Python: `Memory.add_memory({role, content})`.\n",
        "* **Use memory to plan and avoid repeats** → **Brain**\n",
        "  LLM: reads memory in prompt.\n",
        "\n",
        "---\n",
        "\n",
        "### **5) Extensibility — Brain + Body**\n",
        "\n",
        "* **Add new tools (translate, export PDF)** → **Body**\n",
        "  Python: implement env functions + register in action registry.\n",
        "* **Decide when to use new tools** → **Brain**\n",
        "  LLM: selects via function calling.\n",
        "\n",
        "---\n",
        "\n",
        "### **6) Safety & Robustness — Brain + Body**\n",
        "\n",
        "* **Path sanitization, size limits, arg validation, error envelopes** → **Body**\n",
        "  Deterministic Python guardrails.\n",
        "* **Interpret errors & re-plan** → **Brain**\n",
        "  LLM recovery logic.\n",
        "\n"
      ],
      "metadata": {
        "id": "hiADkDJCg5j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Brain vs Body** table\n",
        "\n",
        "| **Function**             | **Task**                         | **Who**   | **Notes**                                       |\n",
        "| ------------------------ | -------------------------------- | --------- | ----------------------------------------------- |\n",
        "| **File Management**      | List files                       | **Body**  | `list_txt_files()` returns list of file names   |\n",
        "|                          | Read file contents               | **Body**  | `read_txt_file(file_name)` with truncation flag |\n",
        "|                          | Write summaries                  | **Body**  | Sanitized filenames → output folder             |\n",
        "| **Summarization**        | Summarize to ≤5 bullets          | **Brain** | LLM, concise/factual tone                       |\n",
        "|                          | Maintain style guardrails        | **Brain** | Via system prompt                               |\n",
        "| **Action Orchestration** | Choose next tool                 | **Brain** | LLM planning via function calling               |\n",
        "|                          | Validate args & execute tool     | **Body**  | Schema checks + `Environment.execute_action`    |\n",
        "|                          | Handle failures                  | **Both**  | Body returns error, Brain decides retry/skip    |\n",
        "| **Memory & Context**     | Store last N steps               | **Body**  | `Memory.add_memory()`                           |\n",
        "|                          | Use memory for planning          | **Brain** | Reads memory in prompt                          |\n",
        "| **Extensibility**        | Add new tools                    | **Body**  | New Python functions + registry entries         |\n",
        "|                          | Decide when to use tools         | **Brain** | LLM picks tools                                 |\n",
        "| **Safety & Robustness**  | Path/size checks, arg validation | **Body**  | Guardrails in Python                            |\n",
        "|                          | Interpret errors & re-plan       | **Brain** | LLM adjusts plan                                |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mRjuTbwvhE8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Recipe v1.1\n",
        "# 1) Idea\n",
        "\n",
        "**Idea:**\n",
        "Create an assistant that reads plain-text documents in a folder, writes short, factual bullet-point summaries for each file, and saves those summaries in a separate folder. It should work step-by-step on its own, choosing the right action at each step, and handle errors gracefully.\n",
        "\n",
        "---\n",
        "\n",
        "# 2) Architecture Map (Brain vs Body)\n",
        "\n",
        "| Function Area   | Task                     | Who       | What it does (plain English)                                                        |\n",
        "| --------------- | ------------------------ | --------- | ----------------------------------------------------------------------------------- |\n",
        "| File management | List files               | **Boyd (Python)**  | Get the list of text files we can work on.                                          |\n",
        "|                 | Read file                | **Boyd (Python)**  | Open a file safely and return its text (with a truncation flag if it’s huge).       |\n",
        "|                 | Write summary            | **Boyd (Python)**  | Save a summary to the summaries folder with a safe filename.                        |\n",
        "| Summarization   | Make a summary           | **Brain (LLM)** | Turn raw text into ≤5 clear, factual bullet points.                                 |\n",
        "| Action planning | Choose next step         | **Brain (LLM)** | Decide which tool to call next (list → read → summarize → write).                   |\n",
        "|                 | Execute the tool safely  | **Boyd (Python)**  | Validate inputs and run the tool; return a structured result or a structured error. |\n",
        "| Errors          | Handle failures          | **Both**  | Boyd (Python) reports a clear error; Brain decides the next recovery step.                   |\n",
        "| Memory          | Store progress           | **Boyd (Python)**  | Keep a small rolling log of decisions and results.                                  |\n",
        "|                 | Use memory               | **Brain (LLM)** | Read recent steps to avoid repeating work and to plan the next step.                |\n",
        "| Extensibility   | Add new tools            | **Boyd (Python)**  | Implement new functions (e.g., translate, export PDF) and register them.            |\n",
        "|                 | Choose new tools         | **Brain (LLM)** | Decide when to use new tools.                                                       |\n",
        "| Safety          | Guardrails               | **Boyd (Python)**  | Path safety, size limits, argument checks, consistent result format.                |\n",
        "|                 | Adjust plan after errors | **Brain (LLM)** | Interpret errors and pick a better next step.                                       |\n",
        "\n",
        "---\n",
        "\n",
        "# 3) Tool Inventory (who + what + short description)\n",
        "\n",
        "1. **list\\_txt\\_files** — **Body**\n",
        "   Return all `.txt` file names in the input folder.\n",
        "\n",
        "2. **read\\_txt\\_file(file\\_name)** — **Body**\n",
        "   Read a specific text file. If it’s very large, return a truncated version and mark it as truncated.\n",
        "\n",
        "3. **summarize\\_text(text, max\\_points=5, style=\"bullet\")** — **Brain**\n",
        "   Produce a short, factual summary of the text. Default to ≤5 bullet points.\n",
        "\n",
        "4. **write\\_summary\\_file(source\\_file, content)** — **Body**\n",
        "   Save the summary to an output folder with a sanitized filename.\n",
        "\n",
        "5. *(Optional)* **terminate(message?)** — **Body**\n",
        "   Signal that the work is completed and the loop can stop.\n",
        "\n",
        "> We’ll review this list before coding to make sure nothing is missing.\n",
        "\n",
        "# 3.5) ActionContext  \n",
        "\n",
        "**What it is:** A tiny object passed around during execution that carries shared dependencies and state the actions might need.\n",
        "\n",
        "**Why:** Keeps function signatures clean and prevents hard-coding globals. Makes tests easier.\n",
        "\n",
        "**Includes (suggested):**\n",
        "\n",
        "* `env` (Environment instance)\n",
        "* `registry` (ActionRegistry)\n",
        "* `memory` (Memory)\n",
        "* `llm` deps (e.g., `openai_chat_fn`, other helper callables)\n",
        "* optional `config` (limits, paths, flags)\n",
        "\n",
        "**Acceptance (quick check):**\n",
        "\n",
        "* Adding a new dependency does **not** require changing action function signatures.\n",
        "* Unit tests can swap in fakes by replacing fields on `ActionContext`.\n",
        "---\n",
        "\n",
        "# 4) Tool Schemas (stacked for easy reading)\n",
        "\n",
        "**read\\_txt\\_file**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"file_name\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": [\"file_name\"]\n",
        "}\n",
        "```\n",
        "\n",
        "**summarize\\_text**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"text\": { \"type\": \"string\" },\n",
        "    \"max_points\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 12 },\n",
        "    \"style\": { \"type\": \"string\", \"enum\": [\"bullet\", \"paragraph\"] }\n",
        "  },\n",
        "  \"required\": [\"text\"]\n",
        "}\n",
        "```\n",
        "\n",
        "**write\\_summary\\_file**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"source_file\": { \"type\": \"string\" },\n",
        "    \"content\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": [\"source_file\", \"content\"]\n",
        "}\n",
        "```\n",
        "\n",
        "**terminate** *(optional)*\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"message\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": []\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 5) Memory Policy (What we remember)\n",
        "\n",
        "**Decide:** What we store and how much of it we show the model.\n",
        "\n",
        "**Write it down (plain English):**\n",
        "\n",
        "* Each memory item looks like: `{role: \"user\" | \"assistant\" | \"tool\", content: <text or small dict>}`.\n",
        "* Keep only the **last 8** items when talking to the model (small window = less noise).\n",
        "* Always log the tool’s result (success or error) and the agent’s decision.\n",
        "\n",
        "**Quick check:** If the model saw only the last 8 items, could it keep going without confusion?\n",
        "\n",
        "---\n",
        "\n",
        "# 6) Goals (What we’re doing and how we’ll do it)\n",
        "\n",
        "**Decide:** One or two short goals in order of importance.\n",
        "\n",
        "**Write it down (example):**\n",
        "\n",
        "```\n",
        "Goal(priority=1, name=\"file_summary\",\n",
        "     description=\"1) list files  2) read each  3) summarize to ≤5 bullets  4) save the summary\")\n",
        "```\n",
        "\n",
        "**Quick check:** Does this still make sense in a blank notebook with no other context?\n",
        "\n",
        "---\n",
        "\n",
        "# 7) Message Plan (what we tell the model)\n",
        "\n",
        "**Decide:** The exact messages we’ll send: system rules, a simple user nudge, recent memory, and the available tools.\n",
        "\n",
        "**Write it down (outline):**\n",
        "\n",
        "* **System message:**\n",
        "  “You are a precise, factual summarizer. Choose exactly one tool per step. After saving all summaries, end the session.”\n",
        "* **User message:**\n",
        "  “Pick the best next tool to make progress. Return a function call, not prose.”\n",
        "* **Memory:**\n",
        "  Include the last 8 items, converting any dicts to short strings.\n",
        "* **Tools:**\n",
        "  Provide tool names, plain-English descriptions, and parameter schemas.\n",
        "\n",
        "**Quick check:** If we run this twice, the messages should be similar and predictable.\n",
        "\n",
        "---\n",
        "\n",
        "# 8) Decision Maker (how we pick the next tool)\n",
        "\n",
        "**Decide:** How we turn our messages into a “do this next” instruction.\n",
        "\n",
        "**Write it down (rules):**\n",
        "\n",
        "* The model should return **exactly one** tool to call each step, with arguments.\n",
        "  Example result: `{\"tool\": \"read_txt_file\", \"args\": {\"file_name\": \"a.txt\"}}`\n",
        "* If the model doesn’t pick a tool, we **default** to:\n",
        "  `{\"tool\": \"list_txt_files\", \"args\": {}}`\n",
        "* Keep creativity low (we want steady choices, not flair).\n",
        "\n",
        "**Quick check:** From a cold start (empty memory), do we still move forward?\n",
        "\n",
        "---\n",
        "# 9) Orchestrator (Capabilities)\n",
        "\n",
        "**What they are:** Small, optional modules that hook into the loop at defined points (before decision, after execution, on error, on terminate).\n",
        "\n",
        "**Examples:**\n",
        "\n",
        "* `PlanFirstCapability` — nudges the model to plan or pre-select a safe first tool (e.g., `list_txt_files`).\n",
        "* `ProgressTrackingCapability` — updates memory with which files are done/remaining.\n",
        "* `RetryBackoffCapability` — suggests pauses/retries after repeated failures.\n",
        "\n",
        "**Why:** Extend behavior without rewriting the loop.\n",
        "\n",
        "**Hooks (suggested):**\n",
        "\n",
        "* `on_before_decision(context)`\n",
        "* `on_after_decision(context, decision)`\n",
        "* `on_after_execution(context, result)`\n",
        "* `on_error(context, error)`\n",
        "* `on_terminate(context)`\n",
        "\n",
        "**Acceptance:**\n",
        "\n",
        "* You can enable/disable a capability without changing the orchestrator code.\n",
        "* Capabilities don’t alter tool contracts; they only observe/annotate or add hints.\n",
        "\n",
        "# 9) PlanFirstCapability  \n",
        "\n",
        "**Purpose:** Ensures the first step is safe and deterministic (e.g., list files) to avoid the model guessing filenames.\n",
        "\n",
        "**Behavior:**\n",
        "\n",
        "* If memory is “cold” (no prior tool results), inject a “start with `list_txt_files`” hint or directly return that decision once.\n",
        "\n",
        "**Acceptance:**\n",
        "\n",
        "* From a cold start, the first decision is always `list_txt_files` (unless you configure otherwise).\n",
        "\n",
        "\n",
        "# 9) The Loop (glue that runs everything)\n",
        "\n",
        "**Decide:** The simple steps the agent repeats.\n",
        "\n",
        "**Write it down (6 steps):**\n",
        "\n",
        "1. Build the messages (goals + recent memory + tools + system rules).\n",
        "2. Ask the model to choose the **one next tool**.\n",
        "3. Check the tool’s arguments; if something’s missing, log the error and let the model try again.\n",
        "4. Run the tool safely and capture the result (or error) in a **uniform shape**.\n",
        "5. Add the decision and the result to memory. If there was an error, the model will recover next step.\n",
        "6. Stop if a **stop tool** is called (like `terminate`) or if we hit a maximum number of steps.\n",
        "\n",
        "**Quick check:** No business rules here—this loop should work for many agents.\n",
        "\n",
        "---\n",
        "\n",
        "# 10) What We Log (so we can debug fast)\n",
        "\n",
        "**Decide:** What to print or store on each step so we can see what happened.\n",
        "\n",
        "**Write it down (three prints):**\n",
        "\n",
        "* `Prompt →` the messages or a compact summary of them\n",
        "* `Decision ←` the chosen tool and arguments\n",
        "* `Result ←` the tool’s success or error in the uniform result shape\n",
        "\n",
        "Also keep a short tail of memory (last 6 items) handy for quick inspection.\n",
        "\n",
        "**Quick check:** If something breaks, can you spot *what* and *why* in under a minute?\n",
        "\n",
        "---\n",
        "\n",
        "# 11) Testing Checklist\n",
        "\n",
        "**What to test before integration:**\n",
        "\n",
        "* **Tools:**\n",
        "\n",
        "  * list returns expected files\n",
        "  * read returns `{content, truncated}` and handles missing files with a helpful hint\n",
        "  * summarize returns a non-empty string for sample text\n",
        "  * write creates a file with sanitized name\n",
        "* **Validation:**\n",
        "\n",
        "  * Missing required arg → validation error (no execution)\n",
        "  * Bad types (if enforced) → clear error\n",
        "* **Orchestrator smoke:**\n",
        "\n",
        "  * Mock decision `{\"tool\": \"list_txt_files\"}` runs and logs a valid result envelope\n",
        "* **Function-calling path:**\n",
        "\n",
        "  * Real model picks a tool on a tiny dataset\n",
        "  * Safe default (list) kicks in if no tool call is returned\n",
        "\n",
        "**Acceptance:**\n",
        "\n",
        "* All unit checks pass locally without the full loop.\n",
        "* One integration smoke test completes a single file end-to-end.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 12) One Pass Storyboard (without code)\n",
        "\n",
        "**Walkthrough:**\n",
        "\n",
        "1. **Brain**: “list files” → **Body** returns `[\"a.txt\",\"b.txt\"]`.\n",
        "2. **Brain**: “read a.txt” → **Body** returns `{content, truncated:false}`.\n",
        "3. **Brain**: “summarize” → **Body** (LLM helper) returns ≤5 bullets.\n",
        "4. **Brain**: “write summary for a.txt” → **Body** returns saved path.\n",
        "5. Repeat 2–4 for `b.txt`.\n",
        "6. **Brain**: “terminate” with message “All summaries written.”\n",
        "\n",
        "**Failure example:**\n",
        "If “read a.txt” fails with “file not found” + hint “list files first”, the **Brain** calls “list files” and tries again.\n",
        "\n",
        "**Quick check:** Does every failure have a clear next step?\n",
        "\n",
        "---\n",
        "\n",
        "# 13) Known Risks and Early Choices\n",
        "\n",
        "**Decide now:**\n",
        "\n",
        "* Very large files → add a “read chunk” tool next iteration if needed.\n",
        "* Mixed encodings → always open with `errors=\"replace\"` so we never crash.\n",
        "* Model wandering → keep the system rule strict and memory short.\n",
        "* Tool names drifting → stick to `verb_object_context` (e.g., `write_summary_file`).\n",
        "\n",
        "**Quick check:** Are we okay shipping v1 with these choices?\n",
        "\n",
        "---\n",
        "\n",
        "# 14) Ready-to-Code Checklist (final gate)\n",
        "\n",
        "* [ ] Brain/Body table finalized\n",
        "* [ ] Tool list + their schemas finalized\n",
        "* [ ] Environment rules agreed (paths, truncation, envelope)\n",
        "* [ ] Memory policy set (shape + window)\n",
        "* [ ] Goal text written\n",
        "* [ ] Message plan written (system + user + memory + tools)\n",
        "* [ ] Decision maker rules written (one tool per step, default start)\n",
        "* [ ] Loop unchanged (simple and reusable)\n",
        "* [ ] “Done” checklist ready\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "F6eEr3OhqshC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Agent Build Recipe – Final Structure**\n",
        "\n",
        "1. **Idea** – Plain-English description of what the agent should do, without implementation details.\n",
        "2. **Brain vs Body Table** – Divide responsibilities between LLM (“Brain”) and Python code (“Body”).\n",
        "3. **Tool Inventory** – List every tool, label Brain or Body, and give a short description of what it does.\n",
        "4. **ActionContext** – Central object holding dependencies (memory, auth, services, registry) for tools.\n",
        "5. **Tool Schemas** – JSON schema definitions for tool inputs/outputs, ensuring safety and clarity.\n",
        "6. **Environment Contracts** – Rules for safe execution (path restrictions, truncation, result envelopes).\n",
        "7. **Memory Policy** – What to remember, in what format, and for how long (rolling window).\n",
        "8. **Goals** – Clear, prioritized statements of what the agent should achieve.\n",
        "9. **Message Plan** – How prompts are built from Goals, Actions, Memory, and Environment for the LLM.\n",
        "10. **Function Calling Driver** – Turns prompts into `{tool, args}` with safe defaults.\n",
        "11. **Capabilities Layer** – Optional modular behaviors that enhance the loop (planning, tracking, retries).\n",
        "12. **Orchestrator Loop** – The minimal “glue” logic to run the agent until done.\n",
        "13. **Logging** – Decide what to record at each step for debugging and transparency.\n",
        "14. **Testing & Acceptance Criteria** – Unit/integration tests plus checklist for pass/fail outcomes.\n",
        "15. **Storyboard (Dry-Run)** – One complete, code-free walk-through of a happy path and an error path.\n",
        "16. **Risks & Early Choices** – Known limitations and pre-decisions to avoid surprises later.\n",
        "17. **Ready-to-Code Checklist** – Final preflight check before implementation.\n",
        "\n",
        "Exactly — I’ll take our improved **Agent Build Recipe** and re-write it so it fully integrates the missing parts you called out:\n",
        "\n",
        "* **ActionContext** explicitly between Tool Inventory and Tool Schemas.\n",
        "* **Capabilities Layer** explicitly between Function Calling Driver and Orchestrator Loop.\n",
        "* **Testing & Acceptance** renamed and broadened to include explicit test planning.\n",
        "* **Known Risks & Early Choices** aligned in order with the checklist.\n",
        "\n",
        "Here’s the revised **final master template**:\n",
        "\n",
        "---\n",
        "\n",
        "## **Agent Build Recipe – Master Template**\n",
        "\n",
        "1. **Idea**\n",
        "   Plain-English description of what the agent should do. No technical paths or code — just the “what” and “why.”\n",
        "\n",
        "2. **Brain vs Body Table**\n",
        "   Map responsibilities between **Brain** (LLM) and **Body** (Python code), with explicit labels.\n",
        "\n",
        "3. **Tool Inventory**\n",
        "   List every tool with:\n",
        "\n",
        "   * Name\n",
        "   * Brain or Body\n",
        "   * Short description of what it does.\n",
        "\n",
        "4. **ActionContext**\n",
        "   Central object that holds and injects dependencies into tools (memory, auth keys, services, registries).\n",
        "\n",
        "5. **Tool Schemas**\n",
        "   JSON schema for each tool’s inputs/outputs, stacked clearly for visibility.\n",
        "\n",
        "   ```json\n",
        "   {\n",
        "     \"type\": \"object\",\n",
        "     \"properties\": { \"file_name\": { \"type\": \"string\" } },\n",
        "     \"required\": [\"file_name\"]\n",
        "   }\n",
        "   ```\n",
        "\n",
        "6. **Environment Contracts**\n",
        "   Rules for safe execution: allowed paths, truncation limits, structured success/failure envelopes.\n",
        "\n",
        "7. **Memory Policy**\n",
        "   Define format, size, and what’s always stored (e.g., tool results, decisions).\n",
        "\n",
        "8. **Goals**\n",
        "   Short, prioritized statements of what the agent is trying to achieve.\n",
        "\n",
        "9. **Message Plan**\n",
        "   How prompts are built from Goals, Actions, Memory, and Environment.\n",
        "\n",
        "10. **Function Calling Driver**\n",
        "    How the prompt is converted into `{tool, args}`. Include safe defaults and temperature settings.\n",
        "\n",
        "11. **Capabilities Layer**\n",
        "    Optional plug-in behaviors like:\n",
        "\n",
        "    * **PlanFirstCapability** (always start with planning tool)\n",
        "    * **ProgressTrackingCapability** (monitor % complete)\n",
        "\n",
        "12. **Orchestrator Loop**\n",
        "    Minimal glue logic that runs until a terminal condition is met.\n",
        "\n",
        "13. **Logging**\n",
        "    Decide exactly what to print/store at each step for debugging and transparency.\n",
        "\n",
        "14. **Testing & Acceptance**\n",
        "    Unit and integration test plan + clear pass/fail checklist.\n",
        "\n",
        "15. **Storyboard (Dry-Run)**\n",
        "    One happy-path and one error-path walkthrough, no code.\n",
        "\n",
        "16. **Known Risks & Early Choices**\n",
        "    Limitations and pre-decisions that affect the build.\n",
        "\n",
        "17. **Ready-to-Code Checklist**\n",
        "    Quick preflight before implementation.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8F4kDc282PPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Build Recipe Doc"
      ],
      "metadata": {
        "id": "ZHxAC2ou_jlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Agent Build Recipe – Final Structure as a text file\n",
        "\n",
        "# 1. Idea – Plain-English description of what the agent should do, without implementation details.\n",
        "# 2. Brain vs Body Table – Divide responsibilities between LLM (“Brain”) and Python code (“Body”).\n",
        "# 3. Tool Inventory – List every tool, label Brain or Body, and give a short description of what it does.\n",
        "# 4. ActionContext – Central object holding dependencies (memory, auth, services, registry) for tools.\n",
        "# 5. Tool Schemas – JSON schema definitions for tool inputs/outputs, ensuring safety and clarity.\n",
        "# 6. Environment Contracts – Rules for safe execution (path restrictions, truncation, result envelopes).\n",
        "# 7. Memory Policy – What to remember, in what format, and for how long (rolling window).\n",
        "# 8. Goals – Clear, prioritized statements of what the agent should achieve.\n",
        "# 9. Message Plan – How prompts are built from Goals, Actions, Memory, and Environment for the LLM.\n",
        "# 10. Function Calling Driver – Turns prompts into {tool, args} with safe defaults.\n",
        "# 11. Capabilities Layer – Optional modular behaviors that enhance the loop (planning, tracking, retries).\n",
        "# 12. Orchestrator Loop – The minimal “glue” logic to run the agent until done.\n",
        "# 13. Logging – Decide what to record at each step for debugging and transparency.\n",
        "# 14. Testing & Acceptance Criteria – Unit/integration tests plus checklist for pass/fail outcomes.\n",
        "# 15. Storyboard (Dry-Run) – One complete, code-free walk-through of a happy path and an error path.\n",
        "# 16. Risks & Early Choices – Known limitations and pre-decisions to avoid surprises later.\n",
        "# 17. Ready-to-Code Checklist – Final preflight check before implementation."
      ],
      "metadata": {
        "id": "b-ygQIrKCEMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the Agent Build Recipe – Final Structure (polished) to a text file\n",
        "\n",
        "recipe_text = \"\"\"Agent Build Recipe – Final Structure (polished)\n",
        "\n",
        "1. Idea – Plain-English description of what the agent should do and why (no paths or code here).\n",
        "2. Brain vs Body Table – Divide responsibilities between LLM (“Brain”) and Python (“Body”) with explicit task ownership.\n",
        "3. Tool Inventory – List every tool, mark Brain/Body owner, add a one-line description and any pre/postconditions.\n",
        "4. ActionContext – Central object holding dependencies (memory, env, registry, LLM helpers, config) that tools receive (no globals).\n",
        "5. Tool Schemas – JSON schema for inputs to each tool; outputs must use the standard result envelope (see Environment).\n",
        "6. Environment Contracts – Safe execution rules (path whitelist, size caps, deterministic side-effects) and the result envelope:\n",
        "   Success -> {\"tool_executed\": true, \"result\": ...}\n",
        "   Failure -> {\"tool_executed\": false, \"error\": \"...\", \"hint\": \"...\", \"retryable\": true|false}\n",
        "7. Memory Policy – What to remember and how (e.g., sliding window vs summarized), item shape, and window size (details live in the particulars sheet).\n",
        "8. Goals – Short, prioritized statements (what + how) that are stable across runs.\n",
        "9. Message Plan – Deterministic prompts built from Goals, Actions, Memory, and Environment; keep them minimal and consistent.\n",
        "10. Function Calling Driver – Convert prompts into exactly one {tool, args} per step; define a safe default if none is chosen.\n",
        "11. Capabilities Layer – Optional plug-ins (e.g., plan-first, progress tracking, retry) that hook into the loop without changing tool contracts.\n",
        "12. Orchestrator Loop – Thin glue only: build -> decide -> validate -> execute -> log -> repeat; no business logic here.\n",
        "13. Logging – Print/store a compact Prompt ->, Decision <-, Result <-; redact secrets and keep a short memory tail for debugging.\n",
        "14. Testing & Acceptance Criteria – Unit + integration tests and a pass/fail checklist tied to the Idea and Goals.\n",
        "15. Storyboard (Dry-Run) – One happy path and one error-recovery path described step-by-step, no code.\n",
        "16. Risks & Early Choices – Known failure modes and guardrails (e.g., large files, encoding, naming conventions, drift controls).\n",
        "17. Ready-to-Code Checklist – Final preflight (tools & schemas frozen, env rules agreed, driver defaults set, tests defined).\n",
        "\"\"\"\n",
        "\n",
        "output_path = \"/content/Agent_Build_Recipe_Master.txt\"\n",
        "\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(recipe_text)\n",
        "\n",
        "print(f\"Saved recipe to: {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ArJIhXY_Mtg",
        "outputId": "0a78bd93-123d-4182-e1cb-2e0675bb7674"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved recipe to: /content/Agent_Build_Recipe_Master.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Master Recipe Dress Reheral\n",
        "---\n",
        "\n",
        "# 1) Idea\n",
        "\n",
        "Create an assistant that reads plain-text documents in a folder, produces short, factual bullet-point summaries for each file, and saves those summaries in a separate folder. It should proceed step-by-step on its own, choose the right action each step, and handle errors gracefully.\n",
        "\n",
        "---\n",
        "\n",
        "# 2) Brain vs Body Table\n",
        "\n",
        "| Function Area   | Task                 | Who       | What it does (plain English)                                      |\n",
        "| --------------- | -------------------- | --------- | ----------------------------------------------------------------- |\n",
        "| File management | List files           | **Body (Python) (Python)**  | Get the list of `.txt` files we can work on.                      |\n",
        "|                 | Read file            | **Body (Python)**  | Open a file safely and return its text (mark if truncated).       |\n",
        "|                 | Write summary        | **Body (Python)**  | Save a summary with a sanitized filename.                         |\n",
        "| Summarization   | Make a summary       | **Brain (LLM)** | Turn raw text into ≤5 factual bullet points.                      |\n",
        "| Action planning | Choose next step     | **Brain (LLM)** | Decide which tool to call next (list → read → summarize → write). |\n",
        "|                 | Execute tool safely  | **Body (Python)**  | Validate inputs and run the tool; return a structured result.     |\n",
        "| Errors          | Handle failures      | **Both**  | Body reports a clear error; Brain decides the next recovery step. |\n",
        "| Memory          | Store progress       | **Body (Python)**  | Keep a small rolling log of decisions and results.                |\n",
        "|                 | Use memory           | **Brain (LLM)** | Read recent steps to avoid repeats and plan next.                 |\n",
        "| Extensibility   | Add new tools        | **Body (Python)**  | Implement new functions and register them.                        |\n",
        "|                 | Use new tools        | **Brain (LLM)** | Choose when to call new tools.                                    |\n",
        "| Safety          | Guardrails           | **Body (Python)**  | Path safety, size limits, argument checks, result envelope.       |\n",
        "|                 | Re-plan after errors | **Brain (LLM)** | Interpret errors and pick a better next step.                     |\n",
        "\n",
        "---\n",
        "\n",
        "# 3) Tool Inventory\n",
        "\n",
        "1. **list\\_txt\\_files** — **Body**\n",
        "   Return all `.txt` filenames in the input folder.\n",
        "\n",
        "2. **read\\_txt\\_file(file\\_name)** — **Body**\n",
        "   Read a text file. If very large, truncate and mark `truncated: true`.\n",
        "\n",
        "3. **summarize\\_text(text, max\\_points=5, style=\"bullet\")** — **Brain**\n",
        "   Produce a concise, factual summary of the text (default ≤5 bullets).\n",
        "\n",
        "4. **write\\_summary\\_file(source\\_file, content)** — **Body**\n",
        "   Save the summary to the output folder using a sanitized filename.\n",
        "\n",
        "5. **terminate(message?)** — **Body** *(optional, terminal)*\n",
        "   Signal that all work is complete and end the loop.\n",
        "\n",
        "---\n",
        "\n",
        "# 4) ActionContext\n",
        "\n",
        "A small object passed around that carries shared dependencies so tool functions stay clean.\n",
        "\n",
        "**Fields (for this agent):**\n",
        "\n",
        "* `env` — the environment (file ops)\n",
        "* `registry` — action registry\n",
        "* `memory` — rolling store of recent steps\n",
        "* `llm` — callable(s) for summarization (e.g., `openai_chat_fn`, or a small dict of helpers)\n",
        "* `config` — paths, truncation limit, etc.\n",
        "\n",
        "---\n",
        "\n",
        "# 5) Tool Schemas (stacked)\n",
        "\n",
        "**read\\_txt\\_file**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"file_name\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": [\"file_name\"]\n",
        "}\n",
        "```\n",
        "\n",
        "**summarize\\_text**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"text\": { \"type\": \"string\" },\n",
        "    \"max_points\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 12 },\n",
        "    \"style\": { \"type\": \"string\", \"enum\": [\"bullet\", \"paragraph\"] }\n",
        "  },\n",
        "  \"required\": [\"text\"]\n",
        "}\n",
        "```\n",
        "\n",
        "**write\\_summary\\_file**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"source_file\": { \"type\": \"string\" },\n",
        "    \"content\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": [\"source_file\", \"content\"]\n",
        "}\n",
        "```\n",
        "\n",
        "**terminate (optional)**\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"message\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": []\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 6) Environment Contracts\n",
        "\n",
        "* **Folders**: input folder for sources; output folder for summaries.\n",
        "* **Path safety**: only allow files inside those folders; sanitize filenames.\n",
        "* **Large files**: cap reads at a safe character limit (e.g., 12,000) and set `truncated: true`.\n",
        "* **Result envelope**:\n",
        "\n",
        "  * Success → `{\"tool_executed\": true, \"result\": ...}`\n",
        "  * Failure → `{\"tool_executed\": false, \"error\": \"...\", \"hint\": \"...\", \"retryable\": boolean}`\n",
        "\n",
        "---\n",
        "\n",
        "# 7) Memory Policy\n",
        "\n",
        "* Each item is `{role: \"user\"|\"assistant\"|\"tool\", content: <text or small dict>}`.\n",
        "* Keep only the **last 8** items in the prompt.\n",
        "* Always log: the agent’s decision and the tool result (success or error).\n",
        "\n",
        "---\n",
        "\n",
        "# 8) Goals\n",
        "\n",
        "```\n",
        "Goal(priority=1, name=\"file_summary\",\n",
        "     description=\"1) list files  2) read each  3) summarize to ≤5 bullets  4) save the summary\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# 9) Message Plan (what we tell the model)\n",
        "\n",
        "* **System:** “You are a precise, factual summarizer. Choose exactly one tool per step. After saving all summaries, end the session.”\n",
        "* **User:** “Pick the best next tool to make progress. Return a function call, not prose.”\n",
        "* **Memory:** last 8 items (dicts coerced to short strings if needed).\n",
        "* **Tools:** names, descriptions, and parameter schemas.\n",
        "\n",
        "---\n",
        "\n",
        "# 10) Function Calling Driver (decision interface)\n",
        "\n",
        "* Convert the messages into **one** `{ \"tool\": \"...\", \"args\": {...} }` per step.\n",
        "* If the model doesn’t pick a tool, **default** to `{\"tool\":\"list_txt_files\",\"args\":{}}`.\n",
        "* Keep temperature low for stable choices.\n",
        "\n",
        "---\n",
        "\n",
        "# 11) Capabilities Layer (optional plug-ins)\n",
        "\n",
        "* **PlanFirstCapability** — if memory is “cold”, nudge “start with `list_txt_files`.”\n",
        "* **ProgressTrackingCapability** — track which files are done/remaining in memory.\n",
        "* **RetryBackoffCapability** — suggest retry spacing after repeated failures.\n",
        "\n",
        "*These hook into the loop but don’t change tool contracts.*\n",
        "\n",
        "---\n",
        "\n",
        "# 12) Orchestrator Loop (glue)\n",
        "\n",
        "1. Build messages (Goals + Memory + Tools + System rules).\n",
        "2. Ask model to choose the next tool.\n",
        "3. Validate arguments; on failure → log error + continue.\n",
        "4. Execute tool via the Environment; write result to memory.\n",
        "5. If execution failed → Brain will re-plan next step.\n",
        "6. Stop on a terminal tool or `max_iterations`.\n",
        "\n",
        "---\n",
        "\n",
        "# 13) Logging (what we record each step)\n",
        "\n",
        "* `Prompt →` (compact summary)\n",
        "* `Decision ←` (tool + args)\n",
        "* `Result ←` (success/failure envelope)\n",
        "* Keep a short tail of memory (last \\~6) for quick inspection.\n",
        "\n",
        "---\n",
        "\n",
        "# 14) Testing & Acceptance\n",
        "\n",
        "**Unit checks**\n",
        "\n",
        "* list returns expected files\n",
        "* read returns `{content, truncated}` and handles missing files with a useful `hint`\n",
        "* summarize returns a non-empty string for sample text\n",
        "* write creates a file with sanitized name\n",
        "* validation: missing required arg → clean error (no execution)\n",
        "\n",
        "**Integration smoke**\n",
        "\n",
        "* Mock decision `{\"tool\":\"list_txt_files\"}` runs and logs a valid result.\n",
        "\n",
        "**Function-calling**\n",
        "\n",
        "* Real model picks a tool on a tiny dataset.\n",
        "* Default to `list_txt_files` if no tool call returned.\n",
        "\n",
        "**Acceptance (Go/No-Go)**\n",
        "\n",
        "* [ ] One `.summary.txt` per source file\n",
        "* [ ] Each has **≤5** bullet points, factual tone\n",
        "* [ ] No unhandled errors in memory tail\n",
        "* [ ] Nonexistent file requests yield helpful hints\n",
        "* [ ] Large files set `truncated: true` and the run still completes\n",
        "\n",
        "---\n",
        "\n",
        "# 15) Storyboard (dry-run)\n",
        "\n",
        "1. **Brain**: list files → **Body**: `[\"a.txt\",\"b.txt\"]`\n",
        "2. **Brain**: read `a.txt` → **Body**: `{content, truncated:false}`\n",
        "3. **Brain**: summarize → **Body**: bullets string\n",
        "4. **Brain**: write summary for `a.txt` → **Body**: saved path\n",
        "5. Repeat for `b.txt`\n",
        "6. **Brain**: terminate (“All summaries written.”)\n",
        "\n",
        "**Failure branch**\n",
        "Read fails (“file not found”, hint “list files first”) → **Brain** calls list, recovers.\n",
        "\n",
        "---\n",
        "\n",
        "# 16) Known Risks & Early Choices\n",
        "\n",
        "* Very large files → add a `read_txt_chunk` tool next iteration.\n",
        "* Mixed encodings → always open with `errors=\"replace\"`.\n",
        "* LLM drift → strict system message + short memory + low temperature.\n",
        "* Naming → stick to `verb_object_context` (e.g., `write_summary_file`).\n",
        "\n",
        "---\n",
        "\n",
        "# 17) Ready-to-Code Checklist\n",
        "\n",
        "* [ ] Brain/Body table finalized\n",
        "* [ ] Tool list + schemas finalized\n",
        "* [ ] Environment rules agreed (paths, truncation, envelope)\n",
        "* [ ] Memory policy set (shape + window)\n",
        "* [ ] Goal text written\n",
        "* [ ] Message plan written\n",
        "* [ ] Function-calling defaults set\n",
        "* [ ] Capabilities selected (optional)\n",
        "* [ ] Loop remains minimal and reusable\n",
        "* [ ] Testing & Acceptance checklist ready\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aCslBBd16D4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dress Rehersal Doc"
      ],
      "metadata": {
        "id": "g3zFYhmVC68x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dress_rehearsal = \"\"\"Master Recipe Dress Reheral\n",
        "---\n",
        "\n",
        "1) Idea\n",
        "\n",
        "Create an assistant that reads plain-text documents in a folder, produces short, factual bullet-point summaries for each file, and saves those summaries in a separate folder. It should proceed step-by-step on its own, choose the right action each step, and handle errors gracefully.\n",
        "\n",
        "---\n",
        "\n",
        "2) Brain vs Body Table\n",
        "\n",
        "| Function Area   | Task                 | Who            | What it does (plain English)                                      |\n",
        "| --------------- | -------------------- | -------------- | ----------------------------------------------------------------- |\n",
        "| File management | List files           | Body (Python)  | Get the list of `.txt` files we can work on.                      |\n",
        "|                 | Read file            | Body (Python)  | Open a file safely and return its text (mark if truncated).       |\n",
        "|                 | Write summary        | Body (Python)  | Save a summary with a sanitized filename.                         |\n",
        "| Summarization   | Make a summary       | Brain (LLM)    | Turn raw text into ≤5 factual bullet points.                      |\n",
        "| Action planning | Choose next step     | Brain (LLM)    | Decide which tool to call next (list → read → summarize → write). |\n",
        "|                 | Execute tool safely  | Body (Python)  | Validate inputs and run the tool; return a structured result.     |\n",
        "| Errors          | Handle failures      | Both           | Body reports a clear error; Brain decides the next recovery step. |\n",
        "| Memory          | Store progress       | Body (Python)  | Keep a small rolling log of decisions and results.                |\n",
        "|                 | Use memory           | Brain (LLM)    | Read recent steps to avoid repeats and plan next.                 |\n",
        "| Extensibility   | Add new tools        | Body (Python)  | Implement new functions and register them.                        |\n",
        "|                 | Use new tools        | Brain (LLM)    | Choose when to call new tools.                                    |\n",
        "| Safety          | Guardrails           | Body (Python)  | Path safety, size limits, argument checks, result envelope.       |\n",
        "|                 | Re-plan after errors | Brain (LLM)    | Interpret errors and pick a better next step.                     |\n",
        "\n",
        "---\n",
        "\n",
        "3) Tool Inventory\n",
        "\n",
        "1. list_txt_files — Body\n",
        "   Return all `.txt` filenames in the input folder.\n",
        "\n",
        "2. read_txt_file(file_name) — Body\n",
        "   Read a text file. If very large, truncate and mark `truncated: true`.\n",
        "\n",
        "3. summarize_text(text, max_points=5, style=\"bullet\") — Brain\n",
        "   Produce a concise, factual summary of the text (default ≤5 bullets).\n",
        "\n",
        "4. write_summary_file(source_file, content) — Body\n",
        "   Save the summary to the output folder using a sanitized filename.\n",
        "\n",
        "5. terminate(message?) — Body (optional, terminal)\n",
        "   Signal that all work is complete and end the loop.\n",
        "\n",
        "---\n",
        "\n",
        "4) ActionContext\n",
        "\n",
        "A small object passed around that carries shared dependencies so tool functions stay clean.\n",
        "\n",
        "Fields (for this agent):\n",
        "- env — the environment (file ops)\n",
        "- registry — action registry\n",
        "- memory — rolling store of recent steps\n",
        "- llm — callable(s) for summarization (e.g., openai_chat_fn, or a small dict of helpers)\n",
        "- config — paths, truncation limit, etc.\n",
        "\n",
        "---\n",
        "\n",
        "5) Tool Schemas (stacked)\n",
        "\n",
        "read_txt_file\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"file_name\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": [\"file_name\"]\n",
        "}\n",
        "\n",
        "summarize_text\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"text\": { \"type\": \"string\" },\n",
        "    \"max_points\": { \"type\": \"integer\", \"minimum\": 1, \"maximum\": 12 },\n",
        "    \"style\": { \"type\": \"string\", \"enum\": [\"bullet\", \"paragraph\"] }\n",
        "  },\n",
        "  \"required\": [\"text\"]\n",
        "}\n",
        "\n",
        "write_summary_file\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"source_file\": { \"type\": \"string\" },\n",
        "    \"content\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": [\"source_file\", \"content\"]\n",
        "}\n",
        "\n",
        "terminate (optional)\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"message\": { \"type\": \"string\" }\n",
        "  },\n",
        "  \"required\": []\n",
        "}\n",
        "\n",
        "---\n",
        "\n",
        "6) Environment Contracts\n",
        "\n",
        "- Folders: input folder for sources; output folder for summaries.\n",
        "- Path safety: only allow files inside those folders; sanitize filenames.\n",
        "- Large files: cap reads at a safe character limit (e.g., 12,000) and set `truncated: true`.\n",
        "- Result envelope:\n",
        "  - Success → {\"tool_executed\": true, \"result\": ...}\n",
        "  - Failure → {\"tool_executed\": false, \"error\": \"...\", \"hint\": \"...\", \"retryable\": boolean}\n",
        "\n",
        "---\n",
        "\n",
        "7) Memory Policy\n",
        "\n",
        "- Each item is {role: \"user\"|\"assistant\"|\"tool\", content: <text or small dict>}.\n",
        "- Keep only the last 8 items in the prompt.\n",
        "- Always log: the agent’s decision and the tool result (success or error).\n",
        "\n",
        "---\n",
        "\n",
        "8) Goals\n",
        "\n",
        "Goal(priority=1, name=\"file_summary\",\n",
        "     description=\"1) list files  2) read each  3) summarize to ≤5 bullets  4) save the summary\")\n",
        "\n",
        "---\n",
        "\n",
        "9) Message Plan (what we tell the model)\n",
        "\n",
        "- System: “You are a precise, factual summarizer. Choose exactly one tool per step. After saving all summaries, end the session.”\n",
        "- User: “Pick the best next tool to make progress. Return a function call, not prose.”\n",
        "- Memory: last 8 items (dicts coerced to short strings if needed).\n",
        "- Tools: names, descriptions, and parameter schemas.\n",
        "\n",
        "---\n",
        "\n",
        "10) Function Calling Driver (decision interface)\n",
        "\n",
        "- Convert the messages into one {\"tool\": \"...\", \"args\": {...}} per step.\n",
        "- If the model doesn’t pick a tool, default to {\"tool\":\"list_txt_files\",\"args\":{}}.\n",
        "- Keep temperature low for stable choices.\n",
        "\n",
        "---\n",
        "\n",
        "11) Capabilities Layer (optional plug-ins)\n",
        "\n",
        "- PlanFirstCapability — if memory is “cold”, nudge “start with list_txt_files.”\n",
        "- ProgressTrackingCapability — track which files are done/remaining in memory.\n",
        "- RetryBackoffCapability — suggest retry spacing after repeated failures.\n",
        "\n",
        "(These hook into the loop but don’t change tool contracts.)\n",
        "\n",
        "---\n",
        "\n",
        "12) Orchestrator Loop (glue)\n",
        "\n",
        "1. Build messages (Goals + Memory + Tools + System rules).\n",
        "2. Ask model to choose the next tool.\n",
        "3. Validate arguments; on failure → log error + continue.\n",
        "4. Execute tool via the Environment; write result to memory.\n",
        "5. If execution failed → Brain will re-plan next step.\n",
        "6. Stop on a terminal tool or max_iterations.\n",
        "\n",
        "---\n",
        "\n",
        "13) Logging (what we record each step)\n",
        "\n",
        "- Prompt → (compact summary)\n",
        "- Decision ← (tool + args)\n",
        "- Result ← (success/failure envelope)\n",
        "- Keep a short tail of memory (last ~6) for quick inspection.\n",
        "\n",
        "---\n",
        "\n",
        "14) Testing & Acceptance\n",
        "\n",
        "Unit checks\n",
        "- list returns expected files\n",
        "- read returns {content, truncated} and handles missing files with a useful hint\n",
        "- summarize returns a non-empty string for sample text\n",
        "- write creates a file with sanitized name\n",
        "- validation: missing required arg → clean error (no execution)\n",
        "\n",
        "Integration smoke\n",
        "- Mock decision {\"tool\":\"list_txt_files\"} runs and logs a valid result.\n",
        "\n",
        "Function-calling\n",
        "- Real model picks a tool on a tiny dataset.\n",
        "- Default to list_txt_files if no tool call returned.\n",
        "\n",
        "Acceptance (Go/No-Go)\n",
        "- [ ] One .summary.txt per source file\n",
        "- [ ] Each has ≤5 bullet points, factual tone\n",
        "- [ ] No unhandled errors in memory tail\n",
        "- [ ] Nonexistent file requests yield helpful hints\n",
        "- [ ] Large files set truncated: true and the run still completes\n",
        "\n",
        "---\n",
        "\n",
        "15) Storyboard (dry-run)\n",
        "\n",
        "1. Brain: list files → Body: [\"a.txt\",\"b.txt\"]\n",
        "2. Brain: read a.txt → Body: {content, truncated:false}\n",
        "3. Brain: summarize → Body: bullets string\n",
        "4. Brain: write summary for a.txt → Body: saved path\n",
        "5. Repeat for b.txt\n",
        "6. Brain: terminate (“All summaries written.”)\n",
        "\n",
        "Failure branch\n",
        "Read fails (“file not found”, hint “list files first”) → Brain calls list, recovers.\n",
        "\n",
        "---\n",
        "\n",
        "16) Known Risks & Early Choices\n",
        "\n",
        "- Very large files → add a read_txt_chunk tool next iteration.\n",
        "- Mixed encodings → always open with errors=\"replace\".\n",
        "- LLM drift → strict system message + short memory + low temperature.\n",
        "- Naming → stick to verb_object_context (e.g., write_summary_file).\n",
        "\n",
        "---\n",
        "\n",
        "17) Ready-to-Code Checklist\n",
        "\n",
        "- [ ] Brain/Body table finalized\n",
        "- [ ] Tool list + schemas finalized\n",
        "- [ ] Environment rules agreed (paths, truncation, envelope)\n",
        "- [ ] Memory policy set (shape + window)\n",
        "- [ ] Goal text written\n",
        "- [ ] Message plan written\n",
        "- [ ] Function-calling defaults set\n",
        "- [ ] Capabilities selected (optional)\n",
        "- [ ] Loop remains minimal and reusable\n",
        "- [ ] Testing & Acceptance checklist ready\n",
        "\"\"\"\n",
        "\n",
        "output_path = \"/content/Master_Recipe_Dress_Rehearsal.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(dress_rehearsal)\n",
        "\n",
        "print(f\"Saved: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kkJqHgXC6Rp",
        "outputId": "0cffbb38-47f5-4bbc-cd1f-2b01e168c950"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/Master_Recipe_Dress_Rehearsal.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Missing\n",
        "\n",
        "## Can you build a fully functioning Agent with the Code?\n",
        "\n",
        "Your checklist is strong enough that I could build a working agent from it, **with a few small clarifications** to remove guesswork and ensure the result matches your expectations exactly.\n",
        "\n",
        "Here’s what I’d tighten before coding:\n",
        "\n",
        "### Must-clarify (to avoid ambiguity)\n",
        "\n",
        "1. **Input/Output folders (exact paths & permissions)**\n",
        "\n",
        "   * Confirm canonical paths (e.g., `/content/files`, `/content/summaries`) and that writing is allowed.\n",
        "\n",
        "2. **File scope**\n",
        "\n",
        "   * v1 = only `.txt`? (You mention future `.md/.pdf/.docx`; specify **not** in scope now.)\n",
        "\n",
        "3. **Truncation rule**\n",
        "\n",
        "   * Exact cap (e.g., **12,000 chars**), and whether the LLM should be told “truncated: true” in the prompt.\n",
        "\n",
        "4. **Termination criteria**\n",
        "\n",
        "   * End when: all listed files have summaries **or** the LLM explicitly calls `terminate` (prefer both).\n",
        "\n",
        "5. **Function-calling defaults**\n",
        "\n",
        "   * Temperature = **0.2**; **one** tool per step; fallback to `list_txt_files` if no tool chosen.\n",
        "\n",
        "6. **Memory window**\n",
        "\n",
        "   * **8** items, roles limited to `user|assistant|tool`. Confirm we stringify dicts before sending to the model.\n",
        "\n",
        "7. **Error envelope**\n",
        "\n",
        "   * Exact shape:\n",
        "\n",
        "     * Success → `{ \"tool_executed\": true, \"result\": ... }`\n",
        "     * Failure → `{ \"tool_executed\": false, \"error\": \"…\", \"hint\": \"…\", \"retryable\": true|false }`\n",
        "\n",
        "8. **Acceptance test corpus**\n",
        "\n",
        "   * Provide 2–3 sample files (e.g., `short.txt`, `long.txt` > 12k chars, and a missing-file scenario) so “Done” is objectively testable.\n",
        "\n",
        "### Should-clarify (quality/reproducibility)\n",
        "\n",
        "1. **Summary format**\n",
        "\n",
        "   * Bullets with `-` prefix; **≤5 bullets**; no intro/outro prose; no markdown headings.\n",
        "\n",
        "2. **LLM prompt style**\n",
        "\n",
        "   * Keep the system message **strict** (“concise, factual, no speculation; one tool per step”).\n",
        "\n",
        "3. **Logging**\n",
        "\n",
        "   * Print the triad every step: `Prompt →` (compact), `Decision ←` (tool+args), `Result ←` (envelope).\n",
        "   * Keep last **6** memory items for quick inspection.\n",
        "\n",
        "4. **Config surface**\n",
        "\n",
        "   * Put paths, truncation cap, temperature, and max iterations in a small `config` dict held by `ActionContext`.\n",
        "\n",
        "5. **Rate limits / retries (optional)**\n",
        "\n",
        "   * If an OpenAI call fails, one retry with exponential backoff? (Simple default: retry once after 1s.)\n",
        "\n",
        "### Nice-to-have (but not blockers)\n",
        "\n",
        "* **`terminate` tool** with `terminal=True`.\n",
        "* **PlanFirstCapability** enabled by default for cold starts.\n",
        "* **Testing plan**: run unit-ish tests for each tool + one integration pass on the sample corpus.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wDF0qjZaEyCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| #      | Master List Item                   | Why Particulars Are Needed                                            |\n",
        "| ------ | ---------------------------------- | --------------------------------------------------------------------- |\n",
        "| **1**  | **Idea & One-Paragraph Spec**      | Needs the exact English goal for *this* agent.                        |\n",
        "| **2**  | **Brain/Body Table**               | Needs the final list of actions with role assignments for this agent. |\n",
        "| **3**  | **Architecture Map**               | Needs actual tools, paths, and flow for *this* build.                 |\n",
        "| **4**  | **Tool Inventory**                 | Needs exact tool names and functions.                                 |\n",
        "| **5**  | **Tool Schemas**                   | Needs JSON schema for each tool.                                      |\n",
        "| **6**  | **ActionContext**                  | Needs the injected dependencies and config for this agent.            |\n",
        "| **7**  | **Environment Contracts**          | Needs final path rules, truncation settings, result envelope format.  |\n",
        "| **8**  | **Memory Policy**                  | Needs memory size, item format, and coercion rules.                   |\n",
        "| **9**  | **Goals**                          | Needs exact goal object(s) with priority and description.             |\n",
        "| **10** | **Agent Language (Prompt Design)** | Needs final system/user prompts and style constraints.                |\n",
        "| **11** | **Function Calling Driver**        | Needs model name, temperature, defaults, and fallback tool.           |\n",
        "| **12** | **Capabilities**                   | Needs which optional capabilities are enabled (e.g., PlanFirst).      |\n",
        "| **13** | **Orchestrator Loop**              | Needs loop limits (max iterations), stop conditions, logging prefs.   |\n",
        "| **14** | **Observability**                  | Needs logging level and which artifacts to store.                     |\n",
        "| **15** | **Testing & Acceptance**           | Needs final pass/fail criteria and test plan.                         |\n",
        "| **16** | **Risks & Early Choices**          | Needs known risks + chosen mitigations for this agent.                |\n",
        "| **17** | **Config Bundle**                  | Needs final key-value pairs for runtime config.                       |\n"
      ],
      "metadata": {
        "id": "UTE7Dikm746c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This “What is Missing” doc is spot-on. It cleanly captures the exact particulars an LLM (and you) need before writing code. I’d keep everything you have and make a few small upgrades so it’s truly turnkey and reusable across agents:\n",
        "\n",
        "## Small upgrades (to make it bulletproof)\n",
        "\n",
        "1. **Model + API settings (explicit)**\n",
        "\n",
        "   * Add: `model = gpt-4o-mini`, `temperature = 0.2`, `top_p = default`, `max_tokens = N (optional)`, `timeout = N sec`.\n",
        "\n",
        "2. **Fallbacks & cold start**\n",
        "\n",
        "   * Already noted: default to `list_txt_files`. Also add: “if tool args fail validation twice in a row → call `list_txt_files` again.”\n",
        "\n",
        "3. **Chunking (future-proof toggle)**\n",
        "\n",
        "   * Add an on/off flag with a stubbed API (`read_txt_chunk(file, start, n_chars)`), even if off in v1.\n",
        "\n",
        "4. **File naming policy (deterministic)**\n",
        "\n",
        "   * Specify: summary filename pattern `f\"{stem}.summary.txt\"` (ASCII-safe, snake/slug policy).\n",
        "   * Collisions: overwrite vs version (v1: overwrite).\n",
        "\n",
        "5. **Security & privacy**\n",
        "\n",
        "   * State: no network/file writes outside whitelisted dirs; redact secrets from logs; never echo API keys in memory.\n",
        "\n",
        "6. **Determinism knobs**\n",
        "\n",
        "   * Temperature low (0.2), seed where supported (if not, document that runs may vary slightly).\n",
        "\n",
        "7. **Observability**\n",
        "\n",
        "   * Log level `INFO` by default, `DEBUG` optional toggle; cap log size (e.g., last 2000 chars per payload).\n",
        "\n",
        "8. **Versioning**\n",
        "\n",
        "   * Add `AGENT_VERSION = \"1.0.0\"`; record it in the first memory item and in each output file header (comment line).\n",
        "\n",
        "9. **Operational limits**\n",
        "\n",
        "   * `max_files_per_run` (v1: all), `max_iterations` (v1: 20), `per_file_retry_limit` (v1: 1).\n",
        "\n",
        "10. **Acceptance corpus**\n",
        "\n",
        "    * Name the exact sample files to include in the repo/notebook (`short.txt`, `very_long.txt`, `missing_case.txt` docstring).\n",
        "\n",
        "## Turn it into a fill-in sheet (ready for each new agent)\n",
        "\n",
        "If you like this structure, here’s a compact “Particulars Sheet v1.0” you can paste into a text file and fill quickly:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GlbwQXy8HY_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "particulars = \"\"\"\n",
        "\n",
        "PARTICULARS SHEET v1.0\n",
        "\n",
        "# Paths & Scope\n",
        "input_dir: /content/files\n",
        "output_dir: /content/summaries\n",
        "in_scope_extensions: [.txt]\n",
        "out_of_scope_extensions: [.md, .pdf, .docx]   # ignored in v1\n",
        "write_permissions_confirmed: true\n",
        "\n",
        "# File Handling\n",
        "truncate_chars: 12000\n",
        "set_truncated_flag: true\n",
        "chunking_enabled: false   # if true, provide read_txt_chunk API\n",
        "\n",
        "# Model & Driver\n",
        "model: gpt-4o-mini\n",
        "temperature: 0.2\n",
        "top_p: default\n",
        "max_tokens: default\n",
        "one_tool_per_step: true\n",
        "fallback_tool: list_txt_files\n",
        "timeout_seconds: 60\n",
        "\n",
        "# Memory\n",
        "memory_window: 8\n",
        "coerce_dicts_to_strings: true\n",
        "allowed_roles: [user, assistant, tool]\n",
        "\n",
        "# Termination & Limits\n",
        "stop_condition: all_files_processed_or_terminate\n",
        "max_iterations: 20\n",
        "max_files_per_run: all\n",
        "per_file_retry_limit: 1\n",
        "\n",
        "# Error Envelope (MUST USE)\n",
        "success_shape: {\"tool_executed\": true, \"result\": ...}\n",
        "failure_shape: {\"tool_executed\": false, \"error\": \"...\", \"hint\": \"...\", \"retryable\": true|false}\n",
        "always_include_hint_on_failure: true\n",
        "\n",
        "# Summary Style\n",
        "bullet_prefix: \"-\"\n",
        "max_bullets: 5\n",
        "disallow_headings_and_fluff: true\n",
        "tone: concise_factual_no_speculation\n",
        "\n",
        "# Capabilities\n",
        "plan_first_enabled: true\n",
        "progress_tracking_enabled: false\n",
        "retry_backoff_enabled: false\n",
        "\n",
        "# Logging & Privacy\n",
        "log_triad_each_step: true       # Prompt → / Decision ← / Result ←\n",
        "memory_tail_visible: 6\n",
        "log_level: INFO                 # DEBUG optional\n",
        "redact_secrets_in_logs: true\n",
        "\n",
        "# Determinism & Versioning\n",
        "seed_supported: false\n",
        "agent_version: \"1.0.0\"\n",
        "\n",
        "# File Naming Policy\n",
        "summary_filename_pattern: \"{stem}.summary.txt\"\n",
        "filename_sanitization: ascii_safe_slug\n",
        "on_collision: overwrite\n",
        "\n",
        "# Tests & Acceptance\n",
        "unit_tests: [list, read, summarize, write, validation_errors]\n",
        "integration_smoke: one_file_end_to_end\n",
        "function_calling_sanity: choose_a_tool_on_tiny_dataset\n",
        "acceptance_checklist:\n",
        "  - one_output_per_input_file\n",
        "  - leq_5_bullets_factual\n",
        "  - no_unhandled_errors\n",
        "  - missing_file_yields_hint\n",
        "  - truncated_true_for_long_files_and_run_completes\n",
        "\n",
        "# Risks & Early Choices\n",
        "large_files_plan: add_read_chunk_in_v2\n",
        "encoding_policy: errors=\"replace\"\n",
        "naming_convention: verb_object_context\n",
        "\"\"\"\n",
        "\n",
        "output_path = \"/content/Master_Recipe_Particulars_A.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(particulars)\n",
        "\n",
        "print(f\"Saved: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_pxCyqS3Vtl",
        "outputId": "79219062-884b-4a10-b7b4-3652bfcc658c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/Master_Recipe_Particulars_A.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "particulars = \"\"\"\n",
        "\n",
        "# Agent Particulars — Indexed by Recipe Steps\n",
        "\n",
        "step_01_idea:\n",
        "  summary: \"<one paragraph, plain English>\"\n",
        "\n",
        "step_02_brain_body_table:\n",
        "  tasks:  # short bullets; this mirrors the table, not the prose\n",
        "    - { area: \"File management\", task: \"List files\", who: \"Body\" }\n",
        "    - { area: \"Summarization\", task: \"Make summary\", who: \"Brain\" }\n",
        "\n",
        "step_03_tool_inventory:\n",
        "  tools:\n",
        "    - name: \"list_txt_files\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Return .txt filenames in input folder\"\n",
        "      preconditions: []\n",
        "      postconditions: [\"returns: [str]\"]\n",
        "    - name: \"read_txt_file\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Read text; mark truncation if over cap\"\n",
        "      preconditions: [\"file exists under input_dir\"]\n",
        "      postconditions: [\"returns: {file_name, content, truncated: bool}\"]\n",
        "    - name: \"summarize_text\"\n",
        "      owner: \"Brain\"\n",
        "      desc: \"≤5 factual bullets\"\n",
        "      preconditions: [\"text non-empty\"]\n",
        "      postconditions: [\"returns: str (bullets)\"]\n",
        "    - name: \"write_summary_file\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Save sanitized summary\"\n",
        "      preconditions: [\"output_dir writable\"]\n",
        "      postconditions: [\"returns: output_path\"]\n",
        "    - name: \"terminate\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Signal completion\"\n",
        "      preconditions: []\n",
        "      postconditions: [\"terminal: true\"]\n",
        "\n",
        "step_03_5_action_context:\n",
        "  env: true\n",
        "  registry: true\n",
        "  memory: true\n",
        "  llm_helpers:\n",
        "    openai_chat_fn: \"enabled\"\n",
        "  config:\n",
        "    input_dir: \"/content/files\"\n",
        "    output_dir: \"/content/summaries\"\n",
        "    truncate_chars: 12000\n",
        "    model: \"gpt-4o-mini\"\n",
        "    temperature: 0.2\n",
        "    max_iterations: 20\n",
        "    memory_window: 8\n",
        "    fallback_tool: \"list_txt_files\"\n",
        "\n",
        "step_04_tool_schemas:\n",
        "  read_txt_file:\n",
        "    type: object\n",
        "    properties: { file_name: { type: string } }\n",
        "    required: [file_name]\n",
        "  summarize_text:\n",
        "    type: object\n",
        "    properties:\n",
        "      text: { type: string }\n",
        "      max_points: { type: integer, minimum: 1, maximum: 12 }\n",
        "      style: { type: string, enum: [bullet, paragraph] }\n",
        "    required: [text]\n",
        "  write_summary_file:\n",
        "    type: object\n",
        "    properties:\n",
        "      source_file: { type: string }\n",
        "      content: { type: string }\n",
        "    required: [source_file, content]\n",
        "  terminate:\n",
        "    type: object\n",
        "    properties: { message: { type: string } }\n",
        "    required: []\n",
        "\n",
        "step_05_environment_contracts:\n",
        "  path_whitelist: [\"${config.input_dir}\", \"${config.output_dir}\"]\n",
        "  filename_policy: \"ascii_safe_slug\"\n",
        "  summary_filename_pattern: \"{stem}.summary.txt\"\n",
        "  on_collision: \"overwrite\"\n",
        "  truncation_cap_chars: \"${config.truncate_chars}\"\n",
        "  result_envelope:\n",
        "    success: { tool_executed: true, result: \"<any>\" }\n",
        "    failure: { tool_executed: false, error: \"<string>\", hint: \"<string>\", retryable: \"<bool>\" }\n",
        "\n",
        "step_06_memory_policy:\n",
        "  item_shape: \"{role: user|assistant|tool, content: str|dict}\"\n",
        "  window_items: \"${config.memory_window}\"\n",
        "  coerce_dicts_to_strings: true\n",
        "  always_log: [\"decision\", \"tool_result\"]\n",
        "\n",
        "step_07_goals:\n",
        "  list:\n",
        "    - { priority: 1, name: \"file_summary\",\n",
        "        description: \"1) list files  2) read each  3) summarize ≤5 bullets  4) save the summary\" }\n",
        "\n",
        "step_08_message_plan:\n",
        "  system: \"You are a precise, factual summarizer. Choose exactly one tool per step. After saving all summaries, end the session.\"\n",
        "  user: \"Pick the best next tool to make progress. Return a function call, not prose.\"\n",
        "  include_tools: true\n",
        "  include_memory_tail_items: \"${config.memory_window}\"\n",
        "\n",
        "step_09_function_calling_driver:\n",
        "  model: \"${config.model}\"\n",
        "  temperature: \"${config.temperature}\"\n",
        "  one_tool_per_step: true\n",
        "  fallback_decision: { tool: \"${config.fallback_tool}\", args: {} }\n",
        "  timeout_seconds: 60\n",
        "\n",
        "step_10_capabilities:\n",
        "  plan_first_enabled: true\n",
        "  progress_tracking_enabled: false\n",
        "  retry_backoff_enabled: false\n",
        "\n",
        "step_11_orchestrator_loop:\n",
        "  stop_conditions: [\"terminal_tool\", \"max_iterations\"]\n",
        "  max_iterations: \"${config.max_iterations}\"\n",
        "\n",
        "step_12_logging:\n",
        "  log_triad_each_step: true\n",
        "  memory_tail_visible: 6\n",
        "  log_level: \"INFO\"\n",
        "  redact_secrets: true\n",
        "\n",
        "step_13_testing_and_acceptance:\n",
        "  unit_tests: [\"list\", \"read\", \"summarize\", \"write\", \"validation_errors\"]\n",
        "  integration_smoke: \"one_file_end_to_end\"\n",
        "  function_calling_sanity: \"choose_tool_on_tiny_dataset\"\n",
        "  acceptance_checklist:\n",
        "    - \"one_output_per_input_file\"\n",
        "    - \"leq_5_bullets_factual\"\n",
        "    - \"no_unhandled_errors\"\n",
        "    - \"missing_file_yields_hint\"\n",
        "    - \"truncated_true_for_long_files_and_run_completes\"\n",
        "\n",
        "step_14_storyboard:\n",
        "  happy_path:\n",
        "    - \"Brain: list files → Body: ['a.txt','b.txt']\"\n",
        "    - \"Brain: read a.txt → Body: {content, truncated: false}\"\n",
        "    - \"Brain: summarize → Body: bullets string\"\n",
        "    - \"Brain: write summary for a.txt → Body: saved path\"\n",
        "    - \"Repeat for b.txt\"\n",
        "    - \"Brain: terminate ('All summaries written.')\"\n",
        "  error_branch:\n",
        "    - \"read a.txt fails: file not found + hint 'list files'\"\n",
        "    - \"Brain: call list_txt_files to recover\"\n",
        "\n",
        "step_15_risks_and_early_choices:\n",
        "  large_files_plan: \"add read_txt_chunk in v2\"\n",
        "  encoding_policy: \"errors='replace'\"\n",
        "  naming_convention: \"verb_object_context\"\n",
        "  determinism: { temperature_low: true, seed_supported: false }\n",
        "\n",
        "step_16_ready_to_code_checklist:\n",
        "  items:\n",
        "    - \"Brain/Body table finalized\"\n",
        "    - \"Tool list + schemas finalized\"\n",
        "    - \"Environment rules agreed\"\n",
        "    - \"Memory policy set\"\n",
        "    - \"Goal text written\"\n",
        "    - \"Message plan written\"\n",
        "    - \"Function-calling defaults set\"\n",
        "    - \"Capabilities chosen\"\n",
        "    - \"Loop thin & reusable\"\n",
        "    - \"Testing & Acceptance checklist ready\"\n",
        "\"\"\"\n",
        "\n",
        "output_path = \"/content/Master_Recipe_Particulars_B.txt\"\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(particulars)\n",
        "\n",
        "print(f\"Saved: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLFKs2gnK4C0",
        "outputId": "88186e0f-87a5-4b70-bb65-590d9f654108"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/Master_Recipe_Particulars_B.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap, os\n",
        "\n",
        "yaml_text = \"\"\"\n",
        "# Agent Particulars — Indexed by Recipe Steps\n",
        "\n",
        "step_01_idea:\n",
        "  summary: \"<one paragraph, plain English>\"\n",
        "\n",
        "step_02_brain_body_table:\n",
        "  tasks:  # short bullets; this mirrors the table, not the prose\n",
        "    - { area: \"File management\", task: \"List files\", who: \"Body\" }\n",
        "    - { area: \"Summarization\", task: \"Make summary\", who: \"Brain\" }\n",
        "\n",
        "step_03_tool_inventory:\n",
        "  tools:\n",
        "    - name: \"list_txt_files\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Return .txt filenames in input folder\"\n",
        "      preconditions: []\n",
        "      postconditions: [\"returns: [str]\"]\n",
        "    - name: \"read_txt_file\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Read text; mark truncation if over cap\"\n",
        "      preconditions: [\"file exists under input_dir\"]\n",
        "      postconditions: [\"returns: {file_name, content, truncated: bool}\"]\n",
        "    - name: \"summarize_text\"\n",
        "      owner: \"Brain\"\n",
        "      desc: \"≤5 factual bullets\"\n",
        "      preconditions: [\"text non-empty\"]\n",
        "      postconditions: [\"returns: str (bullets)\"]\n",
        "    - name: \"write_summary_file\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Save sanitized summary\"\n",
        "      preconditions: [\"output_dir writable\"]\n",
        "      postconditions: [\"returns: output_path\"]\n",
        "    - name: \"terminate\"\n",
        "      owner: \"Body\"\n",
        "      desc: \"Signal completion\"\n",
        "      preconditions: []\n",
        "      postconditions: [\"terminal: true\"]\n",
        "\n",
        "step_03_5_action_context:\n",
        "  env: true\n",
        "  registry: true\n",
        "  memory: true\n",
        "  llm_helpers:\n",
        "    openai_chat_fn: \"enabled\"\n",
        "  config:\n",
        "    input_dir: \"/content/files\"\n",
        "    output_dir: \"/content/summaries\"\n",
        "    truncate_chars: 12000\n",
        "    model: \"gpt-4o-mini\"\n",
        "    temperature: 0.2\n",
        "    max_iterations: 20\n",
        "    memory_window: 8\n",
        "    fallback_tool: \"list_txt_files\"\n",
        "\n",
        "step_04_tool_schemas:\n",
        "  read_txt_file:\n",
        "    type: object\n",
        "    properties: { file_name: { type: string } }\n",
        "    required: [file_name]\n",
        "  summarize_text:\n",
        "    type: object\n",
        "    properties:\n",
        "      text: { type: string }\n",
        "      max_points: { type: integer, minimum: 1, maximum: 12 }\n",
        "      style: { type: string, enum: [bullet, paragraph] }\n",
        "    required: [text]\n",
        "  write_summary_file:\n",
        "    type: object\n",
        "    properties:\n",
        "      source_file: { type: string }\n",
        "      content: { type: string }\n",
        "    required: [source_file, content]\n",
        "  terminate:\n",
        "    type: object\n",
        "    properties: { message: { type: string } }\n",
        "    required: []\n",
        "\n",
        "step_05_environment_contracts:\n",
        "  path_whitelist: [\"${config.input_dir}\", \"${config.output_dir}\"]\n",
        "  filename_policy: \"ascii_safe_slug\"\n",
        "  summary_filename_pattern: \"{stem}.summary.txt\"\n",
        "  on_collision: \"overwrite\"\n",
        "  truncation_cap_chars: \"${config.truncate_chars}\"\n",
        "  result_envelope:\n",
        "    success: { tool_executed: true, result: \"<any>\" }\n",
        "    failure: { tool_executed: false, error: \"<string>\", hint: \"<string>\", retryable: \"<bool>\" }\n",
        "\n",
        "step_06_memory_policy:\n",
        "  item_shape: \"{role: user|assistant|tool, content: str|dict}\"\n",
        "  window_items: \"${config.memory_window}\"\n",
        "  coerce_dicts_to_strings: true\n",
        "  always_log: [\"decision\", \"tool_result\"]\n",
        "\n",
        "step_07_goals:\n",
        "  list:\n",
        "    - { priority: 1, name: \"file_summary\",\n",
        "        description: \"1) list files  2) read each  3) summarize ≤5 bullets  4) save the summary\" }\n",
        "\n",
        "step_08_message_plan:\n",
        "  system: \"You are a precise, factual summarizer. Choose exactly one tool per step. After saving all summaries, end the session.\"\n",
        "  user: \"Pick the best next tool to make progress. Return a function call, not prose.\"\n",
        "  include_tools: true\n",
        "  include_memory_tail_items: \"${config.memory_window}\"\n",
        "\n",
        "step_09_function_calling_driver:\n",
        "  model: \"${config.model}\"\n",
        "  temperature: \"${config.temperature}\"\n",
        "  one_tool_per_step: true\n",
        "  fallback_decision: { tool: \"${config.fallback_tool}\", args: {} }\n",
        "  timeout_seconds: 60\n",
        "\n",
        "step_10_capabilities:\n",
        "  plan_first_enabled: true\n",
        "  progress_tracking_enabled: false\n",
        "  retry_backoff_enabled: false\n",
        "\n",
        "step_11_orchestrator_loop:\n",
        "  stop_conditions: [\"terminal_tool\", \"max_iterations\"]\n",
        "  max_iterations: \"${config.max_iterations}\"\n",
        "\n",
        "step_12_logging:\n",
        "  log_triad_each_step: true\n",
        "  memory_tail_visible: 6\n",
        "  log_level: \"INFO\"\n",
        "  redact_secrets: true\n",
        "\n",
        "step_13_testing_and_acceptance:\n",
        "  unit_tests: [\"list\", \"read\", \"summarize\", \"write\", \"validation_errors\"]\n",
        "  integration_smoke: \"one_file_end_to_end\"\n",
        "  function_calling_sanity: \"choose_tool_on_tiny_dataset\"\n",
        "  acceptance_checklist:\n",
        "    - \"one_output_per_input_file\"\n",
        "    - \"leq_5_bullets_factual\"\n",
        "    - \"no_unhandled_errors\"\n",
        "    - \"missing_file_yields_hint\"\n",
        "    - \"truncated_true_for_long_files_and_run_completes\"\n",
        "\n",
        "step_14_storyboard:\n",
        "  happy_path:\n",
        "    - \"Brain: list files → Body: ['a.txt','b.txt']\"\n",
        "    - \"Brain: read a.txt → Body: {content, truncated: false}\"\n",
        "    - \"Brain: summarize → Body: bullets string\"\n",
        "    - \"Brain: write summary for a.txt → Body: saved path\"\n",
        "    - \"Repeat for b.txt\"\n",
        "    - \"Brain: terminate ('All summaries written.')\"\n",
        "  error_branch:\n",
        "    - \"read a.txt fails: file not found + hint 'list files'\"\n",
        "    - \"Brain: call list_txt_files to recover\"\n",
        "\n",
        "step_15_risks_and_early_choices:\n",
        "  large_files_plan: \"add read_txt_chunk in v2\"\n",
        "  encoding_policy: \"errors='replace'\"\n",
        "  naming_convention: \"verb_object_context\"\n",
        "  determinism: { temperature_low: true, seed_supported: false }\n",
        "\n",
        "step_16_ready_to_code_checklist:\n",
        "  items:\n",
        "    - \"Brain/Body table finalized\"\n",
        "    - \"Tool list + schemas finalized\"\n",
        "    - \"Environment rules agreed\"\n",
        "    - \"Memory policy set\"\n",
        "    - \"Goal text written\"\n",
        "    - \"Message plan written\"\n",
        "    - \"Function-calling defaults set\"\n",
        "    - \"Capabilities chosen\"\n",
        "    - \"Loop thin & reusable\"\n",
        "    - \"Testing & Acceptance checklist ready\"\n",
        "\"\"\"\n",
        "out_path = \"/content/Agent_Particulars_By_Recipe_Step.yaml\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(textwrap.dedent(yaml_text).strip()+\"\\n\")\n",
        "print(f\"Saved: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM9oArofLIUK",
        "outputId": "2ba3db69-5086-4548-a39b-33f4ae81d762"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/Agent_Particulars_By_Recipe_Step.yaml\n"
          ]
        }
      ]
    }
  ]
}