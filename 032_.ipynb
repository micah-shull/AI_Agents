{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZT9Cq28PesTTgcseJJgTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/032_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ðŸ§± Why Structured Output Matters\n",
        "\n",
        "Before function calling, developers had to rely on **prompt engineering** to *hope* the model returned well-formed JSON. But this was:\n",
        "\n",
        "* âœ… *Unreliable* â€“ The model could easily miss a comma or format a string wrong\n",
        "* âœ… *Fragile* â€“ Changes in prompts or slight wording variations would break parsers\n",
        "* âœ… *Error-prone* â€“ You needed lots of custom logic to handle malformed responses\n",
        "\n",
        "### âœ… What Function Calling Solves\n",
        "\n",
        "Function calling changes everything by **guaranteeing structured output**, thanks to OpenAIâ€™s API enforcing a strict format.\n",
        "\n",
        "> *â€œInstead of treating function execution as a free-form text generation task, function calling APIs allow us to explicitly define the tools available to the model using JSON Schema.â€*\n",
        "\n",
        "That means:\n",
        "\n",
        "* The **LLM doesn't try to \"generate JSON\"** anymore â€” it *selects* a function and fills in a structured argument block.\n",
        "* The **OpenAI API enforces that structure** â€” invalid responses are rejected before they even reach you.\n",
        "* You get a `tool_calls` block like this, not unstructured text:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_calls\": [\n",
        "    {\n",
        "      \"function\": {\n",
        "        \"name\": \"search_file_names\",\n",
        "        \"arguments\": \"{ \\\"keyword\\\": \\\"memory\\\", \\\"case_sensitive\\\": false }\"\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "No more manual extraction from text like:\n",
        "\n",
        "> â€œSure, the file names that contain â€˜memoryâ€™ are: ...â€\n",
        "\n",
        "Now you just call:\n",
        "\n",
        "```python\n",
        "tool_name = tool_call.function.name\n",
        "args = json.loads(tool_call.function.arguments)\n",
        "```\n",
        "\n",
        "### ðŸ”„ Youâ€™re Free to Focus on Behavior\n",
        "\n",
        "By delegating **format enforcement** to the API, you can focus on:\n",
        "\n",
        "* Designing great tools\n",
        "* Structuring decision logic\n",
        "* Making agents more intelligent\n",
        "\n",
        "It moves LLMs from being *generative text bots* to *structured collaborators.*\n"
      ],
      "metadata": {
        "id": "duafIwncQ9eZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NT-3fnGEPBS5"
      },
      "outputs": [],
      "source": [
        "%pip install -qU dotenv openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import textwrap\n",
        "from typing import List\n",
        "from litellm import completion\n",
        "\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# 1. Define the Tool Functions\n",
        "#------------------------------\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# First, we define the actual Python functions that will be executed.\n",
        "# These contain the business logic for each tool and handle the actual operations the AI agent can perform.\n",
        "\n",
        "# 2. Create a Function Registry\n",
        "#------------------------------\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file\n",
        "}\n",
        "# We maintain a dictionary that maps function names to their corresponding Python implementations.\n",
        "# This registry allows us to easily look up and execute the appropriate function when the model calls it.\n",
        "\n",
        "# 3. Define Tool Specifications Using JSON Schema\n",
        "#-------------------------------------------------\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "# This is where we describe our tools to the model. Each tool specification includes:\n",
        "# A name that matches a key in our tool_functions dictionary\n",
        "# A description that helps the model understand when to use this tool\n",
        "# Parameters defined using JSON Schema, specifying the expected input format\n",
        "# Note how the list_files function takes no parameters (empty â€œpropertiesâ€ object), while read_file requires a â€œfile_nameâ€ string parameter. The model will use these specifications to generate properly structured calls.\n",
        "\n",
        "# 4. Set Up the Agentâ€™s Instructions\n",
        "#------------------------------------\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\"\"\"\n",
        "}]\n",
        "# The system message provides guidance on how the agent should behave.\n",
        "# With function calling, we donâ€™t need to instruct the model on how to format its outputs - we only need to focus on the decision-making logic.\n",
        "\n",
        "# 5. Prepare the Conversation Context\n",
        "#--------------------------------------\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "messages = agent_rules + memory\n",
        "# We combine the system instructions with the userâ€™s input to create the conversation context.\n",
        "\n",
        "# 6. Make the API Call with Function Definitions\n",
        "#-----------------------------------------------\n",
        "response = completion(\n",
        "    model=\"openai/gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    max_tokens=1024\n",
        ")\n",
        "# The critical difference here is the inclusion of the tools parameter,\n",
        "# which tells the model what functions it can call. This is what activates the function calling mechanism.\n",
        "\n",
        "# 7. Process the Structured Response\n",
        "#------------------------------------\n",
        "tool = response.choices[0].message.tool_calls[0]\n",
        "tool_name = tool.function.name\n",
        "tool_args = json.loads(tool.function.arguments)\n",
        "When using function calling, the response comes back with a dedicated tool_calls array rather than free-text output. This ensures that:\n",
        "\n",
        "# The function name is properly identified\n",
        "# The arguments are correctly formatted as valid JSON\n",
        "# We donâ€™t need to parse or extract from unstructured text\n",
        "# 8. Execute the Function with the Provided Arguments\n",
        "#-----------------------------------------------------\n",
        "result = tool_functions[tool_name](**tool_args)\n",
        "# Finally, we look up the appropriate function in our registry and call it with the arguments\n",
        "# the model provided. The **tool_args syntax unpacks the JSON object into keyword arguments.\n"
      ],
      "metadata": {
        "id": "OmpMV8w9SMk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Letâ€™s walk through this code **step by step**, and Iâ€™ll highlight what you should **focus on and learn**, especially with respect to function calling and agent design.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Conceptual Overview\n",
        "\n",
        "This script demonstrates a **minimal working AI agent** that:\n",
        "\n",
        "1. Accepts user input.\n",
        "2. Lets the **LLM decide** whether a tool is needed.\n",
        "3. **Parses the tool call** (automatically structured).\n",
        "4. Executes the correct Python function with the tool arguments.\n",
        "5. Returns the tool result.\n",
        "\n",
        "This is the core of **tool-using agents**. Letâ€™s now go line by line.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 1. Basic Imports and Tool Functions\n",
        "\n",
        "```python\n",
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "from litellm import completion\n",
        "```\n",
        "\n",
        "* `json`: For parsing structured tool arguments.\n",
        "* `os`: Used in `list_files()` to interact with the file system.\n",
        "* `litellm`: This is a lightweight wrapper for OpenAI (used instead of `openai` package) â€“ interchangeable for your purposes.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 2. Tool Functions (The \"Real\" Logic)\n",
        "\n",
        "```python\n",
        "def list_files() -> List[str]:\n",
        "    return os.listdir(\".\")\n",
        "```\n",
        "\n",
        "* This just returns all files in the current directory.\n",
        "* ðŸ§  **Lesson**: The tool logic is your job â€” the LLM just *calls* it.\n",
        "\n",
        "```python\n",
        "def read_file(file_name: str) -> str:\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "```\n",
        "\n",
        "* Basic file reading with error handling.\n",
        "* ðŸ§  **Lesson**: Include good error messaging â€” the LLM can explain it to users if needed.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 3. Tool Registry (Tool Router)\n",
        "\n",
        "```python\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file\n",
        "}\n",
        "```\n",
        "\n",
        "* A dictionary router so we can call the right function dynamically.\n",
        "* ðŸ§  **Key Skill**: Match tool name to the function â€” super useful for scaling.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 4. Tool Schemas (JSON Schema for the LLM)\n",
        "\n",
        "```python\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "```\n",
        "\n",
        "* Youâ€™re telling the LLM:\n",
        "\n",
        "  * This tool exists (`list_files`)\n",
        "  * It takes **no arguments**\n",
        "  * It should return a list of filenames\n",
        "\n",
        "```python\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "* `read_file` expects one required parameter: `file_name`\n",
        "* ðŸ§  **Lesson**: This is the key part that tells the LLM how to call your function.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 5. System Prompt (Agent Rules)\n",
        "\n",
        "```python\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\"\"\"\n",
        "}]\n",
        "```\n",
        "\n",
        "* This sets behavior â€” think of it like a â€œjob descriptionâ€\n",
        "* ðŸ§  **Tip**: You can get clever here and instruct *decision-making strategies*\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 6. User Input and Messages\n",
        "\n",
        "```python\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "messages = agent_rules + memory\n",
        "```\n",
        "\n",
        "* User input is combined with the system rule to form the full context for the LLM.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 7. Making the Completion Call\n",
        "\n",
        "```python\n",
        "response = completion(\n",
        "    model=\"openai/gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    max_tokens=1024\n",
        ")\n",
        "```\n",
        "\n",
        "* ðŸ”¥ **The key part**:\n",
        "\n",
        "  * You provide tools to the LLM\n",
        "  * The LLM decides if a tool is needed and fills in structured arguments\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 8. Handling the Tool Call\n",
        "\n",
        "```python\n",
        "tool = response.choices[0].message.tool_calls[0]\n",
        "tool_name = tool.function.name\n",
        "tool_args = json.loads(tool.function.arguments)\n",
        "result = tool_functions[tool_name](**tool_args)\n",
        "```\n",
        "\n",
        "* ðŸ” **Take Note**:\n",
        "\n",
        "  * No prompt parsing\n",
        "  * No â€œguessingâ€ what the model meant\n",
        "  * You get a **guaranteed structured response** with name + arguments\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 9. Displaying the Result\n",
        "\n",
        "```python\n",
        "print(f\"Tool Name: {tool_name}\")\n",
        "print(f\"Tool Arguments: {tool_args}\")\n",
        "print(f\"Result: {result}\")\n",
        "```\n",
        "\n",
        "* Simple debug-style output.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… What You Should Learn from This\n",
        "\n",
        "| Concept                               | Why It Matters                                  |\n",
        "| ------------------------------------- | ----------------------------------------------- |\n",
        "| **Tool functions**                    | You still write these â€” traditional coding      |\n",
        "| **Tool schemas**                      | LLM needs this to use tools properly            |\n",
        "| **Structured arguments**              | No more manual parsing â€” huge upgrade           |\n",
        "| **Tool routing**                      | You need a clean way to call the right function |\n",
        "| **System message design**             | Controls how the agent behaves                  |\n",
        "| **LLM doesnâ€™t â€œguessâ€ output format** | OpenAIâ€™s API enforces structure                 |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p7i5tzXuRjEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŽ¯ **Everything you've been learning over the past few notebooks has been building up to this moment.** Letâ€™s connect the dots clearly:\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§± What Youâ€™ve Been Building\n",
        "\n",
        "| **Concept**                     | **What You Did**                                                               | **Why It Matters**                                            |\n",
        "| ------------------------------- | ------------------------------------------------------------------------------ | ------------------------------------------------------------- |\n",
        "| âœ… **Python functions**          | Built tools like `list_files()` and `read_file()`                              | Actual business logic to execute tasks                        |\n",
        "| âœ… **JSON tool schema**          | Defined `type`, `name`, `parameters`, `description`                            | Tells the LLM *what tools exist and how to use them*          |\n",
        "| âœ… **LLM prompt architecture**   | Created `generate_agent_response()` using OpenAIâ€™s `chat.completions.create()` | Enables the LLM to pick a tool or reply naturally             |\n",
        "| âœ… **Routing logic**             | Wrote `tool_router()` to dispatch calls                                        | Bridges LLMâ€™s intent to your real Python functions            |\n",
        "| âœ… **Tool call handling**        | Created `handle_tool_call()` and debug modes                                   | Executes, inspects, and optionally continues the conversation |\n",
        "| âœ… **Structured output parsing** | Noted how `tool_call.function.arguments` is a stringified JSON                 | Understood the benefit of OpenAI enforcing structure          |\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Why This Lecture Summary Ties It All Together\n",
        "\n",
        "The lecture highlights how OpenAIâ€™s **function calling APIs**:\n",
        "\n",
        "* Remove the pain of forcing the LLM to output JSON manually\n",
        "* Let you use schemas (like real APIs) to describe tool usage\n",
        "* Guarantee tool call structure so you donâ€™t need brittle parsing code\n",
        "* Make the LLM your **thinking partner**, not your parser\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ¤¯ The Big Insight\n",
        "\n",
        "> **You're not just building an app that uses GPT. Youâ€™re building a modular AI system.**\n",
        ">\n",
        "> One where:\n",
        ">\n",
        "> * The LLM **understands the user's intent**\n",
        "> * The schema **tells the LLM how to act on that intent**\n",
        "> * The router **executes real-world logic**\n",
        "> * The API **ensures clean boundaries and valid calls**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Soyq7hEkUifE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZ19QY2KRm-x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}