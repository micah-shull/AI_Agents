{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPS5taZiY+vsKqB0CTC1gu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/105_TxtSummarizerAgent_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCM0okWkC7FN"
      },
      "outputs": [],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ SETUP (Notebook-only)                                                        â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "!pip -q install openai python-dotenv\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ IMPORTS                                                                      â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import textwrap\n",
        "import time\n",
        "import re\n",
        "import inspect\n",
        "from typing import Callable, Optional\n",
        "from dataclasses import dataclass\n",
        "import builtins\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ OPENAI CLIENT & ENV VARS                                                     â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Loads API key from a .env file and initializes the OpenAI client.\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found in /content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ STANDARD RESULT ENVELOPE (ok / err)                                          â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def ok(**data):\n",
        "    \"\"\"Successful tool result. Add any fields you like.\"\"\"\n",
        "    return {\"ok\": True, **data}\n",
        "\n",
        "def err(msg, hint=None, retryable=False, **extra):\n",
        "    \"\"\"Error result with optional guidance and flags.\"\"\"\n",
        "    out = {\"ok\": False, \"error\": msg, \"retryable\": retryable}\n",
        "    if hint:\n",
        "        out[\"hint\"] = hint\n",
        "    if extra:\n",
        "        out.update(extra)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ğŸ”¹ Why Standardize the Error Format?\n",
        "\n",
        "Hereâ€™s why the `ok()` / `err()` pattern is such a **powerful design decision** for agents, especially LLM-driven ones:\n",
        "\n",
        "#### 1. **Predictability for the LLM**\n",
        "\n",
        "* Agents work best when they know what to expect from tools.\n",
        "* If every function returns something different on success vs failure (e.g. `None`, strings, exceptions, random dicts), the LLM canâ€™t reliably handle it.\n",
        "* Standardizing ensures the LLM can reason about tool outcomes and recover from failures intelligently.\n",
        "\n",
        "#### 2. **Clear Error Signaling**\n",
        "\n",
        "* The `{\"ok\": False, \"error\": ...}` signature is explicit and machine-friendly.\n",
        "* Enables the agent to **check results simply**:\n",
        "  `if result[\"ok\"] is False: handle_error(result[\"error\"])`\n",
        "\n",
        "#### 3. **Retryability & Hints**\n",
        "\n",
        "* The `err()` format also allows for:\n",
        "\n",
        "  * `hint`: Explains what to try next\n",
        "  * `retryable`: Boolean for whether the step might succeed on retry\n",
        "* This gives agents and users **next-step guidance** â€” *crucial for robust and autonomous execution*.\n",
        "\n",
        "#### 4. **Simplifies Logging and Debugging**\n",
        "\n",
        "* You can log every actionâ€™s outcome uniformly (as seen in `ctx.track_progress(...)`)\n",
        "* Makes it easy to track down issues, spot retries, and debug why something failed.\n",
        "\n",
        "#### 5. **Avoids Exceptions from Bubbling**\n",
        "\n",
        "* Instead of throwing exceptions, tools return structured error info.\n",
        "* Thatâ€™s critical when you're running tools in a loop (as agents do), because a single uncaught exception can crash the agent.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© What Does `**data` Actually Do?\n",
        "\n",
        "```python\n",
        "def ok(**data):\n",
        "    return {\"ok\": True, **data}\n",
        "```\n",
        "\n",
        "This is **keyword argument unpacking**.\n",
        "\n",
        "* `**data` captures **all named arguments** passed to the function as a `dict`.\n",
        "* Then, `{ \"ok\": True, **data }` merges that dict into a new one.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”§ Example in Use:\n",
        "\n",
        "```python\n",
        "return ok(message=\"Plan complete\", steps=plan_steps, next_tool=\"summarize\")\n",
        "```\n",
        "\n",
        "Behind the scenes, that call becomes:\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"ok\": True,\n",
        "    \"message\": \"Plan complete\",\n",
        "    \"steps\": [...],\n",
        "    \"next_tool\": \"summarize\"\n",
        "}\n",
        "```\n",
        "\n",
        "No need to define or update a rigid result schema every time you change what a tool returns.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”„ Why Is This Useful in Agents?\n",
        "\n",
        "Because agent tools **return different kinds of success data**, and you want a **single success wrapper** that doesnâ€™t care what those details are.\n",
        "\n",
        "For example:\n",
        "\n",
        "* A planning tool might return:\n",
        "  `steps`, `next_tool`, `summary`\n",
        "* A file-reading tool might return:\n",
        "  `content`, `path`, `num_lines`\n",
        "* A summarizer might return:\n",
        "  `summary`, `tokens_used`, `raw_prompt`\n",
        "\n",
        "But every one of them can just say:\n",
        "\n",
        "```python\n",
        "return ok(whatever_key=whatever_value)\n",
        "```\n",
        "\n",
        "â€¦and itâ€™ll be uniformly shaped like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"ok\": true,\n",
        "  ...\n",
        "}\n",
        "```\n",
        "\n",
        "Which means:\n",
        "\n",
        "* The orchestrator can just check `result[\"ok\"]` âœ…\n",
        "* It doesnâ€™t need to know or care what else is in the payload â€” that's the tool's business\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Why Not Just Return Raw Dicts?\n",
        "\n",
        "You *could* do:\n",
        "\n",
        "```python\n",
        "return {\"summary\": ..., \"tokens_used\": ...}\n",
        "```\n",
        "\n",
        "But then:\n",
        "\n",
        "* You have **no consistent success/failure signal**\n",
        "* Every downstream function has to **guess whatâ€™s in the result**\n",
        "* You lose the ability to layer in **logging, retry logic, or AI reasoning** safely\n",
        "\n",
        "`ok(**data)` ensures every result is **structured, semantically tagged**, and **agent-friendly**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§ª Bonus: Validating with Schema (Optional)\n",
        "\n",
        "Later on, if you want to enforce expected outputs per tool, you can add something like:\n",
        "\n",
        "```python\n",
        "def ok(schema=None, **data):\n",
        "    if schema:\n",
        "        validate(instance=data, schema=schema)\n",
        "    return {\"ok\": True, **data}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| Concept                | What It Does                                 |\n",
        "| ---------------------- | -------------------------------------------- |\n",
        "| `**data` in `ok()`     | Accepts arbitrary named return values        |\n",
        "| `{\"ok\": True, **data}` | Uniform success shape, customizable per tool |\n",
        "| Benefit                | Flexibility + consistency â€” ideal for agents |\n",
        "| Why use it?            | Keeps agent scaffolds simple, clean, robust  |\n",
        "\n",
        "This is an intentional design pattern â€” a foundational brick in agent infrastructure.\n",
        "\n"
      ],
      "metadata": {
        "id": "5E1EkoJYD6Mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Both of these are **flexible result factories** that take any keyword arguments and return a predictable, agent-friendly shape.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Whatâ€™s Happening Under the Hood?\n",
        "\n",
        "### 1. `ok(**data)`\n",
        "\n",
        "This accepts **any number of named keyword arguments**, e.g.:\n",
        "\n",
        "```python\n",
        "ok(message=\"File saved\", path=\"output.txt\", size_kb=42)\n",
        "```\n",
        "\n",
        "Internally:\n",
        "\n",
        "```python\n",
        "data = {\"message\": \"File saved\", \"path\": \"output.txt\", \"size_kb\": 42}\n",
        "return {\"ok\": True, **data}\n",
        "```\n",
        "\n",
        "Result:\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"ok\": True,\n",
        "  \"message\": \"File saved\",\n",
        "  \"path\": \"output.txt\",\n",
        "  \"size_kb\": 42\n",
        "}\n",
        "```\n",
        "\n",
        "No need to predefine what â€œsuccessâ€ includes. Each tool defines what matters for its own domain.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `err(msg, hint=None, retryable=False, **extra)`\n",
        "\n",
        "You have three â€œcoreâ€ arguments (`msg`, `hint`, `retryable`) â€” and then anything else via `**extra`.\n",
        "\n",
        "This allows you to tack on **diagnostics, debug values, tracebacks, metadata, etc.** without changing the functionâ€™s signature.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "err(\"File too large\", hint=\"Try a smaller file\", retryable=True, path=\"huge.pdf\", size_mb=300)\n",
        "```\n",
        "\n",
        "Internally:\n",
        "\n",
        "```python\n",
        "extra = {\"path\": \"huge.pdf\", \"size_mb\": 300}\n",
        "out = {\n",
        "  \"ok\": False,\n",
        "  \"error\": \"File too large\",\n",
        "  \"retryable\": True,\n",
        "  \"hint\": \"Try a smaller file\",\n",
        "  \"path\": \"huge.pdf\",\n",
        "  \"size_mb\": 300\n",
        "}\n",
        "```\n",
        "\n",
        "So `err()` is just as flexible, but with a stronger opinion about required + optional base fields (`error`, `retryable`, etc).\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ TL;DR\n",
        "\n",
        "| Function                                        | Purpose                               | Flexibility                                       |\n",
        "| ----------------------------------------------- | ------------------------------------- | ------------------------------------------------- |\n",
        "| `ok(**data)`                                    | Standardize **successful** results    | Arbitrary fields allowed                          |\n",
        "| `err(msg, hint=None, retryable=False, **extra)` | Standardize **failures** with context | Arbitrary metadata allowed (e.g. `tool`, `input`) |\n",
        "\n",
        "Both use `**kwargs` to future-proof your agent tools.\n",
        "\n",
        "So yes â€” you can always add more fields **without rewriting the return logic**.\n",
        "\n"
      ],
      "metadata": {
        "id": "ViT40aipG45t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The `ok=True` or `ok=False` is **explicitly set** inside the `ok()` and `err()` functions â€” it doesnâ€™t infer it or guess. Youâ€™re declaring whether a result was successful or not.\n",
        "\n",
        "Hereâ€™s exactly how:\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ The `ok()` Function\n",
        "\n",
        "```python\n",
        "def ok(**data):\n",
        "    return {\"ok\": True, **data}\n",
        "```\n",
        "\n",
        "* This always builds a dictionary where `ok` is set to `True`.\n",
        "* No logic or guessing â€” **it hardcodes success** into the result.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ The `err()` Function\n",
        "\n",
        "```python\n",
        "def err(msg, hint=None, retryable=False, **extra):\n",
        "    out = {\"ok\": False, \"error\": msg, \"retryable\": retryable}\n",
        "    if hint:\n",
        "        out[\"hint\"] = hint\n",
        "    if extra:\n",
        "        out.update(extra)\n",
        "    return out\n",
        "```\n",
        "\n",
        "* This always sets `\"ok\": False`, and includes a mandatory `\"error\"` message.\n",
        "* Youâ€™re declaring that something went wrong, optionally telling the agent:\n",
        "\n",
        "  * whether it's retryable,\n",
        "  * how to fix it (`hint`),\n",
        "  * any extra diagnostics.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ” How Does the Agent Use It?\n",
        "\n",
        "Your agent (like `ScriptedAgent`, `Environment`, or your tool orchestration logic) **checks the `ok` field** in the result dictionary:\n",
        "\n",
        "```python\n",
        "result = some_tool(ctx, input)\n",
        "if not result[\"ok\"]:\n",
        "    log_error(result[\"error\"])\n",
        "    maybe_retry()\n",
        "else:\n",
        "    proceed_to_next_step()\n",
        "```\n",
        "\n",
        "So this flag is **used by your agent as the official signal**:\n",
        "\n",
        "* `\"ok\": True` â†’ âœ… move forward\n",
        "* `\"ok\": False` â†’ âš ï¸ handle failure\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Recap\n",
        "\n",
        "| Function       | What it returns                                        |\n",
        "| -------------- | ------------------------------------------------------ |\n",
        "| `ok(...)`      | `{\"ok\": True, ...}` â€” hardcoded success                |\n",
        "| `err(...)`     | `{\"ok\": False, \"error\": ..., ...}` â€” hardcoded failure |\n",
        "| Agent behavior | Looks at `result[\"ok\"]` to decide what to do next      |\n",
        "\n",
        "So it's never inferred â€” **you always set it on purpose**, and your agent logic treats it as the signal for success or failure.\n",
        "\n"
      ],
      "metadata": {
        "id": "BowWTtMZHXEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ FILESYSTEM ADAPTER (for underscore-DI: _fs)                                  â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# RealFS exposes .path/.makedirs/.open so tools can accept a pluggable FS.\n",
        "class RealFS:\n",
        "    path = os.path\n",
        "    makedirs = staticmethod(os.makedirs)\n",
        "    open = staticmethod(builtins.open)\n"
      ],
      "metadata": {
        "id": "5SBqWaU9ErOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ” So What Does `RealFS` Do?\n",
        "\n",
        "It exposes just **three key things**:\n",
        "\n",
        "| Attribute  | What It Does                                                      |\n",
        "| ---------- | ----------------------------------------------------------------- |\n",
        "| `path`     | Access to file path utilities (`join`, `exists`, `basename`, etc) |\n",
        "| `makedirs` | Creates directories (`os.makedirs(...)`)                          |\n",
        "| `open`     | Opens files for reading/writing (`open(\"file.txt\", \"r\")`)         |\n",
        "\n",
        "And it does this in a way that makes the file system **pluggable**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”Œ Why Make a Filesystem Adapter?\n",
        "\n",
        "Most tools in your agent scaffold will eventually read from or write to files â€” logs, scratchpads, cached results, plans, etc.\n",
        "\n",
        "But:\n",
        "\n",
        "* In dev: you want them to write to your local drive.\n",
        "* In prod: maybe a virtual FS, cloud blob, memory, or sandboxed container.\n",
        "* In tests: maybe just a dummy memory store.\n",
        "\n",
        "Instead of hardcoding `open(...)`, `os.makedirs(...)`, `os.path...` inside your tools, you abstract the FS into an injectable component:\n",
        "\n",
        "```python\n",
        "_fs = RealFS  # Or replace with InMemoryFS, SecureFS, etc\n",
        "```\n",
        "\n",
        "Then your tools use `_fs.open`, `_fs.makedirs`, `_fs.path.exists`, etc.\n",
        "\n",
        "Thatâ€™s **dependency injection** (DI) â€” the â€œunderscore-DIâ€ mentioned in the comment.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  The Underscore Prefix: `_fs`, `_memory`, `_tools`, `_plan`, `_goal`, etc.\n",
        "\n",
        "### âœ… Itâ€™s a **Signal to the LLM**\n",
        "\n",
        "In the prompt (or runtime context), underscore-prefixed variables:\n",
        "\n",
        "* Are not just *arbitrary variables*.\n",
        "* Theyâ€™re **core tools**, **resources**, or **system inputs** meant for the LLM to use.\n",
        "* The underscore acts as a **semantic flag**:\n",
        "  ğŸ‘‰ *\"This is a pluggable utility or scaffold component you can call.\"*\n",
        "\n",
        "### ğŸ§­ It Helps the LLM Decide:\n",
        "\n",
        "> â€œIf I want to read a file, I should use `_fs.open(...)`, not invent my own method.â€\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“¦ Why It Works So Well\n",
        "\n",
        "By consistently using underscore names for LLM-facing tools:\n",
        "\n",
        "* You **reduce confusion** about whatâ€™s user-data vs system-responsibility\n",
        "* You give the LLM a **vocabulary of known interfaces**\n",
        "* You make the prompt context **self-documenting**\n",
        "\n",
        "So instead of:\n",
        "\n",
        "```python\n",
        "memory = MemoryStorage()\n",
        "plan = TaskPlanner()\n",
        "```\n",
        "\n",
        "You do:\n",
        "\n",
        "```python\n",
        "_memory = MemoryStorage()\n",
        "_plan = TaskPlanner()\n",
        "```\n",
        "\n",
        "Now the LLM knows:\n",
        "\n",
        "> \"Oh â€” `_plan` is the thing I use to ask for the next step.\"\n",
        "> \"I donâ€™t need to reason about *how* it works â€” I just *use* it.\"\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ› ï¸ Why This Is Genius in the Agent Scaffold\n",
        "\n",
        "It aligns with:\n",
        "\n",
        "| Design Principle         | Benefit                                                                 |\n",
        "| ------------------------ | ----------------------------------------------------------------------- |\n",
        "| **Dependency Injection** | You can swap `_fs` with a fake or secure version                        |\n",
        "| **Prompt Shaping**       | The LLM sees `_fs`, `_memory`, `_goal`, `_tools` and learns the pattern |\n",
        "| **Semantic Clarity**     | Humans and LLMs both instantly recognize whatâ€™s usable                  |\n",
        "| **LLM Empowerment**      | You reduce hallucination by providing real handles it can call          |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| Underscore Prefix                   | Signals to LLM: \"This is yours to use\"  |\n",
        "| ----------------------------------- | --------------------------------------- |\n",
        "| `_fs`, `_tools`, `_memory`, `_plan` | Agent-facing capabilities               |\n",
        "| `_goal`, `_ctx`, `_input`           | LLM-readable input variables            |\n",
        "| Convention                          | Clarifies intent + improves reliability |\n",
        "\n",
        "This is what makes your agent scaffold **LLM-native**: the code is shaped to speak the LLMâ€™s language from the start.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qcSCeKhbJVLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ MEMORY & CONTEXT                                                             â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "class ScratchMemory:\n",
        "    \"\"\"Minimal in-memory key/value store for agent state.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "\n",
        "    def get(self, key, default=None):   # default added for convenience\n",
        "        return self.store.get(key, default)\n",
        "\n",
        "    def set(self, key, value):\n",
        "        self.store[key] = value"
      ],
      "metadata": {
        "id": "gai5qGtkJfGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ§  What Is `ScratchMemory`?\n",
        "\n",
        "This memory type is designed to be:\n",
        "\n",
        "* **Temporary**\n",
        "* **In-memory (non-persistent)**\n",
        "* **Lightweight and fast**\n",
        "* **Swappable later with something richer**\n",
        "\n",
        "Think of it as a **â€œscratchpadâ€** for the agent â€” where it keeps:\n",
        "\n",
        "| Info Type            | Example                                |\n",
        "| -------------------- | -------------------------------------- |\n",
        "| Short-term state     | Current task, step count, partial plan |\n",
        "| Intermediate results | Cached output, retry flags             |\n",
        "| Contextual bookmarks | â€œWhere was I in the tool sequence?â€    |\n",
        "\n",
        "This is **not** a place to store chat history, long-term user profiles, or RAG embeddings. Itâ€™s meant for **step-to-step execution logic** inside a single agent run.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“¦ Why Include It in the Final Agent?\n",
        "\n",
        "While you may *upgrade* later (to Redis, a DB, or LLM-context memory), you should **absolutely** include *some* memory interface from day one.\n",
        "\n",
        "Reasons:\n",
        "\n",
        "1. **Agent tools often need shared state** (e.g., whatâ€™s the input file name? Did we already search?)\n",
        "2. The agent itself might need to store planning checkpoints, retries, or signals.\n",
        "3. `ScratchMemory` provides a **default that works everywhere**: dev, CLI, tests, cloud.\n",
        "4. Itâ€™s **fully compatible** with the DI scaffold pattern (`_memory = ScratchMemory()`)\n",
        "\n",
        "So yes â€” itâ€™s **valid and useful in a final agent**, especially if:\n",
        "\n",
        "* Your use case doesnâ€™t need persistent memory,\n",
        "* Or you want a fallback/default config,\n",
        "* Or youâ€™re prototyping quickly and cleanly.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”„ Future Upgrades\n",
        "\n",
        "Eventually, you might replace it with something like:\n",
        "\n",
        "| Replacement                              | When to use                                    |\n",
        "| ---------------------------------------- | ---------------------------------------------- |\n",
        "| `RedisMemory`, `DictMemory`, `SQLMemory` | For multi-agent setups or parallel tasking     |\n",
        "| `VectorMemory` or `ContextualMemory`     | For LLM-augmented recall, RAG, semantic lookup |\n",
        "| `FileMemory`                             | If you want to save/load session state         |\n",
        "\n",
        "But critically, they all implement the **same interface**:\n",
        "\n",
        "```python\n",
        "_memory.get(key)\n",
        "_memory.set(key, value)\n",
        "```\n",
        "\n",
        "So the switch is seamless.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| Feature         | Value                                                    |\n",
        "| --------------- | -------------------------------------------------------- |\n",
        "| `ScratchMemory` | Temporary state store for runtime use                    |\n",
        "| Purpose         | Keep track of agent context, progress, or partial output |\n",
        "| Final Use       | âœ… Yes, suitable as default or fallback memory            |\n",
        "| Why Useful      | Enables planning, retries, dynamic context sharing       |\n",
        "| Upgrade Path    | Replace with persistent/semantic memory if needed        |\n",
        "\n"
      ],
      "metadata": {
        "id": "Ectr5QyXK_Fc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Standardization = reduced cognitive load = better LLM performance.**\n",
        "\n",
        "Hereâ€™s what that means in practice:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Why Standardizing Memory (even if it's minimal) Helps the LLM\n",
        "\n",
        "| Without Standardization                     | With `ScratchMemory` or similar                                       |\n",
        "| ------------------------------------------- | --------------------------------------------------------------------- |\n",
        "| LLM doesnâ€™t know how to store/retrieve data | LLM sees `_memory.get(...)`, `_memory.set(...)` and knows the pattern |\n",
        "| May invent variable names or forget keys    | Can rely on known structure                                           |\n",
        "| Canâ€™t coordinate state across tools         | Can persist `step_count`, `task_status`, `intermediate_result`, etc   |\n",
        "| Higher hallucination risk                   | Lower â€” uses grounded handles to interact with memory                 |\n",
        "| Hard to test/replace                        | Easy to upgrade memory system behind the scenes                       |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” Reusability Across Agents\n",
        "\n",
        "By exposing memory as `_memory`, and giving it just two methods:\n",
        "\n",
        "* `.get(key)`\n",
        "* `.set(key, value)`\n",
        "\n",
        "You unlock:\n",
        "\n",
        "* **Consistent tool behavior**\n",
        "* **Easier debug/testing**\n",
        "* **Plug-and-play upgrades**\n",
        "\n",
        "The LLM doesnâ€™t need to reason about where data is stored â€” just what key to use. Same as with `_fs`, `_tools`, `_ctx`.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© Your Agent Scaffold Is Composable\n",
        "\n",
        "Thatâ€™s what makes your scaffold **LLM-native** and **developer-ergonomic** at the same time:\n",
        "\n",
        "* Simple for the LLM to use\n",
        "* Flexible for you to build on\n",
        "* Safe to upgrade under the hood\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5_2qcxQxLek5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Valid progress states for centralized logging.\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}"
      ],
      "metadata": {
        "id": "kFm7Atf0LDU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line is a **tiny piece of standardization** with outsized value:\n",
        "\n",
        "```python\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "```\n",
        "\n",
        "Letâ€™s break down why it matters and how it helps your agent work better.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” What It Does\n",
        "\n",
        "This defines the **allowed values** for logging or tracking an agentâ€™s **progress status**:\n",
        "\n",
        "| Status        | Meaning                                       |\n",
        "| ------------- | --------------------------------------------- |\n",
        "| `\"started\"`   | Agent or tool began executing a task or step  |\n",
        "| `\"completed\"` | The step/task succeeded                       |\n",
        "| `\"error\"`     | The step/task failed (ideally with a message) |\n",
        "\n",
        "Itâ€™s used to **validate or annotate** the state of progress during execution. For example:\n",
        "\n",
        "```python\n",
        "track_progress(\"create_plan\", \"started\")\n",
        "...\n",
        "track_progress(\"create_plan\", \"completed\")\n",
        "```\n",
        "\n",
        "Or, if something failed:\n",
        "\n",
        "```python\n",
        "track_progress(\"search_file\", \"error\", hint=\"File not found\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Why This Matters\n",
        "\n",
        "### 1. ğŸ§  **Helps the LLM Know What Language to Use**\n",
        "\n",
        "The LLM doesnâ€™t need to guess what progress status to return â€” it sees the canonical set.\n",
        "\n",
        "Less guesswork â†’ more reliability.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. ğŸ“Š **Supports Centralized Logging / Debugging**\n",
        "\n",
        "Standardized values let you:\n",
        "\n",
        "* Generate status dashboards\n",
        "* Show agent timelines (step â†’ status)\n",
        "* Run metrics like success rate or error type frequency\n",
        "\n",
        "---\n",
        "\n",
        "### 3. âš ï¸ **Catches Mistakes Early**\n",
        "\n",
        "If a tool tries to log an unsupported status like `\"running\"` or `\"donezo\"`, it can be caught and flagged.\n",
        "\n",
        "This guards against drift or malformed entries.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. ğŸ” **Enables Retry Logic or Progress Tracking**\n",
        "\n",
        "Letâ€™s say a tool failed and logged `\"error\"` â€” your orchestrator might check for that and decide to retry with a different tool or modified input.\n",
        "\n",
        "So this kind of structure makes **control flow more deterministic**.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| What It Is     | Enum-like set of allowed status values         |\n",
        "| -------------- | ---------------------------------------------- |\n",
        "| Why It Exists  | Standardizes step logging across tools         |\n",
        "| Who Uses It    | `track_progress()` and the orchestrator        |\n",
        "| LLM Benefit    | Less hallucination; follows known pattern      |\n",
        "| System Benefit | Easier logging, debugging, retries, dashboards |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hCz8PO6EL1Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActionContext:\n",
        "    \"\"\"\n",
        "    The agent's 'backpack':\n",
        "      - memory: state across steps\n",
        "      - llm:    LLM wrapper\n",
        "      - config: runtime configuration (folders, knobs)\n",
        "      - deps:   injectable dependencies (e.g., fs/clock)\n",
        "    \"\"\"\n",
        "    def __init__(self, memory, llm, config=None, deps=None):\n",
        "        self.memory = memory\n",
        "        self.llm = llm\n",
        "        self.config = config or {}\n",
        "        self.deps = deps or {}\n",
        "\n",
        "    # --- progress helpers ---\n",
        "    def track_progress(self, step, status, note=\"\"):\n",
        "        if status not in VALID_STATUSES:\n",
        "            raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        log.append({\n",
        "            \"step\": step,\n",
        "            \"status\": status,\n",
        "            \"note\": note,\n",
        "            \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        })\n",
        "        self.memory.set(\"progress_log\", log)\n",
        "\n",
        "    def print_progress(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        print(\"\\nğŸ“Š Progress Log:\")\n",
        "        for e in log:\n",
        "            t = f\" ({e.get('time')})\" if e.get(\"time\") else \"\"\n",
        "            note = f\" â€” {e['note']}\" if e.get(\"note\") else \"\"\n",
        "            print(f\"- [{e['status']}] {e['step']}{t}{note}\")\n",
        "\n",
        "    def last_completed_step(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in reversed(log):\n",
        "            if e.get(\"status\") == \"completed\":\n",
        "                return e.get(\"step\")\n",
        "        return None\n",
        "\n",
        "    def first_error(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in log:\n",
        "            if e.get(\"status\") == \"error\":\n",
        "                return e\n",
        "        return None"
      ],
      "metadata": {
        "id": "Yeh5Xl8wL4pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ActionContext` is mostly **self-explanatory**, and that's **by design**. This is a **clean, centralized state carrier** â€” a.k.a., the agentâ€™s **backpack** or â€œruntime brain.â€ Letâ€™s break down its components and purpose:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’ `ActionContext` Overview\n",
        "\n",
        "```python\n",
        "class ActionContext:\n",
        "    \"\"\"\n",
        "    The agent's 'backpack':\n",
        "      - memory: state across steps\n",
        "      - llm:    LLM wrapper\n",
        "      - config: runtime configuration (folders, knobs)\n",
        "      - deps:   injectable dependencies (e.g., fs/clock)\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "This object is **passed to tools** (or used by the environment) to:\n",
        "\n",
        "1. Store + retrieve working state\n",
        "2. Access the LLM itself\n",
        "3. Read runtime config (like working dirs)\n",
        "4. Use injected dependencies like `_fs` or `_clock`\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”§ Constructor: How the Agent Gets Context\n",
        "\n",
        "```python\n",
        "def __init__(self, memory, llm, config=None, deps=None):\n",
        "    self.memory = memory\n",
        "    self.llm = llm\n",
        "    self.config = config or {}\n",
        "    self.deps = deps or {}\n",
        "```\n",
        "\n",
        "It sets up everything the agent will carry around while it's thinking and acting.\n",
        "\n",
        "All tools can then rely on:\n",
        "\n",
        "* `ctx.memory.get(\"key\")`\n",
        "* `ctx.llm.complete(...)`\n",
        "* `ctx.config.get(\"path\")`\n",
        "* `ctx.deps[\"_fs\"].open(...)`\n",
        "\n",
        "No global state. No magic. Everything passed in.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ˆ Progress Tracking Helpers\n",
        "\n",
        "This is a **built-in logbook** the agent can write to:\n",
        "\n",
        "```python\n",
        "def track_progress(self, step, status, note=\"\"): ...\n",
        "def print_progress(self): ...\n",
        "def last_completed_step(self): ...\n",
        "def first_error(self): ...\n",
        "```\n",
        "\n",
        "These methods:\n",
        "\n",
        "* Help tools or the environment **record progress**\n",
        "* Allow the agent to **pick up where it left off**\n",
        "* Allow you (the dev) to **debug at a glance**\n",
        "\n",
        "These make use of `VALID_STATUSES` for sanity and consistency.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Why It Matters for the LLM\n",
        "\n",
        "By standardizing access to memory, tools, and config like this, you allow the LLM to:\n",
        "\n",
        "| Without Context               | With `ActionContext`                                |\n",
        "| ----------------------------- | --------------------------------------------------- |\n",
        "| Guess where state is stored   | Use `.memory` for state                             |\n",
        "| Wonder how to talk to the LLM | Use `.llm.complete(...)`                            |\n",
        "| Not know how to log or resume | Use `.track_progress()` or `.last_completed_step()` |\n",
        "| Juggle globals or shared vars | Use `.deps` to cleanly access shared tools          |\n",
        "\n",
        "This **reduces ambiguity and hallucination**, and makes your scaffold **LLM-legible** â€” it always knows whatâ€™s available.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| Feature            | Description                                           |\n",
        "| ------------------ | ----------------------------------------------------- |\n",
        "| `memory`           | Shared scratch state                                  |\n",
        "| `llm`              | Wrapper to call the model                             |\n",
        "| `config`           | Runtime switches or paths                             |\n",
        "| `deps`             | Pluggable tools like `_fs`, `_clock`                  |\n",
        "| `track_progress()` | Centralized logging mechanism                         |\n",
        "| Design Goal        | Keep tools and agent modular, clean, and LLM-friendly |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yfTr3bbSM_06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ LLM WRAPPER                                                                 â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "class OpenAILLM:\n",
        "    def __init__(self, client, model=\"gpt-4o-mini\", temperature=0.2):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def complete(self, prompt, **kwargs):\n",
        "        temp = kwargs.get(\"temperature\", self.temperature)\n",
        "        resp = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temp,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "N3aXYUAcNGbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> **Why do we create an LLM wrapper instead of calling it directly?**\n",
        "\n",
        "Hereâ€™s the answer, broken down into **6 powerful benefits**:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§± 1. Abstraction: Hide Implementation Details\n",
        "\n",
        "The wrapper (`OpenAILLM`) acts as a **stable interface**, regardless of what API, client, or provider you're using.\n",
        "\n",
        "You could replace OpenAI with Claude, Mistral, Groq, local models â€” and the rest of your agent doesn't need to change.\n",
        "\n",
        "```python\n",
        "# Everywhere else in your code:\n",
        "response = ctx.llm.complete(prompt)\n",
        "\n",
        "# Only the wrapper knows how to call OpenAI, Anthropic, etc.\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## â™»ï¸ 2. Reusability & DRY Code\n",
        "\n",
        "Rather than repeating this in every tool:\n",
        "\n",
        "```python\n",
        "client.chat.completions.create(...temperature=0.2...)\n",
        "```\n",
        "\n",
        "You call:\n",
        "\n",
        "```python\n",
        "llm.complete(prompt)\n",
        "```\n",
        "\n",
        "This avoids copy-pasting config and logic all over your agent â€” **single source of truth**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ› 3. Centralized Config & Defaults\n",
        "\n",
        "Notice how the wrapper sets:\n",
        "\n",
        "```python\n",
        "model=\"gpt-4o-mini\"\n",
        "temperature=0.2\n",
        "```\n",
        "\n",
        "You could later:\n",
        "\n",
        "* Load these from `config.yml`\n",
        "* Override them per call with `llm.complete(prompt, temperature=0.9)`\n",
        "* Switch model versions globally with one change\n",
        "\n",
        "Thatâ€™s powerful when scaling agents.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ›¡ 4. Extend with Features Later (No Breaking Changes)\n",
        "\n",
        "Want to add:\n",
        "\n",
        "* Retry on rate limit?\n",
        "* Logging every prompt?\n",
        "* Token counting?\n",
        "* Streaming or stop tokens?\n",
        "\n",
        "You can add all that **inside the wrapper** without touching the rest of your agent.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "def complete(self, prompt, **kwargs):\n",
        "    log_prompt(prompt)\n",
        "    ...\n",
        "    return response\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  5. Make the LLM Interface LLM-Legible\n",
        "\n",
        "The call pattern becomes:\n",
        "\n",
        "```python\n",
        "response = ctx.llm.complete(\"Write a plan...\")\n",
        "```\n",
        "\n",
        "Thatâ€™s **clear, readable, and learnable** by the model itself. You donâ€™t want it to reason about HTTP headers and API chains.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§ª 6. Easy to Mock or Swap for Testing\n",
        "\n",
        "In tests, you can inject a dummy model:\n",
        "\n",
        "```python\n",
        "class DummyLLM:\n",
        "    def complete(self, prompt, **kwargs):\n",
        "        return \"This is a fake result\"\n",
        "```\n",
        "\n",
        "That makes unit testing tools or flows trivial â€” just plug in a fake LLM that returns static strings.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| Reason              | Benefit                                    |\n",
        "| ------------------- | ------------------------------------------ |\n",
        "| **Abstraction**     | Swap providers (OpenAI, Claude, etc)       |\n",
        "| **Centralization**  | One place to configure model + temperature |\n",
        "| **Maintainability** | Add logging, retry, validation easily      |\n",
        "| **Readability**     | `llm.complete(prompt)` is crystal clear    |\n",
        "| **Testability**     | Plug in a dummy for unit tests             |\n",
        "| **Scalability**     | Future-proof for advanced features         |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Pqm8ZHuNkzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: PLANNING                                                              â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def create_plan(ctx):\n",
        "    goal = ctx.memory.get(\"goal\")\n",
        "    if not goal:\n",
        "        return err(\"No goal provided (memory key 'goal' missing).\",\n",
        "                   hint=\"Set ctx.memory['goal'] before calling create_plan\")\n",
        "\n",
        "    prompt = f\"\"\"You are an expert task planner. Given the goal below, break it down into a clear, short list of steps.\n",
        "\n",
        "Goal: {goal}\n",
        "\n",
        "Respond ONLY with a numbered list, one step per line. No extra prose.\"\"\"\n",
        "    raw = ctx.llm.complete(prompt).strip()\n",
        "\n",
        "    # Prefer numbered steps like \"1. ...\", \"2) ...\"\n",
        "    numbered = re.findall(r'^\\s*(?:\\d+[\\).\\s-]+)\\s*(.+)$', raw, flags=re.M)\n",
        "\n",
        "    if numbered:\n",
        "        steps = numbered\n",
        "    else:\n",
        "        # Fallback to bullets like \"- ...\", \"* ...\", \"â€¢ ...\"\n",
        "        bullets = re.findall(r'^\\s*(?:[-*â€¢]\\s+)(.+)$', raw, flags=re.M)\n",
        "        steps = bullets if bullets else [ln.strip() for ln in raw.splitlines() if ln.strip()]\n",
        "\n",
        "    # Normalize: collapse spaces, trim punctuation, drop empties/dupes\n",
        "    clean_steps = []\n",
        "    seen = set()\n",
        "    for s in steps:\n",
        "        s = re.sub(r'\\s+', ' ', s).strip(' .')\n",
        "        if s and s.lower() not in seen:\n",
        "            seen.add(s.lower())\n",
        "            clean_steps.append(s)\n",
        "\n",
        "    if not clean_steps:\n",
        "        return err(\"Planner returned no steps.\",\n",
        "                   hint=\"Refine the goal or relax the parser constraints\")\n",
        "\n",
        "    ctx.memory.set(\"plan\", clean_steps)\n",
        "    # optional: match handbook wording\n",
        "    # ctx.memory.set(\"current_plan\", clean_steps)\n",
        "\n",
        "    return ok(message=\"Plan created from goal.\", steps=clean_steps)"
      ],
      "metadata": {
        "id": "c6JZTGV9SivL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ”§ Planning Tool\n",
        "\n",
        "Itâ€™s a **tool function** (aka a callable capability) that:\n",
        "\n",
        "* Takes a **goal** (from memory)\n",
        "* Sends it to the LLM in a prompt\n",
        "* Parses the LLMâ€™s response into a **clean list of plan steps**\n",
        "* Saves that plan back into memory (`ctx.memory[\"plan\"]`)\n",
        "* Returns a standardized result (`ok()` or `err()`)\n",
        "\n",
        "In essence:\n",
        "\n",
        "> ğŸ§  **â€œLLM, take this goal and give me a clean, step-by-step plan I can act on.â€**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¤– Why Is This Useful?\n",
        "\n",
        "### 1. **Gives the LLM a Focused Subtask**\n",
        "\n",
        "The LLM is no longer trying to plan, act, and think all at once. This tool lets it:\n",
        "\n",
        "> \"Only focus on planning â€” break down the goal into discrete steps.\"\n",
        "\n",
        "This **modularizes thinking**, which improves reliability and interpretability.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Makes Planning Explicit and Interpretable**\n",
        "\n",
        "By capturing the result as:\n",
        "\n",
        "```python\n",
        "ctx.memory[\"plan\"] = [step1, step2, step3, ...]\n",
        "```\n",
        "\n",
        "â€¦you now have a **clear, inspectable, iterable plan** that can be:\n",
        "\n",
        "* Reviewed\n",
        "* Altered by the user\n",
        "* Executed step by step\n",
        "* Logged and resumed\n",
        "\n",
        "This is a core feature of **structured agents**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Improves Prompt Control and Parsing**\n",
        "\n",
        "The LLM prompt is very tight:\n",
        "\n",
        "```text\n",
        "Respond ONLY with a numbered list, one step per line. No extra prose.\n",
        "```\n",
        "\n",
        "Then you add **regex-based cleanup**:\n",
        "\n",
        "```python\n",
        "re.findall(r'^\\s*(?:\\d+[\\).\\s-]+)\\s*(.+)$', raw)\n",
        "```\n",
        "\n",
        "This ensures you donâ€™t get prose, rambling, or hallucinated YAML. Itâ€™s a bulletproof way to get usable, repeatable structure.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Standardized Result Interface**\n",
        "\n",
        "By wrapping with `ok()` or `err()`, youâ€™re saying:\n",
        "\n",
        "| On Success           | On Failure                                   |\n",
        "| -------------------- | -------------------------------------------- |\n",
        "| âœ… â€œHere's your planâ€ | âŒ â€œHereâ€™s what went wrong and how to fix itâ€ |\n",
        "\n",
        "The LLM (or the environment) doesnâ€™t have to guess what happened. This improves **reliability and recoverability**.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Memory-Based Control Flow**\n",
        "\n",
        "By writing to `ctx.memory[\"plan\"]`, your environment can later do something like:\n",
        "\n",
        "```python\n",
        "plan = ctx.memory.get(\"plan\")\n",
        "for step in plan:\n",
        "    run_tool_for_step(step)\n",
        "```\n",
        "\n",
        "This enables **agent looping** and step-by-step execution â€” one of the key differences between a chat bot and an agent.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  How It Helps the LLM\n",
        "\n",
        "| Without This Tool                                                                    | With This Tool                                                 |\n",
        "| ------------------------------------------------------------------------------------ | -------------------------------------------------------------- |\n",
        "| LLM has to reason about goals, actions, retries, planning, and structure all at once | LLM is asked to do **one focused thing**: generate a step list |\n",
        "| May return unstructured paragraphs or misunderstood tasks                            | Returns a clean, parseable plan list                           |\n",
        "| No guarantee of usable output                                                        | Regex + normalization = predictable agent inputs               |\n",
        "| Harder to debug                                                                      | Errors (like â€œno goal foundâ€) are surfaced clearly and fixable |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "| Feature                | Why It Helps                                        |\n",
        "| ---------------------- | --------------------------------------------------- |\n",
        "| Tight prompt           | Steers the LLM toward usable structure              |\n",
        "| Memory access          | Makes the plan persistent and shared                |\n",
        "| Result standardization | Enables error handling and tool chaining            |\n",
        "| Text parsing           | Prevents hallucinated output or random formatting   |\n",
        "| Focused function       | Keeps the LLM â€œmentally scopedâ€ â€” one job at a time |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s4yr_RwISatZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: I/O (FILES)                                                           â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def read_txt_file(ctx, file_name):\n",
        "    base = os.path.abspath(ctx.config.get(\"input_folder\", \"\"))\n",
        "    path = os.path.abspath(os.path.join(base, file_name))\n",
        "    if not base or not path.startswith(base + os.sep):\n",
        "        return err(\"Path traversal blocked.\", retryable=False)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        return err(f\"File not found: {path}\",\n",
        "                   hint=\"Call list_txt_files to see available files\",\n",
        "                   retryable=True)\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    ctx.memory.set(\"file_name\", file_name)\n",
        "    ctx.memory.set(\"raw_text\", text)\n",
        "    return ok(message=\"File read successfully.\", length=len(text))\n",
        "\n",
        "\n",
        "# â”€â”€ Helper: list available .txt files (for JIT guidance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def list_txt_files(ctx):\n",
        "    base = ctx.config.get(\"input_folder\")\n",
        "    if not base:\n",
        "        return err(\"No input_folder in config.\", hint=\"Set ctx.config['input_folder']\")\n",
        "    if not os.path.isdir(base):\n",
        "        return err(f\"Input folder not found: {base}\", retryable=False)\n",
        "\n",
        "    files = sorted(f for f in os.listdir(base) if f.endswith(\".txt\"))\n",
        "    ctx.memory.set(\"available_txt_files\", files)  # optional: stash for UI/agent\n",
        "    return ok(message=f\"Found {len(files)} .txt files.\", files=files, count=len(files))\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: SUMMARIZATION                                                         â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def generate_summary_prompt(ctx, max_len=None):\n",
        "    text = ctx.memory.get(\"raw_text\")\n",
        "    if not text:\n",
        "        return err(\"No raw text found in memory.\",\n",
        "                   hint=\"Run read_txt_file before generate_summary_prompt\")\n",
        "    if max_len is None:\n",
        "        max_len = ctx.config.get(\"summary_max_chars\", 2000)\n",
        "\n",
        "    truncated = len(text) > max_len\n",
        "    short_text = text[:max_len]\n",
        "\n",
        "    ctx.memory.set(\"was_truncated\", truncated)\n",
        "    ctx.memory.set(\"source_length\", len(text))\n",
        "    ctx.memory.set(\"used_length\", len(short_text))\n",
        "    ctx.memory.set(\"summary_prompt\", f\"\"\"You are an expert technical writer.\n",
        "\n",
        "Summarize the following content into a set of clear, concise bullet points...\n",
        "\\\"\\\"\\\"{short_text}\\\"\\\"\\\"\n",
        "\n",
        "Summary:\"\"\")\n",
        "\n",
        "    return ok(message=\"Summary prompt created.\",\n",
        "              truncated=truncated, used=len(short_text), total=len(text),\n",
        "              prompt_preview=ctx.memory.get(\"summary_prompt\")[:600])\n",
        "\n",
        "\n",
        "def summarize(ctx):\n",
        "    prompt = ctx.memory.get(\"summary_prompt\")\n",
        "    if not prompt:\n",
        "        return err(\"No summary prompt found in memory.\",\n",
        "                   hint=\"Run generate_summary_prompt before summarize\")\n",
        "    response = ctx.llm.complete(prompt)\n",
        "    ctx.memory.set(\"summary\", response)\n",
        "    return ok(message=\"Summary completed.\", summary_preview=response[:1000])\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: OUTPUT                                                                â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def save_summary(ctx, out_name=None, _fs=os):\n",
        "    summary = ctx.memory.get(\"summary\")\n",
        "    if not summary:\n",
        "        return err(\"No summary in memory.\",\n",
        "                   hint=\"Run summarize before save_summary\")\n",
        "    out_dir = ctx.config.get(\"output_folder\")\n",
        "    if not out_dir:\n",
        "        return err(\"No output_folder in config.\",\n",
        "                   hint=\"Set ctx.config['output_folder']\")\n",
        "\n",
        "    _fs.makedirs(out_dir, exist_ok=True)\n",
        "    src = ctx.memory.get(\"file_name\", \"summary\")\n",
        "    root, _ = os.path.splitext(os.path.basename(src))\n",
        "    base = out_name or f\"{root}_summary.txt\"\n",
        "    path = _fs.path.join(out_dir, base)\n",
        "\n",
        "    with _fs.open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    ctx.memory.set(\"summary_path\", path)\n",
        "    return ok(message=\"Summary saved.\", path=path)"
      ],
      "metadata": {
        "id": "f7ndtqC-TGgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ§° FILE TOOLS: `read_txt_file` & `list_txt_files`\n",
        "\n",
        "### ğŸŸ© Good Design Features\n",
        "\n",
        "* **Path Traversal Protection**:\n",
        "\n",
        "  ```python\n",
        "  if not base or not path.startswith(base + os.sep):\n",
        "      return err(\"Path traversal blocked.\")\n",
        "  ```\n",
        "\n",
        "  Prevents LLMs from escaping the input folder. Excellent safety measure, especially for autonomous or semi-autonomous agents.\n",
        "\n",
        "* **File Existence Check**:\n",
        "  Clear error messages guide the LLM (or user) if a file doesnâ€™t exist.\n",
        "\n",
        "* **Memory-first Design**:\n",
        "  `file_name` and `raw_text` go into memory, making them accessible for downstream tools like summarization, without passing them around manually.\n",
        "\n",
        "* **Tool discoverability**:\n",
        "  `list_txt_files()` helps the LLM choose file names in a just-in-time fashion â€” good for chaining.\n",
        "\n",
        "### ğŸ¤– Agent Benefit\n",
        "\n",
        "Helps the LLM **stay safe, stay focused**, and avoid hallucinating filenames or file paths.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  SUMMARIZATION TOOLS: `generate_summary_prompt` + `summarize`\n",
        "\n",
        "### ğŸŸ© Good Design Features\n",
        "\n",
        "* **Prompt Truncation**:\n",
        "\n",
        "  ```python\n",
        "  text[:max_len]\n",
        "  ```\n",
        "\n",
        "  Prevents long texts from overflowing context window.\n",
        "\n",
        "* **Memory Priming**:\n",
        "  Stores useful metadata like:\n",
        "\n",
        "  * `\"was_truncated\"`\n",
        "  * `\"used_length\"`\n",
        "  * `\"summary_prompt\"`\n",
        "\n",
        "* **Prompt Template is Clear & Friendly**:\n",
        "\n",
        "  ```text\n",
        "  You are an expert technical writer...\n",
        "  Summarize the following content...\n",
        "  ```\n",
        "\n",
        "  This sort of system prompt gives the LLM clarity and tone.\n",
        "\n",
        "* **Two-Step Workflow**:\n",
        "  Separation of `generate_summary_prompt` and `summarize()` enables:\n",
        "\n",
        "  * Inspection\n",
        "  * Editing\n",
        "  * Reuse\n",
        "  * Retry with different prompts\n",
        "\n",
        "### ğŸ¤– Agent Benefit\n",
        "\n",
        "Improves **accuracy, customizability, and fail-safety** of summarization. You can reuse the summary prompt for multiple models or re-prompt if the summary wasnâ€™t satisfactory.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§¾ OUTPUT TOOL: `save_summary`\n",
        "\n",
        "### ğŸŸ© Good Design Features\n",
        "\n",
        "* **Filesystem Injection**:\n",
        "  `_fs=os` allows for **mocking**, **virtual filesystems**, or switching to cloud storage without rewriting code.\n",
        "\n",
        "* **Smart Output Naming**:\n",
        "\n",
        "  ```python\n",
        "  base = out_name or f\"{root}_summary.txt\"\n",
        "  ```\n",
        "\n",
        "  Automatically creates descriptive filenames if none are provided.\n",
        "\n",
        "* **Error Handling for Config**:\n",
        "  Ensures `output_folder` is set before saving.\n",
        "\n",
        "* **Memory Stashing**:\n",
        "  Stores `summary_path` in memory, so follow-up steps or UI can show download links.\n",
        "\n",
        "### ğŸ¤– Agent Benefit\n",
        "\n",
        "Ensures **reliable outputs**, can be extended easily (PDF, Markdown, etc), and keeps the result accessible in `ctx.memory`.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ¨ BONUS IDEAS (for the future)\n",
        "\n",
        "Here are **features you could add** if you want to grow the toolkit:\n",
        "\n",
        "| Feature                                                      | Add To                            |\n",
        "| ------------------------------------------------------------ | --------------------------------- |\n",
        "| Token usage count                                            | `summarize()` or `llm.complete()` |\n",
        "| Retry on failed summarization                                | `summarize()`                     |\n",
        "| Metadata report (e.g. file name, word count, summary length) | `save_summary()`                  |\n",
        "| Switchable formats (Markdown/PDF)                            | `save_summary()`                  |\n",
        "| Embedding or vector store logging                            | `read_txt_file()`                 |\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary of Strengths\n",
        "\n",
        "| Design Strength             | Why It Matters                                                  |\n",
        "| --------------------------- | --------------------------------------------------------------- |\n",
        "| Memory-based I/O            | Everything flows through memory â€” consistent access for tools   |\n",
        "| Truncation & parsing        | Prevents LLM failure from long inputs                           |\n",
        "| Friendly prompt scaffolding | Makes agent behavior more consistent                            |\n",
        "| Error handling              | Helps LLMs recover or retry from mistakes                       |\n",
        "| Modular steps               | Makes the pipeline inspectable, testable, and override-friendly |\n",
        "\n"
      ],
      "metadata": {
        "id": "FrEJnHa1Njot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOL REGISTRY â€” TYPES & REGISTRATION                                         â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable\n",
        "\n",
        "@dataclass\n",
        "class ToolDef:\n",
        "    name: str\n",
        "    func: Callable\n",
        "    description: str = \"\"\n",
        "    schema: dict | None = None\n",
        "    returns: dict | None = None   # optional metadata about outputs\n",
        "\n",
        "class ToolRegistry:\n",
        "    def __init__(self):\n",
        "        self._tools = {}\n",
        "\n",
        "    def register(self, tool: ToolDef):\n",
        "        self._tools[tool.name] = tool\n",
        "\n",
        "    def get(self, name: str) -> ToolDef:\n",
        "        if name not in self._tools:\n",
        "            raise KeyError(f\"Unknown tool: {name}\")\n",
        "        return self._tools[name]\n",
        "\n",
        "    def list(self):\n",
        "        return list(self._tools.keys())\n",
        "\n",
        "# -- Build registry -------------------------------------------------------------\n",
        "registry = ToolRegistry()\n",
        "\n",
        "registry.register(ToolDef(\n",
        "    \"create_plan\",\n",
        "    create_plan,\n",
        "    \"Create a plan from goal\",\n",
        "    schema={ \"type\": \"object\", \"properties\": {}, \"required\": [] },   # no kwargs\n",
        "    returns={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"message\": { \"type\": \"string\" },\n",
        "            \"steps\":   { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n",
        "        },\n",
        "        \"required\": [\"message\", \"steps\"]\n",
        "    }\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"read_txt_file\", read_txt_file, \"Read a .txt file from input_folder\",\n",
        "  schema={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "    \"required\": [\"file_name\"]\n",
        "  },\n",
        "  returns={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"message\": {\"type\": \"string\"}, \"length\": {\"type\": \"integer\"}},\n",
        "    \"required\": [\"message\"]\n",
        "  },\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "    \"list_txt_files\",\n",
        "    list_txt_files,\n",
        "    \"List .txt files in input_folder\",\n",
        "    schema={ \"type\": \"object\", \"properties\": {}, \"required\": [] },\n",
        "    returns={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"ok\":    { \"type\": \"boolean\" },\n",
        "            \"message\": { \"type\": \"string\" },\n",
        "            \"files\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n",
        "            \"count\": { \"type\": \"integer\" }\n",
        "        },\n",
        "        \"required\": [\"ok\", \"files\"]\n",
        "    }\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"generate_summary_prompt\", generate_summary_prompt, \"Build a summarization prompt\",\n",
        "  schema={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"max_len\": {\"type\": \"integer\", \"minimum\": 1}},\n",
        "    \"required\": []\n",
        "  }\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"summarize\", summarize, \"Run LLM summarization\",\n",
        "  schema={\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"save_summary\", save_summary, \"Persist summary to output_folder\",\n",
        "  schema={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"out_name\": {\"type\": \"string\"}},\n",
        "    \"required\": []\n",
        "  },\n",
        "))\n"
      ],
      "metadata": {
        "id": "VNC_3H_tTj3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Tool Registry** is one of the most important architectural components in your agent. It not only organizes your tools but also sets the stage for intelligent decision-making and tool use by the LLM. Here's a breakdown of what to focus on and why this matters:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Purpose of the Tool Registry\n",
        "\n",
        "The **Tool Registry** acts like the **agentâ€™s toolbox index** â€” it:\n",
        "\n",
        "1. **Catalogs all available tools** with their:\n",
        "\n",
        "   * Function reference\n",
        "   * Description (natural language)\n",
        "   * Input schema (JSON Schema)\n",
        "   * Output metadata (optional)\n",
        "\n",
        "2. **Provides structured, discoverable access** for agents or UIs to:\n",
        "\n",
        "   * List tools\n",
        "   * Validate tool parameters\n",
        "   * Present usage options to the LLM\n",
        "   * Integrate with planners or routers\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© Key Components\n",
        "\n",
        "### 1. `ToolDef` â€” the definition schema\n",
        "\n",
        "This is a **structured metadata container** for tools.\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class ToolDef:\n",
        "    name: str\n",
        "    func: Callable\n",
        "    description: str = \"\"\n",
        "    schema: dict | None = None\n",
        "    returns: dict | None = None\n",
        "```\n",
        "\n",
        "**Why this matters**:\n",
        "\n",
        "* Enables **decoupling** of logic from registry code.\n",
        "* Powers **UI introspection**, **LLM guidance**, and **validation**.\n",
        "* Helps build **OpenAI function calls** or **LangChain tools** dynamically.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `ToolRegistry` â€” the runtime registry\n",
        "\n",
        "Manages tools internally as a dictionary.\n",
        "\n",
        "```python\n",
        "class ToolRegistry:\n",
        "    def __init__(self):\n",
        "        self._tools = {}\n",
        "```\n",
        "\n",
        "With core methods:\n",
        "\n",
        "* `.register(tool)` â€” add new tool\n",
        "* `.get(name)` â€” fetch by name (with safety check)\n",
        "* `.list()` â€” show available tools\n",
        "\n",
        "**Why this matters**:\n",
        "\n",
        "* Adds **consistency** and **centralization** to tool handling.\n",
        "* Enables custom logic (e.g., search, filtering, categories).\n",
        "* Supports **dynamic tool loading** or plug-and-play systems.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. The Tool Registrations\n",
        "\n",
        "Youâ€™re registering tools with their schema, description, and return shape:\n",
        "\n",
        "```python\n",
        "registry.register(ToolDef(\n",
        "  \"create_plan\",\n",
        "  create_plan,\n",
        "  \"Create a plan from goal\",\n",
        "  schema={ ... },\n",
        "  returns={ ... }\n",
        "))\n",
        "```\n",
        "\n",
        "**Why this matters**:\n",
        "\n",
        "* Empowers LLMs to **choose valid tools** (via name + description).\n",
        "* Enables agents to **auto-check** arguments before calling tools.\n",
        "* Encourages **safe, testable, explainable behavior**.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Why the Registry Is Critical\n",
        "\n",
        "| Feature                | Benefit                                                                                      |\n",
        "| ---------------------- | -------------------------------------------------------------------------------------------- |\n",
        "| ğŸ§© **Modularity**      | Tools can be added/swapped without touching agent logic                                      |\n",
        "| ğŸ“š **Discoverability** | Agents (or UIs) can list & explain tools clearly                                             |\n",
        "| ğŸ” **Safety**          | Input schemas define what arguments are allowed                                              |\n",
        "| ğŸ§ª **Testing**         | Tools can be validated independently of the agent                                            |\n",
        "| ğŸ“ˆ **Extensibility**   | Enables future use of dynamic tool loading, plugin support, UI forms, or OpenAI tool calling |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  How It Helps the LLM\n",
        "\n",
        "When the LLM wants to decide what to do next:\n",
        "\n",
        "* It can query or reason over the tool list\n",
        "* It can infer what arguments are valid via `schema`\n",
        "* It can expect structured results via `returns`\n",
        "* If used in a **router-style agent**, the agent can show available tools as context\n",
        "\n",
        "This is how structured tool calling (like OpenAI's `function_calling` or LangChain's `Tool`) works under the hood.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k2nqY7cpUGQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ§  What `@dataclass` Does (and Why Itâ€™s Used Here)\n",
        "\n",
        "The `@dataclass` decorator in Python auto-generates a bunch of boilerplate code for classes that are **just containers for data**.\n",
        "\n",
        "### Normally, you'd write:\n",
        "\n",
        "```python\n",
        "class ToolDef:\n",
        "    def __init__(self, name, func, description=\"\", schema=None, returns=None):\n",
        "        self.name = name\n",
        "        self.func = func\n",
        "        self.description = description\n",
        "        self.schema = schema\n",
        "        self.returns = returns\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ToolDef(name={self.name!r}, ...)\"\n",
        "```\n",
        "\n",
        "### With `@dataclass`, all of that becomes:\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class ToolDef:\n",
        "    name: str\n",
        "    func: Callable\n",
        "    description: str = \"\"\n",
        "    schema: dict | None = None\n",
        "    returns: dict | None = None\n",
        "```\n",
        "\n",
        "### Benefits in this context:\n",
        "\n",
        "| Feature             | Why it matters here                                        |\n",
        "| ------------------- | ---------------------------------------------------------- |\n",
        "| ğŸ§¹ Less boilerplate | No need to write `__init__`, `__repr__`, `__eq__`, etc.    |\n",
        "| ğŸ“¦ Clarity          | Expresses intent: this class is **just** data              |\n",
        "| ğŸ“‹ Structure        | Easy to pass around in tool registration or introspection  |\n",
        "| ğŸ”„ Future-proofing  | If you want to serialize/compare/inspect tools, you're set |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Why Itâ€™s Only Used Here\n",
        "\n",
        "The other classes (like `ActionContext`, `ScratchMemory`, `ToolRegistry`, etc.) are **not just data containers** â€” they contain **behavior** (methods), and manage **mutable state**, so decorators like `@dataclass` would not add much value.\n",
        "\n",
        "Examples:\n",
        "\n",
        "* `ActionContext` has memory, logging, and utility methods â†’ it's an **operational object**\n",
        "* `ToolRegistry` stores a dynamic set of tools â†’ it's an **internal manager**\n",
        "* `OpenAILLM` wraps a client and runtime config â†’ it's a **service object**\n",
        "\n",
        "For those, using a decorator like `@dataclass` would be unnecessary or misleading.\n",
        "\n",
        "---\n",
        "\n",
        "Using the `@dataclass` decorator **avoids** repetitive boilerplate code like the example you just showed:\n",
        "\n",
        "```python\n",
        "class ToolDef:\n",
        "    def __init__(self, name, func, description=\"\", schema=None, returns=None):\n",
        "        self.name = name\n",
        "        self.func = func\n",
        "        self.description = description\n",
        "        self.schema = schema\n",
        "        self.returns = returns\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ToolDef(name={self.name!r}, ...)\"\n",
        "```\n",
        "\n",
        "Instead, with just:\n",
        "\n",
        "```python\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable\n",
        "\n",
        "@dataclass\n",
        "class ToolDef:\n",
        "    name: str\n",
        "    func: Callable\n",
        "    description: str = \"\"\n",
        "    schema: dict | None = None\n",
        "    returns: dict | None = None\n",
        "```\n",
        "\n",
        "You automatically get:\n",
        "\n",
        "* `__init__`\n",
        "* `__repr__`\n",
        "* `__eq__`\n",
        "* `__hash__` (optional)\n",
        "* `__asdict__()` (via `dataclasses.asdict()`)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§¼ Why This Matters\n",
        "\n",
        "* **Cleaner code** â†’ Less clutter, easier to read.\n",
        "* **Fewer bugs** â†’ Less manual copying of attribute names/values.\n",
        "* **Consistency** â†’ You donâ€™t forget to update `__init__` or `__repr__` when you change fields.\n",
        "* **Better tooling** â†’ IDEs and type checkers can infer structure more reliably.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… When to Use `@dataclass`\n",
        "\n",
        "Use it when your class:\n",
        "\n",
        "* Just holds **structured data**\n",
        "* Doesn't have significant **custom logic or mutable state**\n",
        "* Is passed around frequently (like config objects, data schemas, etc.)\n",
        "\n",
        "In your agent design, `ToolDef` is a perfect fit â€” itâ€™s basically a registration form for tools.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Summary\n",
        "\n",
        "* `@dataclass` is used **only** for **plain data holders**.\n",
        "* `ToolDef` is the only class in your codebase that qualifies.\n",
        "* This choice keeps your code **clean**, **intentional**, and **idiomatic**.\n",
        "* It's **not** about LLMs or agent architecture directly â€” just good Python design.\n"
      ],
      "metadata": {
        "id": "hzJvhagQU7-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ ENVIRONMENT â€” VALIDATION & EXECUTION                                         â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import inspect\n",
        "\n",
        "def _validate(schema, kwargs):\n",
        "    \"\"\"Minimal JSON-schema-ish validator for tool kwargs.\"\"\"\n",
        "    if not schema:\n",
        "        return None\n",
        "    missing = [k for k in schema.get(\"required\", []) if k not in kwargs]\n",
        "    if missing:\n",
        "        return f\"Missing required: {missing}\"\n",
        "    types = {\"string\": str, \"integer\": int, \"number\": (int, float), \"boolean\": bool}\n",
        "    for k, spec in (schema.get(\"properties\") or {}).items():\n",
        "        if k in kwargs and \"type\" in spec:\n",
        "            py_t = types.get(spec[\"type\"])\n",
        "            if py_t and not isinstance(kwargs[k], py_t):\n",
        "                return f\"Bad type for '{k}': expected {spec['type']}\"\n",
        "    return None\n",
        "\n",
        "class Environment:\n",
        "    \"\"\"Runs tools by name with auto-DI, validation, and centralized logging.\"\"\"\n",
        "    def __init__(self, ctx: ActionContext, registry: ToolRegistry):\n",
        "        self.ctx = ctx\n",
        "        self.registry = registry\n",
        "\n",
        "    def run(self, tool_name: str, **kwargs):\n",
        "        tool = self.registry.get(tool_name)\n",
        "        fn = tool.func\n",
        "        sig = inspect.signature(fn)\n",
        "\n",
        "        # 1) Schema validation BEFORE logging/exec\n",
        "        v_err = _validate(tool.schema, kwargs)\n",
        "        if v_err:\n",
        "            self.ctx.track_progress(tool.name, \"error\", note=v_err[:180])\n",
        "            return err(v_err)  # standardized envelope\n",
        "\n",
        "        # 2) Build call args with auto-DI (ctx + underscore deps)\n",
        "        call_args = {}\n",
        "        for pname, param in sig.parameters.items():\n",
        "            if pname == \"ctx\":\n",
        "                call_args[\"ctx\"] = self.ctx\n",
        "            elif pname.startswith(\"_\"):   # underscore dep, e.g. _fs, _clock\n",
        "                dname = pname[1:]\n",
        "                if dname not in self.ctx.deps:\n",
        "                    msg = f\"Missing dep '{dname}' for tool '{tool_name}'\"\n",
        "                    self.ctx.track_progress(tool.name, \"error\", note=msg[:180])\n",
        "                    return err(msg)\n",
        "                call_args[pname] = self.ctx.deps[dname]\n",
        "            else:\n",
        "                if pname in kwargs:\n",
        "                    call_args[pname] = kwargs[pname]\n",
        "                elif param.default is not inspect._empty:\n",
        "                    pass\n",
        "                else:\n",
        "                    msg = f\"Missing required arg '{pname}' for tool '{tool_name}'\"\n",
        "                    self.ctx.track_progress(tool.name, \"error\", note=msg[:180])\n",
        "                    return err(msg)\n",
        "\n",
        "        # 3) Log start, call tool\n",
        "        self.ctx.track_progress(tool.name, \"started\", note=str(kwargs))\n",
        "        try:\n",
        "            result = fn(**call_args)\n",
        "        except Exception as e:\n",
        "            # Normalize exceptions into err(...) so the agent can handle them\n",
        "            msg = f\"{type(e).__name__}: {e}\"\n",
        "            self.ctx.track_progress(tool.name, \"error\", note=msg[:180])\n",
        "            return err(msg)\n",
        "\n",
        "        # 4) Normalize + log outcome\n",
        "        if isinstance(result, dict):\n",
        "            # If tool used envelope:\n",
        "            if result.get(\"ok\") is False:\n",
        "                self.ctx.track_progress(tool.name, \"error\", note=str(result.get(\"error\", \"\"))[:180])\n",
        "                return result\n",
        "            # Back-compat: dict returned with \"error\" but no \"ok\"\n",
        "            if \"ok\" not in result and \"error\" in result:\n",
        "                self.ctx.track_progress(tool.name, \"error\", note=str(result[\"error\"])[:180])\n",
        "                return {\"ok\": False, **result}\n",
        "            # Success path: ensure ok=True for consistency\n",
        "            result = result if \"ok\" in result else {\"ok\": True, **result}\n",
        "            note = result.get(\"message\", \"\")[:120]\n",
        "            self.ctx.track_progress(tool.name, \"completed\", note=note)\n",
        "            return result\n",
        "\n",
        "        # Non-dict success (rare): mark completed with empty note\n",
        "        self.ctx.track_progress(tool.name, \"completed\", note=\"\")\n",
        "        return result"
      ],
      "metadata": {
        "id": "Hdp2yWYBUJuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block is **the brainstem of your agent execution system** â€” and also the most complex. Let's break it down into digestible parts, with **what it does**, **why it matters**, and **what you should focus on**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  What Is Environment Class?\n",
        "\n",
        "This is your **tool execution engine** â€” the `Environment` class. It's the core runtime that:\n",
        "\n",
        "* Validates input against schemas\n",
        "* Wires dependencies\n",
        "* Handles errors\n",
        "* Logs progress\n",
        "* Returns normalized output\n",
        "\n",
        "If the registry is your toolbox, this is the **tool operator** that picks up the right wrench and uses it correctly.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” Overview of Major Sections\n",
        "\n",
        "### 1. `_validate(schema, kwargs)`\n",
        "\n",
        "Validates inputs **before calling a tool**.\n",
        "\n",
        "* Mimics a mini JSON Schema validator.\n",
        "* Ensures required fields are present.\n",
        "* Checks types of parameters.\n",
        "\n",
        "âœ… **Why this helps**:\n",
        "\n",
        "* Catches simple user mistakes (e.g., missing \"file\\_name\").\n",
        "* Prevents LLMs from calling tools with bad arguments.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `Environment.run(...)` â€” THE MAIN EVENT\n",
        "\n",
        "#### ğŸ”¹ Step 1: Schema validation\n",
        "\n",
        "```python\n",
        "v_err = _validate(tool.schema, kwargs)\n",
        "if v_err:\n",
        "    self.ctx.track_progress(tool.name, \"error\", note=v_err[:180])\n",
        "    return err(v_err)\n",
        "```\n",
        "\n",
        "* Ensures arguments to the tool match expectations.\n",
        "* Fails fast if they're wrong.\n",
        "\n",
        "âœ… **Why it matters**:\n",
        "\n",
        "* Protects tools from crashing due to bad input.\n",
        "* Gives LLMs a consistent \"you messed up\" signal.\n",
        "\n",
        "---\n",
        "\n",
        "#### ğŸ”¹ Step 2: Build call arguments with **Auto-DI**\n",
        "\n",
        "```python\n",
        "for pname, param in sig.parameters.items():\n",
        "```\n",
        "\n",
        "This is where the magic happens. It uses Python's `inspect` module to:\n",
        "\n",
        "* Detect all the arguments a tool needs (`ctx`, `file_name`, `_fs`, etc).\n",
        "* Automatically inject:\n",
        "\n",
        "  * `ctx` (context)\n",
        "  * `deps` like `_fs` from `ctx.deps`\n",
        "  * `kwargs` from the caller\n",
        "\n",
        "âœ… **Why it matters**:\n",
        "\n",
        "* Makes tools easy to write â€” no need to manually wire dependencies.\n",
        "* Enforces standardization: tools should **expect** `ctx`, and **use** underscore-prefixed optional deps (`_fs`, `_clock`, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "#### ğŸ”¹ Step 3: Execution and Error Catching\n",
        "\n",
        "```python\n",
        "try:\n",
        "    result = fn(**call_args)\n",
        "except Exception as e:\n",
        "    ...\n",
        "    return err(msg)\n",
        "```\n",
        "\n",
        "âœ… **Why it matters**:\n",
        "\n",
        "* Prevents crashes and always returns a well-formed error envelope (`ok: False`).\n",
        "* Allows the LLM to recover or retry.\n",
        "\n",
        "---\n",
        "\n",
        "#### ğŸ”¹ Step 4: Output normalization\n",
        "\n",
        "```python\n",
        "if isinstance(result, dict):\n",
        "    if result.get(\"ok\") is False:\n",
        "        ...\n",
        "    elif \"ok\" not in result and \"error\" in result:\n",
        "        ...\n",
        "    else:\n",
        "        result = result if \"ok\" in result else {\"ok\": True, **result}\n",
        "```\n",
        "\n",
        "âœ… **Why it matters**:\n",
        "\n",
        "* Guarantees that every result has the same structure (`ok`, `error`, `message`, etc.).\n",
        "* Ensures agents can reason over responses without ambiguity.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ What You Should Focus On\n",
        "\n",
        "| Concept                           | Why It Matters                                       |\n",
        "| --------------------------------- | ---------------------------------------------------- |\n",
        "| **Schema Validation**             | Stops garbage input from reaching tools.             |\n",
        "| **Dependency Injection (DI)**     | Keeps tool code clean and flexible.                  |\n",
        "| **Standardized Result Envelopes** | Lets agents handle success/failure without guessing. |\n",
        "| **Progress Logging**              | Useful for both debugging and LLM self-awareness.    |\n",
        "| **Error Containment**             | Avoids unhandled crashes that break the loop.        |\n",
        "\n"
      ],
      "metadata": {
        "id": "RuPLt6ZxaGNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ SETUP & CONFIG                                                               â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "memory = ScratchMemory()\n",
        "memory.set(\"goal\", \"Summarize the content of a text file.\")\n",
        "\n",
        "config = {\n",
        "    \"input_folder\": \"/content/files\",\n",
        "    \"output_folder\": \"/content/output\",\n",
        "    # \"summary_max_chars\": 2400,  # optional\n",
        "}\n",
        "\n",
        "llm = OpenAILLM(\n",
        "    client,\n",
        "    model=config.get(\"model\", \"gpt-4o-mini\"),\n",
        "    temperature=config.get(\"temperature\", 0.2),\n",
        ")\n"
      ],
      "metadata": {
        "id": "T_wG2D2daR_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## âœ… What This Block Does\n",
        "\n",
        "This section initializes the **core components** your agent needs to run:\n",
        "\n",
        "| Component                  | Purpose                                                                                        |\n",
        "| -------------------------- | ---------------------------------------------------------------------------------------------- |\n",
        "| `memory = ScratchMemory()` | Creates a scratchpad for the agent's short-term memory (e.g. storing `goal`, `raw_text`, etc). |\n",
        "| `config = {...}`           | Provides runtime knobs and folders the agent tools will need (e.g. where to find files).       |\n",
        "| `llm = OpenAILLM(...)`     | Instantiates the LLM wrapper with client, model, and temperature.                              |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Why It Matters\n",
        "\n",
        "Think of this block as the **agentâ€™s environment setup** before you plug it into the `ActionContext` or `Environment`.\n",
        "\n",
        "It's like handing the agent its:\n",
        "\n",
        "* ğŸ§  **Memory**\n",
        "* ğŸ”§ **Configuration knobs**\n",
        "* ğŸ—£ï¸ **LLM interface**\n",
        "\n",
        "Without these, even the best tools and registries wouldnâ€™t know how or where to function.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” What to Focus On\n",
        "\n",
        "Hereâ€™s what deserves your attention as a developer/designer:\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `ScratchMemory()`\n",
        "\n",
        "* **Purpose**: Holds all in-flight values the agent needs during a run (e.g., `goal`, `summary`, `file_name`).\n",
        "* **Focus**: Make sure keys like `\"goal\"`, `\"plan\"`, `\"summary\"` are named clearly and used consistently across tools.\n",
        "* âœ… **Why itâ€™s flexible**: Itâ€™s just a dictionary under the hood â€” dead simple for experimentation or debugging.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `config = {...}`\n",
        "\n",
        "* **Purpose**: Stores global runtime settings.\n",
        "* **Focus**:\n",
        "\n",
        "  * Are all necessary folders and limits set?\n",
        "  * Does `input_folder` match your actual file structure?\n",
        "  * Consider exposing knobs like `summary_max_chars` for agent tuning.\n",
        "\n",
        "ğŸ§© This is where you configure **dynamic behavior without touching code**.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `llm = OpenAILLM(...)`\n",
        "\n",
        "* **Purpose**: Wraps the OpenAI client so the agent can generate completions easily.\n",
        "* **Focus**:\n",
        "\n",
        "  * Is the **model name** set properly (`gpt-4o`, etc)?\n",
        "  * Is the **temperature** appropriate for the task? (Low = factual, high = creative)\n",
        "  * Can this wrapper be easily swapped for Anthropic, local models, etc? (Hint: yes!)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© Summary\n",
        "\n",
        "| Area     | What You Should Double-Check                         |\n",
        "| -------- | ---------------------------------------------------- |\n",
        "| `memory` | Are all necessary values seeded correctly?           |\n",
        "| `config` | Are folders valid and tuned for your workflow?       |\n",
        "| `llm`    | Are the model + params aligned with your task goals? |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A-b5gP4uaqeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ CONTEXT & ENVIRONMENT                                                        â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Create context with DI bag pre-populated (fs adapter)\n",
        "ctx = ActionContext(memory=memory, llm=llm, config=config, deps={\"fs\": RealFS})\n",
        "\n",
        "# Ensure folders exist (lightweight guardrails)\n",
        "os.makedirs(ctx.config[\"input_folder\"], exist_ok=True)\n",
        "os.makedirs(ctx.config[\"output_folder\"], exist_ok=True)\n",
        "ctx.track_progress(\"setup\", \"completed\", \"goal + config injected\")\n",
        "\n",
        "# Build environment (validation + auto-DI + centralized logging)\n",
        "env = Environment(ctx, registry)\n"
      ],
      "metadata": {
        "id": "v6CSFp7AasvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a **critical section** â€” it's the bridge between *setup* and *execution*. Think of it as the moment your agent goes from being a set of disconnected tools to becoming a **self-aware operating unit**.\n",
        "\n",
        "Letâ€™s break it down so you know **exactly what to focus on** as a builder:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§± What This Block Does\n",
        "\n",
        "| Step                       | Purpose                                                                          |\n",
        "| -------------------------- | -------------------------------------------------------------------------------- |\n",
        "| `ctx = ActionContext(...)` | Binds all runtime components into one shared context for every tool.             |\n",
        "| `os.makedirs(...)`         | Ensures the I/O folders exist â€” a simple safety net.                             |\n",
        "| `ctx.track_progress(...)`  | Logs that setup succeeded â€” useful for audits and debugging.                     |\n",
        "| `env = Environment(...)`   | Instantiates the engine that runs tools, with validation + dependency injection. |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ What You Should Focus On\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `ActionContext(...)`\n",
        "\n",
        "This is your agentâ€™s **backpack**. It carries everything the tools need to do their jobs:\n",
        "\n",
        "* `memory`: Temporary working state (e.g., goals, raw text)\n",
        "* `llm`: The language model interface\n",
        "* `config`: Settings like folders or runtime knobs\n",
        "* `deps`: Injected low-level dependencies like filesystem access (`fs`)\n",
        "\n",
        "ğŸ” **Key detail**: You're injecting `RealFS` via the `deps={\"fs\": RealFS}` bag â€” this makes `_fs` in tools work automatically.\n",
        "\n",
        "âœ… **What to verify**:\n",
        "\n",
        "* Are all tools using `ctx.memory`, `ctx.config`, and `ctx.deps` properly?\n",
        "* Do you have a clear convention for what goes into `deps`? (e.g., clock, UUID, time, etc)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `os.makedirs(...)`\n",
        "\n",
        "These are **lightweight guardrails**. They make sure the folders your tools rely on wonâ€™t throw errors.\n",
        "\n",
        "âœ… **Check**:\n",
        "\n",
        "* Are `\"input_folder\"` and `\"output_folder\"` set correctly in `config`?\n",
        "* Are any default paths safe to use on your machine/cloud setup?\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `ctx.track_progress(...)`\n",
        "\n",
        "This logs that **setup is complete**, using the same standardized progress tracker the rest of the agent uses.\n",
        "\n",
        "âœ… **Why this matters**:\n",
        "\n",
        "* Youâ€™ll see this log when debugging or monitoring workflows.\n",
        "* It gives you a first â€œcheckpointâ€ so you can detect failures later.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¹ `env = Environment(...)`\n",
        "\n",
        "This is where you **give the agent its execution engine**.\n",
        "\n",
        "The `Environment` handles:\n",
        "\n",
        "* Validation of tool schemas\n",
        "* Auto-wiring of dependencies (ctx, \\_fs, etc)\n",
        "* Error standardization\n",
        "* Progress tracking\n",
        "\n",
        "âœ… **Check**:\n",
        "\n",
        "* Is this wired to the correct `ctx` and `registry`?\n",
        "* Are all tools registered properly before the environment is built?\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© Summary: What to Double-Check\n",
        "\n",
        "| Area                     | Focus                                                                                 |\n",
        "| ------------------------ | ------------------------------------------------------------------------------------- |\n",
        "| `ActionContext(...)`     | Are all core components (memory, llm, config, deps) present and correct?              |\n",
        "| `deps={\"fs\": RealFS}`    | Are you using the right adapters for tools? Could you inject other helpful utilities? |\n",
        "| `os.makedirs(...)`       | Are folders correct and safe to create on your target system?                         |\n",
        "| `track_progress(...)`    | Does this give you a clear setup signal in logs?                                      |\n",
        "| `env = Environment(...)` | Is this built after registry setup is complete?                                       |\n",
        "\n"
      ],
      "metadata": {
        "id": "Eceky1eabFFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ AGENT STEPS (SCRIPTED PIPELINE)                                              â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "file_name = \"004_AGENT_Tools.txt\"\n",
        "steps = [\n",
        "    (\"create_plan\", {}),\n",
        "    (\"read_txt_file\", {\"file_name\": file_name}),\n",
        "    (\"generate_summary_prompt\", {}),  # or {\"max_len\": 2400}\n",
        "    (\"summarize\", {}),\n",
        "    (\"save_summary\", {}),\n",
        "]\n"
      ],
      "metadata": {
        "id": "-JzOyG1qbIFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block defines the **scripted pipeline** â€” a deterministic list of tool steps that your agent will run *in order*. Itâ€™s like handing your agent a mission briefing: â€œHereâ€™s what to do, and in what order.â€\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ” What This Block Does\n",
        "\n",
        "### ğŸ§¾ `file_name = \"004_AGENT_Tools.txt\"`\n",
        "\n",
        "Sets the name of the input file the agent will read and summarize.\n",
        "\n",
        "> ğŸ“Œ **Used in**: The `read_txt_file` step, passed as a parameter.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸªœ `steps = [...]`\n",
        "\n",
        "This is the **ordered sequence** of tool invocations. Each entry is a tuple:\n",
        "\n",
        "```python\n",
        "(\"tool_name\", {arguments_dict})\n",
        "```\n",
        "\n",
        "Hereâ€™s what each one does:\n",
        "\n",
        "| Step                                          | Tool                                                  | Purpose |\n",
        "| --------------------------------------------- | ----------------------------------------------------- | ------- |\n",
        "| `(\"create_plan\", {})`                         | Calls the planner to break the goal into steps.       |         |\n",
        "| `(\"read_txt_file\", {\"file_name\": file_name})` | Reads the contents of the text file into memory.      |         |\n",
        "| `(\"generate_summary_prompt\", {})`             | Trims the text and formats the prompt for the LLM.    |         |\n",
        "| `(\"summarize\", {})`                           | Feeds the prompt to the LLM and stores the result.    |         |\n",
        "| `(\"save_summary\", {})`                        | Saves the LLM-generated summary to the output folder. |         |\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ What You Should Focus On\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… 1. **Tool Names Must Match Registry**\n",
        "\n",
        "Every tool name must match what you registered in the `ToolRegistry`. If you misspell a tool or forget to register it, `env.run(...)` will throw a `KeyError`.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… 2. **Arguments Must Match Tool Schema**\n",
        "\n",
        "Each tool may expect parameters (like `file_name`). If a required param is missing, the `Environment` will catch it during validation and return a standardized `err(...)`.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… 3. **Order Matters**\n",
        "\n",
        "These tools build on each other. For example:\n",
        "\n",
        "* `generate_summary_prompt` needs `raw_text`, which is only available *after* `read_txt_file`\n",
        "* `summarize` needs the prompt generated by the previous step\n",
        "\n",
        "> ğŸ’¡ You can think of each tool like a **pipe** in a plumbing system â€” the `ctx.memory` is the water flowing through it.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… 4. **Steps Can Be Dynamic**\n",
        "\n",
        "Although this is a **hard-coded plan**, you could dynamically generate or modify the `steps` list based on:\n",
        "\n",
        "* User preferences\n",
        "* LLM-created plans\n",
        "* Prior run results in memory\n",
        "\n",
        "---\n",
        "\n",
        "**That's one of the most powerful capabilities** of your agent scaffold: the `create_plan` tool can be used by the LLM itself to **autonomously generate a dynamic, goal-specific pipeline**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  How It Works in Practice\n",
        "\n",
        "### 1. **Goal Is Set by User**\n",
        "\n",
        "You inject a high-level task into memory like:\n",
        "\n",
        "```python\n",
        "memory.set(\"goal\", \"Summarize all customer feedback files and highlight top pain points.\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **LLM Uses `create_plan`**\n",
        "\n",
        "The agent calls the `create_plan` tool, which prompts the LLM to break that goal into concrete, ordered steps.\n",
        "\n",
        "The LLM might respond with:\n",
        "\n",
        "```\n",
        "1. List all feedback files.\n",
        "2. Read each file.\n",
        "3. Generate a summary for each.\n",
        "4. Extract key pain points.\n",
        "5. Combine and save the final report.\n",
        "```\n",
        "\n",
        "This output becomes a memory-stored `plan`:\n",
        "\n",
        "```python\n",
        "ctx.memory.get(\"plan\")  # list of clean, normalized steps\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **LLM or Agent Maps Steps to Tools**\n",
        "\n",
        "The agent can now **map those plan steps to tool names** (from the registry) and arguments. For example:\n",
        "\n",
        "```python\n",
        "[\n",
        "  (\"list_txt_files\", {}),\n",
        "  (\"read_txt_file\", {\"file_name\": \"feedback1.txt\"}),\n",
        "  (\"generate_summary_prompt\", {}),\n",
        "  (\"summarize\", {}),\n",
        "  (\"save_summary\", {\"out_name\": \"feedback1_summary.txt\"})\n",
        "]\n",
        "```\n",
        "\n",
        "This dynamic plan becomes the `steps` array â€” either built by the LLM or another planning module.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Execution Loop Runs It**\n",
        "\n",
        "You run each step via:\n",
        "\n",
        "```python\n",
        "for tool_name, kwargs in steps:\n",
        "    result = env.run(tool_name, **kwargs)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”‘ Benefits of LLM-Generated Plans\n",
        "\n",
        "| Feature                  | Benefit                                                             |\n",
        "| ------------------------ | ------------------------------------------------------------------- |\n",
        "| Goal-based flexibility   | No need to hard-code pipelines                                      |\n",
        "| Adaptable to new domains | Works for summarization, coding, research, etc.                     |\n",
        "| Customizable             | User could inject constraints (â€œdonâ€™t read files larger than 10MBâ€) |\n",
        "| Human-readable           | Plan steps can be shown to the user for approval                    |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Sx9q6fjabcyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ RUN AGENT                                                                    â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "agent = ScriptedAgent(env, steps)\n",
        "final = agent.run(max_calls=10)  # optional guard\n",
        "print(\"Agent result:\", final[\"final\"])\n",
        "if \"hint\" in final:\n",
        "    print(\"ğŸ’¡ Hint:\", final[\"hint\"])\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ PRETTY PRINTS (FROM MEMORY)                                                  â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "plan = ctx.memory.get(\"plan\") or []\n",
        "print(\"\\nPlan:\")\n",
        "for s in plan:\n",
        "    print(\"-\", s)\n",
        "\n",
        "raw_text = ctx.memory.get(\"raw_text\") or \"\"\n",
        "print(\"\\nğŸ“„ File Preview:\\n\")\n",
        "print(textwrap.fill(raw_text[:600], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "prompt = ctx.memory.get(\"summary_prompt\") or \"\"\n",
        "print(\"\\nğŸ§¾ Prompt Preview:\\n\")\n",
        "print(textwrap.fill(prompt[:600], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "summary = ctx.memory.get(\"summary\") or \"\"\n",
        "print(\"\\nğŸ“ Summary Preview:\\n\")\n",
        "print(textwrap.fill(summary[:1000], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "if ctx.memory.get(\"summary_path\"):\n",
        "    print(\"\\nğŸ“„ Saved to:\", ctx.memory.get(\"summary_path\"))\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ CONTEXT SNAPSHOT / PROGRESS LOG                                              â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“¦ ActionContext Snapshot\")\n",
        "ctx.print_progress()"
      ],
      "metadata": {
        "id": "hQ3rg-ofbeSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## âœ… AGENT RUN\n",
        "\n",
        "```python\n",
        "agent = ScriptedAgent(env, steps)\n",
        "final = agent.run(max_calls=10)\n",
        "```\n",
        "\n",
        "### Key Points:\n",
        "\n",
        "* **`ScriptedAgent`** takes the `env` (which knows how to run tools) and the ordered `steps` list.\n",
        "* **`run(max_calls=10)`** is a safety guard â€” prevents runaway loops.\n",
        "* **`final`** is the last step's output, wrapped in the `ok()` or `err()` envelope.\n",
        "\n",
        "### Why this matters:\n",
        "\n",
        "* This is **the main execution driver**. All planning, memory setup, registry config, and tool wiring comes together *here*.\n",
        "* `ScriptedAgent` is dumb by design (just runs steps in order), but it's enough to prove your architecture is working and test end-to-end flow.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ–¨ï¸ PRETTY PRINTS\n",
        "\n",
        "This section gives **debug visibility into the agentâ€™s state**.\n",
        "\n",
        "```python\n",
        "plan = ctx.memory.get(\"plan\") or []\n",
        "print(\"\\nPlan:\")\n",
        "for s in plan:\n",
        "    print(\"-\", s)\n",
        "```\n",
        "\n",
        "Prints the **human-readable step list** created by the LLM.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "raw_text = ctx.memory.get(\"raw_text\") or \"\"\n",
        "print(\"\\nğŸ“„ File Preview:\\n\")\n",
        "```\n",
        "\n",
        "Gives a **peek at the input content**, helping validate the `read_txt_file` step worked.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "prompt = ctx.memory.get(\"summary_prompt\") or \"\"\n",
        "print(\"\\nğŸ§¾ Prompt Preview:\\n\")\n",
        "```\n",
        "\n",
        "Shows what the LLM was fed â€” useful for debugging prompt quality or truncation issues.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "summary = ctx.memory.get(\"summary\") or \"\"\n",
        "print(\"\\nğŸ“ Summary Preview:\\n\")\n",
        "```\n",
        "\n",
        "Outputs the **actual LLM-generated summary**.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "if ctx.memory.get(\"summary_path\"):\n",
        "    print(\"\\nğŸ“„ Saved to:\", ctx.memory.get(\"summary_path\"))\n",
        "```\n",
        "\n",
        "Confirms the result was successfully saved by `save_summary`.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§¾ CONTEXT SNAPSHOT\n",
        "\n",
        "```python\n",
        "ctx.print_progress()\n",
        "```\n",
        "\n",
        "Prints your **progress log** (step-by-step status trail):\n",
        "\n",
        "* Which tools were called\n",
        "* Whether they succeeded or failed\n",
        "* Any hints or notes\n",
        "\n",
        "This is incredibly useful for tracing and debugging tool pipelines.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary: What to Focus On\n",
        "\n",
        "| Focus Area             | Why It Matters                                     |\n",
        "| ---------------------- | -------------------------------------------------- |\n",
        "| `agent.run(...)`       | Runs the actual toolchain; triggers all the logic  |\n",
        "| `ctx.memory[...]`      | Captures what the agent â€œknowsâ€ at each step       |\n",
        "| Pretty prints          | Give you visibility into key inputs/outputs        |\n",
        "| `ctx.print_progress()` | Tracks status of each step, critical for debugging |\n",
        "\n"
      ],
      "metadata": {
        "id": "E_SbGqjhcRKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ğŸ§  Underscores in Tool Parameters (not Tool Names)\n",
        "\n",
        "In your final agent code, **tools themselves are not named with underscores**, but some of their **dependencies are passed using parameter names with leading underscores**. Thatâ€™s the important distinction.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Example: `save_summary` Tool\n",
        "\n",
        "```python\n",
        "def save_summary(ctx, out_name=None, _fs=os):\n",
        "```\n",
        "\n",
        "Here, `_fs` is a **dependency**. The leading underscore tells the `Environment` class:\n",
        "\n",
        "> â€œDonâ€™t expect the agent to pass this in explicitly â€” inject it from `ctx.deps`.â€\n",
        "\n",
        "And sure enough, in setup:\n",
        "\n",
        "```python\n",
        "ctx = ActionContext(..., deps={\"fs\": RealFS})\n",
        "```\n",
        "\n",
        "So:\n",
        "\n",
        "* The tool **doesnâ€™t need to know** where `_fs` came from.\n",
        "* The `Environment` handles the injection automagically based on name (`_fs â†’ deps[\"fs\"]`).\n",
        "\n",
        "---\n",
        "\n",
        "### âŒ We do **not** do this:\n",
        "\n",
        "```python\n",
        "def _save_summary(...):\n",
        "```\n",
        "\n",
        "Tool **names** and registry identifiers donâ€™t use underscores. Theyâ€™re simple and human-readable:\n",
        "\n",
        "```python\n",
        "\"save_summary\", \"read_txt_file\", \"create_plan\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Why This Matters\n",
        "\n",
        "This convention keeps tools clean:\n",
        "\n",
        "* Use underscores **only in parameter names** to signal dependency injection.\n",
        "* Avoid underscores in tool names, so agents and registries stay human-readable and composable.\n",
        "\n",
        "---\n",
        "\n",
        "### In short:\n",
        "\n",
        "| Use                | Example                 | Purpose                                        |\n",
        "| ------------------ | ----------------------- | ---------------------------------------------- |\n",
        "| Tool name          | `\"save_summary\"`        | Registered for use by agents                   |\n",
        "| Tool param (DI)    | `_fs`                   | Tells the `Environment` to inject `deps[\"fs\"]` |\n",
        "| Tool function name | `def save_summary(...)` | Simple, readable â€” no leading `_`              |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0AYLU7t3c24e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The leading underscores (`_`) are **only for the `Environment` class to recognize dependencies** during execution. Here's a breakdown of how it works:\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… **Underscores Signal Dependency Injection (DI)**\n",
        "\n",
        "When the `Environment.run()` method prepares to call a tool, it uses the toolâ€™s function signature to decide **what to pass in**.\n",
        "\n",
        "```python\n",
        "def save_summary(ctx, out_name=None, _fs=os):\n",
        "```\n",
        "\n",
        "In this signature:\n",
        "\n",
        "* `ctx` â†’ will be passed directly (always).\n",
        "* `out_name` â†’ comes from the agent/tool call arguments.\n",
        "* `_fs` â†’ **is not expected from the agent.** Instead, the `Environment` sees the `_` and goes:\n",
        "\n",
        "  > â€œThis is a dependency â€” look in `ctx.deps` for `'fs'` and inject it.â€\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”§ The key design:\n",
        "\n",
        "```python\n",
        "elif pname.startswith(\"_\"):  # underscore dep, e.g. _fs\n",
        "    dname = pname[1:]        # strip underscore â†’ 'fs'\n",
        "    call_args[pname] = self.ctx.deps[dname]\n",
        "```\n",
        "\n",
        "That line from the `Environment.run()` method is what does the magic:\n",
        "\n",
        "* `_fs` â†’ pulls `fs` from `ctx.deps` and injects it as `_fs`.\n",
        "\n",
        "---\n",
        "\n",
        "## â— Important Clarification:\n",
        "\n",
        "* **The tools themselves donâ€™t know or care** where `_fs` came from.\n",
        "* **Only the `Environment` cares about the underscore.**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ Why This Is Smart\n",
        "\n",
        "* Keeps tool functions clean and minimal â€” no need to clutter them with setup code.\n",
        "* Keeps dependencies configurable â€” you could swap out `fs` or `clock` for mocks in testing.\n",
        "* Makes tool reuse trivial â€” just register the tool and provide its dependencies.\n",
        "\n"
      ],
      "metadata": {
        "id": "HkanYeR7dLnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ SETUP (Notebook-only)                                                        â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "!pip -q install openai python-dotenv\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ IMPORTS                                                                      â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import textwrap\n",
        "import time\n",
        "import re\n",
        "import inspect\n",
        "from typing import Callable, Optional\n",
        "from dataclasses import dataclass\n",
        "import builtins\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ OPENAI CLIENT & ENV VARS                                                     â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Loads API key from a .env file and initializes the OpenAI client.\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found in /content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ STANDARD RESULT ENVELOPE (ok / err)                                          â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def ok(**data):\n",
        "    \"\"\"Successful tool result. Add any fields you like.\"\"\"\n",
        "    return {\"ok\": True, **data}\n",
        "\n",
        "def err(msg, hint=None, retryable=False, **extra):\n",
        "    \"\"\"Error result with optional guidance and flags.\"\"\"\n",
        "    out = {\"ok\": False, \"error\": msg, \"retryable\": retryable}\n",
        "    if hint:\n",
        "        out[\"hint\"] = hint\n",
        "    if extra:\n",
        "        out.update(extra)\n",
        "    return out\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ FILESYSTEM ADAPTER (for underscore-DI: _fs)                                  â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# RealFS exposes .path/.makedirs/.open so tools can accept a pluggable FS.\n",
        "class RealFS:\n",
        "    path = os.path\n",
        "    makedirs = staticmethod(os.makedirs)\n",
        "    open = staticmethod(builtins.open)\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ MEMORY & CONTEXT                                                             â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "class ScratchMemory:\n",
        "    \"\"\"Minimal in-memory key/value store for agent state.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "\n",
        "    def get(self, key, default=None):   # default added for convenience\n",
        "        return self.store.get(key, default)\n",
        "\n",
        "    def set(self, key, value):\n",
        "        self.store[key] = value\n",
        "\n",
        "# Valid progress states for centralized logging.\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "\n",
        "class ActionContext:\n",
        "    \"\"\"\n",
        "    The agent's 'backpack':\n",
        "      - memory: state across steps\n",
        "      - llm:    LLM wrapper\n",
        "      - config: runtime configuration (folders, knobs)\n",
        "      - deps:   injectable dependencies (e.g., fs/clock)\n",
        "    \"\"\"\n",
        "    def __init__(self, memory, llm, config=None, deps=None):\n",
        "        self.memory = memory\n",
        "        self.llm = llm\n",
        "        self.config = config or {}\n",
        "        self.deps = deps or {}\n",
        "\n",
        "    # --- progress helpers ---\n",
        "    def track_progress(self, step, status, note=\"\"):\n",
        "        if status not in VALID_STATUSES:\n",
        "            raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        log.append({\n",
        "            \"step\": step,\n",
        "            \"status\": status,\n",
        "            \"note\": note,\n",
        "            \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        })\n",
        "        self.memory.set(\"progress_log\", log)\n",
        "\n",
        "    def print_progress(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        print(\"\\nğŸ“Š Progress Log:\")\n",
        "        for e in log:\n",
        "            t = f\" ({e.get('time')})\" if e.get(\"time\") else \"\"\n",
        "            note = f\" â€” {e['note']}\" if e.get(\"note\") else \"\"\n",
        "            print(f\"- [{e['status']}] {e['step']}{t}{note}\")\n",
        "\n",
        "    def last_completed_step(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in reversed(log):\n",
        "            if e.get(\"status\") == \"completed\":\n",
        "                return e.get(\"step\")\n",
        "        return None\n",
        "\n",
        "    def first_error(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in log:\n",
        "            if e.get(\"status\") == \"error\":\n",
        "                return e\n",
        "        return None\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ LLM WRAPPER                                                                 â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "class OpenAILLM:\n",
        "    def __init__(self, client, model=\"gpt-4o-mini\", temperature=0.2):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def complete(self, prompt, **kwargs):\n",
        "        temp = kwargs.get(\"temperature\", self.temperature)\n",
        "        resp = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temp,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: PLANNING                                                              â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def create_plan(ctx):\n",
        "    goal = ctx.memory.get(\"goal\")\n",
        "    if not goal:\n",
        "        return err(\"No goal provided (memory key 'goal' missing).\",\n",
        "                   hint=\"Set ctx.memory['goal'] before calling create_plan\")\n",
        "\n",
        "    prompt = f\"\"\"You are an expert task planner. Given the goal below, break it down into a clear, short list of steps.\n",
        "\n",
        "Goal: {goal}\n",
        "\n",
        "Respond ONLY with a numbered list, one step per line. No extra prose.\"\"\"\n",
        "    raw = ctx.llm.complete(prompt).strip()\n",
        "\n",
        "    # Prefer numbered steps like \"1. ...\", \"2) ...\"\n",
        "    numbered = re.findall(r'^\\s*(?:\\d+[\\).\\s-]+)\\s*(.+)$', raw, flags=re.M)\n",
        "\n",
        "    if numbered:\n",
        "        steps = numbered\n",
        "    else:\n",
        "        # Fallback to bullets like \"- ...\", \"* ...\", \"â€¢ ...\"\n",
        "        bullets = re.findall(r'^\\s*(?:[-*â€¢]\\s+)(.+)$', raw, flags=re.M)\n",
        "        steps = bullets if bullets else [ln.strip() for ln in raw.splitlines() if ln.strip()]\n",
        "\n",
        "    # Normalize: collapse spaces, trim punctuation, drop empties/dupes\n",
        "    clean_steps = []\n",
        "    seen = set()\n",
        "    for s in steps:\n",
        "        s = re.sub(r'\\s+', ' ', s).strip(' .')\n",
        "        if s and s.lower() not in seen:\n",
        "            seen.add(s.lower())\n",
        "            clean_steps.append(s)\n",
        "\n",
        "    if not clean_steps:\n",
        "        return err(\"Planner returned no steps.\",\n",
        "                   hint=\"Refine the goal or relax the parser constraints\")\n",
        "\n",
        "    ctx.memory.set(\"plan\", clean_steps)\n",
        "    # optional: match handbook wording\n",
        "    # ctx.memory.set(\"current_plan\", clean_steps)\n",
        "\n",
        "    return ok(message=\"Plan created from goal.\", steps=clean_steps)\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: I/O (FILES)                                                           â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def read_txt_file(ctx, file_name):\n",
        "    base = os.path.abspath(ctx.config.get(\"input_folder\", \"\"))\n",
        "    path = os.path.abspath(os.path.join(base, file_name))\n",
        "    if not base or not path.startswith(base + os.sep):\n",
        "        return err(\"Path traversal blocked.\", retryable=False)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        return err(f\"File not found: {path}\",\n",
        "                   hint=\"Call list_txt_files to see available files\",\n",
        "                   retryable=True)\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    ctx.memory.set(\"file_name\", file_name)\n",
        "    ctx.memory.set(\"raw_text\", text)\n",
        "    return ok(message=\"File read successfully.\", length=len(text))\n",
        "\n",
        "\n",
        "# â”€â”€ Helper: list available .txt files (for JIT guidance) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def list_txt_files(ctx):\n",
        "    base = ctx.config.get(\"input_folder\")\n",
        "    if not base:\n",
        "        return err(\"No input_folder in config.\", hint=\"Set ctx.config['input_folder']\")\n",
        "    if not os.path.isdir(base):\n",
        "        return err(f\"Input folder not found: {base}\", retryable=False)\n",
        "\n",
        "    files = sorted(f for f in os.listdir(base) if f.endswith(\".txt\"))\n",
        "    ctx.memory.set(\"available_txt_files\", files)  # optional: stash for UI/agent\n",
        "    return ok(message=f\"Found {len(files)} .txt files.\", files=files, count=len(files))\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: SUMMARIZATION                                                         â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def generate_summary_prompt(ctx, max_len=None):\n",
        "    text = ctx.memory.get(\"raw_text\")\n",
        "    if not text:\n",
        "        return err(\"No raw text found in memory.\",\n",
        "                   hint=\"Run read_txt_file before generate_summary_prompt\")\n",
        "    if max_len is None:\n",
        "        max_len = ctx.config.get(\"summary_max_chars\", 2000)\n",
        "\n",
        "    truncated = len(text) > max_len\n",
        "    short_text = text[:max_len]\n",
        "\n",
        "    ctx.memory.set(\"was_truncated\", truncated)\n",
        "    ctx.memory.set(\"source_length\", len(text))\n",
        "    ctx.memory.set(\"used_length\", len(short_text))\n",
        "    ctx.memory.set(\"summary_prompt\", f\"\"\"You are an expert technical writer.\n",
        "\n",
        "Summarize the following content into a set of clear, concise bullet points...\n",
        "\\\"\\\"\\\"{short_text}\\\"\\\"\\\"\n",
        "\n",
        "Summary:\"\"\")\n",
        "\n",
        "    return ok(message=\"Summary prompt created.\",\n",
        "              truncated=truncated, used=len(short_text), total=len(text),\n",
        "              prompt_preview=ctx.memory.get(\"summary_prompt\")[:600])\n",
        "\n",
        "\n",
        "def summarize(ctx):\n",
        "    prompt = ctx.memory.get(\"summary_prompt\")\n",
        "    if not prompt:\n",
        "        return err(\"No summary prompt found in memory.\",\n",
        "                   hint=\"Run generate_summary_prompt before summarize\")\n",
        "    response = ctx.llm.complete(prompt)\n",
        "    ctx.memory.set(\"summary\", response)\n",
        "    return ok(message=\"Summary completed.\", summary_preview=response[:1000])\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOLS: OUTPUT                                                                â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def save_summary(ctx, out_name=None, _fs=os):\n",
        "    summary = ctx.memory.get(\"summary\")\n",
        "    if not summary:\n",
        "        return err(\"No summary in memory.\",\n",
        "                   hint=\"Run summarize before save_summary\")\n",
        "    out_dir = ctx.config.get(\"output_folder\")\n",
        "    if not out_dir:\n",
        "        return err(\"No output_folder in config.\",\n",
        "                   hint=\"Set ctx.config['output_folder']\")\n",
        "\n",
        "    _fs.makedirs(out_dir, exist_ok=True)\n",
        "    src = ctx.memory.get(\"file_name\", \"summary\")\n",
        "    root, _ = os.path.splitext(os.path.basename(src))\n",
        "    base = out_name or f\"{root}_summary.txt\"\n",
        "    path = _fs.path.join(out_dir, base)\n",
        "\n",
        "    with _fs.open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    ctx.memory.set(\"summary_path\", path)\n",
        "    return ok(message=\"Summary saved.\", path=path)\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ TOOL REGISTRY â€” TYPES & REGISTRATION                                         â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable\n",
        "\n",
        "@dataclass\n",
        "class ToolDef:\n",
        "    name: str\n",
        "    func: Callable\n",
        "    description: str = \"\"\n",
        "    schema: dict | None = None\n",
        "    returns: dict | None = None   # optional metadata about outputs\n",
        "\n",
        "class ToolRegistry:\n",
        "    def __init__(self):\n",
        "        self._tools = {}\n",
        "\n",
        "    def register(self, tool: ToolDef):\n",
        "        self._tools[tool.name] = tool\n",
        "\n",
        "    def get(self, name: str) -> ToolDef:\n",
        "        if name not in self._tools:\n",
        "            raise KeyError(f\"Unknown tool: {name}\")\n",
        "        return self._tools[name]\n",
        "\n",
        "    def list(self):\n",
        "        return list(self._tools.keys())\n",
        "\n",
        "# -- Build registry -------------------------------------------------------------\n",
        "registry = ToolRegistry()\n",
        "\n",
        "registry.register(ToolDef(\n",
        "    \"create_plan\",\n",
        "    create_plan,\n",
        "    \"Create a plan from goal\",\n",
        "    schema={ \"type\": \"object\", \"properties\": {}, \"required\": [] },   # no kwargs\n",
        "    returns={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"message\": { \"type\": \"string\" },\n",
        "            \"steps\":   { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n",
        "        },\n",
        "        \"required\": [\"message\", \"steps\"]\n",
        "    }\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"read_txt_file\", read_txt_file, \"Read a .txt file from input_folder\",\n",
        "  schema={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "    \"required\": [\"file_name\"]\n",
        "  },\n",
        "  returns={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"message\": {\"type\": \"string\"}, \"length\": {\"type\": \"integer\"}},\n",
        "    \"required\": [\"message\"]\n",
        "  },\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "    \"list_txt_files\",\n",
        "    list_txt_files,\n",
        "    \"List .txt files in input_folder\",\n",
        "    schema={ \"type\": \"object\", \"properties\": {}, \"required\": [] },\n",
        "    returns={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"ok\":    { \"type\": \"boolean\" },\n",
        "            \"message\": { \"type\": \"string\" },\n",
        "            \"files\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n",
        "            \"count\": { \"type\": \"integer\" }\n",
        "        },\n",
        "        \"required\": [\"ok\", \"files\"]\n",
        "    }\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"generate_summary_prompt\", generate_summary_prompt, \"Build a summarization prompt\",\n",
        "  schema={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"max_len\": {\"type\": \"integer\", \"minimum\": 1}},\n",
        "    \"required\": []\n",
        "  }\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"summarize\", summarize, \"Run LLM summarization\",\n",
        "  schema={\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "))\n",
        "\n",
        "registry.register(ToolDef(\n",
        "  \"save_summary\", save_summary, \"Persist summary to output_folder\",\n",
        "  schema={\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"out_name\": {\"type\": \"string\"}},\n",
        "    \"required\": []\n",
        "  },\n",
        "))\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ ENVIRONMENT â€” VALIDATION & EXECUTION                                         â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import inspect\n",
        "\n",
        "def _validate(schema, kwargs):\n",
        "    \"\"\"Minimal JSON-schema-ish validator for tool kwargs.\"\"\"\n",
        "    if not schema:\n",
        "        return None\n",
        "    missing = [k for k in schema.get(\"required\", []) if k not in kwargs]\n",
        "    if missing:\n",
        "        return f\"Missing required: {missing}\"\n",
        "    types = {\"string\": str, \"integer\": int, \"number\": (int, float), \"boolean\": bool}\n",
        "    for k, spec in (schema.get(\"properties\") or {}).items():\n",
        "        if k in kwargs and \"type\" in spec:\n",
        "            py_t = types.get(spec[\"type\"])\n",
        "            if py_t and not isinstance(kwargs[k], py_t):\n",
        "                return f\"Bad type for '{k}': expected {spec['type']}\"\n",
        "    return None\n",
        "\n",
        "class Environment:\n",
        "    \"\"\"Runs tools by name with auto-DI, validation, and centralized logging.\"\"\"\n",
        "    def __init__(self, ctx: ActionContext, registry: ToolRegistry):\n",
        "        self.ctx = ctx\n",
        "        self.registry = registry\n",
        "\n",
        "    def run(self, tool_name: str, **kwargs):\n",
        "        tool = self.registry.get(tool_name)\n",
        "        fn = tool.func\n",
        "        sig = inspect.signature(fn)\n",
        "\n",
        "        # 1) Schema validation BEFORE logging/exec\n",
        "        v_err = _validate(tool.schema, kwargs)\n",
        "        if v_err:\n",
        "            self.ctx.track_progress(tool.name, \"error\", note=v_err[:180])\n",
        "            return err(v_err)  # standardized envelope\n",
        "\n",
        "        # 2) Build call args with auto-DI (ctx + underscore deps)\n",
        "        call_args = {}\n",
        "        for pname, param in sig.parameters.items():\n",
        "            if pname == \"ctx\":\n",
        "                call_args[\"ctx\"] = self.ctx\n",
        "            elif pname.startswith(\"_\"):   # underscore dep, e.g. _fs, _clock\n",
        "                dname = pname[1:]\n",
        "                if dname not in self.ctx.deps:\n",
        "                    msg = f\"Missing dep '{dname}' for tool '{tool_name}'\"\n",
        "                    self.ctx.track_progress(tool.name, \"error\", note=msg[:180])\n",
        "                    return err(msg)\n",
        "                call_args[pname] = self.ctx.deps[dname]\n",
        "            else:\n",
        "                if pname in kwargs:\n",
        "                    call_args[pname] = kwargs[pname]\n",
        "                elif param.default is not inspect._empty:\n",
        "                    pass\n",
        "                else:\n",
        "                    msg = f\"Missing required arg '{pname}' for tool '{tool_name}'\"\n",
        "                    self.ctx.track_progress(tool.name, \"error\", note=msg[:180])\n",
        "                    return err(msg)\n",
        "\n",
        "        # 3) Log start, call tool\n",
        "        self.ctx.track_progress(tool.name, \"started\", note=str(kwargs))\n",
        "        try:\n",
        "            result = fn(**call_args)\n",
        "        except Exception as e:\n",
        "            # Normalize exceptions into err(...) so the agent can handle them\n",
        "            msg = f\"{type(e).__name__}: {e}\"\n",
        "            self.ctx.track_progress(tool.name, \"error\", note=msg[:180])\n",
        "            return err(msg)\n",
        "\n",
        "        # 4) Normalize + log outcome\n",
        "        if isinstance(result, dict):\n",
        "            # If tool used envelope:\n",
        "            if result.get(\"ok\") is False:\n",
        "                self.ctx.track_progress(tool.name, \"error\", note=str(result.get(\"error\", \"\"))[:180])\n",
        "                return result\n",
        "            # Back-compat: dict returned with \"error\" but no \"ok\"\n",
        "            if \"ok\" not in result and \"error\" in result:\n",
        "                self.ctx.track_progress(tool.name, \"error\", note=str(result[\"error\"])[:180])\n",
        "                return {\"ok\": False, **result}\n",
        "            # Success path: ensure ok=True for consistency\n",
        "            result = result if \"ok\" in result else {\"ok\": True, **result}\n",
        "            note = result.get(\"message\", \"\")[:120]\n",
        "            self.ctx.track_progress(tool.name, \"completed\", note=note)\n",
        "            return result\n",
        "\n",
        "        # Non-dict success (rare): mark completed with empty note\n",
        "        self.ctx.track_progress(tool.name, \"completed\", note=\"\")\n",
        "        return result\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ SCRIPTED AGENT â€” FIXED PIPELINE RUNNER                                       â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "class ScriptedAgent:\n",
        "    \"\"\"Executes a predetermined sequence of (tool_name, kwargs) steps.\"\"\"\n",
        "    def __init__(self, env, steps):\n",
        "        self.env = env\n",
        "        self.steps = steps\n",
        "\n",
        "    def run(self, max_calls=None, stop_on_error=True):\n",
        "        calls = 0\n",
        "        for name, kwargs in self.steps:\n",
        "            if max_calls is not None and calls >= max_calls:\n",
        "                return {\"final\": f\"stopped: max_calls={max_calls}\"}\n",
        "            res = self.env.run(name, **(kwargs or {}))\n",
        "            calls += 1\n",
        "            if stop_on_error and isinstance(res, dict) and res.get(\"ok\") is False:\n",
        "                # include hint so you know the next best step\n",
        "                out = {\"final\": f\"stopped at {name}: {res['error']}\"}\n",
        "                if \"hint\" in res: out[\"hint\"] = res[\"hint\"]\n",
        "                return out\n",
        "        return {\"final\": \"done\"}\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ SETUP & CONFIG                                                               â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "memory = ScratchMemory()\n",
        "memory.set(\"goal\", \"Summarize the content of a text file.\")\n",
        "\n",
        "config = {\n",
        "    \"input_folder\": \"/content/files\",\n",
        "    \"output_folder\": \"/content/output\",\n",
        "    # \"summary_max_chars\": 2400,  # optional\n",
        "}\n",
        "\n",
        "llm = OpenAILLM(\n",
        "    client,\n",
        "    model=config.get(\"model\", \"gpt-4o-mini\"),\n",
        "    temperature=config.get(\"temperature\", 0.2),\n",
        ")\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ CONTEXT & ENVIRONMENT                                                        â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Create context with DI bag pre-populated (fs adapter)\n",
        "ctx = ActionContext(memory=memory, llm=llm, config=config, deps={\"fs\": RealFS})\n",
        "\n",
        "# Ensure folders exist (lightweight guardrails)\n",
        "os.makedirs(ctx.config[\"input_folder\"], exist_ok=True)\n",
        "os.makedirs(ctx.config[\"output_folder\"], exist_ok=True)\n",
        "ctx.track_progress(\"setup\", \"completed\", \"goal + config injected\")\n",
        "\n",
        "# Build environment (validation + auto-DI + centralized logging)\n",
        "env = Environment(ctx, registry)\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ AGENT STEPS (SCRIPTED PIPELINE)                                              â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "file_name = \"004_AGENT_Tools.txt\"\n",
        "steps = [\n",
        "    (\"create_plan\", {}),\n",
        "    (\"read_txt_file\", {\"file_name\": file_name}),\n",
        "    (\"generate_summary_prompt\", {}),  # or {\"max_len\": 2400}\n",
        "    (\"summarize\", {}),\n",
        "    (\"save_summary\", {}),\n",
        "]\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ RUN AGENT                                                                    â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "agent = ScriptedAgent(env, steps)\n",
        "final = agent.run(max_calls=10)  # optional guard\n",
        "print(\"Agent result:\", final[\"final\"])\n",
        "if \"hint\" in final:\n",
        "    print(\"ğŸ’¡ Hint:\", final[\"hint\"])\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ PRETTY PRINTS (FROM MEMORY)                                                  â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "plan = ctx.memory.get(\"plan\") or []\n",
        "print(\"\\nPlan:\")\n",
        "for s in plan:\n",
        "    print(\"-\", s)\n",
        "\n",
        "raw_text = ctx.memory.get(\"raw_text\") or \"\"\n",
        "print(\"\\nğŸ“„ File Preview:\\n\")\n",
        "print(textwrap.fill(raw_text[:600], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "prompt = ctx.memory.get(\"summary_prompt\") or \"\"\n",
        "print(\"\\nğŸ§¾ Prompt Preview:\\n\")\n",
        "print(textwrap.fill(prompt[:600], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "summary = ctx.memory.get(\"summary\") or \"\"\n",
        "print(\"\\nğŸ“ Summary Preview:\\n\")\n",
        "print(textwrap.fill(summary[:1000], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "if ctx.memory.get(\"summary_path\"):\n",
        "    print(\"\\nğŸ“„ Saved to:\", ctx.memory.get(\"summary_path\"))\n",
        "\n",
        "\n",
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘ CONTEXT SNAPSHOT / PROGRESS LOG                                              â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ“¦ ActionContext Snapshot\")\n",
        "ctx.print_progress()\n"
      ],
      "metadata": {
        "id": "ZJhqyKOvcUxc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}