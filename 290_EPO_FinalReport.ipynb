{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMExbHJykJRmF3DVabJXWVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/290_EPO_FinalReport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test script for Experimentation Portfolio Orchestrator"
      ],
      "metadata": {
        "id": "4HVS_tygKptW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy94sS8eKjIH"
      },
      "outputs": [],
      "source": [
        "\"\"\"Test script for Experimentation Portfolio Orchestrator\n",
        "\n",
        "Run this to test the orchestrator with the sample data.\n",
        "Includes Phase 1 enhancements: Statistical Significance Testing and ROI Calculations.\n",
        "\n",
        "Usage:\n",
        "    python test_experimentation_portfolio_orchestrator.py\n",
        "\"\"\"\n",
        "\n",
        "from agents.experimentation_portfolio_orchestrator.orchestrator import create_orchestrator\n",
        "from config import ExperimentationPortfolioOrchestratorState\n",
        "\n",
        "\n",
        "def test_full_portfolio_analysis():\n",
        "    \"\"\"Test analyzing the full portfolio.\"\"\"\n",
        "    print(\"ðŸš€ Starting Experimentation Portfolio Orchestrator...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create orchestrator\n",
        "    orchestrator = create_orchestrator()\n",
        "\n",
        "    # Initial state - analyze full portfolio\n",
        "    initial_state: ExperimentationPortfolioOrchestratorState = {\n",
        "        \"experiment_id\": None,  # None = analyze all experiments\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    print(\"\\nðŸ“Š Analyzing full experiment portfolio...\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Run orchestrator\n",
        "    result = orchestrator.invoke(initial_state)\n",
        "\n",
        "    # Check for errors\n",
        "    if result.get(\"errors\"):\n",
        "        print(\"\\nâŒ Errors encountered:\")\n",
        "        for error in result[\"errors\"]:\n",
        "            print(f\"  - {error}\")\n",
        "        return False\n",
        "\n",
        "    # Print summary\n",
        "    portfolio_summary = result.get(\"portfolio_summary\", {})\n",
        "    print(f\"\\nâœ… Portfolio Analysis Complete!\")\n",
        "    print(f\"   Total Experiments: {portfolio_summary.get('total_experiments', 0)}\")\n",
        "    print(f\"   Completed: {portfolio_summary.get('completed_count', 0)}\")\n",
        "    print(f\"   Running: {portfolio_summary.get('running_count', 0)}\")\n",
        "    print(f\"   Planned: {portfolio_summary.get('planned_count', 0)}\")\n",
        "\n",
        "    # Print statistical significance results\n",
        "    calculated_analyses = result.get(\"calculated_analyses\", [])\n",
        "    analysis_lookup = result.get(\"analysis_lookup\", {})\n",
        "    all_analyses = {**analysis_lookup}\n",
        "    for calc in calculated_analyses:\n",
        "        all_analyses[calc[\"experiment_id\"]] = calc\n",
        "\n",
        "    if all_analyses:\n",
        "        print(f\"\\nðŸ“Š Statistical Significance Results:\")\n",
        "        for exp_id, analysis in all_analyses.items():\n",
        "            if \"statistical_test\" in analysis:\n",
        "                stat_test = analysis[\"statistical_test\"]\n",
        "                p_value = stat_test.get(\"p_value\")\n",
        "                is_significant = stat_test.get(\"is_significant\", False)\n",
        "                if p_value is not None:\n",
        "                    sig_status = \"âœ… Significant\" if is_significant else \"âŒ Not Significant\"\n",
        "                    print(f\"   - {exp_id}: {sig_status} (p={p_value:.4f})\")\n",
        "\n",
        "    # Print ROI results\n",
        "    portfolio_roi = result.get(\"portfolio_roi_summary\")\n",
        "    if portfolio_roi and portfolio_roi.get(\"total_experiments\", 0) > 0:\n",
        "        print(f\"\\nðŸ’° Portfolio ROI Summary:\")\n",
        "        print(f\"   Total Revenue Impact: ${portfolio_roi.get('total_revenue_impact', 0):,.2f}\")\n",
        "        print(f\"   Total Cost: ${portfolio_roi.get('total_cost', 0):,.2f}\")\n",
        "        print(f\"   Net Benefit: ${portfolio_roi.get('total_net_benefit', 0):,.2f}\")\n",
        "        print(f\"   Average ROI: {portfolio_roi.get('average_roi_percent', 0):.1f}%\")\n",
        "\n",
        "    experiments_roi = result.get(\"experiments_roi\", [])\n",
        "    if experiments_roi:\n",
        "        print(f\"\\nðŸ’µ Individual Experiment ROI:\")\n",
        "        for roi in experiments_roi:\n",
        "            print(f\"   - {roi['experiment_id']}: ROI {roi.get('roi_percent', 0):.1f}% \"\n",
        "                  f\"(${roi.get('revenue_impact', 0):,.2f} impact, ${roi.get('total_cost', 0):,.2f} cost)\")\n",
        "\n",
        "    # Print generated decisions\n",
        "    generated_decisions = result.get(\"generated_decisions\", [])\n",
        "    if generated_decisions:\n",
        "        print(f\"\\nðŸ“‹ Generated {len(generated_decisions)} new decision(s):\")\n",
        "        for decision in generated_decisions:\n",
        "            print(f\"   - {decision['experiment_id']}: {decision['decision']}\")\n",
        "            print(f\"     Rationale: {decision.get('rationale', 'N/A')[:80]}...\")\n",
        "\n",
        "    # Print report location\n",
        "    report_path = result.get(\"report_file_path\")\n",
        "    if report_path:\n",
        "        print(f\"\\nðŸ“„ Report saved to: {report_path}\")\n",
        "        print(f\"   (Includes statistical significance, ROI analysis, and detailed insights)\")\n",
        "\n",
        "    # Print insights\n",
        "    insights = result.get(\"portfolio_insights\", [])\n",
        "    if insights:\n",
        "        print(f\"\\nðŸ’¡ Generated {len(insights)} insight(s):\")\n",
        "        for insight in insights:\n",
        "            print(f\"   - {insight['title']} ({insight['type']}, {insight['priority']} priority)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"âœ… Test completed successfully!\")\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def test_single_experiment_analysis():\n",
        "    \"\"\"Test analyzing a single experiment.\"\"\"\n",
        "    print(\"\\nðŸ”¬ Testing single experiment analysis...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create orchestrator\n",
        "    orchestrator = create_orchestrator()\n",
        "\n",
        "    # Initial state - analyze specific experiment\n",
        "    initial_state: ExperimentationPortfolioOrchestratorState = {\n",
        "        \"experiment_id\": \"E001\",  # Analyze E001\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    print(\"\\nðŸ“Š Analyzing experiment E001...\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Run orchestrator\n",
        "    result = orchestrator.invoke(initial_state)\n",
        "\n",
        "    # Check for errors\n",
        "    if result.get(\"errors\"):\n",
        "        print(\"\\nâŒ Errors encountered:\")\n",
        "        for error in result[\"errors\"]:\n",
        "            print(f\"  - {error}\")\n",
        "        return False\n",
        "\n",
        "    # Print summary\n",
        "    analyzed_experiments = result.get(\"analyzed_experiments\", [])\n",
        "    if analyzed_experiments:\n",
        "        exp = analyzed_experiments[0]\n",
        "        print(f\"\\nâœ… Experiment Analysis Complete!\")\n",
        "        print(f\"   Experiment ID: {exp.get('experiment_id')}\")\n",
        "        print(f\"   Status: {exp.get('status')}\")\n",
        "        print(f\"   Has Analysis: {exp.get('has_analysis')}\")\n",
        "        print(f\"   Has Decision: {exp.get('has_decision')}\")\n",
        "\n",
        "    # Print statistical significance for this experiment\n",
        "    analysis_lookup = result.get(\"analysis_lookup\", {})\n",
        "    calculated_analyses = result.get(\"calculated_analyses\", [])\n",
        "    exp_id = \"E001\"\n",
        "    analysis = analysis_lookup.get(exp_id) or next((a for a in calculated_analyses if a[\"experiment_id\"] == exp_id), None)\n",
        "\n",
        "    if analysis and \"statistical_test\" in analysis:\n",
        "        stat_test = analysis[\"statistical_test\"]\n",
        "        p_value = stat_test.get(\"p_value\")\n",
        "        is_significant = stat_test.get(\"is_significant\", False)\n",
        "        if p_value is not None:\n",
        "            print(f\"\\nðŸ“Š Statistical Test Results:\")\n",
        "            print(f\"   P-Value: {p_value:.4f}\")\n",
        "            print(f\"   Significant: {'Yes âœ…' if is_significant else 'No âŒ'}\")\n",
        "            print(f\"   Test Type: {stat_test.get('test_type', 'N/A').upper()}\")\n",
        "\n",
        "    # Print ROI for this experiment\n",
        "    experiments_roi = result.get(\"experiments_roi\", [])\n",
        "    exp_roi = next((roi for roi in experiments_roi if roi.get(\"experiment_id\") == exp_id), None)\n",
        "    if exp_roi:\n",
        "        print(f\"\\nðŸ’° ROI Analysis:\")\n",
        "        print(f\"   Revenue Impact: ${exp_roi.get('revenue_impact', 0):,.2f}\")\n",
        "        print(f\"   Total Cost: ${exp_roi.get('total_cost', 0):,.2f}\")\n",
        "        print(f\"   ROI: {exp_roi.get('roi_percent', 0):.1f}% ({exp_roi.get('roi_category', 'unknown')})\")\n",
        "\n",
        "    # Print report location\n",
        "    report_path = result.get(\"report_file_path\")\n",
        "    if report_path:\n",
        "        print(f\"\\nðŸ“„ Report saved to: {report_path}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"âœ… Single experiment test completed successfully!\")\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ðŸ§ª Experimentation Portfolio Orchestrator Test Suite\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Testing Phase 1 Enhancements:\")\n",
        "    print(\"  âœ… Statistical Significance Testing\")\n",
        "    print(\"  âœ… Enhanced Data Validation\")\n",
        "    print(\"  âœ… Cost & ROI Calculations\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Test 1: Full portfolio\n",
        "    success1 = test_full_portfolio_analysis()\n",
        "\n",
        "    # Test 2: Single experiment\n",
        "    success2 = test_single_experiment_analysis()\n",
        "\n",
        "    if success1 and success2:\n",
        "        print(\"\\nðŸŽ‰ All tests passed!\")\n",
        "        print(\"\\nðŸ“ Next Steps:\")\n",
        "        print(\"  1. Check the generated report for detailed analysis\")\n",
        "        print(\"  2. Review statistical significance results\")\n",
        "        print(\"  3. Examine ROI calculations for each experiment\")\n",
        "    else:\n",
        "        print(\"\\nâš ï¸  Some tests had issues. Check output above.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "ldtdeMa4LZHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_002_Experimentation_Portfolio_Orchestrator % python test_experimentation_portfolio_orchestrator.py\n",
        "ðŸ§ª Experimentation Portfolio Orchestrator Test Suite\n",
        "============================================================\n",
        "Testing Phase 1 Enhancements:\n",
        "  âœ… Statistical Significance Testing\n",
        "  âœ… Enhanced Data Validation\n",
        "  âœ… Cost & ROI Calculations\n",
        "============================================================\n",
        "ðŸš€ Starting Experimentation Portfolio Orchestrator...\n",
        "============================================================\n",
        "\n",
        "ðŸ“Š Analyzing full experiment portfolio...\n",
        "------------------------------------------------------------\n",
        "\n",
        "âœ… Portfolio Analysis Complete!\n",
        "   Total Experiments: 3\n",
        "   Completed: 1\n",
        "   Running: 1\n",
        "   Planned: 1\n",
        "\n",
        "ðŸ“Š Statistical Significance Results:\n",
        "   - E001: âœ… Significant (p=0.0028)\n",
        "   - E002: âœ… Significant (p=0.0000)\n",
        "\n",
        "ðŸ“„ Report saved to: output/experimentation_portfolio_reports/portfolio_report_20251216_170620.md\n",
        "   (Includes statistical significance, ROI analysis, and detailed insights)\n",
        "\n",
        "ðŸ’¡ Generated 3 insight(s):\n",
        "   - High-Performing Experiments (opportunity, high priority)\n",
        "   - Portfolio Distribution (trend, low priority)\n",
        "   - Scaling Opportunities (recommendation, medium priority)\n",
        "\n",
        "============================================================\n",
        "âœ… Test completed successfully!\n",
        "\n",
        "ðŸ”¬ Testing single experiment analysis...\n",
        "============================================================\n",
        "\n",
        "ðŸ“Š Analyzing experiment E001...\n",
        "------------------------------------------------------------\n",
        "\n",
        "âœ… Experiment Analysis Complete!\n",
        "   Experiment ID: E001\n",
        "   Status: completed\n",
        "   Has Analysis: True\n",
        "   Has Decision: True\n",
        "\n",
        "ðŸ“Š Statistical Test Results:\n",
        "   P-Value: 0.0028\n",
        "   Significant: Yes âœ…\n",
        "   Test Type: CHI_SQUARE\n",
        "\n",
        "ðŸ“„ Report saved to: output/experimentation_portfolio_reports/portfolio_report_20251216_170620.md\n",
        "\n",
        "============================================================\n",
        "âœ… Single experiment test completed successfully!\n",
        "\n",
        "ðŸŽ‰ All tests passed!\n",
        "\n",
        "ðŸ“ Next Steps:\n",
        "  1. Check the generated report for detailed analysis\n",
        "  2. Review statistical significance results\n",
        "  3. Examine ROI calculations for each experiment\n"
      ],
      "metadata": {
        "id": "mog5HUdELXCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimentation Portfolio Report\n",
        "\n",
        "**Generated:** 2025-12-16 17:06:20\n",
        "\n",
        "---\n",
        "\n",
        "## Portfolio Summary\n",
        "\n",
        "- **Total Experiments:** 3\n",
        "- **Completed:** 1\n",
        "- **Running:** 1\n",
        "- **Planned:** 1\n",
        "- **Domains:** hr, sales, customer_support\n",
        "- **Average Lift:** 44.4%\n",
        "\n",
        "### Analysis Status\n",
        "- **Experiments with Analysis:** 1\n",
        "- **Experiments with Decisions:** 1\n",
        "- **Needing Analysis:** 0\n",
        "- **Needing Decisions:** 0\n",
        "\n",
        "---\n",
        "\n",
        "## Portfolio Insights\n",
        "\n",
        "### High-Performing Experiments\n",
        "\n",
        "**Type:** Opportunity | **Priority:** High\n",
        "\n",
        "1 experiment(s) show >20% improvement and may be ready to scale.\n",
        "\n",
        "**Related Experiments:** E001\n",
        "\n",
        "### Portfolio Distribution\n",
        "\n",
        "**Type:** Trend | **Priority:** Low\n",
        "\n",
        "Experiments span 3 domains: sales, customer_support, hr.\n",
        "\n",
        "**Related Experiments:** N/A\n",
        "\n",
        "### Scaling Opportunities\n",
        "\n",
        "**Type:** Recommendation | **Priority:** Medium\n",
        "\n",
        "1 experiment(s) are recommended for scaling.\n",
        "\n",
        "**Related Experiments:** E001\n",
        "\n",
        "---\n",
        "\n",
        "## Experiment Details\n",
        "\n",
        "### AI Email Drafting for Sales (E001)\n",
        "\n",
        "- **Status:** Completed\n",
        "- **Domain:** sales\n",
        "- **Owner:** growth_team\n",
        "- **Start Date:** 2024-10-01\n",
        "- **End Date:** 2024-10-14\n",
        "\n",
        "#### Hypothesis\n",
        "\n",
        "Using AI-generated email drafts will increase sales reply rates.\n",
        "\n",
        "**Variants:** control, ai_drafted\n",
        "**Primary Metric:** reply_rate\n",
        "**Success Criteria:** ai_drafted reply_rate > control reply_rate\n",
        "\n",
        "#### Analysis Results\n",
        "\n",
        "- **Primary Metric:** reply_rate\n",
        "- **Control Value:** 0.18\n",
        "- **Treatment Value:** 0.26\n",
        "- **Absolute Change/Lift:** 0.08\n",
        "- **Relative Change/Lift:** 44.4%\n",
        "- **Direction:** Positive\n",
        "- **Confidence:** High\n",
        "\n",
        "- **Statistical Significance:** âœ… Statistically Significant\n",
        "- **P-Value:** 0.0028\n",
        "- **Test Type:** CHI_SQUARE\n",
        "\n",
        "- **95% Confidence Interval:** [0.0291, 0.1302]\n",
        "\n",
        "- **Summary:** AI-drafted emails significantly increased reply rates compared to control.\n",
        "\n",
        "#### Decision\n",
        "\n",
        "- **Decision:** Scale\n",
        "- **Rationale:** Reply rate increased by 44% with no negative secondary effects.\n",
        "- **Recommended Action:** Roll out AI email drafting to all outbound sales teams.\n",
        "- **Decision Date:** 2024-10-20\n",
        "\n",
        "---\n",
        "\n",
        "### LLM Support Bot for Tier-1 Tickets (E002)\n",
        "\n",
        "- **Status:** Running\n",
        "- **Domain:** customer_support\n",
        "- **Owner:** support_ops\n",
        "- **Start Date:** 2024-10-10\n",
        "- **End Date:** Ongoing\n",
        "\n",
        "#### Hypothesis\n",
        "\n",
        "An LLM-based support bot will reduce average ticket resolution time.\n",
        "\n",
        "**Variants:** human_only, llm_assisted\n",
        "**Primary Metric:** avg_resolution_time_minutes\n",
        "**Success Criteria:** llm_assisted avg_resolution_time_minutes < human_only\n",
        "\n",
        "#### Analysis Results\n",
        "\n",
        "- **Primary Metric:** avg_resolution_time_minutes\n",
        "- **Control Value:** 42\n",
        "- **Treatment Value:** 29\n",
        "- **Absolute Change/Lift:** -13.00\n",
        "- **Relative Change/Lift:** -31.0%\n",
        "- **Direction:** Positive\n",
        "- **Confidence:** Medium\n",
        "\n",
        "- **Summary:** LLM-assisted support reduced average resolution time without hurting CSAT.\n",
        "\n",
        "#### Decision\n",
        "\n",
        "- **Decision:** Iterate\n",
        "- **Rationale:** Resolution time improved significantly, but CSAT gains are modest.\n",
        "- **Recommended Action:** Continue experiment with improved prompt tuning and agent handoff.\n",
        "- **Decision Date:** 2024-10-22\n",
        "\n",
        "---\n",
        "\n",
        "### Automated Resume Screening (E003)\n",
        "\n",
        "- **Status:** Planned\n",
        "- **Domain:** hr\n",
        "- **Owner:** people_analytics\n",
        "- **Start Date:** None\n",
        "- **End Date:** Ongoing\n",
        "\n",
        "#### Hypothesis\n",
        "\n",
        "Automated resume screening will reduce recruiter screening time without lowering hire quality.\n",
        "\n",
        "**Variants:** manual_review, ai_screening\n",
        "**Primary Metric:** screening_time_minutes\n",
        "**Success Criteria:** ai_screening screening_time_minutes < manual_review\n",
        "\n",
        "#### Decision\n",
        "\n",
        "- **Decision:** Do_Not_Start\n",
        "- **Rationale:** Insufficient data quality and unclear success criteria.\n",
        "- **Recommended Action:** Refine experiment design before launch.\n",
        "- **Decision Date:** 2024-10-25\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "## Report Metadata\n",
        "\n",
        "- **Total Experiments Analyzed:** 3\n",
        "- **Report Generated:** 2025-12-16 17:06:20\n"
      ],
      "metadata": {
        "id": "vHVTEVlSNK-W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Linl8hKMLVsJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}