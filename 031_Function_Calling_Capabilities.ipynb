{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkY3ROMGGdAWUdcMPb2M93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/031_Function_Calling_Capabilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 📘 LUsing Function Calling Capabilities with LLMs\n",
        "\n",
        "In this lesson, we explore **how LLMs can be integrated with tools** using function calling — a structured and robust way to turn free-form user requests into executable actions.\n",
        "\n",
        "### 🧠 Key Takeaways\n",
        "\n",
        "* **Function calling enables structured tool usage.**\n",
        "  Instead of trying to prompt the model to generate JSON (which is unreliable), we use OpenAI’s function calling API, which guarantees structured output using predefined JSON schemas.\n",
        "\n",
        "* **The LLM decides when to use a tool.**\n",
        "  You provide the tools and schema, and the model decides whether to return a function call (with arguments) or a regular assistant message.\n",
        "\n",
        "* **No need for complex prompt engineering.**\n",
        "  Function calling APIs separate *decision logic* (what to do) from *formatting logic* (how to do it). You only define the tools and their expected inputs—OpenAI handles the rest.\n",
        "\n",
        "* **The LLM outputs a `tool_calls` array** (if it chooses a tool), with perfectly structured JSON:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"tool_calls\": [\n",
        "      {\n",
        "        \"function\": {\n",
        "          \"name\": \"read_file\",\n",
        "          \"arguments\": \"{ \\\"filename\\\": \\\"example.txt\\\" }\"\n",
        "        }\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "  ```\n",
        "\n",
        "* **Your code receives this structured result and routes it to the matching function** using Python (e.g., `tool_router()` or a function registry).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IeGpH4vSJ_B5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✅ Key Benefits of Function Calling APIs\n",
        "\n",
        "- **Eliminates prompt engineering for structured responses**  \n",
        "  No need to force the model to output JSON manually.\n",
        "\n",
        "- **Uses standardized JSON Schema**  \n",
        "  The same format used in API documentation applies seamlessly to AI interactions.\n",
        "\n",
        "- **Allows mixed text and tool execution**  \n",
        "  The model can decide whether a tool is necessary or provide a natural language response.\n",
        "\n",
        "- **Simplifies parsing logic**  \n",
        "  Instead of handling inconsistent outputs, developers only check for `tool_calls` in the response.\n",
        "\n",
        "- **Guarantees syntactically correct arguments**  \n",
        "  The model automatically ensures arguments match the expected parameter format.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 Conclusion\n",
        "\n",
        "Function calling APIs significantly improve the reliability of AI-agent interactions by enforcing structured execution. By defining tools with JSON Schema and letting the model determine when to use them, we build a more predictable and maintainable AI interface.\n",
        "\n",
        "\n",
        "## 🎯 Notebook Goals\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Reiterate and apply the 8-step process for enabling function calling.\n",
        "2. Review the anatomy of a tool: from Python function → JSON Schema → OpenAI tool definition.\n",
        "3. Use OpenAI’s built-in `tool_calls` parsing to extract which function the LLM wants to use.\n",
        "4. Route and execute tool calls dynamically.\n",
        "5. Understand the benefits and limitations of this approach.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OvRRXeWOKTnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🧠 8-Step Process for Enabling Function Calling in Agents\n",
        "\n",
        "This process outlines how to go from user input to executing real code with structured tool support using OpenAI's function calling features.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Define Your Python Functions (Tools)**\n",
        "These are the real backend functions that execute logic — reading files, searching directories, analyzing data, etc.\n",
        "\n",
        "```python\n",
        "def read_file(filename): ...\n",
        "def list_files(): ...\n",
        "def search_file_names(keyword, case_sensitive=False): ...\n",
        "````\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Describe Each Tool Using JSON Schema**\n",
        "\n",
        "Wrap each function in a JSON-compliant schema that defines:\n",
        "\n",
        "* Tool name\n",
        "* Description\n",
        "* Parameters (`type`, `properties`, `required`)\n",
        "\n",
        "This schema tells the LLM what the tool does and what inputs it requires.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Combine Tool Definitions into a `tools` List**\n",
        "\n",
        "Format tools according to the OpenAI function-calling spec:\n",
        "\n",
        "```python\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": list_files_tool\n",
        "    },\n",
        "    ...\n",
        "]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Send Tools to the LLM in the API Call**\n",
        "\n",
        "Pass your `tools` list to the `chat.completions.create()` method.\n",
        "\n",
        "```python\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    tool_choice=\"auto\"\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **LLM Decides: Tool Call or Plain Text**\n",
        "\n",
        "The LLM returns either:\n",
        "\n",
        "* Natural language response (`choice.content`)\n",
        "* OR a structured tool call block (`choice.tool_calls`)\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Parse the Tool Call Block**\n",
        "\n",
        "If a tool is selected, extract:\n",
        "\n",
        "* `tool_name = choice.tool_calls[0].function.name`\n",
        "* `args = json.loads(choice.tool_calls[0].function.arguments)`\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Route to the Correct Python Function**\n",
        "\n",
        "Use a tool router that maps `tool_name` to your backend logic:\n",
        "\n",
        "```python\n",
        "def tool_router(tool_name, args): ...\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Execute the Tool and Return Result**\n",
        "\n",
        "Once the tool is run, you can:\n",
        "\n",
        "* Return the result back to the user\n",
        "* Feed it back to the LLM for further reasoning or dialogue\n",
        "\n",
        "```python\n",
        "result = tool_router(tool_name, args)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Summary\n",
        "\n",
        "This structured flow turns the LLM into an intelligent **decision-maker** that:\n",
        "\n",
        "* Interprets the user’s intent\n",
        "* Matches it to the correct tool\n",
        "* Ensures inputs are valid\n",
        "* And executes real actions\n",
        "\n",
        "With minimal parsing and robust logic, this model-driven architecture brings reliability and flexibility to agent design.\n",
        "\n"
      ],
      "metadata": {
        "id": "eVb1MRSYLCn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 🛠️ Part 1: Python Tool Functions\n",
        "\n",
        "We'll define two simple Python tools:\n",
        "\n",
        "### 1. `get_stock_price(ticker: str)`\n",
        "\n",
        "Simulates getting the current price for a given stock ticker.\n",
        "\n",
        "### 2. `search_stock_news(ticker: str)`\n",
        "\n",
        "Simulates returning a recent news headline for a stock.\n",
        "\n",
        "(These are mock tools for now, but later we can plug in real APIs like `yfinance` or web search.)\n"
      ],
      "metadata": {
        "id": "p5aheH1ZXVMv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EBxLJwduJo_c"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# 🟦 Simulated stock price tool\n",
        "def get_stock_price(ticker: str) -> str:\n",
        "    mock_price = round(random.uniform(100, 500), 2)\n",
        "    return f\"{ticker.upper()} is currently trading at ${mock_price}.\"\n",
        "\n",
        "# 🟨 Simulated news search tool\n",
        "def search_stock_news(ticker: str) -> str:\n",
        "    sample_news = {\n",
        "        \"AAPL\": \"Apple unveils new AI-powered chip at WWDC.\",\n",
        "        \"TSLA\": \"Tesla's Q2 deliveries beat expectations, stock jumps.\",\n",
        "        \"NVDA\": \"NVIDIA partners with OpenAI for next-gen GPU architecture.\",\n",
        "    }\n",
        "    return sample_news.get(ticker.upper(), f\"No recent news found for {ticker.upper()}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧰 Part 2: Define Tool Schemas"
      ],
      "metadata": {
        "id": "VgsuLhOSXtoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🛠️ Tool schema for get_stock_price\n",
        "get_stock_price_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"get_stock_price\",\n",
        "        \"description\": \"Gets the current price of a given stock ticker symbol.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"ticker\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The stock ticker symbol (e.g., AAPL, TSLA).\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"ticker\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 🛠️ Tool schema for search_stock_news\n",
        "search_stock_news_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"function\": {\n",
        "        \"name\": \"search_stock_news\",\n",
        "        \"description\": \"Searches for the most recent news about a given stock ticker.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"ticker\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The stock ticker symbol (e.g., AAPL, TSLA).\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"ticker\"]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# 🧰 Master tools list\n",
        "tools = [get_stock_price_tool, search_stock_news_tool]\n"
      ],
      "metadata": {
        "id": "-9oFdQDgXk5Q"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now onto **🤖 Part 3: Agent Response Generator**\n",
        "\n",
        "We'll create a function that:\n",
        "\n",
        "1. Accepts the **user input**\n",
        "2. Builds a chat message history\n",
        "3. Uses the OpenAI API to generate a response\n",
        "4. Returns either:\n",
        "\n",
        "   * a natural language reply\n",
        "   * or a **tool call** if the model chooses to use a function\n",
        "\n",
        "---\n",
        "\n",
        "## 🤖 Part 3: Generate Agent Response\n",
        "\n"
      ],
      "metadata": {
        "id": "QuFkvZ3VX-SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU dotenv openai"
      ],
      "metadata": {
        "id": "Iute9XupYMgP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# ✅ Load API key\n",
        "load_dotenv(\"/content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# 🤖 Agent response generator\n",
        "def generate_agent_response(user_input):\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a financial assistant who can retrieve real-time stock prices and search recent news using tools. Be concise and helpful.\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        tools=tools,              # 🧰 Our tool schemas\n",
        "        tool_choice=\"auto\"        # 🔍 Let model decide\n",
        "    )\n",
        "\n",
        "    choice = response.choices[0].message\n",
        "\n",
        "    if choice.tool_calls:\n",
        "        # 🛠️ Model wants to use a tool\n",
        "        tool_call = choice.tool_calls[0]\n",
        "        return {\"type\": \"tool\", \"tool_call\": tool_call}\n",
        "    else:\n",
        "        # 💬 Regular message\n",
        "        return {\"type\": \"text\", \"content\": choice.content}\n"
      ],
      "metadata": {
        "id": "tQniBMn-YECb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🔧 Part 4: Define the Tool Functions\n",
        "These are the actual Python implementations that the agent will call once the LLM chooses a tool and returns the necessary arguments."
      ],
      "metadata": {
        "id": "-285h1iyYdaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔧 Tool 1: Get stock price (mocked)\n",
        "def get_stock_price(ticker):\n",
        "    # In real use case, you'd call an API like Yahoo Finance or Alpha Vantage\n",
        "    mock_prices = {\n",
        "        \"AAPL\": 187.65,\n",
        "        \"GOOGL\": 2765.21,\n",
        "        \"MSFT\": 412.88,\n",
        "        \"TSLA\": 253.12\n",
        "    }\n",
        "    price = mock_prices.get(ticker.upper(), \"Unknown Ticker\")\n",
        "    return f\"The current price of {ticker.upper()} is ${price}\"\n",
        "\n",
        "# 🔧 Tool 2: Search finance news (mocked)\n",
        "def search_news(ticker, limit=3):\n",
        "    mock_articles = {\n",
        "        \"apple\": [\n",
        "            \"Apple announces record quarterly earnings.\",\n",
        "            \"New iPhone 16 rumored to launch this fall.\",\n",
        "            \"Apple stock surges on AI push.\"\n",
        "        ],\n",
        "        \"tesla\": [\n",
        "            \"Tesla reports delivery beat for Q2.\",\n",
        "            \"Elon Musk teases Robotaxi prototype reveal.\",\n",
        "            \"Tesla stock jumps 12% after earnings.\"\n",
        "        ]\n",
        "    }\n",
        "    articles = mock_articles.get(ticker.lower(), [\"No news found.\"])\n",
        "    return \"\\n\".join(articles[:limit])\n"
      ],
      "metadata": {
        "id": "VGjhXph0YeQ1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Tool Router – Executing the Chosen Tool"
      ],
      "metadata": {
        "id": "DtghWlMwYn6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tool_router(tool_name, args):\n",
        "    if tool_name == \"get_stock_price\":\n",
        "        return get_stock_price(args[\"ticker\"])\n",
        "    elif tool_name == \"search_stock_news\":\n",
        "        return search_news(\n",
        "            ticker=args[\"ticker\"],\n",
        "            limit=args.get(\"limit\", 3)\n",
        "        )\n",
        "    else:\n",
        "        return f\"❌ Unknown tool: {tool_name}\"\n"
      ],
      "metadata": {
        "id": "EBXHJP0iYolj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Handle Tool Call"
      ],
      "metadata": {
        "id": "6yVnMYkWYsx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_tool_call_debug(choice):\n",
        "    if choice[\"type\"] == \"tool\":\n",
        "        tool_name = choice[\"tool_call\"].function.name\n",
        "        args = json.loads(choice[\"tool_call\"].function.arguments)\n",
        "        result = tool_router(tool_name, args)\n",
        "        print(f\"🛠️ Tool Used: {tool_name}\")\n",
        "        print(f\"📤 Args: {args}\")\n",
        "        print(f\"📥 Result:\\n{result}\")\n",
        "    elif choice[\"type\"] == \"text\":\n",
        "        print(f\"💬 Assistant Response:\\n{choice['content']}\")\n",
        "    else:\n",
        "        print(\"❓ Unexpected response type.\")"
      ],
      "metadata": {
        "id": "w4dn6iysYtad"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚙️ Part 7: Run"
      ],
      "metadata": {
        "id": "S93IY4KZZJmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What's the current stock price of AAPL?\"\n",
        "choice = generate_agent_response(user_input)\n",
        "handle_tool_call_debug(choice)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FcCyeRTZTiN",
        "outputId": "41ab87bd-bb8d-422a-d121-d7a18ede224a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🛠️ Tool Used: get_stock_price\n",
            "📤 Args: {'ticker': 'AAPL'}\n",
            "📥 Result:\n",
            "The current price of AAPL is $187.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_tool_call_conversational(tool_call):\n",
        "    name = tool_call.function.name\n",
        "    args = json.loads(tool_call.function.arguments)\n",
        "    result = tool_router(name, args)\n",
        "\n",
        "    # 👇 This is the missing step — add the assistant's tool call message\n",
        "    assistant_message = {\n",
        "        \"role\": \"assistant\",\n",
        "        \"tool_calls\": [tool_call]  # 👈 This is required\n",
        "    }\n",
        "\n",
        "    follow_up = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a financial assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"What's the current stock price of {args['ticker']}?\"},\n",
        "            assistant_message,\n",
        "            {\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"name\": name,\n",
        "                \"content\": result\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return follow_up.choices[0].message.content\n",
        "\n",
        "tool_call = choice[\"tool_call\"]\n",
        "response = handle_tool_call_conversational(tool_call)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBf7m-wWgpht",
        "outputId": "b3c4a786-0ef3-4ff6-95ac-0bedad287823"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current stock price of AAPL (Apple Inc.) is $187.65.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mocking up an agent is *absolutely* the best first step** before implementing real API calls. Here's why it's a smart and strategic move:\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Why Mocking Agents First is a Great Idea\n",
        "\n",
        "#### 1. **Clarifies agent behavior**\n",
        "\n",
        "* You define *what* the agent should do before worrying about *how*.\n",
        "* It helps you test conversation flow, tool orchestration, and logic independently of real-world errors or API quirks.\n",
        "\n",
        "#### 2. **Zero risk and low cost**\n",
        "\n",
        "* No real API keys, credentials, or rate limits to worry about.\n",
        "* You avoid being billed while testing logic and prompt structure.\n",
        "\n",
        "#### 3. **Enables fast iteration**\n",
        "\n",
        "* You can focus on refining tool schemas, tool selection, routing, and conversation design.\n",
        "* No waiting on slow or flaky APIs during debugging.\n",
        "\n",
        "#### 4. **Improves prompt and tool schema quality**\n",
        "\n",
        "* You'll catch edge cases where the LLM picks the wrong tool or misunderstands parameters — and fix those early.\n",
        "* Once you swap in real APIs, the behavior should already be stable.\n",
        "\n",
        "#### 5. **Easy to switch to production**\n",
        "\n",
        "* When you're ready, replace mock return values with real API calls — the rest of the system stays the same.\n",
        "* Your router, agent loop, tool schema, and error handling logic are already done.\n",
        "\n",
        "---\n",
        "\n",
        "### 🛠️ Example Workflow\n",
        "\n",
        "| Step | Description                                                                          |\n",
        "| ---- | ------------------------------------------------------------------------------------ |\n",
        "| 1️⃣  | Build the mock tool function (`def get_weather(city): return \"It's sunny in Miami\"`) |\n",
        "| 2️⃣  | Define the tool schema using JSON Schema                                             |\n",
        "| 3️⃣  | Add it to your agent and test interaction                                            |\n",
        "| 4️⃣  | Refine prompt, tool call, and return handling                                        |\n",
        "| 5️⃣  | Swap mock function with real API call when stable                                    |\n",
        "\n",
        "---\n",
        "\n",
        "### 🔄 Mock → Real API Transition\n",
        "\n",
        "For each mock tool, you’ll eventually:\n",
        "\n",
        "* Import a requests or API client library\n",
        "* Replace mock return value with real data fetch + parsing\n",
        "* Keep the tool signature and schema unchanged\n",
        "\n",
        "---\n",
        "\n",
        "**TL;DR**: Mocking gives you clean separation between *agent logic* and *data plumbing*, making everything more reliable, scalable, and easier to debug.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pqEO2kF3iZai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 🧠 Core Lessons to Remember\n",
        "\n",
        "#### 1. **LLMs can *decide* when to use tools**\n",
        "\n",
        "* `tool_choice=\"auto\"` lets the LLM evaluate whether a tool is appropriate.\n",
        "* Your job is to clearly define tool schemas and let the LLM orchestrate execution.\n",
        "\n",
        "#### 2. **Tool schemas must match OpenAI’s JSON Schema format**\n",
        "\n",
        "* Every tool must be declared using:\n",
        "\n",
        "  * `\"type\": \"function\"`\n",
        "  * `\"function\"` key with name, description, parameters\n",
        "* Inputs must be JSON-serializable.\n",
        "\n",
        "#### 3. **Tool outputs must be fed back into the conversation**\n",
        "\n",
        "* The LLM won’t “see” a tool result unless you return it using the special `role: \"tool\"` message.\n",
        "* It must be paired with the *original assistant message* that triggered the tool via `tool_calls`.\n",
        "\n",
        "#### 4. **You're not replacing the LLM — you're empowering it**\n",
        "\n",
        "* The LLM is your reasoning engine.\n",
        "* Your tools are just \"muscles\" it can use for precise tasks like file access, retrieval, API calls, etc.\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 Pro Tips\n",
        "\n",
        "* **Log every tool call.** It’s super helpful for debugging and transparency.\n",
        "* **Always test tools independently.** If a tool fails, isolate and fix before rerunning the agent loop.\n",
        "* **Use clear tool descriptions.** That helps the LLM know *when* it should call each tool.\n",
        "* **Build small at first.** Then compose multiple tools for more complex agents later.\n",
        "\n",
        "---\n",
        "\n",
        "### 🧭 What's Next?\n",
        "\n",
        "You're now ready for:\n",
        "\n",
        "* ✅ Memory integration (so the agent can build context over time)\n",
        "* ✅ Multi-step planning (chaining tools based on intermediate results)\n",
        "* ✅ Tool routing with decorators (to cleanly register tools)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fhgdlp0kiA5j"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhEFphk9iD13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}