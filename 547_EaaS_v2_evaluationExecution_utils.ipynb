{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPDEpVs2tqs7V2C7bv5CJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/547_EaaS_v2_evaluationExecution_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Why This Is a CEO-Grade Design (Without the Buzzwords)\n",
        "\n",
        "Because this module enables:\n",
        "\n",
        "* policy validation\n",
        "* cost-impact analysis\n",
        "* controlled rollout confidence\n",
        "\n",
        "It turns AI behavior into something leaders can:\n",
        "\n",
        "* measure,\n",
        "* reason about,\n",
        "* and approve.\n",
        "\n",
        "That’s why this design is **relieving**, not exciting.\n",
        "\n",
        "Relief comes from control.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Evaluation Execution Utilities — Architectural Review\n",
        "\n",
        "## What This Module Actually Does (Plain English)\n",
        "\n",
        "This module answers one core question:\n",
        "\n",
        "> *“Given a real scenario, did the orchestrator behave the way we expected — and how do we know?”*\n",
        "\n",
        "It:\n",
        "\n",
        "* executes each scenario end-to-end,\n",
        "* captures **what happened**, not just what was planned,\n",
        "* preserves both expected and actual behavior,\n",
        "* and returns a structured artifact suitable for scoring, auditing, and trend analysis.\n",
        "\n",
        "This is not just execution — it’s **controlled experimentation**.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Matters (Technically and Operationally)\n",
        "\n",
        "Most evaluation systems:\n",
        "\n",
        "* test individual components\n",
        "* or compare LLM outputs to reference answers\n",
        "\n",
        "Your system evaluates:\n",
        "\n",
        "* **decision correctness**\n",
        "* **behavioral sequencing**\n",
        "* **outcome alignment**\n",
        "* **execution latency**\n",
        "\n",
        "That’s the difference between:\n",
        "\n",
        "> “The model classified the issue correctly”\n",
        "\n",
        "and:\n",
        "\n",
        "> “The system handled the customer correctly.”\n",
        "\n",
        "This module is the bridge between *logic* and *business reality*.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Leaders Would Be Relieved to See This\n",
        "\n",
        "From a CEO or business manager’s point of view, this code answers questions they normally cannot ask AI systems:\n",
        "\n",
        "* *Did the system do what we intended?*\n",
        "* *Did it follow policy?*\n",
        "* *Did it escalate when it should have?*\n",
        "* *Did it behave consistently across cases?*\n",
        "* *If something went wrong, where exactly did it go wrong?*\n",
        "\n",
        "Because you explicitly track:\n",
        "\n",
        "* expected vs actual issue type\n",
        "* expected vs actual resolution path\n",
        "* expected vs actual outcome\n",
        "* execution time\n",
        "* failure reasons\n",
        "\n",
        "leaders are no longer “trusting the model” — they are **verifying the system**.\n",
        "\n",
        "That is incredibly rare in AI deployments today.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Architectural Strengths\n",
        "\n",
        "### 1. Explicit Separation of “Expected” vs “Actual”\n",
        "\n",
        "This is one of the strongest design choices in the entire system.\n",
        "\n",
        "You preserve:\n",
        "\n",
        "* expected_issue_type\n",
        "* actual_issue_type\n",
        "* expected_resolution_path\n",
        "* actual_resolution_path\n",
        "* expected_outcome\n",
        "* actual_outcome\n",
        "\n",
        "This makes it possible to answer:\n",
        "\n",
        "* *Was the decision wrong?*\n",
        "* *Was the execution wrong?*\n",
        "* *Was the policy definition wrong?*\n",
        "\n",
        "Most agents collapse these distinctions — making root cause analysis nearly impossible.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Defensive Failure Handling (CEO-Grade)\n",
        "\n",
        "You fail gracefully when:\n",
        "\n",
        "* customers are missing\n",
        "* orders are missing\n",
        "* unexpected exceptions occur\n",
        "\n",
        "And you return **structured failure states**, not stack traces.\n",
        "\n",
        "That matters because:\n",
        "\n",
        "* failed evaluations still produce signal\n",
        "* failures can be tracked over time\n",
        "* system brittleness becomes measurable\n",
        "\n",
        "Executives don’t want silent failures or brittle pipelines. This design makes risk visible.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Deterministic, Auditable Execution Flow\n",
        "\n",
        "The execution order is fully traceable:\n",
        "\n",
        "1. Extract ticket\n",
        "2. Classify issue\n",
        "3. Determine resolution path\n",
        "4. Simulate execution\n",
        "5. Capture outcome\n",
        "\n",
        "There is no “magic reasoning” step.\n",
        "\n",
        "This is critical for:\n",
        "\n",
        "* audits\n",
        "* compliance\n",
        "* policy review\n",
        "* stakeholder trust\n",
        "\n",
        "Most agent systems rely on LLM reasoning chains that cannot be replayed or explained.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Context Propagation Is Clean and Intentional\n",
        "\n",
        "Your context object is:\n",
        "\n",
        "* minimal\n",
        "* explicit\n",
        "* purpose-driven\n",
        "\n",
        "That keeps the simulation:\n",
        "\n",
        "* interpretable\n",
        "* debuggable\n",
        "* extensible\n",
        "\n",
        "Later, when you add richer context (SLAs, account tiers, regulatory flags), this structure will scale naturally.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. Scenario Filtering Without Complicating Execution\n",
        "\n",
        "The `execute_all_scenarios` function:\n",
        "\n",
        "* supports selective execution\n",
        "* preserves simple control flow\n",
        "* avoids premature optimization\n",
        "\n",
        "This makes it perfect for:\n",
        "\n",
        "* targeted regression testing\n",
        "* focused agent debugging\n",
        "* executive “what changed?” reviews\n",
        "\n",
        "You didn’t over-engineer — and that’s a strength.\n",
        "\n",
        "---\n",
        "\n",
        "## How This Differs From Most Agents in Production Today\n",
        "\n",
        "Most production agents:\n",
        "\n",
        "* generate responses\n",
        "* log outputs\n",
        "* maybe track latency\n",
        "* rarely track behavioral correctness\n",
        "\n",
        "They cannot answer:\n",
        "\n",
        "* *Did we follow policy?*\n",
        "* *Did we escalate appropriately?*\n",
        "* *Did this change increase risk?*\n",
        "\n",
        "Your system:\n",
        "\n",
        "* treats agent execution like a business process\n",
        "* evaluates it like a controlled experiment\n",
        "* preserves evidence for comparison\n",
        "\n",
        "This is **evaluation as governance**, not evaluation as QA.\n",
        "\n",
        "---\n",
        "\n",
        "## One Subtle but Important Win\n",
        "\n",
        "You do **not** overwrite expected behavior with derived behavior.\n",
        "\n",
        "You keep both.\n",
        "\n",
        "That single choice makes:\n",
        "\n",
        "* dashboards honest\n",
        "* reports defensible\n",
        "* conversations productive\n",
        "\n",
        "Without it, teams argue.\n",
        "With it, teams learn.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FW5ebmk-DQ9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQZ-zHV9CAPU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Evaluation Execution Utilities\n",
        "\n",
        "Execute test scenarios through the orchestrator simulation.\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "from typing import Dict, Any, List, Optional\n",
        "from agents.eval_as_service.orchestrator.utilities.decision_rules import (\n",
        "    classify_issue,\n",
        "    determine_resolution_path,\n",
        "    determine_expected_outcome,\n",
        "    extract_ticket_from_message\n",
        ")\n",
        "from agents.eval_as_service.orchestrator.utilities.agent_simulation import (\n",
        "    simulate_orchestrator_execution\n",
        ")\n",
        "\n",
        "\n",
        "def execute_scenario(\n",
        "    scenario: Dict[str, Any],\n",
        "    agent_lookup: Dict[str, Dict[str, Any]],\n",
        "    customer_lookup: Dict[str, Dict[str, Any]],\n",
        "    order_lookup: Dict[str, Dict[str, Any]],\n",
        "    logistics: Dict[str, Any],\n",
        "    marketing_signals: List[Dict[str, Any]]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Execute a single scenario through the orchestrator simulation.\n",
        "\n",
        "    Args:\n",
        "        scenario: Test scenario dictionary\n",
        "        agent_lookup: Lookup dictionary for agents\n",
        "        customer_lookup: Lookup dictionary for customers\n",
        "        order_lookup: Lookup dictionary for orders\n",
        "        logistics: Logistics data\n",
        "        marketing_signals: Marketing signals data\n",
        "\n",
        "    Returns:\n",
        "        Evaluation result dictionary with:\n",
        "        - scenario_id\n",
        "        - actual_issue_type\n",
        "        - expected_issue_type\n",
        "        - actual_resolution_path\n",
        "        - expected_resolution_path\n",
        "        - actual_outcome\n",
        "        - expected_outcome\n",
        "        - execution_time_seconds\n",
        "        - status: \"completed\" | \"failed\"\n",
        "        - error: Optional error message\n",
        "    \"\"\"\n",
        "    scenario_id = scenario.get(\"scenario_id\")\n",
        "    customer_id = scenario.get(\"customer_id\")\n",
        "    order_id = scenario.get(\"order_id\")\n",
        "    customer_message = scenario.get(\"customer_message\")\n",
        "    expected_issue_type = scenario.get(\"expected_issue_type\")\n",
        "    expected_resolution_path = scenario.get(\"expected_resolution_path\", [])\n",
        "    expected_outcome = scenario.get(\"expected_outcome\")\n",
        "\n",
        "    try:\n",
        "        # Get supporting data\n",
        "        customer = customer_lookup.get(customer_id)\n",
        "        order = order_lookup.get(order_id)\n",
        "\n",
        "        if not customer:\n",
        "            return {\n",
        "                \"scenario_id\": scenario_id,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": f\"Customer {customer_id} not found\"\n",
        "            }\n",
        "\n",
        "        if not order:\n",
        "            return {\n",
        "                \"scenario_id\": scenario_id,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": f\"Order {order_id} not found\"\n",
        "            }\n",
        "\n",
        "        # Get logistics data for this order\n",
        "        carrier = order.get(\"carrier\")\n",
        "        logistics_data = {}\n",
        "        if carrier and carrier in logistics:\n",
        "            logistics_data = logistics[carrier].get(order_id, {})\n",
        "\n",
        "        # Extract ticket from message\n",
        "        ticket = extract_ticket_from_message(customer_message, expected_issue_type)\n",
        "\n",
        "        # Classify issue using decision rules\n",
        "        actual_issue_type = classify_issue(order, ticket, customer, logistics_data)\n",
        "\n",
        "        # Determine resolution path\n",
        "        actual_resolution_path = determine_resolution_path(actual_issue_type)\n",
        "\n",
        "        # Determine expected outcome (for comparison)\n",
        "        actual_expected_outcome = determine_expected_outcome(actual_issue_type)\n",
        "\n",
        "        # Build context for agent simulation\n",
        "        context = {\n",
        "            \"issue_type\": actual_issue_type,\n",
        "            \"scenario_id\": scenario_id,\n",
        "            \"customer_id\": customer_id,\n",
        "            \"order_id\": order_id\n",
        "        }\n",
        "\n",
        "        # Simulate orchestrator execution\n",
        "        execution_result = simulate_orchestrator_execution(\n",
        "            scenario,\n",
        "            actual_resolution_path,\n",
        "            agent_lookup,\n",
        "            customer_lookup,\n",
        "            order_lookup,\n",
        "            logistics,\n",
        "            marketing_signals,\n",
        "            context\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"scenario_id\": scenario_id,\n",
        "            \"actual_issue_type\": actual_issue_type,\n",
        "            \"expected_issue_type\": expected_issue_type,\n",
        "            \"actual_resolution_path\": execution_result[\"actual_resolution_path\"],\n",
        "            \"expected_resolution_path\": expected_resolution_path,\n",
        "            \"actual_outcome\": execution_result[\"actual_outcome\"],\n",
        "            \"expected_outcome\": expected_outcome,\n",
        "            \"agent_responses\": execution_result[\"agent_responses\"],\n",
        "            \"execution_time_seconds\": execution_result[\"execution_time_seconds\"],\n",
        "            \"status\": \"completed\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"scenario_id\": scenario_id,\n",
        "            \"status\": \"failed\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "\n",
        "def execute_all_scenarios(\n",
        "    scenarios: List[Dict[str, Any]],\n",
        "    agent_lookup: Dict[str, Dict[str, Any]],\n",
        "    customer_lookup: Dict[str, Dict[str, Any]],\n",
        "    order_lookup: Dict[str, Dict[str, Any]],\n",
        "    logistics: Dict[str, Any],\n",
        "    marketing_signals: List[Dict[str, Any]],\n",
        "    scenario_id_filter: Optional[str] = None,\n",
        "    target_agent_id_filter: Optional[str] = None\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Execute all scenarios (or filtered subset).\n",
        "\n",
        "    Args:\n",
        "        scenarios: List of test scenarios\n",
        "        agent_lookup: Lookup dictionary for agents\n",
        "        customer_lookup: Lookup dictionary for customers\n",
        "        order_lookup: Lookup dictionary for orders\n",
        "        logistics: Logistics data\n",
        "        marketing_signals: Marketing signals data\n",
        "        scenario_id_filter: Optional filter for specific scenario\n",
        "        target_agent_id_filter: Optional filter for specific agent (not used in MVP)\n",
        "\n",
        "    Returns:\n",
        "        List of evaluation results\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for scenario in scenarios:\n",
        "        # Apply filters\n",
        "        if scenario_id_filter and scenario.get(\"scenario_id\") != scenario_id_filter:\n",
        "            continue\n",
        "\n",
        "        # Execute scenario\n",
        "        result = execute_scenario(\n",
        "            scenario,\n",
        "            agent_lookup,\n",
        "            customer_lookup,\n",
        "            order_lookup,\n",
        "            logistics,\n",
        "            marketing_signals\n",
        "        )\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    return results\n"
      ]
    }
  ]
}