{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGk3U7RvW/up4+Oa4bvJ6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/657_PDOv2_PortfolioRollup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This module is where PDO V2 **stops being a reporting system and becomes a management control plane**.\n",
        "\n",
        "Everything here is designed to compress thousands of operational signalsâ€”durations, failures, reviews, costs, risk tiersâ€”into a **single executive-ready snapshot** that can:\n",
        "\n",
        "* drive escalation\n",
        "* trigger governance actions\n",
        "* surface systemic problems\n",
        "* justify intervention with numbers\n",
        "\n",
        "It is the analytical heart of the V2 upgrade.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸŽ¯ What This Module Does\n",
        "\n",
        "This file computes the **portfolio rollup**:\n",
        "\n",
        "> one structured object that answers:\n",
        "> **â€œHow exposed are we right now?â€**\n",
        "\n",
        "It aggregates:\n",
        "\n",
        "* workflow bottlenecks\n",
        "* stage overruns\n",
        "* reviewer cost economics\n",
        "* document risk tiers\n",
        "* executive visibility\n",
        "* anomaly counts\n",
        "\n",
        "These outputs feed:\n",
        "\n",
        "* the executive dashboard\n",
        "* escalation logic\n",
        "* board-ready reports\n",
        "* threshold-based alerts\n",
        "\n",
        "Thatâ€™s not incidental.\n",
        "\n",
        "This is where policy meets data.\n",
        "\n",
        "---\n",
        "\n",
        "# â±ï¸ Time Parsing & Duration Calculation\n",
        "\n",
        "The helper functions `_parse_iso` and `_duration_minutes` convert ISO timestamps into measurable cycle-time.\n",
        "\n",
        "Why that matters operationally:\n",
        "\n",
        "* delays are quantified, not anecdotal\n",
        "* SLA breaches are computable\n",
        "* rework loops are visible\n",
        "* governance can be automated\n",
        "\n",
        "Instead of saying â€œcompliance is slow,â€ the system can say:\n",
        "\n",
        "> â€œCompliance ran 113% over baseline.â€\n",
        "\n",
        "Thatâ€™s executive-grade language.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸš¦ Stage Anomalies: Governance by Expectation\n",
        "\n",
        "`compute_stage_anomalies` compares actual stage duration to the **policy baselines** you defined in `stage_cost_baselines.json`.\n",
        "\n",
        "This is critical:\n",
        "\n",
        "* expectations are codified\n",
        "* tolerance bands are explicit\n",
        "* anomalies are mechanical\n",
        "* escalation is defensible\n",
        "\n",
        "The system is not guessing whatâ€™s slow.\n",
        "\n",
        "It is enforcing:\n",
        "\n",
        "> **â€œThis stage is allowed to vary Â±60%. It exceeded that.â€**\n",
        "\n",
        "Thatâ€™s how you build trust.\n",
        "\n",
        "LLMs can draft text.\n",
        "\n",
        "Rules detect operational drift.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§± Bottleneck Detection: Systemic, Not Anecdotal\n",
        "\n",
        "`compute_bottleneck_stages` aggregates:\n",
        "\n",
        "* how often each stage runs\n",
        "* how often it fails\n",
        "* how long it takes\n",
        "* how far it deviates from baseline\n",
        "\n",
        "This is portfolio-level learning.\n",
        "\n",
        "It answers:\n",
        "\n",
        "* Which stages slow us down most?\n",
        "* Where does rework concentrate?\n",
        "* Which approvals are failing repeatedly?\n",
        "* Which controls are expensive but ineffective?\n",
        "\n",
        "Executives love this because it enables:\n",
        "\n",
        "> process redesign, not firefighting.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ’° Reviewer Economics: Pricing Human Judgment\n",
        "\n",
        "`compute_reviewer_economics` joins:\n",
        "\n",
        "* review events\n",
        "* reviewer hourly costs\n",
        "\n",
        "and outputs:\n",
        "\n",
        "* total reviewer spend\n",
        "* spend by role\n",
        "* review counts\n",
        "* minutes consumed\n",
        "\n",
        "This is huge.\n",
        "\n",
        "Most AI systems hide human cost.\n",
        "\n",
        "Yours surfaces it.\n",
        "\n",
        "That allows leaders to ask:\n",
        "\n",
        "* Are lawyers blocking low-risk docs?\n",
        "* Are sales managers over-reviewing?\n",
        "* Are Tier-1 memos too expensive?\n",
        "* Where should we automate next?\n",
        "\n",
        "This is how AI programs earn budget.\n",
        "\n",
        "---\n",
        "\n",
        "# âš–ï¸ Risk Tier Summary: Portfolio Exposure at a Glance\n",
        "\n",
        "`compute_risk_tier_summary` rolls documents into:\n",
        "\n",
        "* Tier 1 / 2 / 3 counts\n",
        "* executive-visible cases\n",
        "* high-risk exposure\n",
        "* regulatory + reputational overlaps\n",
        "\n",
        "This turns individual documents into **enterprise posture**.\n",
        "\n",
        "Executives do not manage DOC_004.\n",
        "\n",
        "They manage:\n",
        "\n",
        "> â€œfour Tier-3 documents and two regulatory risks.â€\n",
        "\n",
        "Thatâ€™s the correct abstraction level.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ“Š Portfolio Rollup: One View to Rule Them All\n",
        "\n",
        "`compute_portfolio_rollup` stitches everything together into a single dict:\n",
        "\n",
        "* totals\n",
        "* risk counts\n",
        "* anomaly volume\n",
        "* reviewer spend\n",
        "* bottlenecks\n",
        "* tier breakdowns\n",
        "\n",
        "Notice the comment:\n",
        "\n",
        "> *Keys must match threshold_config in escalation.*\n",
        "\n",
        "That is incredibly important.\n",
        "\n",
        "It means:\n",
        "\n",
        "* analytics â†’ triggers\n",
        "* metrics â†’ governance\n",
        "* reports â†’ control loops\n",
        "\n",
        "This is a closed system.\n",
        "\n",
        "Data produces metrics.\n",
        "\n",
        "Metrics fire policy.\n",
        "\n",
        "Policy causes intervention.\n",
        "\n",
        "That is real orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§  Why This Design Reassures Executives\n",
        "\n",
        "This module encodes:\n",
        "\n",
        "* explicit expectations\n",
        "* deterministic thresholds\n",
        "* dollar figures\n",
        "* risk tiers\n",
        "* portfolio posture\n",
        "* escalation inputs\n",
        "\n",
        "A CEO seeing outputs from this logic would think:\n",
        "\n",
        "> â€œThis system understands exposure, not just content.â€\n",
        "\n",
        "Thatâ€™s exactly the brand youâ€™re building across your agent portfolio.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸŒŸ How This Differs From Typical Agent Analytics\n",
        "\n",
        "Most agent systems:\n",
        "\n",
        "* summarize logs with LLMs\n",
        "* eyeball dashboards\n",
        "* lack baselines\n",
        "* escalate ad hoc\n",
        "* ignore human cost\n",
        "* treat risk qualitatively\n",
        "\n",
        "Your system:\n",
        "\n",
        "* enforces numeric baselines\n",
        "* prices human intervention\n",
        "* aggregates portfolio-wide\n",
        "* feeds rule engines\n",
        "* separates analysis from language\n",
        "* produces auditable artifacts\n",
        "\n",
        "This is governance engineering.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§  Big Picture\n",
        "\n",
        "This rollup module is the **nervous system** of PDO V2.\n",
        "\n",
        "Everything elseâ€”reports, alerts, DAG routing, escalationâ€”depends on these metrics being:\n",
        "\n",
        "* deterministic\n",
        "* explainable\n",
        "* aligned with executive priorities\n",
        "\n",
        "Itâ€™s an excellent example of how to turn an agent into **business infrastructure**.\n",
        "\n"
      ],
      "metadata": {
        "id": "rqTLiQPJvJ1G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-UK_AL7upPB"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Portfolio-level rollup for PDO V2: bottlenecks, risk tiers, reviewer economics, stage anomalies.\n",
        "\n",
        "Feeds executive one-view and executive_triggers (threshold_config in escalation).\n",
        "\"\"\"\n",
        "from datetime import datetime, timezone\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "\n",
        "def _parse_iso(s: str | None) -> datetime | None:\n",
        "    if not s:\n",
        "        return None\n",
        "    try:\n",
        "        return datetime.fromisoformat(s.replace(\"Z\", \"+00:00\"))\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "\n",
        "def _duration_minutes(started_at: str | None, completed_at: str | None) -> float | None:\n",
        "    s = _parse_iso(started_at)\n",
        "    c = _parse_iso(completed_at)\n",
        "    if s is None or c is None:\n",
        "        return None\n",
        "    delta = c - s\n",
        "    return max(0, delta.total_seconds() / 60.0)\n",
        "\n",
        "\n",
        "def compute_stage_anomalies(\n",
        "    workflow_stages: List[Dict[str, Any]],\n",
        "    stage_cost_baselines_lookup: Dict[str, Dict[str, Any]],\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Compare each completed stage to baselines. Flag when duration or cost exceeds\n",
        "    expected by more than variance_threshold_pct.\n",
        "    \"\"\"\n",
        "    anomalies: List[Dict[str, Any]] = []\n",
        "    for stage in workflow_stages:\n",
        "        if stage.get(\"status\") != \"completed\":\n",
        "            continue\n",
        "        name = stage.get(\"stage_name\")\n",
        "        baseline = stage_cost_baselines_lookup.get(name) if name else None\n",
        "        if not baseline:\n",
        "            continue\n",
        "        expected_min = baseline.get(\"expected_minutes\")\n",
        "        variance_pct = baseline.get(\"variance_threshold_pct\") or 50\n",
        "        duration_min = _duration_minutes(stage.get(\"started_at\"), stage.get(\"completed_at\"))\n",
        "        if expected_min is not None and duration_min is not None and expected_min > 0:\n",
        "            pct_over = ((duration_min - expected_min) / expected_min) * 100\n",
        "            if pct_over > variance_pct:\n",
        "                anomalies.append({\n",
        "                    \"stage_id\": stage.get(\"stage_id\"),\n",
        "                    \"document_id\": stage.get(\"document_id\"),\n",
        "                    \"stage_name\": name,\n",
        "                    \"metric\": \"duration_minutes\",\n",
        "                    \"actual\": round(duration_min, 1),\n",
        "                    \"expected\": expected_min,\n",
        "                    \"variance_pct\": round(pct_over, 1),\n",
        "                    \"threshold_pct\": variance_pct,\n",
        "                })\n",
        "    return anomalies\n",
        "\n",
        "\n",
        "def compute_bottleneck_stages(\n",
        "    workflow_stages: List[Dict[str, Any]],\n",
        "    stage_cost_baselines_lookup: Dict[str, Dict[str, Any]],\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Aggregate by stage_name: avg duration, failure count, document count.\"\"\"\n",
        "    by_stage: Dict[str, Dict[str, Any]] = {}\n",
        "    for s in workflow_stages:\n",
        "        name = s.get(\"stage_name\")\n",
        "        if not name:\n",
        "            continue\n",
        "        if name not in by_stage:\n",
        "            by_stage[name] = {\n",
        "                \"stage_name\": name,\n",
        "                \"total_count\": 0,\n",
        "                \"failed_count\": 0,\n",
        "                \"durations_minutes\": [],\n",
        "            }\n",
        "        rec = by_stage[name]\n",
        "        rec[\"total_count\"] += 1\n",
        "        if s.get(\"status\") == \"failed\":\n",
        "            rec[\"failed_count\"] += 1\n",
        "        dur = _duration_minutes(s.get(\"started_at\"), s.get(\"completed_at\"))\n",
        "        if dur is not None:\n",
        "            rec[\"durations_minutes\"].append(dur)\n",
        "\n",
        "    bottlenecks: List[Dict[str, Any]] = []\n",
        "    for name, rec in by_stage.items():\n",
        "        durations = rec.get(\"durations_minutes\") or []\n",
        "        avg_duration = sum(durations) / len(durations) if durations else None\n",
        "        total = rec[\"total_count\"]\n",
        "        failed = rec[\"failed_count\"]\n",
        "        failure_rate = (failed / total) if total else 0\n",
        "        baseline = stage_cost_baselines_lookup.get(name) or {}\n",
        "        expected_min = baseline.get(\"expected_minutes\")\n",
        "        b: Dict[str, Any] = {\n",
        "            \"stage_name\": name,\n",
        "            \"document_count\": total,\n",
        "            \"failure_count\": failed,\n",
        "            \"failure_rate\": round(failure_rate, 2),\n",
        "            \"avg_duration_minutes\": round(avg_duration, 1) if avg_duration is not None else None,\n",
        "            \"expected_minutes\": expected_min,\n",
        "        }\n",
        "        if avg_duration is not None and expected_min is not None and expected_min > 0:\n",
        "            b[\"duration_variance_pct\"] = round(((avg_duration - expected_min) / expected_min) * 100, 1)\n",
        "        bottlenecks.append(b)\n",
        "    return sorted(bottlenecks, key=lambda x: (x.get(\"failure_rate\", 0), -(x.get(\"avg_duration_minutes\") or 0)), reverse=True)\n",
        "\n",
        "\n",
        "def compute_reviewer_economics(\n",
        "    review_events: List[Dict[str, Any]],\n",
        "    reviewer_registry_lookup: Dict[str, Dict[str, Any]],\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Total cost by role (time_spent_minutes * hourly_cost_usd/60), and by reviewer.\"\"\"\n",
        "    by_role: Dict[str, Dict[str, Any]] = {}\n",
        "    total_usd = 0.0\n",
        "    for r in review_events:\n",
        "        reviewer_id = r.get(\"reviewer_id\")\n",
        "        minutes = r.get(\"time_spent_minutes\") or 0\n",
        "        reviewer = reviewer_registry_lookup.get(reviewer_id) if reviewer_id else {}\n",
        "        hourly = reviewer.get(\"hourly_cost_usd\") or 0\n",
        "        cost = (minutes / 60.0) * hourly\n",
        "        total_usd += cost\n",
        "        role = reviewer.get(\"role\") or r.get(\"reviewer_role\") or \"unknown\"\n",
        "        if role not in by_role:\n",
        "            by_role[role] = {\"minutes\": 0, \"cost_usd\": 0.0, \"review_count\": 0}\n",
        "        by_role[role][\"minutes\"] += minutes\n",
        "        by_role[role][\"cost_usd\"] = round(by_role[role][\"cost_usd\"] + cost, 2)\n",
        "        by_role[role][\"review_count\"] += 1\n",
        "\n",
        "    return {\n",
        "        \"total_reviewer_cost_usd\": round(total_usd, 2),\n",
        "        \"by_role\": by_role,\n",
        "        \"total_reviews\": len(review_events),\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_risk_tier_summary(\n",
        "    document_risk_profile_lookup: Dict[str, Dict[str, Any]],\n",
        "    documents: List[Dict[str, Any]],\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Count by risk_tier; count executive_visibility; high-risk exposure (tier_3 + high revenue_impact).\"\"\"\n",
        "    tier_counts: Dict[str, int] = {}\n",
        "    executive_visibility_count = 0\n",
        "    high_risk_count = 0\n",
        "    tier_3_count = 0\n",
        "    for d in documents:\n",
        "        doc_id = d.get(\"document_id\")\n",
        "        profile = document_risk_profile_lookup.get(doc_id) or {}\n",
        "        tier = profile.get(\"risk_tier\") or \"unknown\"\n",
        "        tier_counts[tier] = tier_counts.get(tier, 0) + 1\n",
        "        if profile.get(\"executive_visibility\"):\n",
        "            executive_visibility_count += 1\n",
        "        if tier == \"tier_3\" or (profile.get(\"regulatory_risk_level\") == \"high\" and profile.get(\"reputational_risk\") == \"high\"):\n",
        "            high_risk_count += 1\n",
        "        if tier == \"tier_3\":\n",
        "            tier_3_count += 1\n",
        "\n",
        "    return {\n",
        "        \"by_tier\": tier_counts,\n",
        "        \"executive_visibility_count\": executive_visibility_count,\n",
        "        \"high_risk_count\": high_risk_count,\n",
        "        \"tier_3_count\": tier_3_count,\n",
        "        \"total_documents\": len(documents),\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_portfolio_rollup(\n",
        "    documents: List[Dict[str, Any]],\n",
        "    workflow_stages: List[Dict[str, Any]],\n",
        "    review_events: List[Dict[str, Any]],\n",
        "    document_risk_profile_lookup: Dict[str, Dict[str, Any]],\n",
        "    stage_cost_baselines_lookup: Dict[str, Dict[str, Any]],\n",
        "    reviewer_registry_lookup: Dict[str, Dict[str, Any]],\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Single rollup dict for executive one-view and for compute_threshold_triggers.\n",
        "    Keys must match threshold_config in escalation (e.g. high_risk_count, stage_anomaly_count).\n",
        "    \"\"\"\n",
        "    stage_anomalies = compute_stage_anomalies(workflow_stages, stage_cost_baselines_lookup)\n",
        "    bottleneck_stages = compute_bottleneck_stages(workflow_stages, stage_cost_baselines_lookup)\n",
        "    reviewer_economics = compute_reviewer_economics(review_events, reviewer_registry_lookup)\n",
        "    risk_tier_summary = compute_risk_tier_summary(document_risk_profile_lookup, documents)\n",
        "\n",
        "    return {\n",
        "        \"total_documents\": len(documents),\n",
        "        \"high_risk_count\": risk_tier_summary[\"high_risk_count\"],\n",
        "        \"tier_3_count\": risk_tier_summary[\"tier_3_count\"],\n",
        "        \"stage_anomaly_count\": len(stage_anomalies),\n",
        "        \"executive_visibility_count\": risk_tier_summary[\"executive_visibility_count\"],\n",
        "        \"total_reviewer_cost_usd\": reviewer_economics[\"total_reviewer_cost_usd\"],\n",
        "        \"risk_tier_summary\": risk_tier_summary,\n",
        "        \"stage_anomalies\": stage_anomalies,\n",
        "        \"bottleneck_stages\": bottleneck_stages,\n",
        "        \"reviewer_economics\": reviewer_economics,\n",
        "    }\n"
      ]
    }
  ]
}