{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXDMBA7sVYOB5516Ndn2Lv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/492_EPOv2_dataLoading_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These utilities are **quietly one of the most important parts of the entire agent**. I’ll explain them as *trust infrastructure*, not as file I/O helpers, and I’ll stay aligned with your review guide: practical purpose, architectural role, and why this design increases control and confidence.\n",
        "\n",
        "---\n",
        "\n",
        "# Data Loading Utilities — Explained\n",
        "\n",
        "## What This Module Does in the System\n",
        "\n",
        "This module is the **boundary between the real world and the agent’s reasoning**.\n",
        "\n",
        "Before any analysis, decisions, or reporting happens, these utilities are responsible for:\n",
        "\n",
        "* loading facts\n",
        "* preserving raw data\n",
        "* enforcing structure\n",
        "* preparing fast, predictable access\n",
        "\n",
        "In short:\n",
        "\n",
        "> This module defines what the agent is *allowed to know* — and how reliably it knows it.\n",
        "\n",
        "That makes it a **trust-critical layer**, not just plumbing.\n",
        "\n",
        "---\n",
        "\n",
        "## Why These Functions Are Intentionally “Boring”\n",
        "\n",
        "Every function in this file is:\n",
        "\n",
        "* pure\n",
        "* deterministic\n",
        "* side-effect free\n",
        "* independently testable\n",
        "\n",
        "That is **by design**.\n",
        "\n",
        "This means:\n",
        "\n",
        "* no hidden mutations\n",
        "* no implicit defaults\n",
        "* no business logic leakage\n",
        "* no LLM involvement\n",
        "\n",
        "If something goes wrong later, you can confidently say:\n",
        "\n",
        "> “The data loaded exactly as it exists on disk.”\n",
        "\n",
        "That’s foundational for auditability.\n",
        "\n",
        "---\n",
        "\n",
        "## `load_json_file`: One Gate for All External Data\n",
        "\n",
        "### What it does\n",
        "\n",
        "This function is the **single ingestion gate** for all JSON-based experiment data.\n",
        "\n",
        "It:\n",
        "\n",
        "* validates file existence\n",
        "* loads JSON safely\n",
        "* normalizes the output into a list\n",
        "\n",
        "### Why this matters\n",
        "\n",
        "You’ve centralized:\n",
        "\n",
        "* error handling\n",
        "* file validation\n",
        "* schema normalization\n",
        "\n",
        "Instead of each loader handling edge cases differently, **everything passes through one controlled gate**.\n",
        "\n",
        "This prevents:\n",
        "\n",
        "* silent failures\n",
        "* partial loads\n",
        "* inconsistent data shapes\n",
        "\n",
        "It also makes testing trivial.\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset-Specific Loaders: Clear Intent, No Surprises\n",
        "\n",
        "Functions like:\n",
        "\n",
        "* `load_portfolio`\n",
        "* `load_experiment_definitions`\n",
        "* `load_experiment_metrics`\n",
        "* `load_experiment_analysis`\n",
        "* `load_experiment_decisions`\n",
        "* `load_experiment_learnings`\n",
        "* `load_experiment_audit_log`\n",
        "\n",
        "are intentionally thin wrappers.\n",
        "\n",
        "### Why that’s a strength\n",
        "\n",
        "Each function:\n",
        "\n",
        "* declares *what kind of data* is being loaded\n",
        "* enforces a consistent naming convention\n",
        "* avoids embedding assumptions about structure\n",
        "\n",
        "This creates **semantic clarity** in your nodes:\n",
        "\n",
        "```python\n",
        "portfolio = load_portfolio(...)\n",
        "```\n",
        "\n",
        "reads very differently (and more safely) than:\n",
        "\n",
        "```python\n",
        "load_json_file(\"some_path\")\n",
        "```\n",
        "\n",
        "This is how you build systems other people can understand and extend.\n",
        "\n",
        "---\n",
        "\n",
        "## Lookup Builders: Turning Data Into Working Memory\n",
        "\n",
        "Once data is loaded, the next problem is **efficient, readable access**.\n",
        "\n",
        "That’s what the lookup builders solve.\n",
        "\n",
        "---\n",
        "\n",
        "### One-to-One Lookups\n",
        "\n",
        "```python\n",
        "build_portfolio_lookup\n",
        "build_definitions_lookup\n",
        "build_analysis_lookup\n",
        "build_decisions_lookup\n",
        "```\n",
        "\n",
        "These convert lists into:\n",
        "\n",
        "```text\n",
        "experiment_id → single authoritative record\n",
        "```\n",
        "\n",
        "Why this matters:\n",
        "\n",
        "* eliminates repeated filtering\n",
        "* makes node logic simpler\n",
        "* reduces bug surface area\n",
        "* enforces “one source of truth” per experiment\n",
        "\n",
        "---\n",
        "\n",
        "### One-to-Many Lookups\n",
        "\n",
        "```python\n",
        "build_metrics_lookup\n",
        "build_learnings_lookup\n",
        "build_audit_log_lookup\n",
        "```\n",
        "\n",
        "These explicitly acknowledge reality:\n",
        "\n",
        "* experiments have multiple variants\n",
        "* experiments produce multiple learnings\n",
        "* experiments accumulate multiple audit events\n",
        "\n",
        "Instead of flattening or overwriting, you **preserve multiplicity**.\n",
        "\n",
        "That’s a subtle but very mature design choice.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Design Scales Cleanly\n",
        "\n",
        "Because loading and indexing are separated:\n",
        "\n",
        "* you can validate schemas later\n",
        "* you can add filters without refactoring loaders\n",
        "* you can introduce caching if needed\n",
        "* you can add new datasets safely\n",
        "\n",
        "Most importantly:\n",
        "\n",
        "> You can reason about **data correctness independently of analysis correctness**.\n",
        "\n",
        "That’s a huge reliability win.\n",
        "\n",
        "---\n",
        "\n",
        "## How This Supports Governance & Auditability\n",
        "\n",
        "From a leadership or compliance perspective, this module guarantees:\n",
        "\n",
        "* raw data is preserved\n",
        "* transformations are explicit\n",
        "* errors are surfaced immediately\n",
        "* nothing is inferred or hallucinated\n",
        "\n",
        "If someone asks:\n",
        "\n",
        "> “What data did the agent base this decision on?”\n",
        "\n",
        "You can trace it *exactly* through these functions.\n",
        "\n",
        "---\n",
        "\n",
        "## What This Module Is *Not* Doing (Intentionally)\n",
        "\n",
        "It does **not**:\n",
        "\n",
        "* validate business rules\n",
        "* infer missing fields\n",
        "* calculate metrics\n",
        "* enforce thresholds\n",
        "* clean data heuristically\n",
        "\n",
        "All of that happens **after** ingestion — on purpose.\n",
        "\n",
        "This keeps the boundary between *facts* and *judgment* crystal clear.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Is Enterprise-Grade, Not Overkill\n",
        "\n",
        "To a casual reader, this might look like “extra code.”\n",
        "\n",
        "To an experienced engineer or executive, it signals:\n",
        "\n",
        "* discipline\n",
        "* separation of concerns\n",
        "* testability\n",
        "* long-term maintainability\n",
        "\n",
        "This is exactly how real analytics platforms are built — just applied to an AI agent.\n",
        "\n",
        "---\n",
        "\n",
        "## Where This Fits in the Overall Workflow\n",
        "\n",
        "In your orchestrator:\n",
        "\n",
        "1. **Goal defined**\n",
        "2. **Plan created**\n",
        "3. **Data loaded (this module)**\n",
        "4. **Analysis & decisions occur**\n",
        "5. **Insights and reports generated**\n",
        "\n",
        "Everything downstream relies on this layer being correct — and you’ve designed it accordingly.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D9GgblNYAI4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06PMamGJ9wBq"
      },
      "outputs": [],
      "source": [
        "\"\"\"Data Loading Utilities for Experimentation Portfolio Orchestrator\n",
        "\n",
        "Functions to load experiment data from JSON files and build lookup dictionaries.\n",
        "All functions are pure and independently testable.\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "\n",
        "def load_json_file(file_path: Path) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load JSON data from a file.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to JSON file\n",
        "\n",
        "    Returns:\n",
        "        List of dictionaries from JSON file\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If file doesn't exist\n",
        "        json.JSONDecodeError: If file is not valid JSON\n",
        "    \"\"\"\n",
        "    if not file_path.exists():\n",
        "        raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Ensure we return a list (some files might be single objects)\n",
        "    if isinstance(data, dict):\n",
        "        return [data]\n",
        "    return data if isinstance(data, list) else []\n",
        "\n",
        "\n",
        "def load_portfolio(data_dir: str, filename: str = \"experiment_portfolio.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load experiment portfolio data.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        filename: Name of portfolio file\n",
        "\n",
        "    Returns:\n",
        "        List of portfolio entries\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_experiment_definitions(data_dir: str, filename: str = \"experiment_definitions.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load experiment definitions data.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        filename: Name of definitions file\n",
        "\n",
        "    Returns:\n",
        "        List of experiment definitions\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_experiment_metrics(data_dir: str, filename: str = \"experiment_metrics.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load experiment metrics data.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        filename: Name of metrics file\n",
        "\n",
        "    Returns:\n",
        "        List of experiment metrics (one per variant)\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_experiment_analysis(data_dir: str, filename: str = \"experiment_analysis.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load experiment analysis data.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        filename: Name of analysis file\n",
        "\n",
        "    Returns:\n",
        "        List of experiment analysis results\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_experiment_decisions(data_dir: str, filename: str = \"experiment_decisions.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load experiment decisions data.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        filename: Name of decisions file\n",
        "\n",
        "    Returns:\n",
        "        List of experiment decisions\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_experiment_learnings(data_dir: str, filename: str = \"experiment_learnings.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load experiment learnings data.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        filename: Name of learnings file\n",
        "\n",
        "    Returns:\n",
        "        List of experiment learnings\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def load_experiment_audit_log(data_dir: str, filename: str = \"experiment_audit_log.json\") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Load experiment audit log data.\n",
        "\n",
        "    Args:\n",
        "        data_dir: Directory containing data files\n",
        "        filename: Name of audit log file\n",
        "\n",
        "    Returns:\n",
        "        List of audit log events\n",
        "    \"\"\"\n",
        "    file_path = Path(data_dir) / filename\n",
        "    return load_json_file(file_path)\n",
        "\n",
        "\n",
        "def build_portfolio_lookup(portfolio: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary for portfolio entries.\n",
        "\n",
        "    Args:\n",
        "        portfolio: List of portfolio entries\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping experiment_id -> portfolio entry\n",
        "    \"\"\"\n",
        "    return {entry[\"experiment_id\"]: entry for entry in portfolio if \"experiment_id\" in entry}\n",
        "\n",
        "\n",
        "def build_definitions_lookup(definitions: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary for experiment definitions.\n",
        "\n",
        "    Args:\n",
        "        definitions: List of experiment definitions\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping experiment_id -> definition\n",
        "    \"\"\"\n",
        "    return {defn[\"experiment_id\"]: defn for defn in definitions if \"experiment_id\" in defn}\n",
        "\n",
        "\n",
        "def build_metrics_lookup(metrics: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary for experiment metrics.\n",
        "    Groups metrics by experiment_id (since each experiment can have multiple variants).\n",
        "\n",
        "    Args:\n",
        "        metrics: List of metric entries (one per variant)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping experiment_id -> list of variant metrics\n",
        "    \"\"\"\n",
        "    lookup: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for metric in metrics:\n",
        "        if \"experiment_id\" in metric:\n",
        "            exp_id = metric[\"experiment_id\"]\n",
        "            if exp_id not in lookup:\n",
        "                lookup[exp_id] = []\n",
        "            lookup[exp_id].append(metric)\n",
        "    return lookup\n",
        "\n",
        "\n",
        "def build_analysis_lookup(analysis: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary for experiment analysis results.\n",
        "\n",
        "    Args:\n",
        "        analysis: List of analysis results\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping experiment_id -> analysis result\n",
        "    \"\"\"\n",
        "    return {result[\"experiment_id\"]: result for result in analysis if \"experiment_id\" in result}\n",
        "\n",
        "\n",
        "def build_decisions_lookup(decisions: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary for experiment decisions.\n",
        "\n",
        "    Args:\n",
        "        decisions: List of decisions\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping experiment_id -> decision\n",
        "    \"\"\"\n",
        "    return {decision[\"experiment_id\"]: decision for decision in decisions if \"experiment_id\" in decision}\n",
        "\n",
        "\n",
        "def build_learnings_lookup(learnings: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary for experiment learnings.\n",
        "    Groups learnings by experiment_id (since each experiment can have multiple learnings).\n",
        "\n",
        "    Args:\n",
        "        learnings: List of learning entries\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping experiment_id -> list of learnings\n",
        "    \"\"\"\n",
        "    lookup: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for learning in learnings:\n",
        "        if \"experiment_id\" in learning:\n",
        "            exp_id = learning[\"experiment_id\"]\n",
        "            if exp_id not in lookup:\n",
        "                lookup[exp_id] = []\n",
        "            lookup[exp_id].append(learning)\n",
        "    return lookup\n",
        "\n",
        "\n",
        "def build_audit_log_lookup(audit_log: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:\n",
        "    \"\"\"\n",
        "    Build lookup dictionary for audit log events.\n",
        "    Groups events by experiment_id (since each experiment can have multiple events).\n",
        "\n",
        "    Args:\n",
        "        audit_log: List of audit log events\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping experiment_id -> list of audit events\n",
        "    \"\"\"\n",
        "    lookup: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for event in audit_log:\n",
        "        if \"experiment_id\" in event:\n",
        "            exp_id = event[\"experiment_id\"]\n",
        "            if exp_id not in lookup:\n",
        "                lookup[exp_id] = []\n",
        "            lookup[exp_id].append(event)\n",
        "    return lookup\n"
      ]
    }
  ]
}