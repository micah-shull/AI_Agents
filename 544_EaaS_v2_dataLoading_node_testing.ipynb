{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHe2X0D3U+0GSYsH0sgeUn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/544_EaaS_v2_dataLoading_node_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Data Loading Node — Architecture Review\n",
        "\n",
        "## What This Node Does in Practical Terms\n",
        "\n",
        "The `data_loading_node` is the **handoff point between intent and execution**.\n",
        "\n",
        "Up to this point, the system has:\n",
        "\n",
        "* declared *what* it wants to evaluate (goal)\n",
        "* defined *how* it will proceed (plan)\n",
        "\n",
        "This node answers the next critical question:\n",
        "\n",
        "> *“Do we have everything we need to evaluate this system responsibly?”*\n",
        "\n",
        "It loads **all factual inputs** required for evaluation and prepares them in a form that downstream nodes can rely on without ambiguity.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Matters Operationally\n",
        "\n",
        "This node establishes a crucial invariant:\n",
        "\n",
        "> **No evaluation happens without validated, complete context.**\n",
        "\n",
        "That invariant is enforced by:\n",
        "\n",
        "* centralized data loading\n",
        "* controlled error handling\n",
        "* explicit state updates\n",
        "\n",
        "If something is missing, malformed, or inconsistent, the system:\n",
        "\n",
        "* stops\n",
        "* records the error\n",
        "* refuses to proceed silently\n",
        "\n",
        "This prevents one of the most dangerous failure modes in AI systems: *confidently evaluating incomplete reality*.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Leaders Would Be Relieved to See This\n",
        "\n",
        "From a CEO or business manager’s perspective, this node quietly answers:\n",
        "\n",
        "> *“Does this system check that it actually knows the facts before it judges performance?”*\n",
        "\n",
        "Because this node:\n",
        "\n",
        "* loads historical baselines explicitly\n",
        "* prepares customer, order, and agent context\n",
        "* fails loudly on missing or invalid inputs\n",
        "* preserves prior state and error history\n",
        "\n",
        "leaders can trust that:\n",
        "\n",
        "* reports are grounded in real data\n",
        "* regressions aren’t artifacts of missing context\n",
        "* performance claims are defensible\n",
        "\n",
        "This is exactly how mature enterprise systems behave — and most AI agents do not.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Design Strengths\n",
        "\n",
        "### 1. The Node Is an Orchestrator, Not a Loader\n",
        "\n",
        "This node does **no file parsing itself**.\n",
        "\n",
        "Instead, it:\n",
        "\n",
        "* delegates loading to utilities\n",
        "* assembles the resulting artifacts\n",
        "* injects them into the orchestration state\n",
        "\n",
        "That separation is extremely important.\n",
        "\n",
        "It means:\n",
        "\n",
        "* the node expresses *intent*\n",
        "* the utilities express *mechanics*\n",
        "* testing can occur at both levels independently\n",
        "\n",
        "This keeps complexity controlled and evolution-safe.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Explicit State Construction (No Hidden Mutation)\n",
        "\n",
        "The return value explicitly lists every field the node adds to state.\n",
        "\n",
        "Nothing is:\n",
        "\n",
        "* modified implicitly\n",
        "* mutated in place\n",
        "* hidden behind side effects\n",
        "\n",
        "This makes the system:\n",
        "\n",
        "* predictable\n",
        "* debuggable\n",
        "* auditable\n",
        "\n",
        "Executives don’t need to understand Python to appreciate this — it mirrors how financial or compliance workflows are built.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Error Handling Is Structured and Honest\n",
        "\n",
        "Your exception handling is intentionally conservative:\n",
        "\n",
        "* `FileNotFoundError` → missing inputs\n",
        "* `JSONDecodeError` → corrupted facts\n",
        "* generic `Exception` → unexpected failure\n",
        "\n",
        "Each one:\n",
        "\n",
        "* appends to the existing error list\n",
        "* preserves prior context\n",
        "* stops the node cleanly\n",
        "\n",
        "This is critical for evaluation systems.\n",
        "\n",
        "It ensures that:\n",
        "\n",
        "* errors are not swallowed\n",
        "* partial state is not trusted\n",
        "* failures are visible upstream\n",
        "\n",
        "Most agents in production today don’t fail — they *degrade silently*. This node refuses to do that.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. Historical Data Is Loaded at the Same Level as Live Data\n",
        "\n",
        "This is a subtle but powerful architectural choice.\n",
        "\n",
        "By loading:\n",
        "\n",
        "* historical evaluation runs\n",
        "* historical metrics\n",
        "* historical scenario evaluations\n",
        "\n",
        "alongside live data, the node enforces a core principle:\n",
        "\n",
        "> **Evaluation is comparative, not absolute.**\n",
        "\n",
        "This enables:\n",
        "\n",
        "* baseline comparisons\n",
        "* regression detection\n",
        "* trend analysis\n",
        "* release gating\n",
        "\n",
        "Most AI agents evaluate “now” in isolation. Yours evaluates **in context**.\n",
        "\n",
        "---\n",
        "\n",
        "## How This Differs From Most Agents in Production Today\n",
        "\n",
        "Most agent systems:\n",
        "\n",
        "* load data lazily\n",
        "* mix loading with execution\n",
        "* assume files exist\n",
        "* overwrite state silently\n",
        "* cannot reproduce past evaluations\n",
        "\n",
        "This node:\n",
        "\n",
        "* centralizes all data access\n",
        "* enforces preconditions\n",
        "* preserves orchestration context\n",
        "* makes failures explicit\n",
        "* supports historical accountability\n",
        "\n",
        "That’s the difference between an experiment and infrastructure.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Design Supports ROI and Accountability\n",
        "\n",
        "Because this node:\n",
        "\n",
        "* fails early\n",
        "* preserves evidence\n",
        "* ensures completeness\n",
        "* supports historical comparison\n",
        "\n",
        "teams spend:\n",
        "\n",
        "* less time debugging weird results\n",
        "* less time questioning metrics\n",
        "* more time improving agents\n",
        "\n",
        "Executives gain:\n",
        "\n",
        "* confidence in reports\n",
        "* trust in trends\n",
        "* clarity around risk\n",
        "\n",
        "That directly protects ROI.\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Takeaway\n",
        "\n",
        "What a leader would see here is not “a loader.”\n",
        "\n",
        "They would see a system that says:\n",
        "\n",
        "> *“If we don’t have the facts, we don’t pretend to evaluate performance.”*\n",
        "\n",
        "That single property — enforced at the node level — is what makes the entire EaaS Orchestrator credible.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "acTQCJmq-rJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loading_node(\n",
        "    state: EvalAsServiceOrchestratorState,\n",
        "    config: EvalAsServiceOrchestratorConfig\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Data Loading Node: Orchestrate loading all data files.\n",
        "\n",
        "    Loads:\n",
        "    - Journey scenarios (test cases)\n",
        "    - Specialist agents (agents to evaluate)\n",
        "    - Supporting data (customers, orders, logistics, marketing)\n",
        "    - Decision rules (orchestrator logic)\n",
        "    - Historical data (for baseline comparison and regression detection)\n",
        "\n",
        "    Also builds lookup dictionaries for efficient access.\n",
        "    \"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    data_dir = config.data_dir\n",
        "\n",
        "    try:\n",
        "        # Load all data using utility\n",
        "        all_data = load_all_data(data_dir)\n",
        "\n",
        "        return {\n",
        "            \"journey_scenarios\": all_data[\"journey_scenarios\"],\n",
        "            \"specialist_agents\": all_data[\"specialist_agents\"],\n",
        "            \"agent_lookup\": all_data[\"agent_lookup\"],\n",
        "            \"supporting_data\": all_data[\"supporting_data\"],\n",
        "            \"customer_lookup\": all_data[\"customer_lookup\"],\n",
        "            \"order_lookup\": all_data[\"order_lookup\"],\n",
        "            \"decision_rules\": all_data[\"decision_rules\"],\n",
        "            \"historical_evaluation_runs\": all_data[\"historical_evaluation_runs\"],\n",
        "            \"historical_run_metrics\": all_data[\"historical_run_metrics\"],\n",
        "            \"historical_scenario_evaluations\": all_data[\"historical_scenario_evaluations\"],\n",
        "            \"run_metrics_lookup\": all_data[\"run_metrics_lookup\"],\n",
        "            \"evaluation_runs_lookup\": all_data[\"evaluation_runs_lookup\"],\n",
        "            \"errors\": errors\n",
        "        }\n",
        "    except FileNotFoundError as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: File not found: {str(e)}\"]\n",
        "        }\n",
        "    except json.JSONDecodeError as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: Invalid JSON: {str(e)}\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: Unexpected error: {str(e)}\"]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "UxtdMEv1997k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Phase 2 Node Test — Data Loading Node\n",
        "\n",
        "## What This Test Validates in Real-World Terms\n",
        "\n",
        "This test suite confirms that the **Data Loading Node functions as a proper orchestration boundary**, not just a thin wrapper around utilities.\n",
        "\n",
        "In practice, it verifies that:\n",
        "\n",
        "* The agent can move from *intent* (goal + plan)\n",
        "* To *prepared execution* (all required data loaded, validated, and indexed)\n",
        "* Without losing state or context\n",
        "\n",
        "That transition is one of the most failure-prone moments in real systems — and you’re explicitly testing it.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Matters Operationally\n",
        "\n",
        "Many AI systems fail not because logic is wrong, but because:\n",
        "\n",
        "* nodes overwrite state\n",
        "* integrations silently drop data\n",
        "* utilities work in isolation but not together\n",
        "* errors are swallowed or misrouted\n",
        "\n",
        "This test ensures that:\n",
        "\n",
        "* the node loads **all required inputs**\n",
        "* no critical datasets are missing\n",
        "* lookup tables are usable immediately\n",
        "* prior orchestration state is preserved\n",
        "* failures surface explicitly in the `errors` channel\n",
        "\n",
        "That’s operational robustness, not just correctness.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Leaders Would Be Relieved to See This\n",
        "\n",
        "From a business or executive perspective, this test answers a critical question:\n",
        "\n",
        "> *“Does the system reliably prepare itself before it starts judging performance?”*\n",
        "\n",
        "Because this test verifies:\n",
        "\n",
        "* presence of historical baselines\n",
        "* completeness of customer, order, and agent data\n",
        "* integrity of lookups\n",
        "* graceful failure when inputs are invalid\n",
        "\n",
        "leaders can trust that:\n",
        "\n",
        "* evaluation results aren’t based on partial data\n",
        "* regressions aren’t caused by missing context\n",
        "* reports don’t silently degrade in quality\n",
        "\n",
        "This is exactly the behavior they expect from production-grade systems — and almost never see from AI agents.\n",
        "\n",
        "---\n",
        "\n",
        "## Key Strengths in This Test Design\n",
        "\n",
        "### 1. You Test the Node, Not Just the Utilities\n",
        "\n",
        "You already tested the utilities in Phase 2.\n",
        "\n",
        "This test goes one level higher and asks:\n",
        "\n",
        "> “Does the orchestrator node correctly assemble everything?”\n",
        "\n",
        "That’s a critical distinction.\n",
        "\n",
        "Many systems stop at utility tests and assume orchestration will “just work.” You explicitly prove that it does.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. Lookup Validation Is Business-Critical\n",
        "\n",
        "You don’t just assert that lookups exist — you assert they work using **real scenario references**:\n",
        "\n",
        "* scenario → customer\n",
        "* scenario → order\n",
        "* agent → agent_id\n",
        "* run → metrics\n",
        "\n",
        "This confirms that:\n",
        "\n",
        "* relational integrity exists\n",
        "* downstream evaluation logic can safely assume lookups will succeed\n",
        "\n",
        "That dramatically reduces runtime surprises later.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Error Handling Is Tested Explicitly\n",
        "\n",
        "The invalid data directory test is particularly important.\n",
        "\n",
        "It proves that:\n",
        "\n",
        "* failures surface early\n",
        "* errors are captured, not swallowed\n",
        "* the system refuses to proceed silently\n",
        "\n",
        "Executives don’t fear AI because it fails — they fear it because it fails quietly. This test directly addresses that concern.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. State Preservation Is Verified\n",
        "\n",
        "The `test_data_loading_after_planning()` test is subtle but powerful.\n",
        "\n",
        "It confirms that:\n",
        "\n",
        "* the agent behaves as a *state machine*\n",
        "* prior nodes’ outputs are preserved\n",
        "* orchestration is additive, not destructive\n",
        "\n",
        "That’s essential for:\n",
        "\n",
        "* debuggability\n",
        "* audit trails\n",
        "* future branching or retries\n",
        "\n",
        "---\n",
        "\n",
        "## How This Differs From Most Agents in Production Today\n",
        "\n",
        "Most agents:\n",
        "\n",
        "* call loaders inline\n",
        "* assume data exists\n",
        "* overwrite state unintentionally\n",
        "* don’t test node-level integration\n",
        "* don’t verify historical data presence\n",
        "\n",
        "Your system:\n",
        "\n",
        "* treats data loading as a formal node\n",
        "* validates integration explicitly\n",
        "* preserves orchestration context\n",
        "* refuses to run under invalid conditions\n",
        "\n",
        "That’s the difference between a demo pipeline and operational infrastructure.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Supports ROI and Accountability\n",
        "\n",
        "Because the system:\n",
        "\n",
        "* fails early\n",
        "* preserves state\n",
        "* validates facts\n",
        "* exposes errors clearly\n",
        "\n",
        "teams spend:\n",
        "\n",
        "* less time debugging\n",
        "* less time questioning results\n",
        "* more time improving agents\n",
        "\n",
        "That directly translates to:\n",
        "\n",
        "* faster iteration\n",
        "* safer releases\n",
        "* higher executive confidence\n",
        "* better adoption\n",
        "\n",
        "Which is exactly how ROI is protected.\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Takeaway\n",
        "\n",
        "What a CEO or business manager would see here is not “test code.”\n",
        "\n",
        "They would see:\n",
        "\n",
        "* discipline\n",
        "* seriousness\n",
        "* operational safeguards\n",
        "* a system that checks itself before making claims\n",
        "\n",
        "This test quietly communicates:\n",
        "\n",
        "> *“If we don’t have the facts, we don’t pretend to evaluate performance.”*\n",
        "\n",
        "That’s a powerful signal — and one that most AI systems never send.\n",
        "\n",
        "---\n",
        "\n",
        "### What You’ve Achieved So Far\n",
        "\n",
        "At this point, you’ve fully locked down:\n",
        "\n",
        "* **intent** (goal)\n",
        "* **structure** (plan)\n",
        "* **facts** (data loading)\n",
        "* **integration safety** (node tests)\n",
        "* **historical grounding**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9ts7GQta-OIg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su9I4DkD9ixF"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Phase 2 Node Test: Data Loading Node\n",
        "\n",
        "Tests that data_loading_node works correctly with utilities.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from agents.eval_as_service.orchestrator.nodes import data_loading_node\n",
        "from config import EvalAsServiceOrchestratorState, EvalAsServiceOrchestratorConfig\n",
        "\n",
        "\n",
        "def test_data_loading_node():\n",
        "    \"\"\"Test data_loading_node with minimal state\"\"\"\n",
        "    print(\"Testing data_loading_node...\")\n",
        "\n",
        "    # Create config\n",
        "    config = EvalAsServiceOrchestratorConfig()\n",
        "\n",
        "    # Test 1: Basic data loading\n",
        "    state: EvalAsServiceOrchestratorState = {\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    result = data_loading_node(state, config)\n",
        "\n",
        "    # Check that all required fields are present\n",
        "    required_fields = [\n",
        "        \"journey_scenarios\",\n",
        "        \"specialist_agents\",\n",
        "        \"agent_lookup\",\n",
        "        \"supporting_data\",\n",
        "        \"customer_lookup\",\n",
        "        \"order_lookup\",\n",
        "        \"decision_rules\",\n",
        "        \"historical_evaluation_runs\",\n",
        "        \"historical_run_metrics\",\n",
        "        \"historical_scenario_evaluations\",\n",
        "        \"run_metrics_lookup\",\n",
        "        \"evaluation_runs_lookup\"\n",
        "    ]\n",
        "\n",
        "    for field in required_fields:\n",
        "        assert field in result, f\"Missing field: {field}\"\n",
        "\n",
        "    # Verify types\n",
        "    assert isinstance(result[\"journey_scenarios\"], list)\n",
        "    assert len(result[\"journey_scenarios\"]) > 0, \"Should have scenarios\"\n",
        "\n",
        "    assert isinstance(result[\"specialist_agents\"], dict)\n",
        "    assert len(result[\"specialist_agents\"]) > 0, \"Should have agents\"\n",
        "\n",
        "    assert isinstance(result[\"agent_lookup\"], dict)\n",
        "    assert len(result[\"agent_lookup\"]) > 0, \"Should have agent lookup\"\n",
        "\n",
        "    assert isinstance(result[\"supporting_data\"], dict)\n",
        "    assert \"customers\" in result[\"supporting_data\"]\n",
        "    assert \"orders\" in result[\"supporting_data\"]\n",
        "    assert \"logistics\" in result[\"supporting_data\"]\n",
        "    assert \"marketing_signals\" in result[\"supporting_data\"]\n",
        "\n",
        "    assert isinstance(result[\"customer_lookup\"], dict)\n",
        "    assert len(result[\"customer_lookup\"]) > 0, \"Should have customer lookup\"\n",
        "\n",
        "    assert isinstance(result[\"order_lookup\"], dict)\n",
        "    assert len(result[\"order_lookup\"]) > 0, \"Should have order lookup\"\n",
        "\n",
        "    assert isinstance(result[\"decision_rules\"], dict)\n",
        "\n",
        "    assert isinstance(result[\"historical_evaluation_runs\"], list)\n",
        "    assert len(result[\"historical_evaluation_runs\"]) > 0, \"Should have historical runs\"\n",
        "\n",
        "    assert isinstance(result[\"historical_run_metrics\"], list)\n",
        "    assert len(result[\"historical_run_metrics\"]) > 0, \"Should have historical metrics\"\n",
        "\n",
        "    assert isinstance(result[\"historical_scenario_evaluations\"], list)\n",
        "    assert len(result[\"historical_scenario_evaluations\"]) > 0, \"Should have historical evaluations\"\n",
        "\n",
        "    assert isinstance(result[\"run_metrics_lookup\"], dict)\n",
        "    assert len(result[\"run_metrics_lookup\"]) > 0, \"Should have run metrics lookup\"\n",
        "\n",
        "    assert isinstance(result[\"evaluation_runs_lookup\"], dict)\n",
        "    assert len(result[\"evaluation_runs_lookup\"]) > 0, \"Should have evaluation runs lookup\"\n",
        "\n",
        "    # Check that errors list is preserved\n",
        "    assert \"errors\" in result\n",
        "    assert isinstance(result[\"errors\"], list)\n",
        "\n",
        "    print(\"✅ Data loading node test 1 passed: All data loaded\")\n",
        "    print(f\"   Scenarios: {len(result['journey_scenarios'])}\")\n",
        "    print(f\"   Agents: {len(result['specialist_agents'])}\")\n",
        "    print(f\"   Customers: {len(result['customer_lookup'])}\")\n",
        "    print(f\"   Orders: {len(result['order_lookup'])}\")\n",
        "    print(f\"   Historical runs: {len(result['historical_evaluation_runs'])}\")\n",
        "    print(f\"   Historical metrics: {len(result['historical_run_metrics'])}\")\n",
        "    print(f\"   Historical evaluations: {len(result['historical_scenario_evaluations'])}\")\n",
        "\n",
        "    # Test 2: Verify lookup functionality\n",
        "    # Test customer lookup\n",
        "    if result[\"journey_scenarios\"]:\n",
        "        scenario = result[\"journey_scenarios\"][0]\n",
        "        customer_id = scenario.get(\"customer_id\")\n",
        "        if customer_id:\n",
        "            assert customer_id in result[\"customer_lookup\"], f\"Customer {customer_id} should be in lookup\"\n",
        "            customer = result[\"customer_lookup\"][customer_id]\n",
        "            assert customer[\"customer_id\"] == customer_id\n",
        "\n",
        "    # Test order lookup\n",
        "    if result[\"journey_scenarios\"]:\n",
        "        scenario = result[\"journey_scenarios\"][0]\n",
        "        order_id = scenario.get(\"order_id\")\n",
        "        if order_id:\n",
        "            assert order_id in result[\"order_lookup\"], f\"Order {order_id} should be in lookup\"\n",
        "            order = result[\"order_lookup\"][order_id]\n",
        "            assert order[\"order_id\"] == order_id\n",
        "\n",
        "    # Test agent lookup\n",
        "    if result[\"specialist_agents\"]:\n",
        "        agent_key = list(result[\"specialist_agents\"].keys())[0]\n",
        "        agent_data = result[\"specialist_agents\"][agent_key]\n",
        "        agent_id = agent_data.get(\"agent_id\")\n",
        "        if agent_id:\n",
        "            assert agent_id in result[\"agent_lookup\"], f\"Agent {agent_id} should be in lookup\"\n",
        "\n",
        "    # Test run metrics lookup\n",
        "    if result[\"historical_run_metrics\"]:\n",
        "        run_id = result[\"historical_run_metrics\"][0][\"run_id\"]\n",
        "        assert run_id in result[\"run_metrics_lookup\"], f\"Run {run_id} should be in metrics lookup\"\n",
        "        metrics = result[\"run_metrics_lookup\"][run_id]\n",
        "        assert metrics[\"run_id\"] == run_id\n",
        "\n",
        "    # Test evaluation runs lookup\n",
        "    if result[\"historical_evaluation_runs\"]:\n",
        "        run_id = result[\"historical_evaluation_runs\"][0][\"run_id\"]\n",
        "        assert run_id in result[\"evaluation_runs_lookup\"], f\"Run {run_id} should be in runs lookup\"\n",
        "        run = result[\"evaluation_runs_lookup\"][run_id]\n",
        "        assert run[\"run_id\"] == run_id\n",
        "\n",
        "    print(\"✅ Data loading node test 2 passed: Lookups work correctly\")\n",
        "\n",
        "    # Test 3: Error handling (invalid data directory)\n",
        "    config_invalid = EvalAsServiceOrchestratorConfig()\n",
        "    config_invalid.data_dir = \"nonexistent/directory\"\n",
        "\n",
        "    state_error: EvalAsServiceOrchestratorState = {\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    result_error = data_loading_node(state_error, config_invalid)\n",
        "    assert \"errors\" in result_error\n",
        "    assert len(result_error[\"errors\"]) > 0, \"Should have errors for invalid directory\"\n",
        "    print(\"✅ Data loading node test 3 passed: Error handling\")\n",
        "\n",
        "\n",
        "def test_data_loading_after_planning():\n",
        "    \"\"\"Test data loading node after planning node\"\"\"\n",
        "    print(\"Testing data_loading_node after planning_node...\")\n",
        "\n",
        "    from agents.eval_as_service.orchestrator.nodes import goal_node, planning_node\n",
        "\n",
        "    config = EvalAsServiceOrchestratorConfig()\n",
        "\n",
        "    # Start with goal and planning\n",
        "    state: EvalAsServiceOrchestratorState = {\n",
        "        \"scenario_id\": None,\n",
        "        \"target_agent_id\": None,\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    # Run goal node\n",
        "    state = goal_node(state)\n",
        "    assert \"goal\" in state\n",
        "\n",
        "    # Run planning node\n",
        "    state = planning_node(state)\n",
        "    assert \"plan\" in state\n",
        "\n",
        "    # Run data loading node\n",
        "    state = data_loading_node(state, config)\n",
        "\n",
        "    # Verify all data is loaded\n",
        "    assert \"journey_scenarios\" in state\n",
        "    assert \"specialist_agents\" in state\n",
        "    assert \"agent_lookup\" in state\n",
        "    assert \"supporting_data\" in state\n",
        "    assert \"customer_lookup\" in state\n",
        "    assert \"order_lookup\" in state\n",
        "    assert \"decision_rules\" in state\n",
        "    assert \"historical_evaluation_runs\" in state\n",
        "    assert \"historical_run_metrics\" in state\n",
        "    assert \"historical_scenario_evaluations\" in state\n",
        "\n",
        "    # Verify previous state is preserved\n",
        "    assert \"goal\" in state\n",
        "    assert \"plan\" in state\n",
        "\n",
        "    print(\"✅ Data loading after planning test passed\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Phase 2 Node Test: Data Loading Node\")\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        test_data_loading_node()\n",
        "        print()\n",
        "        test_data_loading_after_planning()\n",
        "        print()\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"✅ Phase 2 Node Tests: ALL PASSED\")\n",
        "        print(\"=\" * 60)\n",
        "    except AssertionError as e:\n",
        "        print(f\"❌ Test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Unexpected error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "EdGBf6YL-5Lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_021_EAAS % python3 test_eval_as_service_phase2_node.py\n",
        "============================================================\n",
        "Phase 2 Node Test: Data Loading Node\n",
        "============================================================\n",
        "\n",
        "Testing data_loading_node...\n",
        "✅ Data loading node test 1 passed: All data loaded\n",
        "   Scenarios: 10\n",
        "   Agents: 4\n",
        "   Customers: 5\n",
        "   Orders: 5\n",
        "   Historical runs: 6\n",
        "   Historical metrics: 6\n",
        "   Historical evaluations: 6\n",
        "✅ Data loading node test 2 passed: Lookups work correctly\n",
        "✅ Data loading node test 3 passed: Error handling\n",
        "\n",
        "Testing data_loading_node after planning_node...\n",
        "✅ Data loading after planning test passed\n",
        "\n",
        "============================================================\n",
        "✅ Phase 2 Node Tests: ALL PASSED\n",
        "============================================================\n"
      ],
      "metadata": {
        "id": "5vNSWXCk-6Rp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}