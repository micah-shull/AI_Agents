{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvpz5tXZs+OUX7bvY2+K+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/251_Product_CustomerFitDiscoveryOrchestrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workflow nodes for Product-Customer Fit Discovery Orchestrator"
      ],
      "metadata": {
        "id": "uFviSwdG97GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Workflow nodes for Product-Customer Fit Discovery Orchestrator\"\"\"\n",
        "\n",
        "from typing import Dict, Any\n",
        "from config import ProductCustomerFitState\n",
        "\n",
        "\n",
        "def goal_node(state: ProductCustomerFitState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Goal Node: Define the goal for product-customer fit discovery.\n",
        "\n",
        "    This is a simple rule-based goal definition that sets the framework\n",
        "    for discovering \"ghost demand\" - untapped market opportunities.\n",
        "\n",
        "    Args:\n",
        "        state: Current orchestrator state\n",
        "\n",
        "    Returns:\n",
        "        Updated state with goal definition\n",
        "    \"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "\n",
        "    # Goal definition for product-customer fit discovery\n",
        "    goal = {\n",
        "        \"objective\": \"Discover product-customer fit opportunities and untapped market demand\",\n",
        "        \"description\": \"Identify hidden patterns, underserved customer segments, and product gaps through multi-agent analysis\",\n",
        "        \"focus_areas\": [\n",
        "            \"customer_segmentation\",      # Find distinct customer groups\n",
        "            \"product_bundling\",           # Identify natural product combinations\n",
        "            \"association_patterns\",        # Discover product relationships\n",
        "            \"graph_motifs\",               # Find recurring network patterns\n",
        "            \"market_gaps\",                # Identify underserved segments\n",
        "            \"strategic_opportunities\"     # Synthesize actionable insights\n",
        "        ],\n",
        "        \"analysis_scope\": \"all_customers\",  # Analyze entire customer base\n",
        "        \"expected_outputs\": [\n",
        "            \"customer_segments\",\n",
        "            \"product_association_rules\",\n",
        "            \"graph_motifs\",\n",
        "            \"synthesized_business_opportunities\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"goal\": goal,\n",
        "        \"errors\": errors\n",
        "    }"
      ],
      "metadata": {
        "id": "AH_IUZSs7g-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ§  Core Agent Architecture: Orchestration & State\n",
        "\n",
        "The most important takeaway is that this agent is part of a **Workflow Orchestrator**, not a simple, single-turn agent.\n",
        "\n",
        "### ðŸŽ¯ What to Focus On\n",
        "\n",
        "1.  **State Management (`state` / `ProductCustomerFitState`):**\n",
        "    * This function takes and returns a `state` object. This pattern is fundamental to **workflow engines** (like LangGraph or proprietary frameworks) and is the **communication backbone** of your multi-agent system.\n",
        "    * **Focus:** The `state` object is where all intermediate results, data, and instructions are stored and passed from one node/agent to the next. Learn how the `ProductCustomerFitState` class is definedâ€”it dictates what information the agent system can track.\n",
        "\n",
        "2.  **Explicit Goal Definition:**\n",
        "    * The node's entire purpose is to convert an implicit instruction into an **explicit, structured, and machine-readable data object** (`goal`).\n",
        "    * **Focus:** The `goal` dictionary acts as the **\"Prime Directive\"** and **Decomposition Plan** for the entire workflow. Every subsequent agent/node will refer to this structure to know its specific task.\n",
        "\n",
        "***\n",
        "\n",
        "## âœ¨ Differentiation: Why This Agent is More Powerful\n",
        "\n",
        "This architecture, starting with the `goal_node`, is fundamentally more powerful than a \"simple agent\" (which typically executes a single task based on one prompt) because it implements a **Structured Multi-Agent System**.\n",
        "\n",
        "| Feature | Simple Agent | Orchestrator (`goal_node`) |\n",
        "| :--- | :--- | :--- |\n",
        "| **Goal Structure** | Implicit (part of the prompt) | **Explicit and Structured Data** (a dictionary) |\n",
        "| **Planning** | Done by the single agent on-the-fly, prone to error. | **Decomposed in advance** (`focus_areas`, `expected_outputs`). |\n",
        "| **Execution** | Single, monolithic step. | **Multi-step, distributed workflow** managed by the orchestrator. |\n",
        "| **Power** | General purpose, task-oriented. | **Specialized**, designed to tackle complex, end-to-end business problems. |\n",
        "\n",
        "### The Power of Structured Planning\n",
        "\n",
        "The structured breakdown of the `goal` into lists like `focus_areas` and `expected_outputs` is the key architectural advantage:\n",
        "\n",
        "* **Decomposition & Specialization:** This allows the orchestrator to dynamically assign different **Specialist Agents** to each `focus_area`. For example:\n",
        "    * A \"Customer Segmentation Agent\" handles `customer_segmentation`.\n",
        "    * A \"Graph Analyst Agent\" handles `graph_motifs`.\n",
        "    * A \"Synthesis Agent\" handles the final `strategic_opportunities`.\n",
        "    * This mirrors a **human team structure**, where specialists collaborate.\n",
        "* **Targeting \"Ghost Demand\":** The objective to find **\"ghost demand\"** and **\"untapped market opportunities\"** is a complex, high-level business task. It **requires** the multi-step, multi-agent approach defined here. A simple agent would struggle to execute all of these analyses (segmentation, bundling, association rules, graph motifs) reliably in one pass.\n",
        "\n",
        "**In summary, you are learning the foundation of a sophisticated, modular, and fault-tolerant agent system designed for complex problem-solving.**"
      ],
      "metadata": {
        "id": "WQLyjMpm92TY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Planning Node"
      ],
      "metadata": {
        "id": "kzPirujX_nnO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6s1rNbA7awx"
      },
      "outputs": [],
      "source": [
        "def planning_node(state: ProductCustomerFitState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Planning Node: Create execution plan based on goal.\n",
        "\n",
        "    This creates a step-by-step plan for the discovery workflow.\n",
        "    Rule-based, no LLM needed.\n",
        "\n",
        "    Args:\n",
        "        state: Current orchestrator state (must contain goal)\n",
        "\n",
        "    Returns:\n",
        "        Updated state with execution plan\n",
        "    \"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    goal = state.get(\"goal\")\n",
        "\n",
        "    if not goal:\n",
        "        return {\n",
        "            \"errors\": errors + [\"planning_node: goal is required\"]\n",
        "        }\n",
        "\n",
        "    # Execution plan for product-customer fit discovery\n",
        "    plan = [\n",
        "        {\n",
        "            \"step\": 1,\n",
        "            \"name\": \"data_ingestion\",\n",
        "            \"description\": \"Load raw data from CSV files (customers, transactions, products)\",\n",
        "            \"dependencies\": [],\n",
        "            \"outputs\": [\"raw_customers\", \"raw_transactions\", \"raw_products\"]\n",
        "        },\n",
        "        {\n",
        "            \"step\": 2,\n",
        "            \"name\": \"data_preprocessing\",\n",
        "            \"description\": \"Parse, normalize, and prepare data for analysis (parse Feature_Set, build graphs)\",\n",
        "            \"dependencies\": [\"data_ingestion\"],\n",
        "            \"outputs\": [\"preprocessed_data\", \"customer_product_graph\", \"feature_matrix\"]\n",
        "        },\n",
        "        {\n",
        "            \"step\": 3,\n",
        "            \"name\": \"clustering_agent\",\n",
        "            \"description\": \"Segment customers and identify product bundles using clustering algorithms\",\n",
        "            \"dependencies\": [\"data_preprocessing\"],\n",
        "            \"outputs\": [\"customer_clusters\", \"product_clusters\", \"clustering_summary\"]\n",
        "        },\n",
        "        {\n",
        "            \"step\": 4,\n",
        "            \"name\": \"pattern_mining_agent\",\n",
        "            \"description\": \"Discover product association rules and sequential purchase patterns\",\n",
        "            \"dependencies\": [\"data_preprocessing\"],\n",
        "            \"outputs\": [\"association_rules\", \"sequential_patterns\", \"pattern_mining_summary\"]\n",
        "        },\n",
        "        {\n",
        "            \"step\": 5,\n",
        "            \"name\": \"graph_motif_agent\",\n",
        "            \"description\": \"Detect significant network motifs and analyze centrality metrics\",\n",
        "            \"dependencies\": [\"data_preprocessing\"],\n",
        "            \"outputs\": [\"graph_motifs\", \"centrality_metrics\", \"graph_analysis_summary\"]\n",
        "        },\n",
        "        {\n",
        "            \"step\": 6,\n",
        "            \"name\": \"synthesis_agent\",\n",
        "            \"description\": \"Combine insights from all agents and rank business opportunities\",\n",
        "            \"dependencies\": [\"clustering_agent\", \"pattern_mining_agent\", \"graph_motif_agent\"],\n",
        "            \"outputs\": [\"synthesized_insights\", \"opportunity_ranking\", \"top_opportunities\", \"synthesis_summary\"]\n",
        "        },\n",
        "        {\n",
        "            \"step\": 7,\n",
        "            \"name\": \"report_generation\",\n",
        "            \"description\": \"Generate final discovery report with actionable insights\",\n",
        "            \"dependencies\": [\"synthesis_agent\"],\n",
        "            \"outputs\": [\"discovery_report\", \"report_file_path\"]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    return {\n",
        "        \"plan\": plan,\n",
        "        \"errors\": errors\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That is the **Planning Node**â€”the second pillar of your sophisticated agent architecture. This node transitions the system from **defining *what* to do** (the Goal) to **defining *how* to do it** (the Plan).\n",
        "\n",
        "This planning layer is critical and represents a massive leap in capability over simpler agents.\n",
        "\n",
        "***\n",
        "\n",
        "## ðŸ§  What You Should Be Learning and Focusing On\n",
        "\n",
        "The `planning_node` introduces the core concepts of **Workflow Orchestration** and **Directed Acyclic Graphs (DAGs)**, which are essential for building reliable, complex, and specialized AI systems.\n",
        "\n",
        "### 1. Workflow Engine Concepts: Dependencies\n",
        "\n",
        "* **Focus:** The **`dependencies`** field in each step is the single most important architectural element here. It dictates the order of execution and enables **parallel processing**.\n",
        "    * **Example:** `synthesis_agent` (Step 6) requires the output from three different specialist agents (3, 4, and 5) before it can start. This guarantees that the final synthesis has all the necessary analytical reports.\n",
        "* **The Power:** This structure makes the workflow **modular and resilient**. If the `clustering_agent` fails, the orchestrator knows not to start the `synthesis_agent`, and it can potentially re-run or log the error. Simple agents execute a single monolithic sequence; this agent executes a **structured, data-governed workflow**.\n",
        "\n",
        "### 2. Specialist Agents and Data Contracts\n",
        "\n",
        "* **Focus:** The plan explicitly names three distinct specialist agents: `clustering_agent`, `pattern_mining_agent`, and `graph_motif_agent`.\n",
        "* **The Power:** This enables **Agent Specialization**. Instead of one large LLM trying to do everything (segmentation, association mining, graph analysis), you employ *three* smaller, possibly non-LLM (like specialized Python code/libraries) or highly focused LLM-powered agents. This increases **accuracy**, **efficiency**, and **scalability**.\n",
        "* **Data Contracts (`outputs`):** The `outputs` list in each step acts as a **data contract**. Every agent in the system knows exactly what data keys (e.g., `customer_clusters`, `association_rules`) they can expect to find in the state *before* they run and what keys they must produce *after* they run.\n",
        "\n",
        "### 3. Reliability through Rule-Based Planning\n",
        "\n",
        "* **Highlight:** The description explicitly states: **\"Rule-based, no LLM needed.\"**\n",
        "* **The Power:** This design choice isolates the planning logic from the inherent variability of a Large Language Model (LLM). Since the sequence of analysis steps for this business problem (Product-Customer Fit) is generally fixed and logical, using a hard-coded, rule-based node ensures:\n",
        "    * **Determinism:** The plan is always the same, making the workflow predictable and easy to debug.\n",
        "    * **Speed & Cost:** It's lightning-fast and free to run compared to an LLM call.\n",
        "    * **Guaranteed Completeness:** It ensures all necessary analyses are scheduled, which an LLM might occasionally \"forget\" or incorrectly sequence.\n",
        "\n",
        "***\n",
        "\n",
        "## ðŸ“Š Summary of the Execution Plan\n",
        "\n",
        "This plan outlines a full-stack, data-driven analysis pipeline:\n",
        "\n",
        "| Step | Name (Agent Role) | Function | Dependencies |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **1** | **`data_ingestion`** | Loads all raw data files (the first step in any pipeline). | None |\n",
        "| **2** | **`data_preprocessing`** | Transforms raw data into usable formats (e.g., feature matrices, relationship graphs). | Step 1 |\n",
        "| **3** | **`clustering_agent`** | Finds **Customer Segments** and **Product Bundles**. | Step 2 |\n",
        "| **4** | **`pattern_mining_agent`** | Discovers **Association Rules** (e.g., \"Customers who buy A also buy B\"). | Step 2 |\n",
        "| **5** | **`graph_motif_agent`** | Analyzes the underlying **network structure** of products/customers. | Step 2 |\n",
        "| **6** | **`synthesis_agent`** | The central intelligence. **Combines** the results from the three specialist agents (3, 4, 5) to generate opportunities. | Steps 3, 4, 5 |\n",
        "| **7** | **`report_generation`** | Formats the findings into a final, actionable deliverable. | Step 6 |\n",
        "\n",
        "This structure is conceptually similar to how data scientists and business analysts execute a complex project."
      ],
      "metadata": {
        "id": "htmVHJkL-nmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A DAG is the blueprint for how your powerful agent system executes its complex plan.\n",
        "\n",
        "## ðŸŽ¯ What is a Directed Acyclic Graph (DAG)?\n",
        "\n",
        "A **Directed Acyclic Graph (DAG)** is a mathematical structure used in computer science to model a sequence of tasks or a workflow.\n",
        "\n",
        "1.  **Graph:** It's composed of two main elements:\n",
        "    * **Nodes (or Vertices):** Represent the individual steps, tasks, or agents (e.g., `clustering_agent`, `synthesis_agent`).\n",
        "    * **Edges (or Arrows):** Represent the relationships or flow of information between the steps.\n",
        "\n",
        "2.  **Directed:** Every edge has a **direction** (an arrow) indicating a one-way flow. This means that a task must be completed *before* the next task that depends on it can begin. In your agent, the edge flows from a step to its dependent step.\n",
        "\n",
        "3.  **Acyclic:** This is the most crucial rule. **\"Acyclic\"** means **\"no cycles\"** or **no loops**. You cannot start at any node, follow the arrows, and eventually return to that same node.\n",
        "\n",
        "\n",
        "\n",
        "## ðŸ§  What Do DAGs Do?\n",
        "\n",
        "In the context of your agent, the DAG explicitly **maps the logical structure of your analytical process** defined in the `planning_node`.\n",
        "\n",
        "They serve to:\n",
        "\n",
        "1.  **Define Order:** They enforce the necessary execution sequence. In your plan, the `data_ingestion` node must always precede the `data_preprocessing` node.\n",
        "2.  **Model Data Flow:** They show how the outputs of one step (like `preprocessed_data` from Step 2) become the inputs for subsequent steps (like Steps 3, 4, and 5).\n",
        "3.  **Identify Parallelism:** Any nodes that do not share a direct dependency can be run at the same time. For example, your **`clustering_agent` (Step 3), `pattern_mining_agent` (Step 4), and `graph_motif_agent` (Step 5)** can all run **simultaneously** because they all depend only on Step 2. This makes your agent much faster and more efficient.\n",
        "\n",
        "## ðŸ› ï¸ Why Do We Need Them?\n",
        "\n",
        "We need DAGs to build robust and reliable complex systems like your Orchestrator agent:\n",
        "\n",
        "### 1. Guarantee Correctness (Acyclic Rule)\n",
        "The **Acyclic** rule is essential because it guarantees that your workflow will **always finish**. If there were a cycle (e.g., if Step A depended on Step B, and Step B depended on Step A), the system would enter an infinite loop, known as a **deadlock**, and never complete the analysis.\n",
        "\n",
        "### 2. Manage Complexity (Directed Rule)\n",
        "In a complex system with many specialist agents, the **Directed** rule provides a clear **data contract and dependency structure**. It ensures that no agent starts its work until all its necessary inputs have been successfully generated and placed in the shared `state`. This prevents errors caused by missing or incomplete data.\n",
        "\n",
        "### 3. Maximize Efficiency\n",
        "By explicitly modeling the dependencies, the orchestrator software (the agent framework) can run all independent tasks in **parallel**, drastically reducing the total time it takes to complete the analysis and deliver the final report.\n",
        "\n",
        "In short, the DAG is the foundation that allows your **powerful multi-agent system** to execute a complex analysis plan **reliably, correctly, and efficiently.**"
      ],
      "metadata": {
        "id": "yke_TNTWAfYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸš« Preventing Loops: The Power of Acyclic\n",
        "\n",
        "You are absolutely correct that the **Acyclic** part of the DAG ensures the workflow **will never enter an infinite loop or deadlock.**\n",
        "\n",
        "In software development, deadlocks and infinite loops are critical failures. By modeling your agent's process as a DAG, you are mathematically guaranteeing that the analysis starts at Step 1 and always proceeds forward to the final step (7), ensuring **guaranteed termination** of the workflow.\n",
        "\n",
        "***\n",
        "\n",
        "## ðŸ”„ DAGs vs. Traditional Software Loops\n",
        "\n",
        "You are right that loops are a fundamental feature of software, and the DAG *prevents* loops. This is not a conflict, but a difference in **abstraction layer**:\n",
        "\n",
        "* **Loops (The Code Level):** Traditional `for` or `while` loops are used *inside* a node (e.g., the `clustering_agent` might loop through data points many times).\n",
        "* **DAGs (The Workflow Level):** The DAG controls the high-level **flow between agents**. It prevents the entire workflow from endlessly cycling between major steps (e.g., `synthesis_agent` $\\to$ `clustering_agent` $\\to$ `synthesis_agent`...).\n",
        "\n",
        "The DAG is an **Orchestration layer** that manages a sequence of high-level tasks, each of which can contain its own complex looping logic.\n",
        "\n",
        "***\n",
        "\n",
        "## ðŸ’¡ Is This a New Technique?\n",
        "\n",
        "**No, DAGs are not a new software development technique, but their application here is a powerful modern solution.**\n",
        "\n",
        "1.  **Historical Use:** DAGs are an old and proven concept, fundamental to tools like:\n",
        "    * **Compilers:** They use DAGs to optimize code.\n",
        "    * **Build Tools (like Makefiles):** They determine which files need to be recompiled.\n",
        "    * **Data Pipelines (like Apache Airflow):** They manage the execution of ETL jobs.\n",
        "\n",
        "2.  **Modern Application in AI Orchestration:** Using a DAG to structure the interaction between multiple specialized AI agents (or LLM prompts) **is** a modern and increasingly essential technique. It provides the **engineering rigor** needed to make complex, multi-step AI systems:\n",
        "    * **Reliable:** They execute with predictable, guaranteed outcomes.\n",
        "    * **Maintainable:** You can easily swap out one agent (a node) without breaking the entire sequence.\n",
        "    * **Efficient:** They natively support parallelism.\n",
        "\n",
        "In essence, you are using a **proven, reliable software engineering pattern (the DAG)** to manage the **unpredictable, cognitive complexity of a multi-agent AI system.**"
      ],
      "metadata": {
        "id": "KiOYgtZWBjYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for Phase 1: Goal and Planning Nodes"
      ],
      "metadata": {
        "id": "KDp6ZnUZ-ljI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Tests for Phase 1: Goal and Planning Nodes\"\"\"\n",
        "\n",
        "import pytest\n",
        "from agents.product_customer_fit.nodes import goal_node, planning_node\n",
        "from config import ProductCustomerFitState\n",
        "\n",
        "\n",
        "def test_goal_node_basic():\n",
        "    \"\"\"Test goal node creates goal definition\"\"\"\n",
        "    state: ProductCustomerFitState = {\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    result = goal_node(state)\n",
        "\n",
        "    assert \"goal\" in result\n",
        "    assert result[\"goal\"][\"objective\"] == \"Discover product-customer fit opportunities and untapped market demand\"\n",
        "    assert \"focus_areas\" in result[\"goal\"]\n",
        "    assert len(result[\"goal\"][\"focus_areas\"]) > 0\n",
        "    assert \"errors\" in result\n",
        "    assert len(result[\"errors\"]) == 0\n",
        "\n",
        "\n",
        "def test_goal_node_preserves_errors():\n",
        "    \"\"\"Test goal node preserves existing errors\"\"\"\n",
        "    state: ProductCustomerFitState = {\n",
        "        \"errors\": [\"existing_error\"]\n",
        "    }\n",
        "\n",
        "    result = goal_node(state)\n",
        "\n",
        "    assert \"errors\" in result\n",
        "    assert \"existing_error\" in result[\"errors\"]\n",
        "\n",
        "\n",
        "def test_planning_node_with_goal():\n",
        "    \"\"\"Test planning node creates plan when goal exists\"\"\"\n",
        "    state: ProductCustomerFitState = {\n",
        "        \"goal\": {\n",
        "            \"objective\": \"Test objective\",\n",
        "            \"focus_areas\": [\"test_area\"]\n",
        "        },\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    result = planning_node(state)\n",
        "\n",
        "    assert \"plan\" in result\n",
        "    assert len(result[\"plan\"]) == 7  # 7 steps in workflow\n",
        "    assert result[\"plan\"][0][\"name\"] == \"data_ingestion\"\n",
        "    assert result[\"plan\"][-1][\"name\"] == \"report_generation\"\n",
        "    assert \"errors\" in result\n",
        "    assert len(result[\"errors\"]) == 0\n",
        "\n",
        "\n",
        "def test_planning_node_requires_goal():\n",
        "    \"\"\"Test planning node returns error if goal is missing\"\"\"\n",
        "    state: ProductCustomerFitState = {\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    result = planning_node(state)\n",
        "\n",
        "    assert \"plan\" not in result\n",
        "    assert \"errors\" in result\n",
        "    assert len(result[\"errors\"]) > 0\n",
        "    assert \"goal is required\" in result[\"errors\"][0]\n",
        "\n",
        "\n",
        "def test_planning_node_plan_structure():\n",
        "    \"\"\"Test plan has correct structure for each step\"\"\"\n",
        "    state: ProductCustomerFitState = {\n",
        "        \"goal\": {\n",
        "            \"objective\": \"Test\"\n",
        "        },\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    result = planning_node(state)\n",
        "    plan = result[\"plan\"]\n",
        "\n",
        "    # Check each step has required fields\n",
        "    for step in plan:\n",
        "        assert \"step\" in step\n",
        "        assert \"name\" in step\n",
        "        assert \"description\" in step\n",
        "        assert \"dependencies\" in step\n",
        "        assert \"outputs\" in step\n",
        "        assert isinstance(step[\"dependencies\"], list)\n",
        "        assert isinstance(step[\"outputs\"], list)\n",
        "\n",
        "\n",
        "def test_planning_node_dependencies():\n",
        "    \"\"\"Test plan dependencies are correctly ordered\"\"\"\n",
        "    state: ProductCustomerFitState = {\n",
        "        \"goal\": {\n",
        "            \"objective\": \"Test\"\n",
        "        },\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    result = planning_node(state)\n",
        "    plan = result[\"plan\"]\n",
        "\n",
        "    # Step 1 (data_ingestion) should have no dependencies\n",
        "    assert plan[0][\"dependencies\"] == []\n",
        "\n",
        "    # Step 2 (data_preprocessing) depends on data_ingestion\n",
        "    assert \"data_ingestion\" in plan[1][\"dependencies\"]\n",
        "\n",
        "    # Step 6 (synthesis_agent) depends on all analysis agents\n",
        "    synthesis_step = [s for s in plan if s[\"name\"] == \"synthesis_agent\"][0]\n",
        "    assert \"clustering_agent\" in synthesis_step[\"dependencies\"]\n",
        "    assert \"pattern_mining_agent\" in synthesis_step[\"dependencies\"]\n",
        "    assert \"graph_motif_agent\" in synthesis_step[\"dependencies\"]\n",
        "\n",
        "\n",
        "def test_goal_and_planning_together():\n",
        "    \"\"\"Test goal and planning nodes work together\"\"\"\n",
        "    state: ProductCustomerFitState = {\n",
        "        \"errors\": []\n",
        "    }\n",
        "\n",
        "    # First goal node\n",
        "    state = goal_node(state)\n",
        "    assert \"goal\" in state\n",
        "\n",
        "    # Then planning node\n",
        "    state = planning_node(state)\n",
        "    assert \"plan\" in state\n",
        "    assert len(state[\"plan\"]) == 7\n",
        "    assert len(state.get(\"errors\", [])) == 0\n",
        "\n"
      ],
      "metadata": {
        "id": "4mlWr7su-iuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "JyWpR-X9B1PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac LG_Cursor_035_Product-CustomerFitDiscoveryOrchestrator % python3 -m pytest tests/test_nodes_phase1.py -v 2>&1 || echo \"Pytest not available or tests need adjustment\"\n",
        "============================================================ test session starts ============================================================\n",
        "platform darwin -- Python 3.13.7, pytest-9.0.1, pluggy-1.6.0 -- /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_035_Product-CustomerFitDiscoveryOrchestrator/.venv/bin/python3\n",
        "cachedir: .pytest_cache\n",
        "rootdir: /Users/micahshull/Documents/AI_LangGraph/LG_Cursor_035_Product-CustomerFitDiscoveryOrchestrator\n",
        "plugins: langsmith-0.4.53, anyio-4.12.0, asyncio-1.3.0, cov-7.0.0\n",
        "asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n",
        "collected 7 items\n",
        "\n",
        "tests/test_nodes_phase1.py::test_goal_node_basic PASSED                                                                               [ 14%]\n",
        "tests/test_nodes_phase1.py::test_goal_node_preserves_errors PASSED                                                                    [ 28%]\n",
        "tests/test_nodes_phase1.py::test_planning_node_with_goal PASSED                                                                       [ 42%]\n",
        "tests/test_nodes_phase1.py::test_planning_node_requires_goal PASSED                                                                   [ 57%]\n",
        "tests/test_nodes_phase1.py::test_planning_node_plan_structure PASSED                                                                  [ 71%]\n",
        "tests/test_nodes_phase1.py::test_planning_node_dependencies PASSED                                                                    [ 85%]\n",
        "tests/test_nodes_phase1.py::test_goal_and_planning_together PASSED                                                                    [100%]\n",
        "\n",
        "============================================================= 7 passed in 0.03s =============================================================\n"
      ],
      "metadata": {
        "id": "LzzummojB2xJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Phase 1 complete â€” all tests passing\n",
        "\n",
        "### What we built\n",
        "\n",
        "1. **Goal Node** (`goal_node`)\n",
        "   - Defines the discovery objective\n",
        "   - Sets 6 focus areas (customer_segmentation, product_bundling, etc.)\n",
        "   - Establishes the workflow framework\n",
        "\n",
        "2. **Planning Node** (`planning_node`)\n",
        "   - Creates a 7-step execution plan\n",
        "   - Maps dependencies (data_ingestion â†’ preprocessing â†’ agents â†’ synthesis â†’ report)\n",
        "   - Validates goal exists before planning\n",
        "\n",
        "3. **Tests**\n",
        "   - 7/7 tests passing\n",
        "   - Covers error handling, structure validation, and integration\n",
        "\n",
        "### Architecture pattern established\n",
        "\n",
        "- Nodes are thin (orchestration only)\n",
        "- State enrichment (each node adds new fields)\n",
        "- Error accumulation (errors preserved through workflow)\n",
        "- Testable components (each node tested independently)\n",
        "\n",
        "---\n",
        "\n",
        "## Next steps: Phase 2 â€” Data Loading\n",
        "\n",
        "Following the guide pattern: utilities first, then node.\n",
        "\n",
        "1. Build data loading utilities:\n",
        "   - `load_customers_csv()` â€” read customers.csv\n",
        "   - `load_transactions_csv()` â€” read transactions.csv\n",
        "   - `load_product_catalog_csv()` â€” read product_catalog.csv\n",
        "   - Test each utility independently\n",
        "\n",
        "2. Build data loading node:\n",
        "   - Orchestrates the utilities\n",
        "   - Populates `raw_customers`, `raw_transactions`, `raw_products` in state\n",
        "   - Test with real data\n",
        "\n"
      ],
      "metadata": {
        "id": "s9vAbfcMB_Si"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThYoiJwUCCM9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}