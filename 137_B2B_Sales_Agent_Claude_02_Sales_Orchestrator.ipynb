{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOVDGKyfaZMTL3Oxsvzd4/B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/137_B2B_Sales_Agent_Claude_02_Sales_Orchestrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sales Orchestrator"
      ],
      "metadata": {
        "id": "ogeg_6lGo1_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcSIPrcKacCT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Sales Orchestrator - Manages multi-agent sales pipeline workflow\n",
        "\n",
        "This orchestrator demonstrates:\n",
        "- Workflow management and state handling\n",
        "- Error handling and retry logic\n",
        "- Agent coordination and data flow\n",
        "- Monitoring and logging\n",
        "- Human-in-the-loop capabilities\n",
        "\"\"\"\n",
        "\n",
        "import logging\n",
        "import time\n",
        "from typing import Dict, List, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "from research_agent import ResearchAgent, CompanyInfo\n",
        "from analysis_agent import AnalysisAgent, AnalysisResult\n",
        "from personalization_agent import PersonalizationAgent, PersonalizationResult\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class WorkflowStatus(Enum):\n",
        "    \"\"\"Workflow execution status\"\"\"\n",
        "    PENDING = \"pending\"\n",
        "    IN_PROGRESS = \"in_progress\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    RETRYING = \"retrying\"\n",
        "\n",
        "class AgentStatus(Enum):\n",
        "    \"\"\"Individual agent status\"\"\"\n",
        "    READY = \"ready\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    SKIPPED = \"skipped\"\n",
        "\n",
        "@dataclass\n",
        "class WorkflowStep:\n",
        "    \"\"\"Represents a step in the workflow\"\"\"\n",
        "    step_id: str\n",
        "    agent_name: str\n",
        "    status: AgentStatus = AgentStatus.PENDING\n",
        "    start_time: Optional[datetime] = None\n",
        "    end_time: Optional[datetime] = None\n",
        "    error_message: Optional[str] = None\n",
        "    retry_count: int = 0\n",
        "    max_retries: int = 3\n",
        "    input_data: Optional[Dict[str, Any]] = None\n",
        "    output_data: Optional[Dict[str, Any]] = None\n",
        "\n",
        "@dataclass\n",
        "class WorkflowState:\n",
        "    \"\"\"Complete workflow state\"\"\"\n",
        "    workflow_id: str\n",
        "    company_name: str\n",
        "    status: WorkflowStatus = WorkflowStatus.PENDING\n",
        "    start_time: Optional[datetime] = None\n",
        "    end_time: Optional[datetime] = None\n",
        "    steps: List[WorkflowStep] = field(default_factory=list)\n",
        "    current_step_index: int = 0\n",
        "    error_message: Optional[str] = None\n",
        "    human_intervention_required: bool = False\n",
        "    human_intervention_reason: Optional[str] = None\n",
        "\n",
        "class SalesOrchestrator:\n",
        "    \"\"\"\n",
        "    Sales Orchestrator that manages the complete sales research pipeline\n",
        "\n",
        "    This orchestrator demonstrates:\n",
        "    - Sequential workflow execution\n",
        "    - Error handling and retry logic\n",
        "    - State management across agents\n",
        "    - Human-in-the-loop capabilities\n",
        "    - Comprehensive monitoring and logging\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, orchestrator_id: str = \"sales_orchestrator\"):\n",
        "        self.orchestrator_id = orchestrator_id\n",
        "        self.logger = logging.getLogger(f\"{__name__}.{orchestrator_id}\")\n",
        "\n",
        "        # Initialize agents\n",
        "        self.research_agent = ResearchAgent()\n",
        "        self.analysis_agent = AnalysisAgent()\n",
        "        self.personalization_agent = PersonalizationAgent()\n",
        "\n",
        "        # Workflow configuration\n",
        "        self.workflow_steps = [\n",
        "            {\n",
        "                \"step_id\": \"research\",\n",
        "                \"agent_name\": \"research_agent\",\n",
        "                \"description\": \"Research company information\"\n",
        "            },\n",
        "            {\n",
        "                \"step_id\": \"analysis\",\n",
        "                \"agent_name\": \"analysis_agent\",\n",
        "                \"description\": \"Analyze pain points and opportunities\"\n",
        "            },\n",
        "            {\n",
        "                \"step_id\": \"personalization\",\n",
        "                \"agent_name\": \"personalization_agent\",\n",
        "                \"description\": \"Create personalized outreach messages\"\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Active workflows\n",
        "        self.active_workflows: Dict[str, WorkflowState] = {}\n",
        "\n",
        "        self.logger.info(f\"Sales Orchestrator initialized with {len(self.workflow_steps)} steps\")\n",
        "\n",
        "    def execute_sales_pipeline(self, company_name: str, sender_name: str = \"Sales Professional\") -> WorkflowState:\n",
        "        \"\"\"\n",
        "        Execute the complete sales research pipeline\n",
        "\n",
        "        Args:\n",
        "            company_name: Name of the company to research\n",
        "            sender_name: Name of the person sending outreach\n",
        "\n",
        "        Returns:\n",
        "            WorkflowState with complete execution results\n",
        "        \"\"\"\n",
        "        workflow_id = f\"workflow_{int(time.time())}_{company_name.replace(' ', '_')}\"\n",
        "\n",
        "        self.logger.info(f\"Starting sales pipeline for {company_name} (Workflow ID: {workflow_id})\")\n",
        "\n",
        "        # Initialize workflow state\n",
        "        workflow_state = WorkflowState(\n",
        "            workflow_id=workflow_id,\n",
        "            company_name=company_name,\n",
        "            status=WorkflowStatus.IN_PROGRESS,\n",
        "            start_time=datetime.now()\n",
        "        )\n",
        "\n",
        "        # Initialize workflow steps\n",
        "        for step_config in self.workflow_steps:\n",
        "            step = WorkflowStep(\n",
        "                step_id=step_config[\"step_id\"],\n",
        "                agent_name=step_config[\"agent_name\"]\n",
        "            )\n",
        "            workflow_state.steps.append(step)\n",
        "\n",
        "        # Store active workflow\n",
        "        self.active_workflows[workflow_id] = workflow_state\n",
        "\n",
        "        try:\n",
        "            # Execute workflow steps\n",
        "            self._execute_workflow_steps(workflow_state, sender_name)\n",
        "\n",
        "            # Mark workflow as completed\n",
        "            workflow_state.status = WorkflowStatus.COMPLETED\n",
        "            workflow_state.end_time = datetime.now()\n",
        "\n",
        "            self.logger.info(f\"Sales pipeline completed for {company_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle workflow failure\n",
        "            workflow_state.status = WorkflowStatus.FAILED\n",
        "            workflow_state.end_time = datetime.now()\n",
        "            workflow_state.error_message = str(e)\n",
        "\n",
        "            self.logger.error(f\"Sales pipeline failed for {company_name}: {str(e)}\")\n",
        "\n",
        "        return workflow_state\n",
        "\n",
        "    def _execute_workflow_steps(self, workflow_state: WorkflowState, sender_name: str):\n",
        "        \"\"\"Execute all workflow steps in sequence\"\"\"\n",
        "\n",
        "        # Step 1: Research Company\n",
        "        self._execute_research_step(workflow_state)\n",
        "\n",
        "        # Check if research succeeded\n",
        "        if workflow_state.steps[0].status == AgentStatus.FAILED:\n",
        "            raise Exception(f\"Research step failed: {workflow_state.steps[0].error_message}\")\n",
        "\n",
        "        # Step 2: Analyze Company\n",
        "        self._execute_analysis_step(workflow_state)\n",
        "\n",
        "        # Check if analysis succeeded\n",
        "        if workflow_state.steps[1].status == AgentStatus.FAILED:\n",
        "            raise Exception(f\"Analysis step failed: {workflow_state.steps[1].error_message}\")\n",
        "\n",
        "        # Step 3: Personalize Outreach\n",
        "        self._execute_personalization_step(workflow_state, sender_name)\n",
        "\n",
        "        # Check if personalization succeeded\n",
        "        if workflow_state.steps[2].status == AgentStatus.FAILED:\n",
        "            raise Exception(f\"Personalization step failed: {workflow_state.steps[2].error_message}\")\n",
        "\n",
        "    def _execute_research_step(self, workflow_state: WorkflowState):\n",
        "        \"\"\"Execute the research step\"\"\"\n",
        "        step = workflow_state.steps[0]\n",
        "        step.status = AgentStatus.RUNNING\n",
        "        step.start_time = datetime.now()\n",
        "\n",
        "        self.logger.info(f\"Executing research step for {workflow_state.company_name}\")\n",
        "\n",
        "        try:\n",
        "            # Execute research agent\n",
        "            company_info = self.research_agent.research_company(workflow_state.company_name)\n",
        "\n",
        "            if company_info:\n",
        "                step.status = AgentStatus.COMPLETED\n",
        "                step.output_data = {\n",
        "                    \"company_info\": company_info,\n",
        "                    \"success\": True\n",
        "                }\n",
        "                self.logger.info(f\"Research completed for {workflow_state.company_name}\")\n",
        "            else:\n",
        "                step.status = AgentStatus.FAILED\n",
        "                step.error_message = f\"No information found for {workflow_state.company_name}\"\n",
        "                self.logger.warning(f\"Research failed for {workflow_state.company_name}: No information found\")\n",
        "\n",
        "        except Exception as e:\n",
        "            step.status = AgentStatus.FAILED\n",
        "            step.error_message = str(e)\n",
        "            self.logger.error(f\"Research step failed: {str(e)}\")\n",
        "\n",
        "        step.end_time = datetime.now()\n",
        "\n",
        "    def _execute_analysis_step(self, workflow_state: WorkflowState):\n",
        "        \"\"\"Execute the analysis step\"\"\"\n",
        "        step = workflow_state.steps[1]\n",
        "        step.status = AgentStatus.RUNNING\n",
        "        step.start_time = datetime.now()\n",
        "\n",
        "        self.logger.info(f\"Executing analysis step for {workflow_state.company_name}\")\n",
        "\n",
        "        try:\n",
        "            # Get company info from previous step\n",
        "            company_info = workflow_state.steps[0].output_data[\"company_info\"]\n",
        "\n",
        "            # Execute analysis agent\n",
        "            analysis_result = self.analysis_agent.analyze_company(company_info)\n",
        "\n",
        "            step.status = AgentStatus.COMPLETED\n",
        "            step.output_data = {\n",
        "                \"analysis_result\": analysis_result,\n",
        "                \"success\": True\n",
        "            }\n",
        "            self.logger.info(f\"Analysis completed for {workflow_state.company_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            step.status = AgentStatus.FAILED\n",
        "            step.error_message = str(e)\n",
        "            self.logger.error(f\"Analysis step failed: {str(e)}\")\n",
        "\n",
        "        step.end_time = datetime.now()\n",
        "\n",
        "    def _execute_personalization_step(self, workflow_state: WorkflowState, sender_name: str):\n",
        "        \"\"\"Execute the personalization step\"\"\"\n",
        "        step = workflow_state.steps[2]\n",
        "        step.status = AgentStatus.RUNNING\n",
        "        step.start_time = datetime.now()\n",
        "\n",
        "        self.logger.info(f\"Executing personalization step for {workflow_state.company_name}\")\n",
        "\n",
        "        try:\n",
        "            # Get data from previous steps\n",
        "            company_info = workflow_state.steps[0].output_data[\"company_info\"]\n",
        "            analysis_result = workflow_state.steps[1].output_data[\"analysis_result\"]\n",
        "\n",
        "            # Execute personalization agent\n",
        "            personalization_result = self.personalization_agent.personalize_outreach(\n",
        "                company_info, analysis_result, sender_name\n",
        "            )\n",
        "\n",
        "            step.status = AgentStatus.COMPLETED\n",
        "            step.output_data = {\n",
        "                \"personalization_result\": personalization_result,\n",
        "                \"success\": True\n",
        "            }\n",
        "            self.logger.info(f\"Personalization completed for {workflow_state.company_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            step.status = AgentStatus.FAILED\n",
        "            step.error_message = str(e)\n",
        "            self.logger.error(f\"Personalization step failed: {str(e)}\")\n",
        "\n",
        "        step.end_time = datetime.now()\n",
        "\n",
        "    def get_workflow_status(self, workflow_id: str) -> Optional[WorkflowState]:\n",
        "        \"\"\"Get status of a specific workflow\"\"\"\n",
        "        return self.active_workflows.get(workflow_id)\n",
        "\n",
        "    def get_all_workflows(self) -> Dict[str, WorkflowState]:\n",
        "        \"\"\"Get all active workflows\"\"\"\n",
        "        return self.active_workflows.copy()\n",
        "\n",
        "    def retry_failed_step(self, workflow_id: str, step_id: str) -> bool:\n",
        "        \"\"\"Retry a failed workflow step\"\"\"\n",
        "        if workflow_id not in self.active_workflows:\n",
        "            return False\n",
        "\n",
        "        workflow_state = self.active_workflows[workflow_id]\n",
        "\n",
        "        # Find the step\n",
        "        step = next((s for s in workflow_state.steps if s.step_id == step_id), None)\n",
        "        if not step:\n",
        "            return False\n",
        "\n",
        "        # Check retry limits\n",
        "        if step.retry_count >= step.max_retries:\n",
        "            self.logger.warning(f\"Step {step_id} has exceeded max retries\")\n",
        "            return False\n",
        "\n",
        "        # Increment retry count\n",
        "        step.retry_count += 1\n",
        "        step.status = AgentStatus.RETRYING\n",
        "\n",
        "        self.logger.info(f\"Retrying step {step_id} (attempt {step.retry_count})\")\n",
        "\n",
        "        # Retry the step based on step type\n",
        "        try:\n",
        "            if step_id == \"research\":\n",
        "                self._execute_research_step(workflow_state)\n",
        "            elif step_id == \"analysis\":\n",
        "                self._execute_analysis_step(workflow_state)\n",
        "            elif step_id == \"personalization\":\n",
        "                self._execute_personalization_step(workflow_state, \"Sales Professional\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Retry failed for step {step_id}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_orchestrator_status(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get orchestrator status and metrics\"\"\"\n",
        "        total_workflows = len(self.active_workflows)\n",
        "        completed_workflows = len([w for w in self.active_workflows.values() if w.status == WorkflowStatus.COMPLETED])\n",
        "        failed_workflows = len([w for w in self.active_workflows.values() if w.status == WorkflowStatus.FAILED])\n",
        "\n",
        "        return {\n",
        "            \"orchestrator_id\": self.orchestrator_id,\n",
        "            \"status\": \"ready\",\n",
        "            \"total_workflows\": total_workflows,\n",
        "            \"completed_workflows\": completed_workflows,\n",
        "            \"failed_workflows\": failed_workflows,\n",
        "            \"success_rate\": completed_workflows / total_workflows if total_workflows > 0 else 0,\n",
        "            \"workflow_steps\": len(self.workflow_steps),\n",
        "            \"active_agents\": [\n",
        "                self.research_agent.get_status(),\n",
        "                self.analysis_agent.get_status(),\n",
        "                self.personalization_agent.get_status()\n",
        "            ]\n",
        "        }\n",
        "\n",
        "# Example usage and testing\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Sales Orchestrator Demo ===\\n\")\n",
        "\n",
        "    # Create orchestrator\n",
        "    orchestrator = SalesOrchestrator()\n",
        "\n",
        "    # Execute sales pipeline\n",
        "    workflow_state = orchestrator.execute_sales_pipeline(\"Acme Corporation\", \"John Smith\")\n",
        "\n",
        "    print(f\"Workflow ID: {workflow_state.workflow_id}\")\n",
        "    print(f\"Company: {workflow_state.company_name}\")\n",
        "    print(f\"Status: {workflow_state.status.value}\")\n",
        "    print(f\"Start Time: {workflow_state.start_time}\")\n",
        "    print(f\"End Time: {workflow_state.end_time}\")\n",
        "\n",
        "    if workflow_state.error_message:\n",
        "        print(f\"Error: {workflow_state.error_message}\")\n",
        "\n",
        "    print(f\"\\nWorkflow Steps:\")\n",
        "    for i, step in enumerate(workflow_state.steps, 1):\n",
        "        print(f\"  {i}. {step.step_id.upper()}\")\n",
        "        print(f\"     Status: {step.status.value}\")\n",
        "        print(f\"     Duration: {step.end_time - step.start_time if step.start_time and step.end_time else 'N/A'}\")\n",
        "        if step.error_message:\n",
        "            print(f\"     Error: {step.error_message}\")\n",
        "        if step.output_data and step.output_data.get(\"success\"):\n",
        "            print(f\"     Success: {step.output_data['success']}\")\n",
        "\n",
        "    # Show final results if successful\n",
        "    if workflow_state.status == WorkflowStatus.COMPLETED:\n",
        "        personalization_result = workflow_state.steps[2].output_data[\"personalization_result\"]\n",
        "\n",
        "        print(f\"\\n=== Final Results ===\")\n",
        "        print(f\"Strategy: {personalization_result.personalization_strategy}\")\n",
        "        print(f\"Messages Created: {len(personalization_result.messages)}\")\n",
        "        print(f\"Recommended Sequence: {', '.join(personalization_result.recommended_sequence)}\")\n",
        "\n",
        "        print(f\"\\nSample Email Message:\")\n",
        "        email_msg = next((msg for msg in personalization_result.messages if msg.channel == \"email\"), None)\n",
        "        if email_msg:\n",
        "            print(f\"Subject: {email_msg.subject}\")\n",
        "            print(f\"Body Preview: {email_msg.body[:200]}...\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    # Show orchestrator status\n",
        "    status = orchestrator.get_orchestrator_status()\n",
        "    print(f\"Orchestrator Status:\")\n",
        "    print(json.dumps(status, indent=2, default=str))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script is indeed *massive* â€” but the good news is that itâ€™s structured around **very clear learning themes**. Let me break it down into digestible layers so you know what to focus on:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 1. Orchestrator Concept\n",
        "\n",
        "* **What it does:** Coordinates multiple agents (Research, Analysis, Personalization) into a **workflow pipeline**.\n",
        "* **Why it matters:** This is the backbone of *agent orchestration* â€” youâ€™re learning how to make independent agents cooperate step by step.\n",
        "\n",
        "ğŸ‘‰ *Focus on understanding:*\n",
        "\n",
        "* Each step = one agent doing its job.\n",
        "* The orchestrator manages execution order, error handling, and data passing.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 2. State & Status Tracking\n",
        "\n",
        "* `WorkflowStatus` (overall pipeline state) vs `AgentStatus` (individual step state).\n",
        "* `WorkflowStep` dataclass: records **start/end times, retries, outputs, errors**.\n",
        "* `WorkflowState` dataclass: holds the entire workflow context for one company.\n",
        "\n",
        "ğŸ‘‰ *Focus on understanding:*\n",
        "\n",
        "* Why we log every stepâ€™s input/output â†’ **observability**.\n",
        "* Why states matter â†’ you can pause, retry, resume, or audit workflows.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 3. Error Handling & Retry Logic\n",
        "\n",
        "* Each step sets status (`RUNNING`, `FAILED`, `COMPLETED`).\n",
        "* If something fails, the workflow stops and records the error.\n",
        "* `retry_failed_step()` lets you retry specific steps with a max retry count.\n",
        "\n",
        "ğŸ‘‰ *Focus on understanding:*\n",
        "\n",
        "* This is **production readiness**: real systems always fail sometimes.\n",
        "* Learning how retry counts and limits are tracked is key to resilience.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 4. Human-in-the-Loop Hooks\n",
        "\n",
        "* The orchestrator includes `human_intervention_required` and `human_intervention_reason` flags.\n",
        "* Currently placeholders, but designed for scenarios where an agent says: *â€œI need a human to approve this before proceeding.â€*\n",
        "\n",
        "ğŸ‘‰ *Focus on understanding:*\n",
        "\n",
        "* How you might insert **manual review** (e.g., outreach message approval).\n",
        "* Why orchestration needs to allow both automation and human checkpoints.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 5. Monitoring & Metrics\n",
        "\n",
        "* `get_orchestrator_status()` returns success rate, completed/failed workflows, and each agentâ€™s status.\n",
        "* At the bottom (`if __name__ == \"__main__\":`) â†’ demo run prints **workflow summary, final results, and orchestrator health**.\n",
        "\n",
        "ğŸ‘‰ *Focus on understanding:*\n",
        "\n",
        "* Metrics arenâ€™t just nice-to-have; theyâ€™re essential for scaling.\n",
        "* Learn how orchestration turns into **system observability**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 6. Software Best Practices in This File\n",
        "\n",
        "* **Logging instead of print** â†’ scalable debugging.\n",
        "* **Enums** for clean state/status tracking.\n",
        "* **Dataclasses** to structure data consistently (instead of messy dicts).\n",
        "* **Separation of Concerns**: orchestration logic is separate from agent logic.\n",
        "* **Demo harness** (`if __name__ == \"__main__\":`) for quick local testing.\n",
        "\n",
        "ğŸ‘‰ *Focus on understanding:*\n",
        "\n",
        "* These patterns make your code closer to *production-grade software*.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… What you should learn here\n",
        "\n",
        "If I were to prioritize:\n",
        "\n",
        "1. **Workflow orchestration** â†’ sequencing agents into pipelines.\n",
        "2. **State & logging** â†’ traceability is everything in multi-agent systems.\n",
        "3. **Error handling & retries** â†’ building robustness.\n",
        "4. **Extensibility** â†’ how easy it is to add a new agent step.\n",
        "\n",
        "---\n",
        "\n",
        "ğŸ“Œ You donâ€™t need to memorize the whole file. Instead, treat it as a **reference pattern**: *â€œThis is how I design an orchestrator thatâ€™s production-ready.â€*\n",
        "\n"
      ],
      "metadata": {
        "id": "l9WO-IIHk9vQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Youâ€™re looking at **Enums** (short for *Enumerations*), which are a Python way of defining a **fixed set of named values**. Think of them like categories or states that canâ€™t be misspelled and are easy to check in logic.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ `WorkflowStatus`\n",
        "\n",
        "```python\n",
        "class WorkflowStatus(Enum):\n",
        "    \"\"\"Workflow execution status\"\"\"\n",
        "    PENDING = \"pending\"\n",
        "    IN_PROGRESS = \"in_progress\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    RETRYING = \"retrying\"\n",
        "```\n",
        "\n",
        "ğŸ‘‰ **What it is:**\n",
        "Represents the *overall state* of a workflow (the entire pipeline, not just one step).\n",
        "\n",
        "ğŸ‘‰ **Why itâ€™s needed:**\n",
        "It lets the orchestrator know *where in its lifecycle* the whole workflow is.\n",
        "\n",
        "* `PENDING` â†’ workflow hasnâ€™t started yet.\n",
        "* `IN_PROGRESS` â†’ currently running through agents.\n",
        "* `COMPLETED` â†’ everything finished successfully.\n",
        "* `FAILED` â†’ something broke and the workflow couldnâ€™t finish.\n",
        "* `RETRYING` â†’ the system is trying again after an error.\n",
        "\n",
        "âœ… This gives you a **high-level view** of whether a companyâ€™s entire sales analysis pipeline is still waiting, currently running, done, or broken.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ `AgentStatus`\n",
        "\n",
        "```python\n",
        "class AgentStatus(Enum):\n",
        "    \"\"\"Individual agent status\"\"\"\n",
        "    READY = \"ready\"\n",
        "    RUNNING = \"running\"\n",
        "    COMPLETED = \"completed\"\n",
        "    FAILED = \"failed\"\n",
        "    SKIPPED = \"skipped\"\n",
        "```\n",
        "\n",
        "ğŸ‘‰ **What it is:**\n",
        "Represents the *state of a single agent step* inside the workflow.\n",
        "\n",
        "ğŸ‘‰ **Why itâ€™s needed:**\n",
        "It lets the orchestrator (and you) track whatâ€™s happening at the **granular agent level**.\n",
        "\n",
        "* `READY` â†’ agent is set up, waiting to run.\n",
        "* `RUNNING` â†’ currently executing.\n",
        "* `COMPLETED` â†’ finished successfully.\n",
        "* `FAILED` â†’ this agent step broke.\n",
        "* `SKIPPED` â†’ orchestrator decided to skip this agent (e.g., input invalid, human intervention required).\n",
        "\n",
        "âœ… This gives you **fine-grained observability** â€” you can tell *exactly which agent* in the pipeline caused problems, rather than just â€œworkflow failed.â€\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why do we need both?\n",
        "\n",
        "* **WorkflowStatus = â€œbig pictureâ€** â†’ status of the *whole* pipeline.\n",
        "* **AgentStatus = â€œzoomed inâ€** â†’ status of *individual steps*.\n",
        "\n",
        "Without this separation:\n",
        "\n",
        "* Youâ€™d have no way to distinguish *where* something went wrong.\n",
        "* Debugging multi-agent pipelines would be chaos (â€œDid the ResearchAgent fail, or the AnalysisAgent?â€).\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In short:**\n",
        "These enums are like **traffic lights** for your orchestrator:\n",
        "\n",
        "* `WorkflowStatus` is the light for the *entire highway*.\n",
        "* `AgentStatus` is the light for each *intersection*.\n",
        "\n"
      ],
      "metadata": {
        "id": "bQXB3SYNmmKb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "These enums are **traffic lights** for your orchestrator. Let me break it down in practical terms:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 1. Informed Debugging\n",
        "\n",
        "Yes â€” the whole point is **observability**.\n",
        "\n",
        "* If a workflow fails, you donâ€™t just see *â€œError: pipeline broke.â€*\n",
        "* You can see *â€œWorkflow FAILED because AnalysisAgent status = FAILED while ResearchAgent status = COMPLETED.â€*\n",
        "\n",
        "ğŸ‘‰ That lets you debug **where** the problem happened, instead of hunting blindly.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 2. Orchestrator as Traffic Controller\n",
        "\n",
        "Think of the orchestrator as a **traffic cop**:\n",
        "\n",
        "* It checks each agentâ€™s `AgentStatus`.\n",
        "* It only moves to the next step if the current stepâ€™s status is `COMPLETED`.\n",
        "* If a stepâ€™s status is `FAILED`, the orchestrator can:\n",
        "\n",
        "  * Stop the workflow (`WorkflowStatus = FAILED`).\n",
        "  * Or flip to `RETRYING` if retries are allowed.\n",
        "* If a step is `SKIPPED`, the orchestrator just moves on.\n",
        "\n",
        "ğŸ‘‰ So yes â€” itâ€™s like the orchestrator waits for the **green light** (`COMPLETED`) before sending data to the next agent.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 3. Does it â€œpauseâ€ like a real traffic light?\n",
        "\n",
        "Not literally *pause threads* (unless you add async/parallelism), but logically:\n",
        "\n",
        "* The orchestrator wonâ€™t **start the next action** until the current oneâ€™s light is green.\n",
        "* If the light turns red (`FAILED`), it stops the car (workflow) until you fix it or retry.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 4. Why this is powerful\n",
        "\n",
        "Without these enums:\n",
        "\n",
        "* Agents might run out of order, overlap, or silently fail.\n",
        "* Youâ€™d have no record of what happened mid-workflow.\n",
        "\n",
        "With them:\n",
        "\n",
        "* You get **control + transparency**.\n",
        "* You can build dashboards showing workflows â€œin progress,â€ agents â€œwaiting,â€ etc.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In short:**\n",
        "The orchestrator uses these enums as **synchronization checkpoints** â€” only moving forward when conditions are right. Itâ€™s not just debugging, itâ€™s also *flow control*.\n",
        "\n"
      ],
      "metadata": {
        "id": "XhFkWS2ynZiz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Yes â€” **classic control flow** (like `if / then / else`) is great for *deterministic programs* where you know every branch ahead of time. But when you start orchestrating **LLM-based agents**, the game changes:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why `if / then / else` isnâ€™t enough\n",
        "\n",
        "1. **LLMs are non-deterministic**\n",
        "\n",
        "   * The same input can produce different outputs.\n",
        "   * You canâ€™t hardcode every branch because you canâ€™t predict all possible outcomes.\n",
        "\n",
        "2. **Multiple agents = concurrent or staged tasks**\n",
        "\n",
        "   * You might have ResearchAgent fetching data while AnalysisAgent waits.\n",
        "   * Or in advanced setups, you run agents in parallel (e.g., multiple enrichment sources).\n",
        "\n",
        "3. **Failures are common**\n",
        "\n",
        "   * API call fails, LLM times out, bad data formatting, etc.\n",
        "   * You donâ€™t want the whole workflow to just crash â€” you want retries, skips, or human-in-the-loop.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why we need a status system (traffic lights)\n",
        "\n",
        "Thatâ€™s where enums like `WorkflowStatus` and `AgentStatus` come in:\n",
        "\n",
        "* They provide a **shared language** for the orchestrator and all agents.\n",
        "* Instead of nested `if` statements everywhere, you centralize control:\n",
        "\n",
        "Example in words:\n",
        "\n",
        "* Orchestrator: â€œIs ResearchAgent status = COMPLETED?â€\n",
        "\n",
        "  * âœ… Yes â†’ start AnalysisAgent.\n",
        "  * âŒ No (FAILED) â†’ switch workflow to RETRYING, maybe try again.\n",
        "  * â­ SKIPPED â†’ move directly to the next one.\n",
        "\n",
        "ğŸ‘‰ This keeps the flow **modular and resilient**, not tangled in spaghetti `if / else`.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Analogy\n",
        "\n",
        "Think of it like:\n",
        "\n",
        "* `if / then / else` = traffic cop with one intersection.\n",
        "* `status system` = traffic lights across a whole city grid, with coordination.\n",
        "\n",
        "LLM pipelines are more like a **city grid** â€” multiple agents, multiple possible paths, unexpected breakdowns â€” so you need traffic lights and signals, not just a single cop shouting instructions.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In short:**\n",
        "\n",
        "* For **simple scripts**: `if / else` works.\n",
        "* For **multi-agent, LLM-driven pipelines**: you need **status-based orchestration** (like traffic lights) to keep order, handle retries, and support parallelism.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7a_mTaapn7vM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`WorkflowStep` is where things go from abstract traffic lights (statuses) to **real-world execution tracking**. Letâ€™s break it down:\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What `WorkflowStep` is\n",
        "\n",
        "Itâ€™s a **record for one agentâ€™s execution** inside the workflow.\n",
        "Every time an agent runs (ResearchAgent, AnalysisAgent, etc.), the orchestrator wraps it in one of these.\n",
        "\n",
        "Think of it as a **flight log entry**: who flew (agent), when, what happened, and whether it crashed or landed.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Field-by-field breakdown\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class WorkflowStep:\n",
        "    step_id: str\n",
        "    agent_name: str\n",
        "    status: AgentStatus = AgentStatus.PENDING\n",
        "    start_time: Optional[datetime] = None\n",
        "    end_time: Optional[datetime] = None\n",
        "    error_message: Optional[str] = None\n",
        "    retry_count: int = 0\n",
        "    max_retries: int = 3\n",
        "    input_data: Optional[Dict[str, Any]] = None\n",
        "    output_data: Optional[Dict[str, Any]] = None\n",
        "```\n",
        "\n",
        "* **`step_id`** â†’ unique identifier (like â€œstep\\_001â€), lets you track each run.\n",
        "* **`agent_name`** â†’ which agent ran this step (ResearchAgent, etc.).\n",
        "* **`status`** â†’ current `AgentStatus` (READY, RUNNING, COMPLETED, FAILED, SKIPPED).\n",
        "* **`start_time` / `end_time`** â†’ timestamps so you can see *when* things happened, and measure duration. âœ… Yes, you can **look at errors chronologically** and even analyze bottlenecks.\n",
        "* **`error_message`** â†’ if the agent fails, capture the error (e.g., â€œAPI timeoutâ€ or â€œKeyErrorâ€).\n",
        "* **`retry_count` & `max_retries`** â†’ built-in **retry logic**. If an API call fails, the orchestrator can try again (say, up to 3 times). This is critical in production because APIs and LLM calls are flaky.\n",
        "* **`input_data`** â†’ what the agent was given (lead profile, company info, etc.).\n",
        "* **`output_data`** â†’ what the agent produced (enriched data, analysis results, etc.).\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why this is powerful\n",
        "\n",
        "1. **Chronological error tracking**\n",
        "\n",
        "   * You can see exactly when each step failed and how long it took.\n",
        "   * Makes debugging easy: â€œAnalysisAgent failed after 2.3s with timeout.â€\n",
        "\n",
        "2. **Retries baked in**\n",
        "\n",
        "   * You donâ€™t want the workflow to collapse because of one flaky call.\n",
        "   * With retries, you can survive transient issues (e.g., API hiccups).\n",
        "\n",
        "3. **Structured audit trail**\n",
        "\n",
        "   * You can save these steps into a DB/log file.\n",
        "   * Later, you can analyze success rates, average runtimes, most common failure points.\n",
        "\n",
        "4. **Data transparency**\n",
        "\n",
        "   * By storing both input and output, you always know what was passed in and what came out.\n",
        "   * This is critical when LLMs are involved â€” you can review prompts and responses if things go wrong.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Things to be aware of\n",
        "\n",
        "* **Storage** â†’ If you keep full `input_data` and `output_data` (especially raw LLM responses), logs can get *huge*. You may need a policy (truncate, store in S3, etc.).\n",
        "* **Retries** â†’ Great for transient failures (timeouts, 500 errors). But you also want a **backoff strategy** (e.g., wait 2s â†’ 4s â†’ 8s) so you donâ€™t hammer an API.\n",
        "* **Error messages** â†’ Not every exception is meaningful. Sometimes youâ€™ll want to add **custom messages** like â€œInvalid ICP matchâ€ instead of just â€œValueError.â€\n",
        "* **Chaining** â†’ Since each step has `output_data`, the orchestrator can pass it straight into the next stepâ€™s `input_data`. Thatâ€™s how the pipeline flows.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In short:**\n",
        "`WorkflowStep` is your **black box recorder** for each agent run. It gives you **when, what, how long, what went wrong, and what was retried**. Thatâ€™s gold for both debugging and optimization.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BXgss9rFotoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ”¹ `WorkflowStep` (zoomed in)\n",
        "\n",
        "Think of this as the **log entry for one agent**.\n",
        "\n",
        "* Tracks *one unit of work* (e.g., â€œResearchAgent ran for Acme Inc, took 2s, succeeded on 2nd retryâ€).\n",
        "* Holds input/output data, errors, retries, and timing for that step.\n",
        "* Youâ€™ll usually have **many WorkflowSteps per WorkflowState**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ `WorkflowState` (zoomed out)\n",
        "\n",
        "This is the **control tower view of the whole workflow**.\n",
        "\n",
        "* Represents the **entire pipeline** as it runs for a single company or lead.\n",
        "* Tracks:\n",
        "\n",
        "  * **Which company** is being processed (`company_name`).\n",
        "  * **Overall workflow status** (`WorkflowStatus.PENDING / IN_PROGRESS / COMPLETED / FAILED`).\n",
        "  * **When it started / ended** (so you can measure total runtime).\n",
        "  * **All steps together** (`steps: List[WorkflowStep]`).\n",
        "  * **Where we are right now** (`current_step_index`).\n",
        "  * **Why things failed** (`error_message`).\n",
        "  * **Whether we paused for a human** (`human_intervention_required`).\n",
        "\n",
        "ğŸ‘‰ In other words: `WorkflowState` is the *big container* that holds every `WorkflowStep` for one run of the pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Analogy\n",
        "\n",
        "* **WorkflowStep** = one *stop* on a train journey (station log: when you arrived, what happened, whether delayed).\n",
        "* **WorkflowState** = the *entire trip* from New York to Boston (all stops combined, total time, current station).\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why both are needed\n",
        "\n",
        "* If you only had `WorkflowState` â†’ youâ€™d know â€œworkflow failedâ€ but not which agent caused it.\n",
        "* If you only had `WorkflowStep` â†’ youâ€™d know individual results, but no unified picture of how they tie together for a company.\n",
        "\n",
        "Together:\n",
        "\n",
        "* You can say: *â€œFor Acme Inc, workflow status = FAILED because step 3 (AnalysisAgent) failed after 2 retries at 3:14pm.â€*\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In short:**\n",
        "\n",
        "* `WorkflowStep` = **microscope** (one agent run).\n",
        "* `WorkflowState` = **map** (the whole workflow journey).\n",
        "\n"
      ],
      "metadata": {
        "id": "oupH9pNDpSM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This touches both **software design** and **agent system design**. Letâ€™s break it down carefully.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What youâ€™re looking at\n",
        "\n",
        "`SalesOrchestrator` is **not** â€œinside an agentâ€ â€” itâ€™s actually a **separate controller class** that *owns* the agents and manages how they run.\n",
        "\n",
        "Think of it like this:\n",
        "\n",
        "* **Agents** = workers (ResearchAgent, AnalysisAgent, PersonalizationAgent).\n",
        "* **Orchestrator** = manager (decides which worker runs when, collects reports, retries on failure, escalates to humans if needed).\n",
        "\n",
        "So the orchestrator sits **above** the agents. Itâ€™s not a sub-agent, itâ€™s the conductor of the whole pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why is the orchestrator defined *here* (in this module)?\n",
        "\n",
        "A few practical reasons:\n",
        "\n",
        "1. **Encapsulation for demo/testing**\n",
        "\n",
        "   * Keeping everything in one file/script is convenient while learning.\n",
        "   * You can see the agents *and* the orchestrator working together in one place.\n",
        "\n",
        "2. **Coupling workflow to specific agents**\n",
        "\n",
        "   * This orchestrator is designed specifically for a *sales research pipeline*.\n",
        "   * It wires together exactly these three agents: research â†’ analysis â†’ personalization.\n",
        "   * By embedding them here, you get a **concrete, runnable orchestrator** instead of an abstract one.\n",
        "\n",
        "3. **Teaching pattern**\n",
        "\n",
        "   * The docstring is telling you what this is about: sequential execution, retries, state management, human-in-the-loop, monitoring/logging.\n",
        "   * The author wants you to learn *how an orchestrator class is structured and used*.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What should you be learning here?\n",
        "\n",
        "This code block is **not about the agents themselves** â€” itâ€™s about orchestration as a design pattern.\n",
        "\n",
        "Key lessons:\n",
        "\n",
        "1. **Composition over inheritance**\n",
        "\n",
        "   * Orchestrator *owns* agents (`self.research_agent = ResearchAgent()`) instead of subclassing them.\n",
        "   * This is the â€œmanager with workersâ€ pattern.\n",
        "\n",
        "2. **Declarative workflow definition**\n",
        "\n",
        "   * `self.workflow_steps = [...]` is a **mini pipeline config**.\n",
        "   * Each step has an ID, which agent to run, and a description.\n",
        "   * Later, you could load this from JSON/YAML to make it more flexible.\n",
        "\n",
        "3. **Stateful orchestration**\n",
        "\n",
        "   * `self.active_workflows: Dict[str, WorkflowState]` is where all running workflows are tracked.\n",
        "   * This is how you can run multiple leads/companies in parallel, each with its own state.\n",
        "\n",
        "4. **Logging & monitoring baked in**\n",
        "\n",
        "   * Orchestrator has its own logger.\n",
        "   * Every decision (step started, failed, retried, escalated) gets logged for observability.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why not a totally separate module?\n",
        "\n",
        "You *could* â€” and in production, you probably would.\n",
        "\n",
        "* Agents might live in `agents/` folder.\n",
        "* Orchestrator might live in `orchestration/`.\n",
        "* Config in `config/`.\n",
        "\n",
        "But here, the code is **teaching you the orchestration pattern**, not project structure. Keeping it in one file means you can see the entire flow end-to-end without hunting through files.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… In short\n",
        "\n",
        "Youâ€™re learning how an orchestrator:\n",
        "\n",
        "* **Holds agents**\n",
        "* **Defines workflow steps**\n",
        "* **Tracks active workflow state**\n",
        "* **Manages retries, errors, and logging**\n",
        "\n",
        "Thatâ€™s the *core pattern* youâ€™ll reuse whether you later split into modules or scale up.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jMq3jzi2tDgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ğŸ”¹ Orchestrator vs Pipeline\n",
        "\n",
        "* **`SalesOrchestrator` class**\n",
        "\n",
        "  * The *manager object*.\n",
        "  * It owns the agents, workflow config, and all active workflow states.\n",
        "  * Think of it as a **control tower** that *can* run many workflows.\n",
        "\n",
        "* **`execute_sales_pipeline` method**\n",
        "\n",
        "  * A *single flight*.\n",
        "  * Runs the **entire workflow once**, for a given company.\n",
        "  * Uses the orchestratorâ€™s config + agents to execute the steps sequentially.\n",
        "  * Returns a `WorkflowState` (the full record of that run).\n",
        "\n",
        "So the orchestrator is the **framework**, while the pipeline is the **execution instance**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What the pipeline method does\n",
        "\n",
        "1. **Creates a unique workflow ID**\n",
        "\n",
        "   ```python\n",
        "   workflow_id = f\"workflow_{int(time.time())}_{company_name.replace(' ', '_')}\"\n",
        "   ```\n",
        "\n",
        "   Each run is traceable.\n",
        "\n",
        "2. **Initializes workflow state**\n",
        "\n",
        "   * Creates a `WorkflowState` object.\n",
        "   * Marks it as `IN_PROGRESS`.\n",
        "   * Stamps the start time.\n",
        "\n",
        "3. **Sets up workflow steps**\n",
        "\n",
        "   * For every entry in `self.workflow_steps`, creates a `WorkflowStep`.\n",
        "   * Adds them to the workflow state.\n",
        "   * This builds the â€œflight plan.â€\n",
        "\n",
        "4. **Executes the steps**\n",
        "\n",
        "   ```python\n",
        "   self._execute_workflow_steps(workflow_state, sender_name)\n",
        "   ```\n",
        "\n",
        "   (this private method actually runs the agents).\n",
        "\n",
        "5. **Marks completion or failure**\n",
        "\n",
        "   * If all steps succeed â†’ status = `COMPLETED`, log success.\n",
        "   * If any step blows up â†’ catch exception, mark as `FAILED`, record error message.\n",
        "\n",
        "6. **Returns final state**\n",
        "\n",
        "   * So the caller gets the full story of what happened.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why not put this outside the orchestrator?\n",
        "\n",
        "You *could*. For example:\n",
        "\n",
        "* Have a separate `SalesPipeline` class.\n",
        "* Or a top-level function like `run_sales_pipeline(company)`.\n",
        "\n",
        "But embedding it here has two benefits:\n",
        "\n",
        "1. **Cohesion** â†’ The orchestrator is the thing responsible for running workflows. It makes sense for it to have a method to *execute* one.\n",
        "2. **State tracking** â†’ By storing the workflow in `self.active_workflows`, the orchestrator can track multiple pipelines at once.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Analogy\n",
        "\n",
        "* **SalesOrchestrator class** = Airport control tower.\n",
        "* **execute\\_sales\\_pipeline** = A single flight plan for Acme Corp today.\n",
        "* **WorkflowState** = The flight logbook (how the flight actually went).\n",
        "* **WorkflowStep** = Each stopover during the flight.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **So the pipeline method is basically â€œRun one workflow using the orchestratorâ€™s playbook.â€**\n",
        "The orchestrator provides the structure, the pipeline method provides execution.\n",
        "\n"
      ],
      "metadata": {
        "id": "HmWkRt3gv3tg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ah, excellent â€” youâ€™re noticing the **underscore convention** in Python and wondering if itâ€™s Cursor being â€œsmartâ€ with your doc, or just standard practice. Letâ€™s unpack this carefully.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What underscore means in Python\n",
        "\n",
        "In Python, a **leading underscore** in a method or variable name (e.g. `_execute_workflow_steps`) signals:\n",
        "\n",
        "* **â€œThis is private/internal.â€**\n",
        "* Itâ€™s not meant to be called directly by users of the class.\n",
        "* Itâ€™s an implementation detail the class hides behind its public API.\n",
        "\n",
        "ğŸ‘‰ Importantly, this is **a convention**, not enforced by the language (unlike `private` in Java or C++). Python trusts developers to respect it.\n",
        "\n",
        "So when you see:\n",
        "\n",
        "```python\n",
        "def _execute_workflow_steps(...):\n",
        "```\n",
        "\n",
        "It means: *â€œThis function is for internal use by the orchestrator; you shouldnâ€™t call it directly from outside.â€*\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why use it here?\n",
        "\n",
        "In your `SalesOrchestrator`, thereâ€™s a clear **public API** vs **internal plumbing** split:\n",
        "\n",
        "* **Public API** â†’ the methods youâ€™re supposed to call from outside.\n",
        "\n",
        "  * `execute_sales_pipeline()` â† this is the main entrypoint.\n",
        "  * Itâ€™s clean, friendly, and safe.\n",
        "\n",
        "* **Private helpers** â†’ the methods that *do the dirty work* inside.\n",
        "\n",
        "  * `_execute_workflow_steps` (drives step execution).\n",
        "  * `_execute_research_step`, `_execute_analysis_step`, etc.\n",
        "  * These exist so the public method stays simple and readable.\n",
        "\n",
        "Without them, `execute_sales_pipeline` would be a giant blob of code.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What you should learn here\n",
        "\n",
        "1. **Public/private split matters** in agent systems.\n",
        "\n",
        "   * You want a clear external API (`execute_sales_pipeline`).\n",
        "   * You want to hide messy internals (`_execute_analysis_step`).\n",
        "\n",
        "2. **Decomposition** makes the code maintainable.\n",
        "\n",
        "   * Each `_execute_*` method focuses on one agent.\n",
        "   * Easier to test, debug, and swap out agents later.\n",
        "\n",
        "3. **Cursor following convention** is a *good sign*.\n",
        "\n",
        "   * It means the generated code is idiomatic and would be instantly readable to another Python dev.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… **In short**: The underscore isnâ€™t Cursor obeying your doc â€” itâ€™s just **good Python practice**. Your â€œagent recipeâ€ doc happens to echo the same principle, because thatâ€™s what professionals do when building orchestrators: clear public entrypoints, private internal helpers.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WZ1QuRcbw399"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You donâ€™t want to just read code, you want to **extract the design lessons**. This script is full of them. Letâ€™s pull out the most important takeaways.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 1. **The Orchestrator Pattern**\n",
        "\n",
        "* Instead of agents calling each other directly, you have a **central orchestrator** that controls order, retries, and failure handling.\n",
        "* This makes the system more **predictable and debuggable**.\n",
        "* *Takeaway*: Always separate **what agents do** from **who decides when/how they run**.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 2. **State Management is Explicit**\n",
        "\n",
        "* `WorkflowState` (macro-level view of the workflow).\n",
        "* `WorkflowStep` (micro-level logs for each agent).\n",
        "* Enums like `WorkflowStatus` and `AgentStatus` standardize state instead of ad-hoc strings.\n",
        "* *Takeaway*: Explicit state makes your system observable and easier to monitor/debug.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 3. **Error Handling + Retries Are First-Class**\n",
        "\n",
        "* Each step can retry on failure.\n",
        "* Failures bubble up to the workflow state with timestamps + error messages.\n",
        "* *Takeaway*: LLMs and APIs fail often â€” design resilience in from the start.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 4. **Human-in-the-Loop Hooks**\n",
        "\n",
        "* `human_intervention_required` is baked into `WorkflowState`.\n",
        "* The orchestrator can pause and wait for a human decision before continuing.\n",
        "* *Takeaway*: Good orchestration anticipates where automation may fail or need judgment.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 5. **Separation of Concerns**\n",
        "\n",
        "* Agents: single-purpose (research, analysis, personalization).\n",
        "* Orchestrator: just coordinates, doesnâ€™t â€œdo the workâ€ itself.\n",
        "* Config: `self.workflow_steps` describes the pipeline declaratively.\n",
        "* *Takeaway*: Keep your pipeline modular and swappable. Tomorrow you can add a `ValidationAgent` without rewriting the orchestrator.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 6. **Observability via Logging**\n",
        "\n",
        "* The orchestrator has its own logger.\n",
        "* Every major event (workflow start, step execution, failure, completion) is logged.\n",
        "* *Takeaway*: Treat logging as a **first-class citizen** â€” youâ€™ll need it once you run multiple workflows in parallel.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ 7. **Good Python Practices**\n",
        "\n",
        "* Leading underscores for private helpers (`_execute_analysis_step`).\n",
        "* Dataclasses for clean structured data (`WorkflowState`, `WorkflowStep`).\n",
        "* Enums for states instead of loose strings.\n",
        "* *Takeaway*: These arenâ€™t just Python tricks â€” they build **clarity and safety** into your agent systems.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… The Big Picture\n",
        "\n",
        "This script is teaching you **how to build a production-grade pipeline**:\n",
        "\n",
        "* **Clear public API**: `execute_sales_pipeline()`\n",
        "* **Internal helpers**: `_execute_*` methods\n",
        "* **Structured state tracking**: dataclasses + enums\n",
        "* **Resilience**: retries, error messages, human intervention\n",
        "* **Scalability**: active workflows stored and tracked\n",
        "\n",
        "ğŸ‘‰ The most important lesson is that **control flow in multi-agent systems should be explicit, observable, and resilient**. Thatâ€™s the difference between a toy script and a reliable orchestrator.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DRs72UpcxgT3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-THNqRJflEKO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}