{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh2ngxMBVkAjEjTanGSQkk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/089_ParseResponse_ExecuteAction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üéØ Major Concepts to Focus On\n",
        "\n",
        "### 1Ô∏è‚É£ Parsing the LLM‚Äôs Response into a **Structured Action**\n",
        "\n",
        "* **Why:** Free-form text is ambiguous; a structured format (e.g., JSON inside a markdown block) lets you *reliably* figure out what to do next.\n",
        "* **What to learn:**\n",
        "\n",
        "  * Define a clear **action schema** (e.g., `{\"tool_name\": \"...\", \"args\": {...}}`).\n",
        "  * Extract that schema from the LLM‚Äôs raw output.\n",
        "  * Validate it ‚Äî if it‚Äôs missing fields or malformed, produce an **error action** so the agent can recover.\n",
        "\n",
        "---\n",
        "\n",
        "### 2Ô∏è‚É£ **Executing the Action**\n",
        "\n",
        "* **Why:** This is where decisions turn into *real effects* ‚Äî reading files, calling APIs, updating data.\n",
        "* **What to learn:**\n",
        "\n",
        "  * Map `tool_name` ‚Üí the right function.\n",
        "  * Pass `args` into that function.\n",
        "  * Handle unknown tools or bad arguments gracefully.\n",
        "  * Think of this step as the **‚Äúhands‚Äù** of your agent; parsing was the **‚Äúeyes‚Äù**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3Ô∏è‚É£ **Updating Memory with Results**\n",
        "\n",
        "* **Why:** The agent needs to remember *both* what it intended to do (assistant output) and what happened (user feedback with action results).\n",
        "* **What to learn:**\n",
        "\n",
        "  * Store the LLM‚Äôs structured action output as an `assistant` message.\n",
        "  * Store the action‚Äôs **result** as a `user` message.\n",
        "  * This ensures the LLM ‚Äúknows‚Äù the outcome of its previous step on the next turn.\n",
        "\n",
        "---\n",
        "\n",
        "### 4Ô∏è‚É£ **Deciding Whether to Continue**\n",
        "\n",
        "* **Why:** You need an exit strategy so the loop doesn‚Äôt run forever.\n",
        "* **What to learn:**\n",
        "\n",
        "  * Check if `tool_name` is `\"terminate\"`.\n",
        "  * End after a set max iterations or other stopping conditions.\n",
        "  * Provide a clear final message on termination.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© How These Fit Together\n",
        "\n",
        "In the **Agent Loop**:\n",
        "\n",
        "1. **Memory window** ‚Üí LLM ‚Üí *structured action* (parsed from text).\n",
        "2. **Execute** that action (call the matching tool).\n",
        "3. **Update memory** with the action + result.\n",
        "4. **Decide to continue or stop**.\n",
        "\n",
        "This is the shift from *purely conversational* to **goal-oriented** agents that can:\n",
        "\n",
        "* Plan a step\n",
        "* Take an action\n",
        "* Observe the outcome\n",
        "* Iterate until the task is complete\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "89JCDBHD1OdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse Response\n",
        "\n",
        "\n",
        "### **Purpose**\n",
        "\n",
        "`parse_action` takes the **raw text** from the LLM and converts it into a **structured Python dictionary** that the rest of your agent can actually *use*.\n",
        "\n",
        "Without this, the agent would be stuck with free-form text that might be inconsistent or hard to interpret.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step-by-step**\n",
        "\n",
        "```python\n",
        "response = extract_markdown_block(response, \"action\")\n",
        "```\n",
        "\n",
        "* Pulls out **only** the contents inside a markdown code block starting with \\`\\`\\`action.\n",
        "* Example raw output from the LLM:\n",
        "\n",
        "  ````\n",
        "  ```action\n",
        "  {\"tool_name\": \"list_files\", \"args\": {}}\n",
        "  ````\n",
        "\n",
        "  ````\n",
        "  After extraction:  \n",
        "  ```json\n",
        "  {\"tool_name\": \"list_files\", \"args\": {}}\n",
        "  ````\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "response_json = json.loads(response)\n",
        "```\n",
        "\n",
        "* Converts the JSON string into a **Python dictionary**.\n",
        "* If the LLM output isn‚Äôt valid JSON, this will raise a `json.JSONDecodeError` and jump to the `except` block.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "    return response_json\n",
        "else:\n",
        "    return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "```\n",
        "\n",
        "* Ensures the two required keys are present:\n",
        "\n",
        "  * `\"tool_name\"` ‚Äî which tool to run\n",
        "  * `\"args\"` ‚Äî parameters for that tool\n",
        "* If either is missing, it returns a special **error action** telling the LLM what went wrong.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "except json.JSONDecodeError:\n",
        "    return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "```\n",
        "\n",
        "* If the JSON was broken (bad syntax, missing quotes, etc.), return an **error action** saying the JSON is invalid.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why this matters**\n",
        "\n",
        "1. **Consistency** ‚Äî The agent‚Äôs execution code can rely on always getting a dictionary with the same structure.\n",
        "2. **Safety** ‚Äî You detect and handle malformed output instead of letting your code break.\n",
        "3. **Control** ‚Äî You can feed the `error` action back to the LLM so it knows to fix its formatting on the next turn.\n",
        "\n",
        "---\n",
        "\n",
        "**Example:**\n",
        "\n",
        "````python\n",
        "raw = \"\"\"```action\n",
        "{\"tool_name\": \"list_files\", \"args\": {}}\n",
        "```\"\"\"\n",
        "parsed = parse_action(raw)\n",
        "# parsed -> {\"tool_name\": \"list_files\", \"args\": {}}\n",
        "````\n",
        "\n",
        "Now your agent can do:\n",
        "\n",
        "```python\n",
        "if parsed[\"tool_name\"] == \"list_files\":\n",
        "    run list_files()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "QGwX-SxcD-HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
        "    try:\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        response_json = json.loads(response)\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "# This parsing step is critical to ensuring the response is actionable. It provides a structured output, such as:\n",
        "\n",
        "{\n",
        "    \"tool_name\": \"list_files\",\n",
        "    \"args\": {}\n",
        "}\n",
        "\n",
        "# By breaking down the LLM‚Äôs output into tool_name and args,\n",
        "# the agent can precisely determine the next action and its inputs."
      ],
      "metadata": {
        "id": "sCsvwfU0D8LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Install dependencies ---\n",
        "!pip install --quiet python-dotenv openai\n",
        "\n",
        "import os, json, re\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- 1) Load API key from /content/API_KEYS.env ---\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found in /content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# --- 2) System prompt + chat history ---\n",
        "system_instructions = (\n",
        "    \"\"\"\n",
        "You are an AI file assistant.\n",
        "Respond ONLY with a JSON action inside a markdown block, like:\n",
        "\n",
        "```action\n",
        "{\"tool_name\": \"list_files\", \"args\": {}}\n",
        "```\n",
        "\n",
        "Available tools:\n",
        "- list_files: returns list of files in /content/files\n",
        "- read_file: args={\"file_name\": \"<filename>\"}\n",
        "\n",
        "Rules:\n",
        "- Respond with exactly one JSON object inside a ```action block.\n",
        "- If unsure, return an error action instead of prose.\n",
        "\"\"\"\n",
        ").strip()\n",
        "\n",
        "messages = [{\"role\": \"system\", \"content\": system_instructions}]\n",
        "\n",
        "def add_message(role, content):\n",
        "    messages.append({\"role\": role, \"content\": content})\n",
        "\n",
        "# --- 3) Extract JSON from a ```action code block ---\n",
        "def extract_markdown_block(text, block_name):\n",
        "    pattern = rf\"```{block_name}\\s*(.*?)\\s*```\"\n",
        "    match = re.search(pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# --- 4) Parse the model's response into an action dict ---\n",
        "def parse_action(response_text):\n",
        "    action_str = extract_markdown_block(response_text, \"action\")\n",
        "    if not action_str:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"No action block found.\"}}\n",
        "    try:\n",
        "        action_json = json.loads(action_str)\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON.\"}}\n",
        "    if isinstance(action_json, dict) and \"tool_name\" in action_json and \"args\" in action_json:\n",
        "        return action_json\n",
        "    return {\"tool_name\": \"error\", \"args\": {\"message\": \"Missing tool_name or args.\"}}\n",
        "\n",
        "# --- 5) Tools ---\n",
        "FILES_DIR = \"/content/files\"\n",
        "\n",
        "def list_files():\n",
        "    try:\n",
        "        return sorted(os.listdir(FILES_DIR))\n",
        "    except FileNotFoundError:\n",
        "        return [f\"Error: Folder not found: {FILES_DIR}\"]\n",
        "\n",
        "def read_file(file_name, max_chars=2000):\n",
        "    path = os.path.join(FILES_DIR, file_name)\n",
        "    if not os.path.isfile(path):\n",
        "        return f\"Error: File not found: {file_name}\"\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "            content = f.read(max_chars + 1)\n",
        "        if len(content) > max_chars:\n",
        "            content = content[:max_chars] + \"\\n... [truncated]\"\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        return f\"Error reading {file_name}: {e}\"\n",
        "\n",
        "# --- 6) Execute action ---\n",
        "\n",
        "def execute_action(action):\n",
        "    tool = (action or {}).get(\"tool_name\")\n",
        "    args = (action or {}).get(\"args\", {})\n",
        "\n",
        "    if tool == \"list_files\":\n",
        "        return {\"result\": list_files()}\n",
        "    elif tool == \"read_file\":\n",
        "        fname = args.get(\"file_name\")\n",
        "        if not fname:\n",
        "            return {\"error\": \"Missing arg: file_name\"}\n",
        "        return {\"result\": read_file(fname)}\n",
        "    elif tool == \"error\":\n",
        "        return {\"error\": args.get(\"message\", \"Unknown error\")}\n",
        "    elif tool == \"terminate\":\n",
        "        return {\"result\": args.get(\"message\", \"Terminated\")}\n",
        "    else:\n",
        "        return {\"error\": f\"Unknown tool: {tool}\"}\n",
        "\n",
        "# --- 7) Full step: prompt -> parse -> execute ---\n",
        "\n",
        "def step(user_input, memory_size=None):\n",
        "    add_message(\"user\", user_input)\n",
        "    visible = messages if memory_size is None else messages[-memory_size:]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=visible,\n",
        "    )\n",
        "    reply = response.choices[0].message.content\n",
        "    print(\"Raw model output:\\n\", reply)\n",
        "\n",
        "    action = parse_action(reply)\n",
        "    print(\"\\nParsed action:\", action)\n",
        "\n",
        "    result = execute_action(action)\n",
        "    print(\"\\nExecution result (JSON):\", result)\n",
        "\n",
        "    # Update history so the model sees outcomes next turn\n",
        "    add_message(\"assistant\", reply)              # the model's action choice\n",
        "    add_message(\"user\", json.dumps(result))      # the tool result as feedback\n",
        "    return result"
      ],
      "metadata": {
        "id": "cW4mOmDo9I-4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8) Demo ---\n",
        "_ = step(\"List all files in the /content/files directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-T3iV-tCMfT",
        "outputId": "4628ce55-a67c-4ef9-b210-c265d2ba7dd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw model output:\n",
            " ```action\n",
            "{\"tool_name\": \"list_files\", \"args\": {}}\n",
            "```\n",
            "\n",
            "Parsed action: {'tool_name': 'list_files', 'args': {}}\n",
            "\n",
            "Execution result (JSON): {'result': ['000_Prompting for Agents -GAIL.txt', '001_PArse_the Response.txt', '002_Execute_the_Action.txt', '003_gent Feedback and Memory.txt']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = step(\"Read the file named '001_PArse_the Response.txt'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDdau2K5AEDJ",
        "outputId": "72b66949-7e61-4007-b33b-aaeebd1f1909"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw model output:\n",
            " ```action\n",
            "{\"tool_name\": \"read_file\", \"args\":{\"file_name\":\"001_PArse_the Response.txt\"}}\n",
            "```\n",
            "\n",
            "Parsed action: {'tool_name': 'read_file', 'args': {'file_name': '001_PArse_the Response.txt'}}\n",
            "\n",
            "Execution result (JSON): {'result': '\\n#==========Parse the Response\\n\\nAfter generating a response, the next step is to extract the intended action and its parameters from the LLM‚Äôs output. The response is expected to follow a predefined structure, such as a JSON format encapsulated within a markdown code block. This structure ensures the action can be parsed and executed without ambiguity.\\n\\nIn the code, this is accomplished by locating and extracting the content between the ```action markers. If the response does not include a valid action block, the agent defaults to a termination action, returning the raw response as the message:\\n\\n#==============\\n\\ndef parse_action(response: str) -> Dict:\\n    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\\n    try:\\n        response = extract_markdown_block(response, \"action\")\\n        response_json = json.loads(response)\\n        if \"tool_name\" in response_json and \"args\" in response_json:\\n            return response_json\\n        else:\\n            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\\n    except json.JSONDecodeError:\\n        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\\n\\nThis parsing step is critical to ensuring the response is actionable. It provides a structured output, such as:\\n\\n{\\n    \"tool_name\": \"list_files\",\\n    \"args\": {}\\n}\\n\\nBy breaking down the LLM‚Äôs output into tool_name and args, the agent can precisely determine the next action and its inputs.\\n\\nIf the LLM response does not contain a valid action block, the agent defaults to an error message, prompting the LLM to provide a valid JSON tool invocation. The error message appears to have come from the ‚Äúuser‚Äù. This fallback mechanism ensures the agent can recover if it starts outputting invalid responses that aren‚Äôt in the desired format.\\n\\n\\n\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üîë Why returning a specific format matters\n",
        "\n",
        "1. **Reliability**\n",
        "\n",
        "   * Free-form text is hard for code to work with ‚Äî the model could change wording, punctuation, or order at any time.\n",
        "   * A strict JSON schema gives you something you can parse without guesswork.\n",
        "\n",
        "2. **Automation**\n",
        "\n",
        "   * If the output is always `{\"tool_name\": \"...\", \"args\": {...}}`, your agent loop can directly map `tool_name` to a function and pass `args` without human intervention.\n",
        "   * This is what lets agents run unattended.\n",
        "\n",
        "3. **Error handling**\n",
        "\n",
        "   * When the model violates the format, you can detect it and return an `error` action ‚Äî keeping the loop safe.\n",
        "   * Without a schema, you might try to run the wrong tool or crash the agent.\n",
        "\n",
        "4. **Interoperability**\n",
        "\n",
        "   * Other parts of your system (UI, logging, APIs) can consume this structured output without needing to ‚Äúunderstand‚Äù natural language.\n",
        "   * You can swap models without changing the rest of the pipeline.\n",
        "\n",
        "5. **Future expansion**\n",
        "\n",
        "   * You can add more tools simply by adding more `tool_name` values ‚Äî the model just picks the right one and you‚Äôre done.\n",
        "   * The execution layer stays the same.\n",
        "\n",
        "---\n",
        "\n",
        "The key point:\n",
        "\n",
        "> **Structured output turns the LLM into a decision-maker you can reliably hook into code** ‚Äî rather than just a conversational partner.\n",
        "\n"
      ],
      "metadata": {
        "id": "EqwWyhdBDBZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install openai python-dotenv\n",
        "import os, json, re\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "from pathlib import Path\n",
        "\n",
        "# ---- Setup (safe to re-run) ----\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found in /content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "FILES_DIR = Path(\"/content/files\")\n",
        "\n",
        "# ---- Tools ----\n",
        "\n",
        "def list_files():\n",
        "    try:\n",
        "        return sorted([p.name for p in FILES_DIR.iterdir() if p.is_file()])\n",
        "    except FileNotFoundError:\n",
        "        return [f\"Error: Folder not found: {FILES_DIR}\"]\n",
        "\n",
        "def read_file(file_name, max_chars=2400):\n",
        "    target = (FILES_DIR / file_name).resolve()\n",
        "    if FILES_DIR not in target.parents and target != FILES_DIR:\n",
        "        return f\"Error: {file_name} is outside {FILES_DIR}\"\n",
        "    if not target.exists() or not target.is_file():\n",
        "        return f\"Error: File not found: {file_name}\"\n",
        "    try:\n",
        "        with open(target, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "            content = f.read(max_chars + 1)\n",
        "        if len(content) > max_chars:\n",
        "            content = content[:max_chars] + \"\\n... [truncated]\"\n",
        "        return content\n",
        "    except Exception as e:\n",
        "        return f\"Error reading {file_name}: {e}\"\n",
        "\n",
        "# ---- Action parsing ----\n",
        "\n",
        "def extract_markdown_block(text, block_name):\n",
        "    pattern = rf\"```{block_name}\\s*(.*?)\\s*```\"\n",
        "    m = re.search(pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def parse_action(response_text):\n",
        "    action_str = extract_markdown_block(response_text, \"action\")\n",
        "    if not action_str:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"No action block found.\"}}\n",
        "    try:\n",
        "        action_json = json.loads(action_str)\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON.\"}}\n",
        "    if isinstance(action_json, dict) and \"tool_name\" in action_json and \"args\" in action_json:\n",
        "        return action_json\n",
        "    return {\"tool_name\": \"error\", \"args\": {\"message\": \"Missing tool_name or args.\"}}\n",
        "\n",
        "# ---- Execute action ----\n",
        "\n",
        "def execute_action(action):\n",
        "    tool = (action or {}).get(\"tool_name\")\n",
        "    args = (action or {}).get(\"args\", {})\n",
        "\n",
        "    if tool == \"list_files\":\n",
        "        return {\"result\": list_files()}\n",
        "    elif tool == \"read_file\":\n",
        "        fname = args.get(\"file_name\")\n",
        "        if not fname:\n",
        "            return {\"error\": \"Missing arg: file_name\"}\n",
        "        return {\"result\": read_file(fname)}\n",
        "    elif tool == \"error\":\n",
        "        return {\"error\": args.get(\"message\", \"Unknown error\")}\n",
        "    elif tool == \"terminate\":\n",
        "        return {\"result\": args.get(\"message\", \"Terminated\")}\n",
        "    else:\n",
        "        return {\"error\": f\"Unknown tool: {tool}\"}\n",
        "\n",
        "# ---- System prompt for multi-step behavior ----\n",
        "SYSTEM_V3 = (\n",
        "    \"\"\"\n",
        "You are an AI file agent. You can take multiple steps to complete the user's task.\n",
        "Respond ONLY with a single JSON action inside a markdown block like:\n",
        "\n",
        "```action\n",
        "{\"tool_name\": \"list_files\", \"args\": {}}\n",
        "```\n",
        "\n",
        "Available tools:\n",
        "- list_files: returns list of files in /content/files\n",
        "- read_file: args={\"file_name\": \"<filename>\"}\n",
        "- terminate: args={\"message\": \"<final summary or reason>\"}\n",
        "- error: args={\"message\": \"<what went wrong>\"}\n",
        "\n",
        "Rules:\n",
        "1) Use tool(s) as needed. When done, return a terminate action with a clear message.\n",
        "2) After each tool result is returned to you (as a user message), decide the next step.\n",
        "3) No prose outside the JSON action block.\n",
        "\"\"\"\n",
        ").strip()\n",
        "\n",
        "# ---- Agent loop (Feedback + Memory) ----\n",
        "\n",
        "def run_agent(task: str, max_iters: int = 5, memory_size=None):\n",
        "    messages = [{\"role\": \"system\", \"content\": SYSTEM_V3},\n",
        "                {\"role\": \"user\", \"content\": task}]\n",
        "\n",
        "    for i in range(1, max_iters + 1):\n",
        "        visible = messages if memory_size is None else messages[-memory_size:]\n",
        "        resp = client.chat.completions.create(model=\"gpt-4o-mini\", messages=visible)\n",
        "        reply = resp.choices[0].message.content\n",
        "        print(f\"\\n=== Iteration {i}: Raw model output ===\\n{reply}\")\n",
        "\n",
        "        action = parse_action(reply)\n",
        "        print(\"Parsed action:\", action)\n",
        "\n",
        "        result = execute_action(action)\n",
        "        print(\"Execution result:\", (str(result)[:400] + (\"...\" if len(str(result))>400 else \"\")))\n",
        "\n",
        "        # Update memory: assistant (the action) + user (the result)\n",
        "        messages.append({\"role\": \"assistant\", \"content\": reply})\n",
        "        messages.append({\"role\": \"user\", \"content\": json.dumps(result)})\n",
        "\n",
        "        # Check for termination\n",
        "        if action.get(\"tool_name\") == \"terminate\":\n",
        "            print(\"\\nAgent terminated:\", result.get(\"result\"))\n",
        "            return {\"messages\": messages, \"final\": result}\n",
        "\n",
        "    # Safety stop\n",
        "    print(\"\\nMax iterations reached. Terminating.\")\n",
        "    return {\"messages\": messages, \"final\": {\"error\": \"max_iters_reached\"}}"
      ],
      "metadata": {
        "id": "fgpq3_iEAEiq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Demo calls ----\n",
        "# Example 1: Ask it to pick and read a file, then summarize and terminate\n",
        "out = run_agent(\"Find a file that mentions 'Parse' in the name, read it, then give me a 2-sentence summary and terminate.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs8QLp6MEkKc",
        "outputId": "28824b31-1b87-4b16-bff8-9892d1592f7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Iteration 1: Raw model output ===\n",
            "```action\n",
            "{\"tool_name\": \"list_files\", \"args\": {}}\n",
            "```\n",
            "Parsed action: {'tool_name': 'list_files', 'args': {}}\n",
            "Execution result: {'result': ['000_Prompting for Agents -GAIL.txt', '001_PArse_the Response.txt', '002_Execute_the_Action.txt', '003_gent Feedback and Memory.txt']}\n",
            "\n",
            "=== Iteration 2: Raw model output ===\n",
            "```action\n",
            "{\"tool_name\": \"read_file\", \"args\":{\"file_name\": \"001_PArse_the Response.txt\"}}\n",
            "```\n",
            "Parsed action: {'tool_name': 'read_file', 'args': {'file_name': '001_PArse_the Response.txt'}}\n",
            "Execution result: {'result': '\\n#==========Parse the Response\\n\\nAfter generating a response, the next step is to extract the intended action and its parameters from the LLM‚Äôs output. The response is expected to follow a predefined structure, such as a JSON format encapsulated within a markdown code block. This structure ensures the action can be parsed and executed without ambiguity.\\n\\nIn the code, this is accomp...\n",
            "\n",
            "=== Iteration 3: Raw model output ===\n",
            "```action\n",
            "{\"tool_name\": \"terminate\", \"args\":{\"message\": \"The file explains the process of parsing LLM responses to extract actions and parameters. It emphasizes the importance of returning a valid JSON format to ensure the response is interpretable and actionable.\"}}\n",
            "```\n",
            "Parsed action: {'tool_name': 'terminate', 'args': {'message': 'The file explains the process of parsing LLM responses to extract actions and parameters. It emphasizes the importance of returning a valid JSON format to ensure the response is interpretable and actionable.'}}\n",
            "Execution result: {'result': 'The file explains the process of parsing LLM responses to extract actions and parameters. It emphasizes the importance of returning a valid JSON format to ensure the response is interpretable and actionable.'}\n",
            "\n",
            "Agent terminated: The file explains the process of parsing LLM responses to extract actions and parameters. It emphasizes the importance of returning a valid JSON format to ensure the response is interpretable and actionable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Just list files, then stop\n",
        "out = run_agent(\"List the files and then terminate with a short description of what you see.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDFhNHznErLD",
        "outputId": "6b7bd017-a9c6-4572-a8f9-9ffbc60822eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Iteration 1: Raw model output ===\n",
            "```action\n",
            "{\"tool_name\": \"list_files\", \"args\": {}}\n",
            "```\n",
            "Parsed action: {'tool_name': 'list_files', 'args': {}}\n",
            "Execution result: {'result': ['000_Prompting for Agents -GAIL.txt', '001_PArse_the Response.txt', '002_Execute_the_Action.txt', '003_gent Feedback and Memory.txt']}\n",
            "\n",
            "=== Iteration 2: Raw model output ===\n",
            "```action\n",
            "{\"tool_name\": \"terminate\", \"args\":{\"message\": \"Files listed: 000_Prompting for Agents -GAIL.txt, 001_PArse_the Response.txt, 002_Execute_the_Action.txt, 003_gent Feedback and Memory.txt.\"}}\n",
            "```\n",
            "Parsed action: {'tool_name': 'terminate', 'args': {'message': 'Files listed: 000_Prompting for Agents -GAIL.txt, 001_PArse_the Response.txt, 002_Execute_the_Action.txt, 003_gent Feedback and Memory.txt.'}}\n",
            "Execution result: {'result': 'Files listed: 000_Prompting for Agents -GAIL.txt, 001_PArse_the Response.txt, 002_Execute_the_Action.txt, 003_gent Feedback and Memory.txt.'}\n",
            "\n",
            "Agent terminated: Files listed: 000_Prompting for Agents -GAIL.txt, 001_PArse_the Response.txt, 002_Execute_the_Action.txt, 003_gent Feedback and Memory.txt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How the parsing + feedback loop self-corrects bad model output.\n",
        "\n",
        "# How the loop ‚Äúteaches‚Äù the model to fix itself\n",
        "\n",
        "1. Model replies (maybe with bad formatting).\n",
        "2. `parse_action(...)` tries to parse.\n",
        "3. If parsing fails, you create an **error action**.\n",
        "4. You then feed that **error** back to the model as a **`user`** message (feedback).\n",
        "5. On the next turn, the model sees the error and (usually) fixes its format.\n",
        "\n",
        "Tiny, minimal demo (no external calls), just to see the flow:\n",
        "\n",
        "````python\n",
        "# Minimal illustration of the feedback loop using fake replies:\n",
        "\n",
        "messages = []\n",
        "\n",
        "def add_message(role, content):\n",
        "    messages.append({\"role\": role, \"content\": content})\n",
        "\n",
        "def parse_action(response_text):\n",
        "    import json, re\n",
        "    m = re.search(r\"```action\\s*(.*?)\\s*```\", response_text, re.DOTALL|re.IGNORECASE)\n",
        "    if not m:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"No action block found.\"}}\n",
        "    try:\n",
        "        data = json.loads(m.group(1))\n",
        "        if \"tool_name\" in data and \"args\" in data:\n",
        "            return data\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Missing tool_name or args.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON.\"}}\n",
        "\n",
        "# 1) Bad model reply (no code fence at all)\n",
        "bad_reply = '{\"tool_name\": \"list_files\", \"args\": {}}'  # missing ```action ... ```\n",
        "add_message(\"assistant\", bad_reply)\n",
        "action = parse_action(bad_reply)\n",
        "print(\"Parsed:\", action)  # -> error\n",
        "\n",
        "# 2) Feed the error back as *user* feedback\n",
        "add_message(\"user\", json.dumps(action))\n",
        "\n",
        "# 3) Next (improved) model reply, now correctly wrapped\n",
        "fixed_reply = \"\"\"```action\n",
        "{\"tool_name\": \"list_files\", \"args\": {}}\n",
        "```\"\"\"\n",
        "add_message(\"assistant\", fixed_reply)\n",
        "print(\"Parsed:\", parse_action(fixed_reply))  # -> valid action dict\n",
        "````\n",
        "\n",
        "What to notice:\n",
        "\n",
        "* The first parse fails ‚Üí returns `{\"tool_name\":\"error\", \"args\":{\"message\":\"...\"}}`.\n",
        "* That error is appended as a **user** message (feedback the model will see next turn).\n",
        "* The second reply is corrected and parses cleanly.\n",
        "\n"
      ],
      "metadata": {
        "id": "h8NK3gyJFngn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üîë Key Points to Carry Forward\n",
        "\n",
        "1. **Formatting is a contract**\n",
        "\n",
        "   * The model‚Äôs ‚Äúcontract‚Äù with the agent is: *I‚Äôll always return this JSON schema inside a code block*.\n",
        "   * Parsing enforces the contract and protects your code from unstructured surprises.\n",
        "\n",
        "2. **Memory enables self-correction**\n",
        "\n",
        "   * By saving the **error message** in the chat history, you give the model a chance to ‚Äúsee its mistake‚Äù and fix it.\n",
        "   * Without memory, the model wouldn‚Äôt know what went wrong last time.\n",
        "\n",
        "3. **Error messages are just instructions**\n",
        "\n",
        "   * An ‚Äúerror‚Äù in the agent loop is just another message to the LLM ‚Äî you can phrase it however is most useful for guiding correction.\n",
        "\n",
        "4. **Parse early, execute later**\n",
        "\n",
        "   * You always want to parse the model‚Äôs intent before running tools.\n",
        "   * This separation makes it easy to handle errors, log intentions, or even override them.\n",
        "\n",
        "5. **Graceful degradation**\n",
        "\n",
        "   * If parsing fails multiple times, you can fall back to a safe termination instead of letting the loop spin forever.\n",
        "\n"
      ],
      "metadata": {
        "id": "2aXTtiPpGIMe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nbnzRtyOFq2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}