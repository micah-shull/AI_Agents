{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJNRS9/KnDz0c0RcpTplGA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/003_Agents_TaskManager.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß™ Example Agent Projects\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 1. `llm = pipeline(...)`  \n",
        "**What it is:**  \n",
        "Your agent‚Äôs *brain*. This is what reads the user input and reasons about what action to take.\n",
        "\n",
        "**What you‚Äôre learning:**  \n",
        "- Every agent needs a model that acts as the **decision engine**.\n",
        "- We‚Äôre starting with `flan-t5-base` ‚Äî a small model that‚Äôs good at instructions.\n",
        "- You're not building the brain ‚Äî you're *giving it clear guidance through prompts*.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 2. `tasks_db = []`  \n",
        "**What it is:**  \n",
        "A very simple, in-memory database ‚Äî your agent‚Äôs **working memory**.\n",
        "\n",
        "**What you‚Äôre learning:**  \n",
        "- Agents often need **state** ‚Äî a way to remember things they‚Äôve done.\n",
        "- This could become a file, a database, a remote API ‚Äî but the concept is the same.\n",
        "- It supports real-world use, like: \"What did I ask you to do yesterday?\"\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 3. Tool functions (`save_task`, `get_recent_tasks`, `mark_done`)  \n",
        "**What they are:**  \n",
        "The agent‚Äôs **hands** ‚Äî what it uses to get stuff done.\n",
        "\n",
        "**What you‚Äôre learning:**  \n",
        "- You don‚Äôt want the LLM doing everything ‚Äî you want it to **delegate** to structured code.\n",
        "- Each tool does **one specific thing**, and the model chooses when to call it.\n",
        "- Tools make agents *actionable*, not just chatty.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ 4. `tools = { ... }`  \n",
        "**What it is:**  \n",
        "The agent‚Äôs **toolbox** ‚Äî a registry of the things it can use.\n",
        "\n",
        "**What you‚Äôre learning:**  \n",
        "- You can build more and more tools and just register them ‚Äî no need to rewrite your agent loop.\n",
        "- This pattern keeps your agent **modular** and **scalable**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Key Takeaway Concepts So Far\n",
        "\n",
        "| üß© Concept | üí¨ What You Should Learn |\n",
        "|-----------|--------------------------|\n",
        "| **Model** | The LLM is the agent‚Äôs reasoning engine, but it needs guidance |\n",
        "| **Tools** | Actions the agent can take ‚Äî your functions handle the doing |\n",
        "| **Memory (State)** | Even simple agents benefit from keeping track of things |\n",
        "| **Tool Registry** | Keeps your agent flexible and extensible |\n",
        "\n",
        "---\n",
        "\n",
        "Once we add the **agent logic + prompts**, you‚Äôll see how it all comes together:\n",
        "- User says: ‚ÄúRemind me to get groceries.‚Äù\n",
        "- Agent thinks: *‚ÄúAh, a save_note-type task‚Äù*\n",
        "- Agent acts: `save_task(\"get groceries\", \"personal\")`\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hhh1pyDEyHRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task Manager Agent** üìù  \n",
        "**Goal**: Build an agent that can categorize tasks (e.g., Work, Personal, Urgent), save them, and retrieve recent ones.\n",
        "\n",
        "#### üîß Tools:\n",
        "- `save_task(task_text, category)`\n",
        "- `get_recent_tasks(category)`\n",
        "- `mark_done(task_id)`\n",
        "\n",
        "#### üß† New Concepts:\n",
        "- Custom tool parameters\n",
        "- Task parsing and classification\n",
        "- Mini memory system (recent tasks)\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Agent Designer Mindset: What Are You Actually Building?\n",
        "\n",
        "You're building a **thinking assistant** that:\n",
        "- Understands natural language input (LLM)\n",
        "- Decides what kind of task the user wants to do (instructions + prompt)\n",
        "- Takes action using pre-built tools (save, retrieve, complete)\n",
        "- Manages a memory (task list) to stay useful over time\n",
        "\n"
      ],
      "metadata": {
        "id": "ds3UpSps5OOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet"
      ],
      "metadata": {
        "id": "uxBg8hdTym0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import uuid\n",
        "\n",
        "# Load small LLM\n",
        "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "# Simple in-memory task list\n",
        "tasks_db = []\n",
        "\n",
        "# --- Tools ---\n",
        "def save_task(task_text, category):\n",
        "    task = {\n",
        "        \"id\": str(uuid.uuid4())[:8],\n",
        "        \"text\": task_text,\n",
        "        \"category\": category.lower(),\n",
        "        \"done\": False\n",
        "    }\n",
        "    tasks_db.append(task)\n",
        "    return f\"Task saved under '{category}': {task['text']} (ID: {task['id']})\"\n",
        "\n",
        "def get_recent_tasks(category):\n",
        "    recent = [t for t in tasks_db if t['category'] == category.lower() and not t['done']]\n",
        "    if not recent:\n",
        "        return f\"No active tasks found in category '{category}'.\"\n",
        "    return \"\\n\".join([f\"- [{t['id']}] {t['text']}\" for t in recent])\n",
        "\n",
        "def mark_done(task_id):\n",
        "    for t in tasks_db:\n",
        "        if t[\"id\"] == task_id:\n",
        "            t[\"done\"] = True\n",
        "            return f\"Marked task '{t['text']}' as done.\"\n",
        "    return f\"No task found with ID '{task_id}'.\"\n",
        "\n",
        "# Tool registry\n",
        "tools = {\n",
        "    \"save_task\": save_task,\n",
        "    \"get_recent_tasks\": get_recent_tasks,\n",
        "    \"mark_done\": mark_done\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452,
          "referenced_widgets": [
            "ea8985c0e45a415e9b1ed3b5df0470ab",
            "a0ef8e1bf2864fbe8ecfbf9e60019959",
            "9d87276357fb49cbbdb8bc7a55104f71",
            "fa7fc9d4c8734dff9eede78e77935c2c",
            "b1c81451f9c24c5da95bcf5323d710c4",
            "cfe05ba3510841fd9494c0e7e7cbcf42",
            "a34bffaca5dd44c98ca18b82860b999a",
            "5daadf0fe39845efbec224a2964ad816",
            "07dce848c5cf485e8a0c4bef49c957d6",
            "9ca20f938eb94de39478c2b6bc6cebb6",
            "e8ccf0269b3441cf969f0131c66d17f5",
            "4220f78e801d4bfc947e11ae131c733c",
            "688d7c8e628f4e69bd34474ad0d27666",
            "ff082afd8e6d4c048cabf4e0d1d855b3",
            "6614490cb4224399bd809494ea0be8ff",
            "06f3087162fc40818ea14fa4f9a6fd4b",
            "847f665716a1422e933d5121cf57d6a7",
            "456519fa9967448b97bce6d4a8beb887",
            "293ee272034941378678c2810a5db498",
            "0aaba9592c48468c9bf66b80cef82700",
            "dee56d524f6640c99f074afa10bd71c7",
            "dabee2df731a4a9384887d267a26f931",
            "c075a5898e454630994e2b33b49c382e",
            "8d0d4305784b45c59bb80728a313b4f8",
            "92b888d9e2d9422a92b91312488241cc",
            "d8c57d4c37ec4c0aa781d8f9c218c979",
            "e9a2819c08f14961a76db70d866b5320",
            "80797e32f3d548a191bfee6ca5ab77d9",
            "8b620570bad74d8b88842d08a329c768",
            "b73fe10ea20e4afaa3c7f1da2425b7d8",
            "c16ecee0371741a5a78ecafaecb74647",
            "65edc7bc0f524eac911e65312af5f626",
            "e6ea4e5b7b8e482fb74f00162504669c",
            "5c09587e2f4e49bcbf70e8b2450b0314",
            "e2b703f4a4d9422794d941f95323a359",
            "297e4e01caaf43a28e303d850a7e3f6a",
            "a5df88518d5e42038ff43da78650328b",
            "18731ff9939048c39a258b09613213e1",
            "560f3891ed9540ddb17187d9eabe99c5",
            "ad0bdc45e1bf467e8a18035e5d0ac8f7",
            "79cb2904e86d4bae8fe7f1aec7735481",
            "ab7587bdad304061b1ac9c3b2ecde0d4",
            "c48460095fb248f4ba7aa04bf6802eb3",
            "a62e8b8592aa4e68a06b9e9045dd7152",
            "bdfd057741f14855b30e3d440bb2e2be",
            "4ceb9e1284444d99898bae754dca7077",
            "f6e506258a3649989a8cd6bc96456e8c",
            "4c7b1e7076de4111b3230803d5567237",
            "6de4e483c1f54d23afcfa32450addf33",
            "83a04b9caf0640098af955093f08ef29",
            "80189a79303844118c40d2095318bead",
            "e933f7ed581846bbbe94d7b068bd2beb",
            "93908ed0b10a48c3831c45ba7c66e2be",
            "c26af12fb02f49d08d006023f9315a3c",
            "2ccd66178fb2415c979a1bba79ec0cf3",
            "16963cefbb1c49cebeb52c79aead9ea1",
            "4929a93efb644915a891b0ce638e2c01",
            "86091c330b6c4ff785a300b100021616",
            "cff1721f4c2a4aab8943a7aff75c347d",
            "6c989ae623be494ba98497559f3052a4",
            "8e9cb35a872c4dda9905b37a060556cf",
            "58777c1fb6da4e06a1cf6c7baddb4831",
            "0852598fd61e48c5a4091ef51ef1d896",
            "72dc778147ec4d9aae7e7b170df23187",
            "5c407d28d86a4fe0adce5b0da67024f7",
            "4f663012f8434d67a1982b57dd5f4749",
            "37f80fe05cfd4596afe53b2c9e382db4",
            "77588b837eb44e499e8f24f59395147b",
            "1563b555a3af404a9790131df614dad5",
            "beaa5f4de0c7483c90a81817052f8e00",
            "69ba294253844de9ba68f2f4f2f423c5",
            "f40d42f4afbf44bab0324f998f9df0b0",
            "7b8bbfeaeca940efbb0362f01b588914",
            "b6309df101474ca7aaa653874a636492",
            "b03d4216758d4deea145c80d5ee0ee7f",
            "4c5b7ee3c327497fab98ca4d8c3ca3e1",
            "1ccc1e4b899841a1962eda6f6cb1b50c"
          ]
        },
        "id": "x4FgRtlOyebK",
        "outputId": "da6a233d-1919-4995-8477-32dc196d0f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea8985c0e45a415e9b1ed3b5df0470ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4220f78e801d4bfc947e11ae131c733c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c075a5898e454630994e2b33b49c382e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c09587e2f4e49bcbf70e8b2450b0314"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdfd057741f14855b30e3d440bb2e2be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16963cefbb1c49cebeb52c79aead9ea1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37f80fe05cfd4596afe53b2c9e382db4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### üîç UID - What is it?\n",
        "\n",
        "```python\n",
        "\"id\": str(uuid.uuid4())[:8],\n",
        "```\n",
        "\n",
        "This line is deceptively small but teaches an important **agent-building concept** This creates a **unique identifier (ID)** for each task the agent saves.\n",
        "\n",
        "### Here's what it's doing:\n",
        "- `uuid.uuid4()` ‚Üí generates a random universally unique ID (like `a4f7c9e1-12ab-4ef6-8bdf-8d8b1abf019d`)\n",
        "- `str(...)[ :8 ]` ‚Üí trims it down to just the first 8 characters for simplicity (e.g., `a4f7c9e1`)\n",
        "\n",
        "So, each task looks like:\n",
        "```python\n",
        "{\n",
        "  \"id\": \"a4f7c9e1\",\n",
        "  \"text\": \"Call the plumber\",\n",
        "  \"category\": \"personal\",\n",
        "  \"done\": False\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why is this important for agents?\n",
        "\n",
        "### ‚úÖ 1. **Tracking and Referencing**\n",
        "Agents need a way to refer back to things they‚Äôve done ‚Äî like saying:\n",
        "> ‚ÄúMark task `a4f7c9e1` as done.‚Äù\n",
        "\n",
        "Without an ID, you‚Äôd be stuck searching for full task text (which might be ambiguous or duplicated).\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ 2. **User Interaction**\n",
        "Users can say:\n",
        "> ‚ÄúMark task `ab12f3d1` as done‚Äù\n",
        "\n",
        "This gives a clean interface ‚Äî like a **tiny API between the agent and the user**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ 3. **State Management**\n",
        "In real-world agents, IDs are used to:\n",
        "- Update or delete records\n",
        "- Connect logs and audit trails\n",
        "- Pass state between agent components (or between agents)\n",
        "\n",
        "Even though this is just a toy agent for now, you're learning the *right patterns* that apply to full-blown production agents.\n",
        "\n",
        "---\n",
        "\n",
        "### üß© TL;DR:\n",
        "\n",
        "| Why We Use It | What You‚Äôre Learning |\n",
        "|---------------|----------------------|\n",
        "| To uniquely identify tasks | Agents need internal references |\n",
        "| To support updates and lookups | IDs make actions like \"mark done\" possible |\n",
        "| To simulate real-world memory | All useful agents track what they‚Äôre doing |\n",
        "\n"
      ],
      "metadata": {
        "id": "3ydWFQTS0Nsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üîÅ Build the Agent Loop\n",
        "\n",
        "This is the part that:\n",
        "1. **Prompts the LLM** to decide what tool to use\n",
        "2. **Parses the LLM‚Äôs response**\n",
        "3. **Routes the action** to the right tool\n",
        "4. **Returns a result**\n",
        "\n",
        "\n",
        "\n",
        "## üß† What You‚Äôre Learning\n",
        "\n",
        "| üîç Concept | üí¨ What It Teaches |\n",
        "|-----------|--------------------|\n",
        "| Prompt = decision maker | The LLM is selecting a tool based on natural language |\n",
        "| Routing logic | You're interpreting fuzzy model output to take structured action |\n",
        "| Handling fallback | You‚Äôre giving the agent a way to gracefully reject unrelated requests |\n",
        "| Simulated task management | You‚Äôre now maintaining and updating real state through conversation |\n",
        "\n",
        "\n",
        "## üîç Line Breakdown\n",
        "\n",
        "```python\n",
        "matched_tool = next((name for name in tools if name in model_output), None)\n",
        "```\n",
        "\n",
        "### üîß What It Does (Technically):\n",
        "It loops through the tool names (`\"save_task\"`, `\"get_recent_tasks\"`, `\"mark_done\"`), and returns the **first one it finds** inside the model‚Äôs output string.\n",
        "\n",
        "If none are found, it returns `None`.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† What You‚Äôre *Actually* Learning\n",
        "\n",
        "### üéØ **1. Fuzzy Matching to Structured Action**\n",
        "The LLM might return:\n",
        "- `\"save_task\"`\n",
        "- `\"Use save_task\"`  \n",
        "- `\"I think the correct tool is save_task\"`  \n",
        "- `\"save_task: Save a task.\"`\n",
        "\n",
        "‚Üí All of these are fuzzy variations, not perfect matches.\n",
        "\n",
        "So instead of expecting **exact output**, you're doing **pattern recognition**:\n",
        "```python\n",
        "if \"save_task\" in model_output:\n",
        "```\n",
        "That‚Äôs the core of how agents work ‚Äî **interpreting intent**, not exact strings.\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ **2. Safe Lookup with Fallback**\n",
        "By wrapping it in `next(..., None)`, you avoid crashes:\n",
        "- If no tool is matched, `matched_tool = None`\n",
        "- This triggers your fallback response: *\"Sorry, I didn‚Äôt understand.\"*\n",
        "\n",
        "So you‚Äôre learning to:\n",
        "- Let the model guess\n",
        "- Validate its answer\n",
        "- Safely **handle uncertainty**\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ **3. Agent Flexibility**\n",
        "This line lets you **grow your agent‚Äôs capabilities** without rewriting routing logic:\n",
        "- Add a new tool like `\"delete_task\"` to the `tools` dict\n",
        "- That tool gets matched automatically by this line if the model ever returns `\"delete_task\"`\n",
        "\n",
        "No extra `if` blocks required. This is why **tool registries + dynamic matching** are agent superpowers.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ TL;DR\n",
        "\n",
        "| Concept | What You‚Äôre Learning |\n",
        "|--------|-----------------------|\n",
        "| Fuzzy intent ‚Üí action mapping | LLMs aren‚Äôt exact ‚Äî you interpret what they mean |\n",
        "| Safe failover | Don‚Äôt crash if the model gets it wrong |\n",
        "| Extensibility | New tools become usable without changing logic |\n"
      ],
      "metadata": {
        "id": "HeC_jDhf3iX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzRM_oCYxgIo"
      },
      "outputs": [],
      "source": [
        "def task_agent(user_input):\n",
        "    # Prompt the model to choose an action\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful task assistant. Based on the user input below, decide which tool to use.\n",
        "\n",
        "Available tools:\n",
        "- save_task: Save a task. Use if the user wants to add something to a to-do list.\n",
        "- get_recent_tasks: Use if the user wants to view their active tasks.\n",
        "- mark_done: Use if the user wants to mark a task as completed.\n",
        "\n",
        "IMPORTANT:\n",
        "- Return only the tool name: save_task, get_recent_tasks, or mark_done.\n",
        "- Do not return full sentences or explanations.\n",
        "- If the user asks something unrelated, respond: \"I'm only here to help you manage tasks. Please ask something related.\"\n",
        "\n",
        "User input: {user_input}\n",
        "Tool:\n",
        "    \"\"\"\n",
        "    model_output = llm(prompt, max_new_tokens=30)[0][\"generated_text\"].strip().lower()\n",
        "\n",
        "    # Extract tool name or handle fallback\n",
        "    matched_tool = next((name for name in tools if name in model_output), None)\n",
        "\n",
        "    if matched_tool == \"save_task\":\n",
        "        # For now, save everything as a \"personal\" task\n",
        "        return tools[\"save_task\"](user_input, category=\"personal\")\n",
        "\n",
        "    elif matched_tool == \"get_recent_tasks\":\n",
        "        return tools[\"get_recent_tasks\"](\"personal\")\n",
        "\n",
        "    elif matched_tool == \"mark_done\":\n",
        "        # Simulate a naive ID extraction\n",
        "        task_id = user_input.split()[-1]\n",
        "        return tools[\"mark_done\"](task_id)\n",
        "\n",
        "    else:\n",
        "        return model_output  # Model-generated fallback message\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(task_agent(\"Remind me to buy groceries\"))\n",
        "print(task_agent(\"What are my personal tasks?\"))\n",
        "print(task_agent(\"Mark task 1234abcd as done\"))\n",
        "print(task_agent(\"Can you tell me a joke?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afCrXaRA57JN",
        "outputId": "c3b60c21-2d23-4312-af2f-5fa553e131fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task saved under 'personal': Remind me to buy groceries (ID: d838fd25)\n",
            "- [d838fd25] Remind me to buy groceries\n",
            "No task found with ID 'done'.\n",
            "if the user asks something unrelated, respond: \"i'm only here to help you manage tasks. please ask something related.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Fix 1: Improve ID Extraction for mark_done\n",
        "\n",
        "import re\n",
        "\n",
        "elif matched_tool == \"mark_done\":\n",
        "    # Look for any 8-character alphanumeric pattern (UUID substring)\n",
        "    match = re.search(r\"\\b[a-f0-9]{8}\\b\", user_input)\n",
        "    if match:\n",
        "        task_id = match.group()\n",
        "        return tools[\"mark_done\"](task_id)\n",
        "    else:\n",
        "        return \"Hmm, I couldn't find a valid task ID in your message. Try saying: 'Mark task ab12cd34 as done'\"\n"
      ],
      "metadata": {
        "id": "q7c4fSxe6YrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Fix 2: Improve Prompt Instructions for Fallback\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a task assistant. Based on the user input below, decide which tool to use.\n",
        "\n",
        "Tools you can use:\n",
        "- save_task\n",
        "- get_recent_tasks\n",
        "- mark_done\n",
        "\n",
        "Respond with only ONE of the following:\n",
        "- The name of the tool to use (save_task, get_recent_tasks, mark_done)\n",
        "- Or this exact sentence if unrelated: \"I'm only here to help you manage tasks. Please ask something related.\"\n",
        "\n",
        "User input: {user_input}\n",
        "Your response:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "kfKylKgL6hCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def task_agent(user_input):\n",
        "    # Prompt the model to choose an action\n",
        "    prompt = f\"\"\"\n",
        "You are a task assistant. Based on the user input below, decide which tool to use.\n",
        "\n",
        "Tools you can use:\n",
        "- save_task\n",
        "- get_recent_tasks\n",
        "- mark_done\n",
        "\n",
        "Respond with only ONE of the following:\n",
        "- The name of the tool to use (save_task, get_recent_tasks, mark_done)\n",
        "- Or this exact sentence if unrelated: \"I'm only here to help you manage tasks. Please ask something related.\"\n",
        "\n",
        "User input: {user_input}\n",
        "Your response:\n",
        "\"\"\"\n",
        "\n",
        "    model_output = llm(prompt, max_new_tokens=30)[0][\"generated_text\"].strip().lower()\n",
        "\n",
        "    # Extract tool name or handle fallback\n",
        "    matched_tool = next((name for name in tools if name in model_output), None)\n",
        "\n",
        "    if matched_tool == \"save_task\":\n",
        "        # For now, save everything as a \"personal\" task\n",
        "        return tools[\"save_task\"](user_input, category=\"personal\")\n",
        "\n",
        "    elif matched_tool == \"get_recent_tasks\":\n",
        "        return tools[\"get_recent_tasks\"](\"personal\")\n",
        "\n",
        "    elif matched_tool == \"mark_done\":\n",
        "        # Look for any 8-character alphanumeric pattern (UUID substring)\n",
        "        match = re.search(r\"\\b[a-f0-9]{8}\\b\", user_input)\n",
        "        if match:\n",
        "            task_id = match.group()\n",
        "            return tools[\"mark_done\"](task_id)\n",
        "        else:\n",
        "            return \"Hmm, I couldn't find a valid task ID in your message. Try saying: 'Mark task ab12cd34 as done'\"\n",
        "\n",
        "    else:\n",
        "        return model_output  # Model-generated fallback message\n",
        "\n",
        "print(task_agent(\"Remind me to buy groceries\"))\n",
        "print(task_agent(\"What are my personal tasks?\"))\n",
        "print(task_agent(\"Mark task 1234abcd as done\"))\n",
        "print(task_agent(\"Can you tell me a joke?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8d-ZN_16oao",
        "outputId": "5f367e8f-228d-4176-f427-9d3b52e8cf82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task saved under 'personal': Remind me to buy groceries (ID: f79f979e)\n",
            "Task saved under 'personal': What are my personal tasks? (ID: f38838b1)\n",
            "No task found with ID '1234abcd'.\n",
            "Task saved under 'personal': Can you tell me a joke? (ID: 93bdd0ec)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! üéâ That‚Äôs a solid step forward ‚Äî you‚Äôre getting reliable task creation, safer fallback behavior, and more structured handling overall.\n",
        "\n",
        "Let‚Äôs break down what‚Äôs **working**, what‚Äôs **still a little off**, and how we can level up this agent.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ What‚Äôs Working Great\n",
        "\n",
        "### ‚úîÔ∏è 1. Task Saving (Core Functionality)\n",
        "You're saving tasks, generating unique IDs, and maintaining state correctly:\n",
        "```text\n",
        "Task saved under 'personal': Remind me to buy groceries (ID: f79f979e)\n",
        "```\n",
        "\n",
        "‚úÖ This is core to the agent‚Äôs usefulness. Great job!\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úîÔ∏è 2. Invalid Task ID Handling\n",
        "```text\n",
        "No task found with ID '1234abcd'.\n",
        "```\n",
        "‚úÖ Your regex and fallback message are working beautifully ‚Äî users get helpful guidance when they make a mistake.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùå What Still Needs a Tiny Fix\n",
        "\n",
        "### üòÖ The model is still guessing ‚Äúsave_task‚Äù when it shouldn‚Äôt:\n",
        "```text\n",
        "Task saved under 'personal': Can you tell me a joke?\n",
        "Task saved under 'personal': What are my personal tasks?\n",
        "```\n",
        "\n",
        "This means the model is **failing to reject** unrelated or ambiguous input ‚Äî instead, it just defaults to saving everything as a task.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Fix This With Stronger Prompt Conditioning\n",
        "\n",
        "Let‚Äôs *strengthen the fallback behavior* by nudging the model harder. Update your prompt to include **more examples of off-topic rejection**\n",
        "\n",
        "This uses few-shot examples to steer the model ‚Äî even small models like `flan-t5-base` benefit from this structure.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† What You‚Äôre Practicing Now\n",
        "\n",
        "| Skill | Why It Matters |\n",
        "|------|----------------|\n",
        "| Prompt steering | Crucial for keeping agents on-task |\n",
        "| Instruction-following | Model behavior is shaped by examples, not just rules |\n",
        "| Intent classification | This is the beginning of building *routing logic* for multi-agent systems |\n",
        "\n"
      ],
      "metadata": {
        "id": "JIwZDxF_7yq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def task_agent(user_input):\n",
        "    # Prompt the model to choose an action\n",
        "    prompt = f\"\"\"\n",
        "You are a task assistant. You can help the user by using one of the following tools:\n",
        "\n",
        "- save_task: Save a new to-do item.\n",
        "- get_recent_tasks: Show active tasks in a category.\n",
        "- mark_done: Mark a task as complete.\n",
        "\n",
        "You should only respond with:\n",
        "- One of these tool names: save_task, get_recent_tasks, mark_done\n",
        "- OR say exactly: \"I'm only here to help you manage tasks. Please ask something related.\"\n",
        "\n",
        "Examples:\n",
        "- Input: \"Add buy groceries to my list\" ‚Üí Response: save_task\n",
        "- Input: \"List my current tasks\" ‚Üí Response: get_recent_tasks\n",
        "- Input: \"Mark task 1234abcd as done\" ‚Üí Response: mark_done\n",
        "- Input: \"What‚Äôs the weather today?\" ‚Üí Response: I'm only here to help you manage tasks. Please ask something related.\n",
        "- Input: \"Tell me a joke\" ‚Üí Response: I'm only here to help you manage tasks. Please ask something related.\n",
        "\n",
        "Now try it yourself:\n",
        "User input: {user_input}\n",
        "Your response:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    model_output = llm(prompt, max_new_tokens=30)[0][\"generated_text\"].strip().lower()\n",
        "\n",
        "    # Extract tool name or handle fallback\n",
        "    matched_tool = next((name for name in tools if name in model_output), None)\n",
        "\n",
        "    if matched_tool == \"save_task\":\n",
        "        # For now, save everything as a \"personal\" task\n",
        "        return tools[\"save_task\"](user_input, category=\"personal\")\n",
        "\n",
        "    elif matched_tool == \"get_recent_tasks\":\n",
        "        return tools[\"get_recent_tasks\"](\"personal\")\n",
        "\n",
        "    elif matched_tool == \"mark_done\":\n",
        "        # Look for any 8-character alphanumeric pattern (UUID substring)\n",
        "        match = re.search(r\"\\b[a-f0-9]{8}\\b\", user_input)\n",
        "        if match:\n",
        "            task_id = match.group()\n",
        "            return tools[\"mark_done\"](task_id)\n",
        "        else:\n",
        "            return \"Hmm, I couldn't find a valid task ID in your message. Try saying: 'Mark task ab12cd34 as done'\"\n",
        "\n",
        "    else:\n",
        "        return model_output  # Model-generated fallback message\n",
        "\n",
        "print(task_agent(\"Remind me to buy groceries\"))\n",
        "print(task_agent(\"What are my personal tasks?\"))\n",
        "print(task_agent(\"Mark task 1234abcd as done\"))\n",
        "print(task_agent(\"Can you tell me a joke?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIYglvJU8DbZ",
        "outputId": "f6ef7f69-eb16-4619-f7c2-b1e9baa86d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task saved under 'personal': Remind me to buy groceries (ID: fdb9cb84)\n",
            "what are my personal tasks?\n",
            "No task found with ID '1234abcd'.\n",
            "i'm only here to help you manage tasks. please ask something related.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## üß† Why This Is So Different from Standard Coding\n",
        "\n",
        "This is the moment where your thinking officially levels up from *traditional developer* to *agent architect*.\n",
        "\n",
        "| üß± Traditional Programming | ü§ñ Agent Development |\n",
        "|--------------------------|----------------------|\n",
        "| Input must match exactly | Input is fuzzy, inferred |\n",
        "| Errors must be caught precisely | Mistakes must be interpreted and handled gracefully |\n",
        "| Deterministic: A + B = C | Probabilistic: It *might* say \"C\" (or something close) |\n",
        "| You control the flow | The LLM reasons *about* the flow |\n",
        "\n",
        "---\n",
        "\n",
        "## ü™Ñ This Line is the ‚ÄúMagic Filter‚Äù\n",
        "\n",
        "```python\n",
        "matched_tool = next((name for name in tools if name in model_output), None)\n",
        "```\n",
        "\n",
        "It acts as:\n",
        "- ‚úÖ A **translation layer** from language to action\n",
        "- ‚úÖ A **flexible bridge** between the LLM's fuzzy guesses and your concrete tools\n",
        "- ‚úÖ A **safety net** to protect against unexpected output\n",
        "\n",
        "You‚Äôre not saying:\n",
        "> ‚ÄúDo this exact thing if the model says `get_recent_tasks`.‚Äù\n",
        "\n",
        "You‚Äôre saying:\n",
        "> ‚ÄúI trust the model to *try* ‚Äî and I‚Äôll be ready to interpret what it meant.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ The Agent Loop in a Nutshell:\n",
        "\n",
        "```text\n",
        "User speaks ‚Üí Model interprets ‚Üí Agent tries to match ‚Üí Tool takes action\n",
        "```\n",
        "\n",
        "And that **try to match** step is the heart of this new agent paradigm.\n",
        "\n"
      ],
      "metadata": {
        "id": "ogk0UZnN4uoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Remove Widgets\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ExHFt_jlyc5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "notebook_path = \"/content/drive/My Drive/AI AGENTS/003_Agents_TaskManager.ipynb\"\n",
        "\n",
        "# Load the notebook JSON\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "# 1. Remove widgets from notebook-level metadata\n",
        "if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "    del nb[\"metadata\"][\"widgets\"]\n",
        "    print(\"‚úÖ Removed notebook-level 'widgets' metadata.\")\n",
        "\n",
        "# 2. Remove widgets from each cell's metadata\n",
        "for i, cell in enumerate(nb.get(\"cells\", [])):\n",
        "    if \"metadata\" in cell and \"widgets\" in cell[\"metadata\"]:\n",
        "        del cell[\"metadata\"][\"widgets\"]\n",
        "        print(f\"‚úÖ Removed 'widgets' from cell {i}\")\n",
        "\n",
        "# Save the cleaned notebook\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Notebook deeply cleaned. Try uploading to GitHub again.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4zmfKN7yhqY",
        "outputId": "0ee9a98e-e514-40b2-e43d-81da96993980"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Notebook deeply cleaned. Try uploading to GitHub again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkTAm09hyhnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qcQzX2Oyhi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lZqfPwVygZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYj-reJoyiWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BoPozWygyiTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQDXh5WlyiQM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}