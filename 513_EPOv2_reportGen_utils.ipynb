{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYi2mtBXbtzl1ZRAJWC6aT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/513_EPOv2_reportGen_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a **strong, production-ready reporting layer**. I‚Äôll do three things:\n",
        "\n",
        "1. **Validate what you built (it‚Äôs very good)**\n",
        "2. **Call out a few concrete issues / mismatches to fix**\n",
        "3. **Propose small, high-leverage improvements that elevate this to CEO-grade**\n",
        "\n",
        "No fluff.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Overall Verdict\n",
        "\n",
        "This report generator is:\n",
        "\n",
        "* ‚úÖ Deterministic\n",
        "* ‚úÖ Auditable\n",
        "* ‚úÖ Human-readable\n",
        "* ‚úÖ Executive-ready\n",
        "* ‚úÖ Fully derived from state (no hidden logic)\n",
        "\n",
        "Most agent ‚Äúreports‚Äù are LLM prose stitched together.\n",
        "This is **state-driven narrative synthesis**, which is exactly right.\n",
        "\n",
        "You‚Äôve effectively built:\n",
        "\n",
        "> **A reproducible business memo generator backed by hard metrics**\n",
        "\n",
        "That‚Äôs rare.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. One Critical Mismatch You Should Fix (Important)\n",
        "\n",
        "### ‚ùå `portfolio_insights` structure mismatch\n",
        "\n",
        "In **Phase 6**, `generate_portfolio_insights()` returns:\n",
        "\n",
        "```python\n",
        "List[Dict[str, Any]]\n",
        "```\n",
        "\n",
        "Each item looks like:\n",
        "\n",
        "```python\n",
        "{\n",
        "  \"type\": \"trend\" | \"risk\" | \"opportunity\" | \"recommendation\",\n",
        "  \"title\": ...,\n",
        "  \"description\": ...,\n",
        "  \"priority\": ...\n",
        "}\n",
        "```\n",
        "\n",
        "But in the report you assume:\n",
        "\n",
        "```python\n",
        "portfolio_insights = state.get(\"portfolio_insights\", {})\n",
        "\n",
        "trends = portfolio_insights.get(\"trends\", [])\n",
        "risks = portfolio_insights.get(\"risks\", [])\n",
        "opportunities = portfolio_insights.get(\"opportunities\", [])\n",
        "recommendations = portfolio_insights.get(\"recommendations\", [])\n",
        "```\n",
        "\n",
        "### ‚úÖ Fix (simple and clean)\n",
        "\n",
        "Convert once at the top of the report section:\n",
        "\n",
        "```python\n",
        "insights = state.get(\"portfolio_insights\", [])\n",
        "\n",
        "trends = [i for i in insights if i.get(\"type\") == \"trend\"]\n",
        "risks = [i for i in insights if i.get(\"type\") == \"risk\"]\n",
        "opportunities = [i for i in insights if i.get(\"type\") == \"opportunity\"]\n",
        "recommendations = [i for i in insights if i.get(\"type\") == \"recommendation\"]\n",
        "```\n",
        "\n",
        "This keeps **Phase 6 and reporting fully aligned**.\n",
        "\n",
        "This is the only *real* bug I see.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Executive Summary: Very Strong, One Upgrade\n",
        "\n",
        "Current summary is solid.\n",
        "You can make it *exceptional* with **one sentence**:\n",
        "\n",
        "### Add a decision-oriented closing line\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "summary += f\"\"\"\n",
        "**Key Takeaway:** {portfolio_roi.get('experiments_with_positive_roi', 0)} experiments are delivering positive ROI, with priority focus recommended on scaling high-confidence results and addressing flagged risks.\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "This turns the summary from **descriptive ‚Üí directive**.\n",
        "\n",
        "CEOs love that.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Experiment Section: Excellent Design Choice\n",
        "\n",
        "This part is particularly well done:\n",
        "\n",
        "* Status\n",
        "* Decision stage\n",
        "* Analysis presence\n",
        "* Needs decision\n",
        "* Statistical results\n",
        "* Decision rationale\n",
        "\n",
        "You‚Äôve implicitly answered:\n",
        "\n",
        "* ‚ÄúDo we know?‚Äù\n",
        "* ‚ÄúDo we trust it?‚Äù\n",
        "* ‚ÄúWhat should we do next?‚Äù\n",
        "\n",
        "### Small polish suggestion\n",
        "\n",
        "Add icons for decision types to improve scanning:\n",
        "\n",
        "```python\n",
        "decision_icon = {\n",
        "    \"scale\": \"üöÄ\",\n",
        "    \"iterate\": \"üîÅ\",\n",
        "    \"retire\": \"üõë\",\n",
        "    \"do_not_start\": \"‚õî\"\n",
        "}.get(decision_type, \"‚ÑπÔ∏è\")\n",
        "```\n",
        "\n",
        "Then:\n",
        "\n",
        "```markdown\n",
        "- Decision: üöÄ **SCALE**\n",
        "```\n",
        "\n",
        "Pure UX win, zero logic risk.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Statistical Summary: Correct and Honest\n",
        "\n",
        "I really like this:\n",
        "\n",
        "```python\n",
        "significant_count / total_tests\n",
        "```\n",
        "\n",
        "You‚Äôre not overselling significance, you‚Äôre reporting it.\n",
        "\n",
        "This aligns perfectly with your philosophy:\n",
        "\n",
        "> *The LLM explains what the system has already proven.*\n",
        "\n",
        "No changes needed here.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. ROI Section: This Is Where You Stand Out\n",
        "\n",
        "This block is excellent:\n",
        "\n",
        "* Total investment\n",
        "* Revenue impact\n",
        "* Net ROI\n",
        "* ROI %\n",
        "* Positive vs negative experiments\n",
        "* ROI by category\n",
        "\n",
        "### One high-leverage addition\n",
        "\n",
        "Add **ROI concentration**:\n",
        "\n",
        "```python\n",
        "top_roi_share = portfolio_roi.get(\"top_experiment_roi_share\")\n",
        "```\n",
        "\n",
        "Or even simpler:\n",
        "\n",
        "```markdown\n",
        "**ROI Concentration:** Top 1‚Äì2 experiments account for the majority of net ROI\n",
        "```\n",
        "\n",
        "This is exactly the insight executives care about:\n",
        "\n",
        "> ‚ÄúIs this portfolio dependent on a few wins?‚Äù\n",
        "\n",
        "You already have the data ‚Äî this is just framing.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Performance Metrics: Subtle but Powerful\n",
        "\n",
        "Including system performance metrics is **quietly brilliant**.\n",
        "\n",
        "It says:\n",
        "\n",
        "* We measure decisions\n",
        "* We measure outcomes\n",
        "* **We measure the system itself**\n",
        "\n",
        "That‚Äôs what separates tools from platforms.\n",
        "\n",
        "No changes recommended here.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Saving Reports: Clean and Correct\n",
        "\n",
        "`save_epo_report()` is well designed:\n",
        "\n",
        "* Deterministic naming\n",
        "* Portfolio vs single experiment handled\n",
        "* Toolshed abstraction respected\n",
        "\n",
        "You‚Äôve future-proofed this nicely.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Final Architectural Observation (Important)\n",
        "\n",
        "You have now completed a **closed loop**:\n",
        "\n",
        "```\n",
        "Data ‚Üí Analysis ‚Üí Decision ‚Üí Insight ‚Üí ROI ‚Üí Report\n",
        "```\n",
        "\n",
        "And crucially:\n",
        "\n",
        "* Every step is test-covered\n",
        "* Every step is deterministic\n",
        "* Every step is explainable\n",
        "\n",
        "This is not an ‚ÄúAI agent‚Äù.\n",
        "\n",
        "This is a **Decision Intelligence System**.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. What I‚Äôd Do Next (One Clear Recommendation)\n",
        "\n",
        "Before adding *anything* else:\n",
        "\n",
        "### üîπ Add a `report_node`\n",
        "\n",
        "A thin node that:\n",
        "\n",
        "* Calls `generate_experiment_report`\n",
        "* Saves it\n",
        "* Attaches `report_path` to state\n",
        "\n",
        "That gives you:\n",
        "\n",
        "* Full automation\n",
        "* Immutable artifacts per run\n",
        "* Audit-ready outputs\n",
        "\n",
        "After that, *then* consider:\n",
        "\n",
        "* LLM-polished executive summaries\n",
        "* Historical report comparisons\n",
        "* Scenario reports\n",
        "\n",
        "But first: **lock in the artifact**.\n",
        "\n",
        "---\n",
        "\n",
        "## Bottom Line\n",
        "\n",
        "This report generator is:\n",
        "\n",
        "* Thoughtful\n",
        "* Grounded\n",
        "* Honest\n",
        "* Executive-aligned\n",
        "* Technically correct\n",
        "\n",
        "Fix the portfolio_insights structure mismatch, add one directive sentence to the executive summary, and you have something that is genuinely **board-ready**.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y0ZNw6yltAaK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE3A5i0AsOmn"
      },
      "outputs": [],
      "source": [
        "\"\"\"Report Generation Utilities for Experimentation Portfolio Orchestrator\n",
        "\n",
        "Generates executive-ready markdown reports from EPO agent state.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Any, Optional\n",
        "from datetime import datetime\n",
        "from toolshed.reporting.file_handling import save_report\n",
        "\n",
        "\n",
        "def generate_executive_summary(state: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Generate executive summary for EPO report.\n",
        "\n",
        "    Args:\n",
        "        state: Complete EPO state\n",
        "\n",
        "    Returns:\n",
        "        Executive summary text\n",
        "    \"\"\"\n",
        "    goal = state.get(\"goal\", {})\n",
        "    scope = goal.get(\"scope\", \"unknown\")\n",
        "    portfolio_summary = state.get(\"portfolio_summary\", {})\n",
        "    portfolio_roi = state.get(\"portfolio_roi\", {})\n",
        "    performance_metrics = state.get(\"performance_metrics\", {})\n",
        "\n",
        "    total_experiments = portfolio_summary.get(\"total_experiments\", 0)\n",
        "    completed_count = portfolio_summary.get(\"completed_count\", 0)\n",
        "    running_count = portfolio_summary.get(\"running_count\", 0)\n",
        "\n",
        "    net_roi = portfolio_roi.get(\"net_roi\", 0)\n",
        "    roi_percent = portfolio_roi.get(\"roi_percent\", 0)\n",
        "\n",
        "    summary = f\"\"\"**Analysis Scope:** {scope.title()}\n",
        "**Total Experiments:** {total_experiments}\n",
        "**Completed:** {completed_count} | **Running:** {running_count} | **Planned:** {portfolio_summary.get('planned_count', 0)}\n",
        "**Portfolio ROI:** ${net_roi:,.2f} ({roi_percent:.1f}%)\n",
        "**Processing Time:** {state.get('processing_time', 0):.2f} seconds\"\"\"\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def generate_experiment_report(state: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Generate comprehensive markdown report for experiment portfolio analysis.\n",
        "\n",
        "    Args:\n",
        "        state: Complete EPO state\n",
        "\n",
        "    Returns:\n",
        "        Markdown report string\n",
        "    \"\"\"\n",
        "    goal = state.get(\"goal\", {})\n",
        "    plan = state.get(\"plan\", [])\n",
        "    portfolio_summary = state.get(\"portfolio_summary\", {})\n",
        "    analyzed_experiments = state.get(\"analyzed_experiments\", [])\n",
        "    calculated_analyses = state.get(\"calculated_analyses\", [])\n",
        "    generated_decisions = state.get(\"generated_decisions\", [])\n",
        "    portfolio_insights = state.get(\"portfolio_insights\", {})\n",
        "    portfolio_roi = state.get(\"portfolio_roi\", {})\n",
        "    performance_metrics = state.get(\"performance_metrics\", {})\n",
        "\n",
        "    experiment_id = state.get(\"experiment_id\")\n",
        "    scope = goal.get(\"scope\", \"portfolio\")\n",
        "\n",
        "    # Report header\n",
        "    report = f\"\"\"# Experimentation Portfolio Analysis Report\n",
        "\n",
        "**Analysis Type:** {scope.title()}\n",
        "**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\"\"\"\n",
        "\n",
        "    if experiment_id:\n",
        "        report += f\"**Experiment ID:** {experiment_id}\n",
        "\"\n",
        "\n",
        "    report += \"\\n---\\n\\n\"\n",
        "\n",
        "    # Executive Summary\n",
        "    report += \"## Executive Summary\\n\\n\"\n",
        "    report += generate_executive_summary(state)\n",
        "    report += \"\\n\\n---\\n\\n\"\n",
        "\n",
        "    # Portfolio Overview\n",
        "    if portfolio_summary:\n",
        "        report += \"## Portfolio Overview\\n\\n\"\n",
        "        report += f\"**Total Experiments:** {portfolio_summary.get('total_experiments', 0)}\\n\\n\"\n",
        "        report += \"### Status Breakdown\\n\\n\"\n",
        "        report += f\"- ‚úÖ **Completed:** {portfolio_summary.get('completed_count', 0)}\\n\"\n",
        "        report += f\"- üîÑ **Running:** {portfolio_summary.get('running_count', 0)}\\n\"\n",
        "        report += f\"- üìã **Planned:** {portfolio_summary.get('planned_count', 0)}\\n\\n\"\n",
        "\n",
        "        # Decision stage breakdown\n",
        "        decision_stages = portfolio_summary.get(\"decision_stage_breakdown\", {})\n",
        "        if decision_stages:\n",
        "            report += \"### Decision Stage Breakdown\\n\\n\"\n",
        "            for stage, count in decision_stages.items():\n",
        "                report += f\"- **{stage.title()}:** {count}\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "        report += \"---\\n\\n\"\n",
        "\n",
        "    # Individual Experiments\n",
        "    if analyzed_experiments:\n",
        "        report += \"## Experiment Analysis\\n\\n\"\n",
        "\n",
        "        for exp in analyzed_experiments:\n",
        "            exp_id = exp.get(\"experiment_id\")\n",
        "            exp_name = exp.get(\"experiment_name\", \"Unknown\")\n",
        "            status = exp.get(\"status\", \"unknown\")\n",
        "            decision_stage = exp.get(\"decision_stage\", \"unknown\")\n",
        "            has_analysis = exp.get(\"has_analysis\", False)\n",
        "            needs_analysis = exp.get(\"needs_analysis\", False)\n",
        "            needs_decision = exp.get(\"needs_decision\", False)\n",
        "\n",
        "            report += f\"### {exp_id}: {exp_name}\\n\\n\"\n",
        "            report += f\"**Status:** {status.title()}\n",
        "**Decision Stage:** {decision_stage.title()}\n",
        "**Has Analysis:** {'Yes' if has_analysis else 'No'}\n",
        "**Needs Analysis:** {'Yes' if needs_analysis else 'No'}\n",
        "**Needs Decision:** {'Yes' if needs_decision else 'No'}\n",
        "\\n\"\n",
        "\n",
        "            # Find corresponding analysis\n",
        "            analysis = next((a for a in calculated_analyses if a.get(\"experiment_id\") == exp_id), None)\n",
        "            if analysis:\n",
        "                statistical_test = analysis.get(\"statistical_test\", {})\n",
        "                test_type = statistical_test.get(\"test_type\", \"N/A\")\n",
        "                p_value = analysis.get(\"p_value\")\n",
        "                is_significant = analysis.get(\"is_significant\", False)\n",
        "                relative_lift = analysis.get(\"relative_lift_percent\", 0)\n",
        "\n",
        "                report += \"**Statistical Analysis:**\\n\"\n",
        "                report += f\"- Test Type: {test_type}\\n\"\n",
        "                if p_value is not None:\n",
        "                    report += f\"- P-value: {p_value:.4f}\\n\"\n",
        "                    report += f\"- Significant: {'Yes' if is_significant else 'No'}\\n\"\n",
        "                report += f\"- Relative Lift: {relative_lift:.1f}%\\n\\n\"\n",
        "\n",
        "            # Find corresponding decision\n",
        "            decision = next((d for d in generated_decisions if d.get(\"experiment_id\") == exp_id), None)\n",
        "            if decision:\n",
        "                decision_type = decision.get(\"decision\", \"N/A\")\n",
        "                confidence = decision.get(\"decision_confidence\", \"N/A\")\n",
        "                risk = decision.get(\"decision_risk\", \"N/A\")\n",
        "                rationale = decision.get(\"rationale\", \"\")\n",
        "\n",
        "                report += \"**Decision Recommendation:**\\n\"\n",
        "                report += f\"- Decision: **{decision_type.upper()}**\\n\"\n",
        "                report += f\"- Confidence: {confidence}\\n\"\n",
        "                report += f\"- Risk: {risk}\\n\"\n",
        "                if rationale:\n",
        "                    report += f\"- Rationale: {rationale}\\n\"\n",
        "                report += \"\\n\"\n",
        "\n",
        "            report += \"---\\n\\n\"\n",
        "\n",
        "    # Statistical Analysis Summary\n",
        "    if calculated_analyses:\n",
        "        report += \"## Statistical Analysis Summary\\n\\n\"\n",
        "\n",
        "        significant_count = sum(1 for a in calculated_analyses if a.get(\"is_significant\", False))\n",
        "        total_tests = len(calculated_analyses)\n",
        "\n",
        "        report += f\"**Total Tests Performed:** {total_tests}\n",
        "**Statistically Significant:** {significant_count} ({significant_count/total_tests*100:.1f}%)\\n\\n\"\n",
        "\n",
        "        report += \"### Test Results\\n\\n\"\n",
        "        for analysis in calculated_analyses:\n",
        "            exp_id = analysis.get(\"experiment_id\")\n",
        "            test_type = analysis.get(\"statistical_test\", {}).get(\"test_type\", \"N/A\")\n",
        "            p_value = analysis.get(\"p_value\")\n",
        "            is_significant = analysis.get(\"is_significant\", False)\n",
        "            relative_lift = analysis.get(\"relative_lift_percent\", 0)\n",
        "\n",
        "            significance_icon = \"‚úÖ\" if is_significant else \"‚ÑπÔ∏è\"\n",
        "            report += f\"{significance_icon} **{exp_id}**: {test_type}\"\n",
        "            if p_value is not None:\n",
        "                report += f\" (p={p_value:.4f})\"\n",
        "            report += f\" | Lift: {relative_lift:.1f}%\\n\"\n",
        "\n",
        "        report += \"\\n---\\n\\n\"\n",
        "\n",
        "    # Decision Recommendations\n",
        "    if generated_decisions:\n",
        "        report += \"## Decision Recommendations\\n\\n\"\n",
        "\n",
        "        decision_counts = {}\n",
        "        for decision in generated_decisions:\n",
        "            decision_type = decision.get(\"decision\", \"unknown\")\n",
        "            decision_counts[decision_type] = decision_counts.get(decision_type, 0) + 1\n",
        "\n",
        "        report += \"### Decision Summary\\n\\n\"\n",
        "        for decision_type, count in decision_counts.items():\n",
        "            report += f\"- **{decision_type.upper()}**: {count}\\n\"\n",
        "        report += \"\\n\"\n",
        "\n",
        "        report += \"### Detailed Recommendations\\n\\n\"\n",
        "        for decision in generated_decisions:\n",
        "            exp_id = decision.get(\"experiment_id\")\n",
        "            decision_type = decision.get(\"decision\", \"N/A\")\n",
        "            confidence = decision.get(\"decision_confidence\", \"N/A\")\n",
        "            risk = decision.get(\"decision_risk\", \"N/A\")\n",
        "            rationale = decision.get(\"rationale\", \"\")\n",
        "            recommended_action = decision.get(\"recommended_action\", \"\")\n",
        "\n",
        "            report += f\"**{exp_id}**: {decision_type.upper()}\\n\"\n",
        "            report += f\"- Confidence: {confidence} | Risk: {risk}\\n\"\n",
        "            if rationale:\n",
        "                report += f\"- Rationale: {rationale}\\n\"\n",
        "            if recommended_action:\n",
        "                report += f\"- Action: {recommended_action}\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "        report += \"---\\n\\n\"\n",
        "\n",
        "    # Portfolio Insights\n",
        "    if portfolio_insights:\n",
        "        report += \"## Portfolio Insights\\n\\n\"\n",
        "\n",
        "        trends = portfolio_insights.get(\"trends\", [])\n",
        "        risks = portfolio_insights.get(\"risks\", [])\n",
        "        opportunities = portfolio_insights.get(\"opportunities\", [])\n",
        "        recommendations = portfolio_insights.get(\"recommendations\", [])\n",
        "\n",
        "        if trends:\n",
        "            report += \"### Trends\\n\\n\"\n",
        "            for trend in trends[:5]:  # Top 5\n",
        "                report += f\"- {trend.get('description', 'N/A')}\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "        if risks:\n",
        "            report += \"### Risks\\n\\n\"\n",
        "            for risk in risks[:5]:  # Top 5\n",
        "                report += f\"- ‚ö†Ô∏è {risk.get('description', 'N/A')}\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "        if opportunities:\n",
        "            report += \"### Opportunities\\n\\n\"\n",
        "            for opp in opportunities[:5]:  # Top 5\n",
        "                report += f\"- üí° {opp.get('description', 'N/A')}\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "        if recommendations:\n",
        "            report += \"### Strategic Recommendations\\n\\n\"\n",
        "            for rec in recommendations[:5]:  # Top 5\n",
        "                priority = rec.get(\"priority\", \"medium\")\n",
        "                priority_icon = \"üî¥\" if priority == \"high\" else \"üü°\" if priority == \"medium\" else \"üü¢\"\n",
        "                report += f\"{priority_icon} **{priority.upper()}**: {rec.get('description', 'N/A')}\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "        report += \"---\\n\\n\"\n",
        "\n",
        "    # ROI Analysis\n",
        "    if portfolio_roi:\n",
        "        report += \"## ROI Analysis\\n\\n\"\n",
        "\n",
        "        total_cost = portfolio_roi.get(\"total_cost\", 0)\n",
        "        total_revenue_impact = portfolio_roi.get(\"total_revenue_impact\", 0)\n",
        "        net_roi = portfolio_roi.get(\"net_roi\", 0)\n",
        "        roi_percent = portfolio_roi.get(\"roi_percent\", 0)\n",
        "        positive_roi_count = portfolio_roi.get(\"experiments_with_positive_roi\", 0)\n",
        "        negative_roi_count = portfolio_roi.get(\"experiments_with_negative_roi\", 0)\n",
        "\n",
        "        report += f\"**Total Investment:** ${total_cost:,.2f}\n",
        "**Total Revenue Impact:** ${total_revenue_impact:,.2f}\n",
        "**Net ROI:** ${net_roi:,.2f}\n",
        "**ROI Percentage:** {roi_percent:.1f}%\n",
        "**Positive ROI Experiments:** {positive_roi_count}\n",
        "**Negative ROI Experiments:** {negative_roi_count}\n",
        "\\n\"\n",
        "\n",
        "        roi_by_category = portfolio_roi.get(\"roi_by_category\", {})\n",
        "        if roi_by_category:\n",
        "            report += \"### ROI by Category\\n\\n\"\n",
        "            for category, count in roi_by_category.items():\n",
        "                report += f\"- **{category.title()}**: {count}\\n\"\n",
        "            report += \"\\n\"\n",
        "\n",
        "        report += \"---\\n\\n\"\n",
        "\n",
        "    # Performance Metrics\n",
        "    if performance_metrics:\n",
        "        report += \"## Performance Metrics\\n\\n\"\n",
        "\n",
        "        total_analyzed = performance_metrics.get(\"total_experiments_analyzed\", 0)\n",
        "        success_rate = performance_metrics.get(\"analysis_success_rate\", 0)\n",
        "        tests_performed = performance_metrics.get(\"statistical_tests_performed\", 0)\n",
        "        decisions_generated = performance_metrics.get(\"decisions_generated\", 0)\n",
        "        processing_time = performance_metrics.get(\"average_processing_time\")\n",
        "\n",
        "        report += f\"**Experiments Analyzed:** {total_analyzed}\n",
        "**Analysis Success Rate:** {success_rate:.1%}\n",
        "**Statistical Tests Performed:** {tests_performed}\n",
        "**Decisions Generated:** {decisions_generated}\n",
        "\"\"\"\n",
        "\n",
        "        if processing_time:\n",
        "            report += f\"**Average Processing Time:** {processing_time:.2f} seconds\n",
        "\"\n",
        "\n",
        "        report += \"\\n---\\n\\n\"\n",
        "\n",
        "    # Errors\n",
        "    errors = state.get(\"errors\", [])\n",
        "    if errors:\n",
        "        report += \"## Errors & Warnings\\n\\n\"\n",
        "        for error in errors:\n",
        "            report += f\"- ‚ö†Ô∏è {error}\\n\"\n",
        "        report += \"\\n---\\n\\n\"\n",
        "\n",
        "    # Footer\n",
        "    report += \"*Report generated by Experimentation Portfolio Orchestrator Agent*\\n\"\n",
        "\n",
        "    return report\n",
        "\n",
        "\n",
        "def save_epo_report(\n",
        "    state: Dict[str, Any],\n",
        "    reports_dir: str = \"output/experimentation_portfolio_reports\",\n",
        "    prefix: str = \"epo_report\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generate and save EPO report to file.\n",
        "\n",
        "    Args:\n",
        "        state: Complete EPO state\n",
        "        reports_dir: Directory to save reports\n",
        "        prefix: Filename prefix\n",
        "\n",
        "    Returns:\n",
        "        Path to saved report file\n",
        "    \"\"\"\n",
        "    # Generate report\n",
        "    report_content = generate_experiment_report(state)\n",
        "\n",
        "    # Create report ID\n",
        "    experiment_id = state.get(\"experiment_id\")\n",
        "    if experiment_id:\n",
        "        report_id = f\"{prefix}_{experiment_id}\"\n",
        "    else:\n",
        "        report_id = f\"{prefix}_portfolio\"\n",
        "\n",
        "    # Save using toolshed utility\n",
        "    filepath = save_report(\n",
        "        report_content=report_content,\n",
        "        report_id=report_id,\n",
        "        reports_dir=reports_dir,\n",
        "        prefix=prefix\n",
        "    )\n",
        "\n",
        "    return filepath\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Results"
      ],
      "metadata": {
        "id": "kq3QIBWmt-_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_017_EPO_2.0 % python3 test_epo_e2e.py\n",
        "\n",
        "======================================================================\n",
        "End-to-End Integration Tests for EPO Agent\n",
        "======================================================================\n",
        "\n",
        "======================================================================\n",
        "Test 1: Portfolio-Wide Analysis (Full Workflow)\n",
        "======================================================================\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:44: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"data_loading\", partial(data_loading_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:45: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"portfolio_analysis\", partial(portfolio_analysis_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:46: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"statistical_analysis\", partial(statistical_analysis_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:47: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"decision_evaluation\", partial(decision_evaluation_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:48: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"portfolio_insights\", partial(portfolio_insights_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:49: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"roi_calculation\", partial(roi_calculation_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:50: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"reporting\", partial(reporting_node, config=config))\n",
        "\n",
        "üìä Starting portfolio-wide analysis...\n",
        "\n",
        "‚è±Ô∏è  Total processing time: 0.06 seconds\n",
        "\n",
        "‚úÖ No errors in workflow\n",
        "\n",
        "üìà Results Summary:\n",
        "   - Experiments analyzed: 3\n",
        "   - Statistical tests: 0\n",
        "   - Decisions generated: 0\n",
        "   - Portfolio status: 3 total\n",
        "     - Completed: 1\n",
        "     - Running: 1\n",
        "     - Planned: 1\n",
        "\n",
        "üí∞ Portfolio ROI:\n",
        "   - Total Cost: $2,250.00\n",
        "   - Total Revenue Impact: $14,800.00\n",
        "   - Net ROI: $12,550.00\n",
        "   - ROI %: 557.78%\n",
        "   - Positive ROI experiments: 2\n",
        "\n",
        "‚ö° Performance Metrics:\n",
        "   - Analysis success rate: 66.7%\n",
        "   - Statistical tests performed: 0\n",
        "   - Decisions generated: 0\n",
        "\n",
        "üìÑ Report Generated:\n",
        "   - Path: output/experimentation_portfolio_reports/epo_report_epo_report_portfolio_20260118_150651.md\n",
        "   - File exists: ‚úÖ\n",
        "\n",
        "‚úÖ Portfolio-wide E2E test passed!\n",
        "\n",
        "======================================================================\n",
        "Test 2: Single Experiment Analysis (E001)\n",
        "======================================================================\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:44: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"data_loading\", partial(data_loading_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:45: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"portfolio_analysis\", partial(portfolio_analysis_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:46: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"statistical_analysis\", partial(statistical_analysis_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:47: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"decision_evaluation\", partial(decision_evaluation_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:48: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"portfolio_insights\", partial(portfolio_insights_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:49: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"roi_calculation\", partial(roi_calculation_node, config=config))\n",
        "/Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_017_EPO_2.0/agents/epo/orchestrator.py:50: UserWarning: The 'config' parameter should be typed as 'RunnableConfig' or 'RunnableConfig | None', not 'typing.Optional[config.ExperimentationPortfolioOrchestratorConfig]'.\n",
        "  workflow.add_node(\"reporting\", partial(reporting_node, config=config))\n",
        "\n",
        "üî¨ Starting single experiment analysis for E001...\n",
        "\n",
        "‚è±Ô∏è  Total processing time: 0.00 seconds\n",
        "\n",
        "‚úÖ No errors in workflow\n",
        "\n",
        "üìà Results Summary:\n",
        "\n",
        "üí∞ ROI:\n",
        "   - Total Cost: $850.00\n",
        "   - Net ROI: $9,150.00\n",
        "   - ROI %: 1076.47%\n",
        "\n",
        "üìÑ Report Generated:\n",
        "   - Path: output/experimentation_portfolio_reports/epo_report_epo_report_E001_20260118_150651.md\n",
        "   - File exists: ‚úÖ\n",
        "\n",
        "‚úÖ Single experiment E2E test passed!\n",
        "\n",
        "======================================================================\n",
        "Test 3: State Progression Validation\n",
        "======================================================================\n",
        "\n",
        "‚úÖ All required fields present in final state\n",
        "‚úÖ Data integrity validated: 3 experiments\n",
        "\n",
        "‚úÖ State progression test passed!\n",
        "\n",
        "======================================================================\n",
        "Test 4: Error Handling\n",
        "======================================================================\n",
        "\n",
        "üîç Testing with non-existent experiment ID (E999)...\n",
        "‚úÖ Errors captured: 3\n",
        "   - statistical_analysis_node: definitions_lookup and metrics_lookup required. Run data_loading_node first.\n",
        "   - decision_evaluation_node: definitions_lookup required. Run data_loading_node first.\n",
        "   - roi_calculation_node: analyzed_experiments or experiment_id with analysis required\n",
        "\n",
        "‚úÖ Error handling test passed!\n",
        "\n",
        "======================================================================\n",
        "‚úÖ ALL END-TO-END TESTS PASSED!\n",
        "======================================================================\n",
        "\n",
        "The EPO agent workflow is fully functional and ready for use.\n",
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_017_EPO_2.0 %"
      ],
      "metadata": {
        "id": "-f-a-GcRuAA8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}