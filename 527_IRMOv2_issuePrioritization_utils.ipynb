{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZo16C1E/gcgPKMFcvhiUL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/527_IRMOv2_issuePrioritization_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Issue Prioritization – Turning Signals Into Executive Action\n",
        "\n",
        "This module is where the orchestrator converts **dozens of signals** into a **small, defensible list of actions** leadership can actually take.\n",
        "\n",
        "Most AI systems stop at analysis.\n",
        "This one goes further: it decides **what matters most, right now**, and explains why.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Prioritization Is the Hardest (and Most Important) Step\n",
        "\n",
        "Executives don’t suffer from a lack of data.\n",
        "They suffer from a lack of **clear priorities**.\n",
        "\n",
        "Without disciplined prioritization:\n",
        "\n",
        "* Important issues compete with noise\n",
        "* Technical problems crowd out business risks\n",
        "* Leadership attention is diluted\n",
        "\n",
        "This module exists to prevent that.\n",
        "\n",
        "---\n",
        "\n",
        "## Converting Analysis Into Issues\n",
        "\n",
        "Each analysis layer produces raw insight.\n",
        "This utility converts those insights into **standardized, comparable issues**.\n",
        "\n",
        "### Integration Issues\n",
        "\n",
        "Generated when a system is degraded or critical, capturing:\n",
        "\n",
        "* Health status\n",
        "* Impacted agents\n",
        "* Specific failure drivers\n",
        "\n",
        "### Risk Issues\n",
        "\n",
        "Raised for agents with high or critical risk levels, grounded in:\n",
        "\n",
        "* Aggregated risk scoring\n",
        "* Severity and urgency\n",
        "* Explicit priority actions\n",
        "\n",
        "### Value Leakage Issues\n",
        "\n",
        "Triggered when economic drift crosses defined thresholds:\n",
        "\n",
        "* ROI gaps\n",
        "* Cost overruns\n",
        "* Manual effort creep\n",
        "\n",
        "This ensures **financial erosion is treated as a risk**, not an afterthought.\n",
        "\n",
        "### Workflow Issues\n",
        "\n",
        "Raised when execution reliability degrades:\n",
        "\n",
        "* Elevated failure rates\n",
        "* Structural bottlenecks\n",
        "* Required intervention\n",
        "\n",
        "Each issue is normalized into a common structure so it can be compared fairly.\n",
        "\n",
        "---\n",
        "\n",
        "## No Hidden Logic: Every Issue Is Explainable\n",
        "\n",
        "Each issue includes:\n",
        "\n",
        "* A clear type\n",
        "* A severity level\n",
        "* A numeric risk score\n",
        "* A plain-language description\n",
        "* Supporting evidence\n",
        "\n",
        "Nothing is inferred implicitly.\n",
        "Nothing is hidden inside a model.\n",
        "\n",
        "This is how you make AI output **review-ready**.\n",
        "\n",
        "---\n",
        "\n",
        "## Consolidation & Scoring: One Priority List, One Truth\n",
        "\n",
        "Once issues are created, they are consolidated and prioritized using the toolshed prioritization engine.\n",
        "\n",
        "This step is critical.\n",
        "\n",
        "Instead of ranking issues independently by source, the system:\n",
        "\n",
        "* Combines them into a single pool\n",
        "* Applies consistent scoring logic\n",
        "* Recalculates priority using explicit weights\n",
        "\n",
        "This ensures:\n",
        "\n",
        "* Integration failures don’t drown out economic risk\n",
        "* Cost leakage competes fairly with operational risk\n",
        "* Critical agents receive appropriate attention\n",
        "\n",
        "---\n",
        "\n",
        "## Context-Aware Prioritization\n",
        "\n",
        "Priority scoring is not done in isolation.\n",
        "\n",
        "The system incorporates **contextual business factors**, including:\n",
        "\n",
        "* Agent criticality\n",
        "* Number of affected workflows\n",
        "* Downstream blast radius\n",
        "\n",
        "This means the same technical issue can be prioritized differently depending on **business impact**.\n",
        "\n",
        "That’s how prioritization stays aligned with strategy.\n",
        "\n",
        "---\n",
        "\n",
        "## From Issues to Ecosystem Health\n",
        "\n",
        "Beyond individual actions, the module produces an **ecosystem summary** that answers executive-level questions instantly:\n",
        "\n",
        "* How many agents are active?\n",
        "* How many systems are degraded?\n",
        "* How many high-priority issues exist?\n",
        "* What is total cost vs ROI?\n",
        "* Is overall health improving or degrading?\n",
        "\n",
        "This turns the orchestrator into a **portfolio management tool**, not just an alerting system.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Executives Trust This Output\n",
        "\n",
        "This prioritization layer ensures the agent is:\n",
        "\n",
        "* **Focused** — surfaces only what matters\n",
        "* **Consistent** — applies the same rules every time\n",
        "* **Explainable** — decisions can be defended\n",
        "* **Balanced** — technical, operational, and financial risks compete fairly\n",
        "* **Actionable** — output maps directly to decisions\n",
        "\n",
        "Most AI agents generate *more work*.\n",
        "This one reduces it.\n",
        "\n",
        "---\n",
        "\n",
        "## Architectural Takeaway\n",
        "\n",
        "This module demonstrates a core belief of your system:\n",
        "\n",
        "> **AI should not just detect problems.\n",
        "> It should help leaders decide what to do first.**\n",
        "\n",
        "By combining structured issue creation, explicit weighting, and contextual scoring, your orchestrator earns the right to influence executive attention.\n",
        "\n",
        "That’s rare — and extremely valuable.\n",
        "\n"
      ],
      "metadata": {
        "id": "6HwkmmES3N1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfkCiIe1pjsG"
      },
      "outputs": [],
      "source": [
        "\"\"\"Issue prioritization utilities using toolshed\"\"\"\n",
        "\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from toolshed.prioritization import (\n",
        "    consolidate_and_prioritize_issues,\n",
        "    calculate_ecosystem_summary,\n",
        "    normalize_severity,\n",
        "    normalize_criticality\n",
        ")\n",
        "\n",
        "\n",
        "def create_integration_issues(\n",
        "    integration_health: List[Dict[str, Any]],\n",
        "    issue_counter: int = 1\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Create issues from integration health analysis\"\"\"\n",
        "    issues = []\n",
        "    for health in integration_health:\n",
        "        if health.get(\"health_status\") != \"healthy\":\n",
        "            issue = {\n",
        "                \"issue_id\": f\"integration_{issue_counter:03d}\",\n",
        "                \"type\": \"integration\",\n",
        "                \"system_id\": health.get(\"system_id\"),\n",
        "                \"severity\": health.get(\"health_status\"),  # degraded or critical\n",
        "                \"risk_score\": 100.0 - health.get(\"overall_score\", 0.0),\n",
        "                \"description\": f\"Integration {health.get('system_id')} is {health.get('health_status')} (score: {health.get('overall_score', 0):.1f})\",\n",
        "                \"affected_agents\": health.get(\"affected_agents\", []),\n",
        "                \"issues\": health.get(\"issues\", [])\n",
        "            }\n",
        "            issues.append(issue)\n",
        "            issue_counter += 1\n",
        "    return issues\n",
        "\n",
        "\n",
        "def create_risk_issues(\n",
        "    risk_assessments: List[Dict[str, Any]],\n",
        "    issue_counter: int = 1\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Create issues from risk assessments\"\"\"\n",
        "    issues = []\n",
        "    for assessment in risk_assessments:\n",
        "        agent_id = assessment.get(\"agent_id\")\n",
        "        risk_level = assessment.get(\"risk_level\")\n",
        "\n",
        "        if risk_level in [\"high\", \"critical\"]:\n",
        "            # Create issue for high/critical risk agents\n",
        "            issue = {\n",
        "                \"issue_id\": f\"risk_{issue_counter:03d}\",\n",
        "                \"type\": \"operational\",\n",
        "                \"agent_id\": agent_id,\n",
        "                \"severity\": risk_level,\n",
        "                \"risk_score\": assessment.get(\"total_risk_score\", 0.0),\n",
        "                \"description\": f\"Agent {agent_id} has {risk_level} risk level (score: {assessment.get('total_risk_score', 0):.1f})\",\n",
        "                \"priority_actions\": assessment.get(\"priority_actions\", [])\n",
        "            }\n",
        "            issues.append(issue)\n",
        "            issue_counter += 1\n",
        "    return issues\n",
        "\n",
        "\n",
        "def create_value_leakage_issues(\n",
        "    value_leakage_analysis: List[Dict[str, Any]],\n",
        "    thresholds: Dict[str, float],\n",
        "    issue_counter: int = 1\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Create issues from value leakage analysis\"\"\"\n",
        "    issues = []\n",
        "    for analysis in value_leakage_analysis:\n",
        "        leakage_score = analysis.get(\"value_leakage_score\", 0.0)\n",
        "\n",
        "        if leakage_score > thresholds.get(\"degraded\", 40.0):\n",
        "            severity = \"critical\" if leakage_score > thresholds.get(\"critical\", 40.0) else \"high\"\n",
        "            issue = {\n",
        "                \"issue_id\": f\"value_{issue_counter:03d}\",\n",
        "                \"type\": \"cost\",\n",
        "                \"agent_id\": analysis.get(\"agent_id\"),\n",
        "                \"severity\": severity,\n",
        "                \"risk_score\": leakage_score,\n",
        "                \"description\": f\"Agent {analysis.get('agent_id')} has value leakage score of {leakage_score:.1f} (ROI gap: {analysis.get('roi_gap_percent', 0):.1f}%)\",\n",
        "                \"roi_gap\": analysis.get(\"roi_gap\", 0.0),\n",
        "                \"cost_overrun\": analysis.get(\"cost_overrun\", 0.0),\n",
        "                \"recommendations\": analysis.get(\"recommendations\", [])\n",
        "            }\n",
        "            issues.append(issue)\n",
        "            issue_counter += 1\n",
        "    return issues\n",
        "\n",
        "\n",
        "def create_workflow_issues(\n",
        "    workflow_analysis: List[Dict[str, Any]],\n",
        "    issue_counter: int = 1\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Create issues from workflow analysis\"\"\"\n",
        "    issues = []\n",
        "    for workflow in workflow_analysis:\n",
        "        if workflow.get(\"requires_attention\", False):\n",
        "            issue = {\n",
        "                \"issue_id\": f\"workflow_{issue_counter:03d}\",\n",
        "                \"type\": \"workflow\",\n",
        "                \"workflow_id\": workflow.get(\"workflow_id\"),\n",
        "                \"agent_id\": workflow.get(\"agent_id\"),\n",
        "                \"severity\": workflow.get(\"health_status\"),  # degraded or critical\n",
        "                \"risk_score\": 100.0 - (workflow.get(\"health_score\", 0.0) if \"health_score\" in workflow else 50.0),\n",
        "                \"description\": f\"Workflow {workflow.get('workflow_id')} requires attention (failure rate: {workflow.get('failure_rate', 0):.1f}%)\",\n",
        "                \"recommendations\": workflow.get(\"recommendations\", [])\n",
        "            }\n",
        "            issues.append(issue)\n",
        "            issue_counter += 1\n",
        "    return issues\n",
        "\n",
        "\n",
        "def prioritize_all_issues(\n",
        "    integration_health: List[Dict[str, Any]],\n",
        "    risk_assessments: List[Dict[str, Any]],\n",
        "    value_leakage_analysis: List[Dict[str, Any]],\n",
        "    workflow_analysis: List[Dict[str, Any]],\n",
        "    agents_lookup: Dict[str, Dict[str, Any]],\n",
        "    weights: Dict[str, float],\n",
        "    thresholds: Dict[str, float]\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"Consolidate and prioritize all issues\"\"\"\n",
        "    # Create issues from each analysis\n",
        "    all_issues = []\n",
        "    issue_counter = 1\n",
        "\n",
        "    integration_issues = create_integration_issues(integration_health, issue_counter)\n",
        "    all_issues.extend(integration_issues)\n",
        "    issue_counter += len(integration_issues)\n",
        "\n",
        "    risk_issues = create_risk_issues(risk_assessments, issue_counter)\n",
        "    all_issues.extend(risk_issues)\n",
        "    issue_counter += len(risk_issues)\n",
        "\n",
        "    value_issues = create_value_leakage_issues(value_leakage_analysis, thresholds, issue_counter)\n",
        "    all_issues.extend(value_issues)\n",
        "    issue_counter += len(value_issues)\n",
        "\n",
        "    workflow_issues = create_workflow_issues(workflow_analysis, issue_counter)\n",
        "    all_issues.extend(workflow_issues)\n",
        "\n",
        "    # Prepare issue sources for toolshed\n",
        "    issue_sources = [\n",
        "        (\"integration_health\", integration_issues),\n",
        "        (\"risk_assessments\", risk_issues),\n",
        "        (\"value_leakage\", value_issues),\n",
        "        (\"workflows\", workflow_issues)\n",
        "    ]\n",
        "\n",
        "    # Context for priority scoring\n",
        "    context = {\"agents_lookup\": agents_lookup}\n",
        "\n",
        "    # Field mappers for priority scoring\n",
        "    field_mappers = {\n",
        "        \"criticality\": lambda issue, ctx: normalize_criticality(\n",
        "            ctx.get(\"agents_lookup\", {}).get(issue.get(\"agent_id\", \"\"), {}).get(\"criticality\", \"medium\")\n",
        "        ),\n",
        "        \"affected_workflows\": lambda issue, ctx: len(issue.get(\"affected_agents\", []))\n",
        "    }\n",
        "\n",
        "    # Prioritize using toolshed\n",
        "    prioritized = consolidate_and_prioritize_issues(\n",
        "        issue_sources=issue_sources,\n",
        "        context=context,\n",
        "        weights=weights,\n",
        "        recalculate_scores=True\n",
        "    )\n",
        "\n",
        "    return prioritized\n",
        "\n",
        "\n",
        "def calculate_ecosystem_summary_metrics(\n",
        "    agents: List[Dict[str, Any]],\n",
        "    systems: List[Dict[str, Any]],\n",
        "    integration_health: List[Dict[str, Any]],\n",
        "    prioritized_issues: List[Dict[str, Any]],\n",
        "    kpis_lookup: Dict[str, Dict[str, Any]]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Calculate ecosystem summary metrics\"\"\"\n",
        "    # Basic counts\n",
        "    total_agents = len(agents)\n",
        "    active_agents = len([a for a in agents if a.get(\"status\") == \"active\"])\n",
        "    total_systems = len(systems)\n",
        "\n",
        "    # Health counts\n",
        "    healthy_systems = len([h for h in integration_health if h.get(\"health_status\") == \"healthy\"])\n",
        "    degraded_systems = len([h for h in integration_health if h.get(\"health_status\") == \"degraded\"])\n",
        "    critical_systems = len([h for h in integration_health if h.get(\"health_status\") == \"critical\"])\n",
        "\n",
        "    # Risk counts\n",
        "    total_risks = len(prioritized_issues)\n",
        "    high_priority_risks = len([i for i in prioritized_issues if i.get(\"severity\") in [\"high\", \"critical\"]])\n",
        "\n",
        "    # Cost and ROI totals\n",
        "    total_cost_30d = sum(\n",
        "        kpis.get(\"cost_usd_30d\", 0.0)\n",
        "        for kpis in kpis_lookup.values()\n",
        "    )\n",
        "    total_roi_estimate = sum(\n",
        "        kpis.get(\"roi_estimate_usd\", 0.0)\n",
        "        for kpis in kpis_lookup.values()\n",
        "    )\n",
        "\n",
        "    # Overall health score (average of system health scores)\n",
        "    if integration_health:\n",
        "        overall_health_score = sum(h.get(\"overall_score\", 0.0) for h in integration_health) / len(integration_health)\n",
        "    else:\n",
        "        overall_health_score = 0.0\n",
        "\n",
        "    return {\n",
        "        \"total_agents\": total_agents,\n",
        "        \"active_agents\": active_agents,\n",
        "        \"total_systems\": total_systems,\n",
        "        \"healthy_systems\": healthy_systems,\n",
        "        \"degraded_systems\": degraded_systems,\n",
        "        \"critical_systems\": critical_systems,\n",
        "        \"total_risks\": total_risks,\n",
        "        \"high_priority_risks\": high_priority_risks,\n",
        "        \"total_cost_30d\": round(total_cost_30d, 2),\n",
        "        \"total_roi_estimate\": round(total_roi_estimate, 2),\n",
        "        \"overall_health_score\": round(overall_health_score, 1)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prioritization_node(\n",
        "    state: IntegrationRiskManagementOrchestratorState,\n",
        "    config: IntegrationRiskManagementOrchestratorConfig\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Prioritization Node: Consolidate and prioritize all issues\"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    integration_health = state.get(\"integration_health\", [])\n",
        "    risk_assessments = state.get(\"risk_assessments\", [])\n",
        "    value_leakage_analysis = state.get(\"value_leakage_analysis\", [])\n",
        "    workflow_analysis = state.get(\"workflow_analysis\", [])\n",
        "    agents_lookup = state.get(\"agents_lookup\", {})\n",
        "    systems = state.get(\"system_integrations\", [])\n",
        "    kpis_lookup = state.get(\"kpis_lookup\", {})\n",
        "\n",
        "    if not integration_health or not risk_assessments:\n",
        "        return {\n",
        "            \"errors\": errors + [\"prioritization_node: integration_health and risk_assessments required\"]\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        # Prioritize all issues\n",
        "        prioritized_issues = prioritize_all_issues(\n",
        "            integration_health,\n",
        "            risk_assessments,\n",
        "            value_leakage_analysis,\n",
        "            workflow_analysis,\n",
        "            agents_lookup,\n",
        "            config.priority_scoring_weights,\n",
        "            config.value_leakage_thresholds\n",
        "        )\n",
        "\n",
        "        # Calculate ecosystem summary\n",
        "        ecosystem_summary = calculate_ecosystem_summary_metrics(\n",
        "            list(agents_lookup.values()),\n",
        "            systems,\n",
        "            integration_health,\n",
        "            prioritized_issues,\n",
        "            kpis_lookup\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"prioritized_issues\": prioritized_issues,\n",
        "            \"ecosystem_summary\": ecosystem_summary,\n",
        "            \"errors\": errors\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"prioritization_node: {str(e)}\"]"
      ],
      "metadata": {
        "id": "lC6n6-Je2cWR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}