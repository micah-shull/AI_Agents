{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZiILa18YCbup6ZIfY6FnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/429_PDO_AgentState.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Proposal & Document Orchestrator — Architecture Review\n",
        "\n",
        "## 1. What This Code Is Doing (In Real Terms)\n",
        "\n",
        "This code defines **the entire operating contract** for your Proposal & Document Orchestrator.\n",
        "\n",
        "Before any logic runs, before any analysis happens, before any report is written, this file answers:\n",
        "\n",
        "* What information the agent is allowed to see\n",
        "* What decisions the agent is responsible for\n",
        "* What metrics it must produce\n",
        "* How success, risk, and failure are defined\n",
        "* What leaders can expect to trust in the output\n",
        "\n",
        "This is not a data structure — it is **a control framework**.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Why the State Definition Is the Most Important Part of the Agent\n",
        "\n",
        "### `ProposalDocumentOrchestratorState`\n",
        "\n",
        "This `TypedDict` is doing something subtle but powerful:\n",
        "\n",
        "> It turns an AI agent into a **bounded, auditable system**.\n",
        "\n",
        "Every major concern a CEO, legal team, or auditor would ask about is explicitly represented:\n",
        "\n",
        "* Inputs (what documents are analyzed)\n",
        "* Process (plans, stages, reviews, checks)\n",
        "* Costs (AI, human, infrastructure)\n",
        "* Outcomes (time saved, risk avoided)\n",
        "* KPIs (operational, effectiveness, business)\n",
        "* ROI (hard numbers, not vibes)\n",
        "* Errors and processing metadata\n",
        "\n",
        "Nothing is implicit. Nothing is “magic.”\n",
        "\n",
        "That alone puts this agent far above most LLM-based systems.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Strong Architectural Decisions Worth Calling Out\n",
        "\n",
        "### A. Goal & Plan as First-Class Citizens\n",
        "\n",
        "```python\n",
        "goal: Dict[str, Any]\n",
        "plan: List[Dict[str, Any]]\n",
        "```\n",
        "\n",
        "This is a **Mission Orchestrator pattern** applied correctly.\n",
        "\n",
        "Instead of the agent “just running,” it:\n",
        "\n",
        "* Declares *why* it’s running\n",
        "* Declares *how* it plans to run\n",
        "* Produces outputs that can be checked against that plan\n",
        "\n",
        "This is exactly how you build **explainable automation**.\n",
        "\n",
        "---\n",
        "\n",
        "### B. Explicit Separation of Data vs Analysis vs Outcomes\n",
        "\n",
        "You very clearly separate:\n",
        "\n",
        "* Raw data (documents, versions, stages, reviews)\n",
        "* Derived analysis (per-document metrics)\n",
        "* Aggregated KPIs\n",
        "* Executive interpretation (status, ROI, trends)\n",
        "\n",
        "This mirrors how **real organizations operate**:\n",
        "\n",
        "* Operations generate data\n",
        "* Analysts interpret it\n",
        "* Leaders make decisions\n",
        "\n",
        "Your agent respects that boundary instead of collapsing everything into a single “answer.”\n",
        "\n",
        "---\n",
        "\n",
        "### C. Lookup Tables = Performance *and* Traceability\n",
        "\n",
        "```python\n",
        "documents_lookup\n",
        "document_versions_lookup\n",
        "workflow_stages_lookup\n",
        "...\n",
        "```\n",
        "\n",
        "This is not just a performance optimization.\n",
        "\n",
        "It enables:\n",
        "\n",
        "* Fast, repeatable analysis\n",
        "* Deterministic results\n",
        "* Easy debugging (“show me exactly which record caused this KPI”)\n",
        "\n",
        "This is how you avoid “LLM hallucination” accusations — the answers are traceable.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. KPI Design: This Is Executive-Grade\n",
        "\n",
        "### Operational KPIs (Agent Health)\n",
        "\n",
        "These answer:\n",
        "\n",
        "> “Is the system functioning reliably?”\n",
        "\n",
        "Success rate, latency, override frequency, compliance failures — exactly right.\n",
        "\n",
        "---\n",
        "\n",
        "### Effectiveness KPIs (Workflow Quality)\n",
        "\n",
        "These answer:\n",
        "\n",
        "> “Is the process actually improving?”\n",
        "\n",
        "Cycle time, rework loops, reviewer time saved — these are **process improvement metrics**, not AI vanity metrics.\n",
        "\n",
        "---\n",
        "\n",
        "### Business KPIs (ROI & Value)\n",
        "\n",
        "These answer:\n",
        "\n",
        "> “Is this worth the investment?”\n",
        "\n",
        "Cost per document, hours saved, ROI %, revenue impact — this is the language leadership speaks.\n",
        "\n",
        "Crucially:\n",
        "You define **baselines** explicitly. That’s what makes ROI credible.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. KPI Status & Thresholds: Why This Builds Trust\n",
        "\n",
        "```python\n",
        "kpi_warning_threshold\n",
        "kpi_critical_threshold\n",
        "```\n",
        "\n",
        "This is a **huge trust signal**.\n",
        "\n",
        "Instead of the agent declaring “success,” leadership can see:\n",
        "\n",
        "* What “on track” means\n",
        "* When things are degraded\n",
        "* When intervention is required\n",
        "\n",
        "This mirrors real-world management dashboards and avoids subjective interpretation.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Workflow & Statistical Analysis: Mature by Design\n",
        "\n",
        "### Workflow Analysis\n",
        "\n",
        "You’re not just reporting averages — you’re identifying:\n",
        "\n",
        "* Bottleneck stages\n",
        "* Failure-prone steps\n",
        "* Overall workflow health\n",
        "\n",
        "This turns the agent into a **continuous improvement system**, not a reporting tool.\n",
        "\n",
        "---\n",
        "\n",
        "### Statistical Assessments\n",
        "\n",
        "Including statistical tests at the state level is a strong signal that:\n",
        "\n",
        "* Improvements must be *proven*\n",
        "* Not all changes are meaningful\n",
        "* Leadership should trust statistically significant results\n",
        "\n",
        "Very few agent builders do this correctly — this is a major differentiator.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Configuration Class: Why This Is Excellent\n",
        "\n",
        "### `ProposalDocumentOrchestratorConfig`\n",
        "\n",
        "This config class is doing exactly what it should:\n",
        "\n",
        "* Separating **policy from execution**\n",
        "* Making assumptions explicit\n",
        "* Allowing leadership to tune risk tolerance and targets\n",
        "\n",
        "Key strengths:\n",
        "\n",
        "* KPI targets are transparent\n",
        "* Cost assumptions are configurable\n",
        "* LLM usage is optional and gated\n",
        "* Toolshed integrations are explicitly controlled\n",
        "\n",
        "This design makes the agent:\n",
        "\n",
        "* Safer\n",
        "* Easier to govern\n",
        "* Easier to adapt across organizations\n",
        "\n",
        "---\n",
        "\n",
        "## 8. LLM Usage: Correctly De-Prioritized\n",
        "\n",
        "```python\n",
        "enable_llm_summary: bool = False\n",
        "```\n",
        "\n",
        "This is an important design signal.\n",
        "\n",
        "You are clearly saying:\n",
        "\n",
        "> “The system works without the LLM.\n",
        "> The LLM enhances communication, not decision-making.”\n",
        "\n",
        "That single choice aligns perfectly with your guiding principle:\n",
        "\n",
        "> *The LLM explains what the system has already proven.*\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Overall Assessment\n",
        "\n",
        "This is **strong, disciplined architecture**.\n",
        "\n",
        "What stands out most:\n",
        "\n",
        "* You designed for **trust first**\n",
        "* You separated reasoning from reporting\n",
        "* You built explicit accountability into the state\n",
        "* You made ROI unavoidable, not optional\n",
        "\n",
        "This code sets you up to build an agent that:\n",
        "\n",
        "* Can survive executive scrutiny\n",
        "* Can be audited\n",
        "* Can evolve without losing control\n",
        "* Can be defended in front of legal, finance, and operations\n",
        "\n"
      ],
      "metadata": {
        "id": "ZDLraBeY6Mf6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVwaaiq_1mUh"
      },
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# Proposal & Document Orchestrator Agent\n",
        "# ============================================================================\n",
        "\n",
        "class ProposalDocumentOrchestratorState(TypedDict, total=False):\n",
        "    \"\"\"State for Proposal & Document Orchestrator Agent\n",
        "\n",
        "    This orchestrator manages the end-to-end document lifecycle, from creation\n",
        "    through review, validation, and continuous improvement. It functions as a\n",
        "    document production control system with explicit quality controls, evaluation\n",
        "    criteria, human review points, and measurable outcomes.\n",
        "    \"\"\"\n",
        "\n",
        "    # Input fields\n",
        "    document_id: Optional[str]              # Single document to analyze (if provided)\n",
        "    analysis_mode: str                      # \"single\" | \"portfolio\" (analyze all documents)\n",
        "    filter_criteria: Optional[Dict[str, Any]]  # Optional filters (document_type, status, priority, date_range)\n",
        "\n",
        "    # Goal & Planning fields (Universal patterns - always include)\n",
        "    goal: Dict[str, Any]                   # Goal definition (from goal_node)\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"objective\": \"Analyze document workflow performance and calculate KPIs\",\n",
        "    #   \"analysis_mode\": \"portfolio\",\n",
        "    #   \"focus_areas\": [\"operational_kpis\", \"effectiveness_kpis\", \"business_kpis\", \"roi\"]\n",
        "    # }\n",
        "\n",
        "    plan: List[Dict[str, Any]]             # Execution plan (from planning_node)\n",
        "    # Structure per step:\n",
        "    # {\n",
        "    #   \"step\": 1,\n",
        "    #   \"name\": \"data_loading\",\n",
        "    #   \"description\": \"Load all document data files\",\n",
        "    #   \"dependencies\": [],\n",
        "    #   \"outputs\": [\"documents\", \"document_versions\", \"workflow_stages\", ...]\n",
        "    # }\n",
        "\n",
        "    # Data Loading - All 7 data files\n",
        "    documents: List[Dict[str, Any]]        # All documents from documents.json\n",
        "    # Structure per document:\n",
        "    # {\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"document_type\": \"proposal\",\n",
        "    #   \"client_name\": \"Acme Manufacturing\",\n",
        "    #   \"industry\": \"Manufacturing\",\n",
        "    #   \"status\": \"submitted\",\n",
        "    #   \"target_outcome\": \"win_contract\",\n",
        "    #   \"priority\": \"high\",\n",
        "    #   \"owner_role\": \"sales\",\n",
        "    #   \"created_at\": \"2026-01-08T14:12:00Z\",\n",
        "    #   \"updated_at\": \"2026-01-10T09:45:00Z\"\n",
        "    # }\n",
        "\n",
        "    document_versions: List[Dict[str, Any]] # All versions from document_versions.json\n",
        "    # Structure per version:\n",
        "    # {\n",
        "    #   \"version_id\": \"V_DOC_001_1\",\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"version_number\": 1,\n",
        "    #   \"created_by\": \"agent\",\n",
        "    #   \"change_summary\": \"Initial draft created\",\n",
        "    #   \"word_count\": 1850,\n",
        "    #   \"content_reference\": \"documents/DOC_001/v1.md\",\n",
        "    #   \"created_at\": \"2026-01-08T14:25:00Z\"\n",
        "    # }\n",
        "\n",
        "    workflow_stages: List[Dict[str, Any]]  # All stages from workflow_stages.json\n",
        "    # Structure per stage:\n",
        "    # {\n",
        "    #   \"stage_id\": \"STG_001\",\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"version_id\": \"V_DOC_001_1\",\n",
        "    #   \"stage_name\": \"structure_planning\",\n",
        "    #   \"stage_order\": 1,\n",
        "    #   \"status\": \"completed\",\n",
        "    #   \"started_at\": \"2026-01-08T14:25:00Z\",\n",
        "    #   \"completed_at\": \"2026-01-08T14:40:00Z\",\n",
        "    #   \"failure_reason\": null\n",
        "    # }\n",
        "\n",
        "    review_events: List[Dict[str, Any]]    # All reviews from review_events.json\n",
        "    # Structure per review:\n",
        "    # {\n",
        "    #   \"review_id\": \"REV_001\",\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"version_id\": \"V_DOC_001_1\",\n",
        "    #   \"reviewer_id\": \"REVIEWER_LEGAL_001\",\n",
        "    #   \"reviewer_role\": \"legal\",\n",
        "    #   \"decision\": \"reject\",\n",
        "    #   \"reason\": \"Missing liability clause\",\n",
        "    #   \"time_spent_minutes\": 18,\n",
        "    #   \"human_override\": true,\n",
        "    #   \"reviewed_at\": \"2026-01-08T15:30:00Z\"\n",
        "    # }\n",
        "\n",
        "    compliance_checks: List[Dict[str, Any]] # All checks from compliance_checks.json\n",
        "    # Structure per check:\n",
        "    # {\n",
        "    #   \"check_id\": \"COMP_001\",\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"version_id\": \"V_DOC_001_1\",\n",
        "    #   \"rule_name\": \"liability_clause_required\",\n",
        "    #   \"rule_category\": \"legal\",\n",
        "    #   \"status\": \"failed\",\n",
        "    #   \"severity\": \"high\",\n",
        "    #   \"details\": \"Missing required liability clause\",\n",
        "    #   \"checked_at\": \"2026-01-08T15:20:00Z\"\n",
        "    # }\n",
        "\n",
        "    cost_tracking: List[Dict[str, Any]]    # All costs from cost_tracking.json\n",
        "    # Structure per cost entry:\n",
        "    # {\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"llm_cost_usd\": 2.85,\n",
        "    #   \"tooling_cost_usd\": 0.65,\n",
        "    #   \"human_review_cost_usd\": 54.00,\n",
        "    #   \"total_cost_usd\": 57.50,\n",
        "    #   \"stage_breakdown\": {\n",
        "    #     \"structure_planning\": 0.30,\n",
        "    #     \"content_generation\": 1.95,\n",
        "    #     \"content_revision\": 0.60\n",
        "    #   },\n",
        "    #   \"tracked_at\": \"2026-01-10T09:50:00Z\"\n",
        "    # }\n",
        "\n",
        "    outcomes: List[Dict[str, Any]]         # All outcomes from outcomes.json\n",
        "    # Structure per outcome:\n",
        "    # {\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"final_status\": \"submitted\",\n",
        "    #   \"baseline_cycle_time_hours\": 72,\n",
        "    #   \"actual_cycle_time_hours\": 36,\n",
        "    #   \"estimated_hours_saved\": 6,\n",
        "    #   \"outcome_proxy\": \"proposal_submitted_faster\",\n",
        "    #   \"completed_at\": \"2026-01-10T09:45:00Z\"\n",
        "    # }\n",
        "\n",
        "    # Lookup dictionaries (for performance - access entities by ID multiple times)\n",
        "    documents_lookup: Dict[str, Dict[str, Any]]      # document_id → document\n",
        "    document_versions_lookup: Dict[str, List[Dict[str, Any]]]  # document_id → [versions]\n",
        "    workflow_stages_lookup: Dict[str, List[Dict[str, Any]]]    # document_id → [stages]\n",
        "    review_events_lookup: Dict[str, List[Dict[str, Any]]]      # document_id → [reviews]\n",
        "    compliance_checks_lookup: Dict[str, List[Dict[str, Any]]]  # document_id → [checks]\n",
        "    cost_tracking_lookup: Dict[str, Dict[str, Any]]             # document_id → cost_entry\n",
        "    outcomes_lookup: Dict[str, Dict[str, Any]]                  # document_id → outcome\n",
        "\n",
        "    # Analysis Results\n",
        "    document_analysis: List[Dict[str, Any]]  # Per-document analysis results\n",
        "    # Structure per document analysis:\n",
        "    # {\n",
        "    #   \"document_id\": \"DOC_001\",\n",
        "    #   \"revision_count\": 2,\n",
        "    #   \"total_stages\": 5,\n",
        "    #   \"failed_stages\": 1,\n",
        "    #   \"compliance_failures\": 1,\n",
        "    #   \"human_overrides\": 1,\n",
        "    #   \"total_cost_usd\": 57.50,\n",
        "    #   \"cycle_time_hours\": 36,\n",
        "    #   \"baseline_cycle_time_hours\": 72,\n",
        "    #   \"hours_saved\": 6,\n",
        "    #   \"avg_stage_duration_minutes\": 15.2\n",
        "    # }\n",
        "\n",
        "    # KPI Metrics (from orchestrator spec)\n",
        "    # 1. Operational KPIs (Agent Health)\n",
        "    operational_kpis: Dict[str, Any]\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"document_generation_success_rate\": 0.90,  # 90% success\n",
        "    #   \"avg_stage_latency_minutes\": 12.5,\n",
        "    #   \"avg_revision_count\": 1.8,\n",
        "    #   \"compliance_failure_rate\": 0.20,  # 20% failure rate\n",
        "    #   \"human_override_frequency\": 0.30,  # 30% override rate\n",
        "    #   \"source_validation_pass_rate\": 0.95\n",
        "    # }\n",
        "\n",
        "    # 2. Effectiveness KPIs (Workflow Quality)\n",
        "    effectiveness_kpis: Dict[str, Any]\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"avg_time_to_first_draft_hours\": 4.5,\n",
        "    #   \"avg_cycle_time_hours\": 32.0,\n",
        "    #   \"avg_cycle_time_reduction_percent\": 50.0,  # vs baseline\n",
        "    #   \"avg_rework_loops\": 1.2,\n",
        "    #   \"reviewer_time_saved_hours\": 2.5,\n",
        "    #   \"consistency_score\": 0.85  # Similarity across similar documents\n",
        "    # }\n",
        "\n",
        "    # 3. Business KPIs (ROI & Value)\n",
        "    business_kpis: Dict[str, Any]\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"avg_cost_per_document_usd\": 35.50,\n",
        "    #   \"baseline_cost_per_document_usd\": 120.00,  # Before automation\n",
        "    #   \"cost_reduction_percent\": 70.4,\n",
        "    #   \"avg_hours_saved_per_document\": 4.5,\n",
        "    #   \"total_hours_saved\": 45.0,  # Across all documents\n",
        "    #   \"estimated_revenue_impact_usd\": 5000.0,  # Faster cycles = revenue timing\n",
        "    #   \"compliance_risk_reduction_percent\": 40.0\n",
        "    # }\n",
        "\n",
        "    # KPI Status Assessment\n",
        "    kpi_status: Dict[str, str]              # KPI achievement status\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"document_generation_success_rate\": \"on_track\" | \"at_risk\" | \"exceeded\",\n",
        "    #   \"avg_cycle_time_reduction\": \"on_track\" | \"at_risk\" | \"exceeded\",\n",
        "    #   \"cost_reduction\": \"on_track\" | \"at_risk\" | \"exceeded\",\n",
        "    #   ...\n",
        "    # }\n",
        "\n",
        "    # ROI & Cost Analysis (CEO Trust Requirements)\n",
        "    total_cost_usd: float                   # Total cost across all documents\n",
        "    total_revenue_impact_usd: float         # Total revenue impact\n",
        "    net_roi_usd: float                      # Net ROI (revenue - cost)\n",
        "    roi_percent: float                      # ROI percentage\n",
        "    roi_ratio: float                        # ROI ratio (revenue / cost)\n",
        "    roi_status: str                         # \"positive\" | \"negative\" | \"neutral\"\n",
        "    cost_efficiency: Dict[str, Any]         # Cost efficiency analysis\n",
        "\n",
        "    # Workflow Analysis\n",
        "    workflow_analysis: Dict[str, Any]       # Workflow health and bottleneck analysis\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"bottleneck_stages\": [\n",
        "    #     {\"stage_name\": \"compliance_check\", \"avg_duration_minutes\": 25.0, \"failure_rate\": 0.30}\n",
        "    #   ],\n",
        "    #   \"stage_performance\": {\n",
        "    #     \"structure_planning\": {\"avg_duration\": 12.0, \"success_rate\": 0.95},\n",
        "    #     \"content_generation\": {\"avg_duration\": 28.0, \"success_rate\": 0.90},\n",
        "    #     ...\n",
        "    #   },\n",
        "    #   \"workflow_health\": \"healthy\" | \"degraded\" | \"critical\"\n",
        "    # }\n",
        "\n",
        "    # Portfolio Summary\n",
        "    portfolio_summary: Dict[str, Any]       # High-level portfolio metrics\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"total_documents\": 10,\n",
        "    #   \"documents_by_type\": {\"proposal\": 5, \"policy_update\": 2, \"client_report\": 2, \"internal_memo\": 1},\n",
        "    #   \"documents_by_status\": {\"submitted\": 2, \"in_review\": 2, \"approved\": 2, \"delivered\": 2, \"rejected\": 1, \"in_progress\": 1},\n",
        "    #   \"documents_by_priority\": {\"high\": 5, \"medium\": 4, \"low\": 1},\n",
        "    #   \"total_versions\": 15,\n",
        "    #   \"total_reviews\": 8,\n",
        "    #   \"total_compliance_checks\": 9\n",
        "    # }\n",
        "\n",
        "    # Statistical Assessment (CEO Trust Requirements)\n",
        "    statistical_assessments: Dict[str, Any]  # Statistical significance tests\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"cycle_time_improvement\": {\n",
        "    #     \"test_type\": \"t_test\",\n",
        "    #     \"p_value\": 0.001,\n",
        "    #     \"is_significant\": True,\n",
        "    #     \"confidence_interval\": {\"lower\": 30.0, \"upper\": 42.0}\n",
        "    #   },\n",
        "    #   \"cost_reduction\": {...},\n",
        "    #   ...\n",
        "    # }\n",
        "\n",
        "    # Trends & Historical Comparison (if historical data available)\n",
        "    trends: Dict[str, Dict[str, Any]]       # Trend analysis\n",
        "    # Structure:\n",
        "    # {\n",
        "    #   \"cycle_time\": {\n",
        "    #     \"direction\": \"improving\",\n",
        "    #     \"indicator\": \"↓\",\n",
        "    #     \"percent_change\": -50.0,\n",
        "    #     \"is_significant\": True\n",
        "    #   },\n",
        "    #   \"cost\": {...},\n",
        "    #   \"roi\": {...}\n",
        "    # }\n",
        "\n",
        "    historical_comparison: Optional[Dict[str, Any]]  # Comparison to previous analysis\n",
        "\n",
        "    # Output\n",
        "    executive_report: str                   # Final markdown report\n",
        "    report_file_path: Optional[str]         # Path to saved report file\n",
        "\n",
        "    # Metadata (Universal patterns - always include)\n",
        "    errors: List[str]                       # Any errors encountered\n",
        "    processing_time: Optional[float]        # Time taken to process (seconds)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ProposalDocumentOrchestratorConfig:\n",
        "    \"\"\"Configuration for Proposal & Document Orchestrator Agent\"\"\"\n",
        "\n",
        "    # LLM Settings\n",
        "    llm_model: str = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
        "    temperature: float = 0.3\n",
        "\n",
        "    # Data file paths\n",
        "    data_dir: str = \"agents/data\"\n",
        "    documents_file: str = \"documents.json\"\n",
        "    document_versions_file: str = \"document_versions.json\"\n",
        "    workflow_stages_file: str = \"workflow_stages.json\"\n",
        "    review_events_file: str = \"review_events.json\"\n",
        "    compliance_checks_file: str = \"compliance_checks.json\"\n",
        "    cost_tracking_file: str = \"cost_tracking.json\"\n",
        "    outcomes_file: str = \"outcomes.json\"\n",
        "\n",
        "    # Output settings\n",
        "    reports_dir: str = \"output/proposal_document_orchestrator\"\n",
        "\n",
        "    # KPI Thresholds (CEO-friendly transparency)\n",
        "    kpi_warning_threshold: float = 0.8      # Warn if KPI is 80% of target\n",
        "    kpi_critical_threshold: float = 0.5     # Critical if KPI is 50% of target\n",
        "\n",
        "    # Operational KPI Targets\n",
        "    target_document_success_rate: float = 0.90      # 90% success rate target\n",
        "    target_avg_stage_latency_minutes: float = 15.0  # 15 min average stage latency\n",
        "    max_avg_revision_count: float = 2.0             # Max 2 revisions on average\n",
        "    target_compliance_pass_rate: float = 0.85       # 85% compliance pass rate\n",
        "    max_human_override_rate: float = 0.25           # Max 25% override rate\n",
        "\n",
        "    # Effectiveness KPI Targets\n",
        "    target_time_to_first_draft_hours: float = 6.0   # 6 hours to first draft\n",
        "    target_cycle_time_reduction_percent: float = 40.0  # 40% cycle time reduction\n",
        "    max_avg_rework_loops: float = 1.5               # Max 1.5 rework loops\n",
        "\n",
        "    # Business KPI Targets\n",
        "    target_cost_reduction_percent: float = 50.0     # 50% cost reduction target\n",
        "    target_hours_saved_per_document: float = 3.0    # 3 hours saved per document\n",
        "    min_roi_percent: float = 100.0                  # Minimum 100% ROI\n",
        "\n",
        "    # ROI Calculation Settings\n",
        "    cost_per_human_review_hour: float = 60.0       # Cost per hour of human review\n",
        "    cost_per_llm_call: float = 0.01                 # Estimated cost per LLM call\n",
        "    cost_per_api_call: float = 0.001                # Estimated cost per API call\n",
        "    infrastructure_cost_per_month: float = 500.0     # Infrastructure cost per month\n",
        "    revenue_per_hour_saved: float = 50.0            # Revenue impact per hour saved (timing)\n",
        "\n",
        "    # Statistical Testing\n",
        "    confidence_level: float = 0.95                  # 95% confidence level for statistical tests\n",
        "\n",
        "    # Toolshed Integration Flags\n",
        "    enable_progress_tracking: bool = True           # Use toolshed.progress\n",
        "    enable_kpi_tracking: bool = True               # Use toolshed.kpi\n",
        "    enable_statistical_testing: bool = True         # Use toolshed.statistics\n",
        "    enable_reporting: bool = True                   # Use toolshed.reporting\n",
        "    enable_validation: bool = True                   # Use toolshed.validation\n",
        "    enable_workflow_analysis: bool = True           # Use toolshed.workflows\n",
        "\n",
        "    # LLM Enhancement (Optional - Phase 8)\n",
        "    enable_llm_summary: bool = False               # Enable LLM-generated executive summary (MVP: rule-based)\n",
        "    llm_summary_max_tokens: int = 500              # Max tokens for executive summary\n"
      ]
    }
  ]
}