{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzf3zbTLDKio4nHqL3yuiG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/161_LangGraph_ToolNode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Tools and `ToolNode` are the practical bridge between **LangChain‚Äôs ‚Äútools‚Äù world** and **LangGraph‚Äôs ‚Äúnodes‚Äù world**. Let‚Äôs unpack this step by step, tying it back to your recipe.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è What is a Tool in LangChain?\n",
        "\n",
        "In **LangChain**:\n",
        "\n",
        "* A **Tool** is just a wrapper around a function (or service/API call) that agents can call.\n",
        "* It carries **metadata** like:\n",
        "\n",
        "  * `name`\n",
        "  * `description`\n",
        "  * JSON schema for parameters\n",
        "* It enforces a consistent API: `tool.invoke(input_dict)`.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add(x: int, y: int) -> int:\n",
        "    \"\"\"Add two numbers.\"\"\"\n",
        "    return x + y\n",
        "```\n",
        "\n",
        "Now `add` is a LangChain `Tool` object that knows:\n",
        "\n",
        "* What it‚Äôs called (`\"add\"`)\n",
        "* What arguments it expects\n",
        "* How to execute itself\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ Where `ToolNode` Comes In (LangGraph)\n",
        "\n",
        "LangGraph extends this by introducing the **`ToolNode`**:\n",
        "\n",
        "* A **`ToolNode`** is a **LangGraph node** that knows how to execute one or more LangChain tools.\n",
        "* It basically says: *‚ÄúThis node = run this tool when invoked.‚Äù*\n",
        "* It handles:\n",
        "\n",
        "  * Mapping `state` ‚Üí tool arguments\n",
        "  * Calling the tool\n",
        "  * Returning the tool‚Äôs output back into `state`\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "tools = [add]   # can be a list of LangChain Tool objects\n",
        "tool_node = ToolNode(tools)\n",
        "```\n",
        "\n",
        "Now `tool_node` is a graph node. You can plug it into your `StateGraph` like any other node:\n",
        "\n",
        "```python\n",
        "builder.add_node(\"math\", tool_node)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° Why ToolNode Matters\n",
        "\n",
        "1. **Bridging Your Recipe**\n",
        "   In your `Agent_1_Recipe`, tools were registered into a `ToolRegistry`.\n",
        "   With LangGraph + LangChain:\n",
        "\n",
        "   * **LangChain Tool = your recipe‚Äôs tool definition**\n",
        "   * **ToolNode = your recipe‚Äôs tool registry entry wired into the graph**\n",
        "\n",
        "   So instead of writing your own registry + environment executor, you get it free.\n",
        "\n",
        "---\n",
        "\n",
        "2. **Multi-Tool Support**\n",
        "   `ToolNode` can wrap a *list* of tools, not just one.\n",
        "   Inside the graph, you can route based on the tool name:\n",
        "\n",
        "   ```python\n",
        "   tool_node = ToolNode([add, subtract, multiply])\n",
        "   builder.add_node(\"math_tools\", tool_node)\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "3. **Integration with LLMs**\n",
        "   If you use an LLM as a ‚Äúcontroller‚Äù node (e.g. deciding what to do next), it can output `\"tool\": \"add\", \"args\": {\"x\": 2, \"y\": 3}`.\n",
        "   Then you connect that to a `ToolNode`, and LangGraph handles calling the tool and returning its result to state.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© How This Maps to Your Recipe\n",
        "\n",
        "* **Your recipe‚Äôs `@register_tool` decorator** ‚Üí LangChain‚Äôs `@tool` decorator\n",
        "* **Your `ToolRegistry`** ‚Üí implicit in `ToolNode` (you just pass a list of tools)\n",
        "* **Your `Environment.execute(tool_name, args)`** ‚Üí handled by `ToolNode.invoke()`\n",
        "\n",
        "So LangGraph + ToolNode essentially *collapses three parts* of your recipe (tool registry, DI environment, execution handler) into one elegant abstraction.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Minimal Example\n",
        "\n",
        "```python\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    result: str\n",
        "\n",
        "@tool\n",
        "def shout(text: str) -> str:\n",
        "    \"\"\"Make text loud.\"\"\"\n",
        "    return text.upper()\n",
        "\n",
        "# Wrap the tool in a ToolNode\n",
        "shout_node = ToolNode([shout])\n",
        "\n",
        "# Build the graph\n",
        "builder = StateGraph(AgentState)\n",
        "builder.add_node(\"shout\", shout_node)\n",
        "builder.set_entry_point(\"shout\")\n",
        "graph = builder.compile()\n",
        "\n",
        "# Run it\n",
        "result = graph.invoke({\"result\": \"hello\"})\n",
        "print(result)  # \"HELLO\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ TL;DR\n",
        "\n",
        "* **LangChain Tool** = your recipe‚Äôs *tool definition* (name, schema, function).\n",
        "* **ToolNode** = a LangGraph node that wraps one or more tools so they can be wired into the graph.\n",
        "* It removes the need for a manual `ToolRegistry` + `Environment.execute` pattern ‚Äî LangGraph takes care of the orchestration.\n"
      ],
      "metadata": {
        "id": "5TYjGecSWKgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üîé 1. Are the details like args available through ToolNode?\n",
        "\n",
        "Yes ‚úÖ\n",
        "\n",
        "When you create a tool with LangChain‚Äôs `@tool`, it automatically generates:\n",
        "\n",
        "* **Name** ‚Üí the string identifier\n",
        "* **Description** ‚Üí from the docstring\n",
        "* **Argument schema** ‚Üí JSON schema inferred from function signature or Pydantic model\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add_two_numbers(x: int, y: int) -> int:\n",
        "    \"\"\"Add two integers together.\"\"\"\n",
        "    return x + y\n",
        "```\n",
        "\n",
        "This produces a `StructuredTool` under the hood that carries:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"add_two_numbers\",\n",
        "  \"description\": \"Add two integers together.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"x\": {\"type\": \"integer\"},\n",
        "      \"y\": {\"type\": \"integer\"}\n",
        "    },\n",
        "    \"required\": [\"x\", \"y\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "When you wrap it in a `ToolNode`:\n",
        "\n",
        "```python\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "tool_node = ToolNode([add_two_numbers])\n",
        "```\n",
        "\n",
        "üëâ The schema and metadata are preserved. LangGraph uses them to:\n",
        "\n",
        "* Validate input\n",
        "* Expose to the LLM what arguments are needed\n",
        "* Route execution to the correct function\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 2. What does the LLM see when calling a tool?\n",
        "\n",
        "The LLM sees a **function signature in JSON schema form**, almost like OpenAI‚Äôs ‚Äúfunction calling‚Äù format.\n",
        "\n",
        "So instead of free-text guessing, the LLM gets:\n",
        "\n",
        "* Tool **name** (string)\n",
        "* Tool **description** (natural language, from your docstring)\n",
        "* Tool **parameters** (typed, structured, validated)\n",
        "\n",
        "For the above `add_two_numbers`, the LLM would see something like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"add_two_numbers\",\n",
        "  \"description\": \"Add two integers together.\",\n",
        "  \"parameters\": {\n",
        "    \"x\": \"integer\",\n",
        "    \"y\": \"integer\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "When the LLM decides to use this tool, it emits JSON like:\n",
        "\n",
        "```json\n",
        "{\"tool\": \"add_two_numbers\", \"arguments\": {\"x\": 2, \"y\": 3}}\n",
        "```\n",
        "\n",
        "LangGraph routes this to your `ToolNode`, executes the tool, and merges the result back into state.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© 3. Does giving tools explicit names help the LLM?\n",
        "\n",
        "100% ‚úÖ\n",
        "\n",
        "Naming is **hugely important** for LLM reasoning. Here‚Äôs why:\n",
        "\n",
        "* The LLM has to **choose between tools** when planning.\n",
        "* If tools have **clear, descriptive names** like `add_two_numbers` vs vague ones like `math`:\n",
        "\n",
        "  * üß† The LLM can reason about which one matches the user goal more easily.\n",
        "  * üö´ It avoids ‚Äúhallucinating‚Äù tool calls.\n",
        "* The description also matters ‚Äî you want it concise, action-oriented, and unique.\n",
        "\n",
        "### Example:\n",
        "\n",
        "Bad tool set:\n",
        "\n",
        "* `process` (what does this mean?)\n",
        "* `handle` (too vague)\n",
        "\n",
        "Better tool set:\n",
        "\n",
        "* `add_two_numbers` ‚Üí ‚ÄúAdd two integers together.‚Äù\n",
        "* `fetch_weather_forecast` ‚Üí ‚ÄúGet the 5-day weather forecast for a city.‚Äù\n",
        "* `send_email_via_smtp` ‚Üí ‚ÄúSend an email using SMTP with subject and body.‚Äù\n",
        "\n",
        "üëâ The more **self-descriptive** the tool names and docstrings, the **less mental overhead** for the LLM, and the more consistent the orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ TL;DR\n",
        "\n",
        "* **ToolNode preserves tool metadata**: name, description, args schema.\n",
        "* **The LLM sees the JSON schema** (like OpenAI function calling) ‚Üí precise, structured tool use.\n",
        "* **Explicit, descriptive names reduce LLM overhead** and improve tool selection accuracy.\n"
      ],
      "metadata": {
        "id": "YDmbNLF3YHjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "You‚Äôre **not giving up anything** by moving from your custom `@register_tool` + `ToolRegistry` + `Environment.execute` setup to **LangChain `@tool` + LangGraph `ToolNode`**. In fact:\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ What You *Keep* (parity with your recipe)\n",
        "\n",
        "* **Explicit tool definitions** ‚Üí same JSON schema: name, description, parameters\n",
        "* **Injection of arguments** ‚Üí still works, but handled for you by LangChain\n",
        "* **Clear naming conventions** ‚Üí you can still define descriptive names like `add_two_numbers`\n",
        "* **Composable wiring** ‚Üí just like your recipe‚Äôs `wire_agent`, but with `StateGraph`\n",
        "\n",
        "So, the thing you loved in your recipe ‚Äî tools being **clear, schema-defined contracts** ‚Äî is still there.\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ What You *Gain* with LangGraph + ToolNode\n",
        "\n",
        "1. **No custom registry/environment needed**\n",
        "\n",
        "   * You don‚Äôt have to hand-roll a `ToolRegistry` and DI system.\n",
        "   * `ToolNode` does the registration + execution logic automatically.\n",
        "\n",
        "2. **Structured execution & orchestration**\n",
        "\n",
        "   * Tools plug directly into your state graph.\n",
        "   * You wire them into flow (`add_edge`, `add_conditional_edges`) instead of writing manual orchestration logic.\n",
        "\n",
        "3. **Built-in schema parsing**\n",
        "\n",
        "   * LangChain auto-generates JSON schema from your function signature.\n",
        "   * LLMs get exactly the metadata they need ‚Üí less error-prone.\n",
        "\n",
        "4. **Validation + error handling**\n",
        "\n",
        "   * ToolNode validates args before execution.\n",
        "   * If the LLM passes something invalid, LangGraph can route to retries or error-handling nodes.\n",
        "\n",
        "5. **Streaming + branching**\n",
        "\n",
        "   * With ActionContext you‚Äôd have to build this yourself.\n",
        "   * LangGraph handles streaming intermediate states and branching workflows out of the box.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Analogy\n",
        "\n",
        "Think of your **recipe system** like writing your own small **web framework**:\n",
        "\n",
        "* You defined routes (tool registry)\n",
        "* A request object (ActionContext)\n",
        "* A dispatcher (Environment)\n",
        "\n",
        "Now LangGraph is like **switching to FastAPI** ‚Äî you keep the same declarative style (functions + schemas), but the framework handles all the wiring, validation, and orchestration.\n",
        "\n",
        "---\n",
        "\n",
        "## üèÜ Bottom Line\n",
        "\n",
        "Yes ‚Äî **LangGraph is simplifying and streamlining your agent**.\n",
        "You‚Äôre not losing the rigor of your recipe ‚Äî you‚Äôre gaining:\n",
        "\n",
        "* Less boilerplate\n",
        "* More orchestration power\n",
        "* Built-in schema/validation\n",
        "* Better alignment with LLM-native tool calling\n",
        "\n"
      ],
      "metadata": {
        "id": "jSqrM837YwrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "When you expose tools via **LangChain** and wire them into **LangGraph**, the LLM doesn‚Äôt call them by ‚Äúguessing text‚Äù ‚Äî it calls them by emitting **structured JSON** that matches the schema.\n",
        "\n",
        "Let me show you concretely.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Define a Tool with LangChain\n",
        "\n",
        "```python\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def add_two_numbers(x: int, y: int) -> int:\n",
        "    \"\"\"Add two integers together.\"\"\"\n",
        "    return x + y\n",
        "```\n",
        "\n",
        "üëâ This automatically creates a tool object with:\n",
        "\n",
        "* `name = \"add_two_numbers\"`\n",
        "* `description = \"Add two integers together.\"`\n",
        "* `parameters = {\"x\": int, \"y\": int}`\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Wrap the Tool in a ToolNode (LangGraph)\n",
        "\n",
        "```python\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    result: str\n",
        "\n",
        "tool_node = ToolNode([add_two_numbers])\n",
        "\n",
        "builder = StateGraph(AgentState)\n",
        "builder.add_node(\"math\", tool_node)\n",
        "builder.set_entry_point(\"math\")\n",
        "builder.add_edge(\"math\", END)\n",
        "\n",
        "graph = builder.compile()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. What the LLM Sees\n",
        "\n",
        "When the LLM is given access to this tool, it receives something like this (JSON schema):\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"add_two_numbers\",\n",
        "  \"description\": \"Add two integers together.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"x\": {\"type\": \"integer\"},\n",
        "      \"y\": {\"type\": \"integer\"}\n",
        "    },\n",
        "    \"required\": [\"x\", \"y\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "This is injected into the LLM‚Äôs context, so the LLM knows:\n",
        "\n",
        "* The tool name to call\n",
        "* What arguments are needed\n",
        "* That it must return structured JSON\n",
        "\n",
        "---\n",
        "\n",
        "## 4. How the LLM Calls It\n",
        "\n",
        "If the user says: *‚ÄúWhat‚Äôs 2 + 3?‚Äù* ‚Üí the LLM generates a tool invocation like this:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool\": \"add_two_numbers\",\n",
        "  \"arguments\": {\"x\": 2, \"y\": 3}\n",
        "}\n",
        "```\n",
        "\n",
        "üëâ LangGraph intercepts this, routes it to the `ToolNode`, which executes `add_two_numbers(2, 3)`, and returns:\n",
        "\n",
        "```json\n",
        "{\"result\": 5}\n",
        "```\n",
        "\n",
        "That result goes back into the `state`, and the agent loop continues.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Streaming Example (Optional)\n",
        "\n",
        "LangGraph can also **stream** intermediate states.\n",
        "If you enable streaming, you‚Äôd actually see something like this live:\n",
        "\n",
        "```\n",
        "LLM: {\"tool\": \"add_two_numbers\", \"arguments\": {\"x\": 2, \"y\": 3}}\n",
        "ToolNode executing add_two_numbers...\n",
        "ToolNode result: {\"result\": 5}\n",
        "LLM: \"The answer is 5.\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ TL;DR\n",
        "\n",
        "* The **LLM doesn‚Äôt ‚Äúguess‚Äù text** like `\"call add_two_numbers with 2 and 3\"`.\n",
        "* Instead, it **emits structured JSON** that matches the tool schema.\n",
        "* LangGraph executes the function, merges results into `state`, and passes them back into the reasoning loop.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xojq5wXulHNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. `builder.set_entry_point(\"math\")`\n",
        "\n",
        "This tells LangGraph:\n",
        "üëâ *‚ÄúWhen this graph starts, execution begins at the node called `math`.‚Äù*\n",
        "\n",
        "* A **graph can have many nodes**, but you need to pick a **starting node**.\n",
        "* That‚Äôs your **entry point** ‚Äî like `main()` in a program or the first step in a workflow.\n",
        "* Without this, LangGraph wouldn‚Äôt know where to begin.\n",
        "\n",
        "So in our earlier example:\n",
        "\n",
        "```python\n",
        "builder.set_entry_point(\"math\")\n",
        "```\n",
        "\n",
        "means:\n",
        "\n",
        "* Start execution at the node we registered as `\"math\"` (the ToolNode wrapping `add_two_numbers`).\n",
        "\n",
        "---\n",
        "\n",
        "## 2. `builder.add_edge(\"math\", END)`\n",
        "\n",
        "This wires the graph‚Äôs flow.\n",
        "üëâ *‚ÄúAfter the `math` node runs, go to the special node `END`.‚Äù*\n",
        "\n",
        "* In LangGraph, `END` is a **sentinel** that represents graph termination.\n",
        "* You can wire multiple nodes to `END`, or you can wire them to other nodes for longer workflows.\n",
        "\n",
        "So here:\n",
        "\n",
        "```python\n",
        "builder.add_edge(\"math\", END)\n",
        "```\n",
        "\n",
        "means:\n",
        "\n",
        "* After `math` runs, stop execution.\n",
        "* If you didn‚Äôt wire this edge, the graph would never know when to stop.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Putting It Together\n",
        "\n",
        "The combination:\n",
        "\n",
        "```python\n",
        "builder.set_entry_point(\"math\")\n",
        "builder.add_edge(\"math\", END)\n",
        "```\n",
        "\n",
        "translates to:\n",
        "\n",
        "> ‚ÄúWhen the graph starts, run the `math` node. Once it‚Äôs done, terminate the graph.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Bigger Picture\n",
        "\n",
        "This is where **LangGraph feels orchestration-friendly**:\n",
        "\n",
        "* You‚Äôre explicitly drawing a **flowchart in code**:\n",
        "\n",
        "  * **Nodes** = tasks/tools\n",
        "  * **Edges** = what happens after each task\n",
        "* `set_entry_point` = ‚Äústart node‚Äù\n",
        "* `add_edge(..., END)` = ‚Äústop after this step‚Äù\n",
        "\n",
        "In a more complex graph, you might see:\n",
        "\n",
        "```python\n",
        "builder.set_entry_point(\"create_plan\")\n",
        "builder.add_edge(\"create_plan\", \"track_progress\")\n",
        "builder.add_edge(\"track_progress\", \"finish\")\n",
        "builder.add_edge(\"finish\", END)\n",
        "```\n",
        "\n",
        "This literally encodes:\n",
        "\n",
        "> ‚ÄúStart with planning ‚Üí then track progress ‚Üí then finish ‚Üí then stop.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **TL;DR**\n",
        "\n",
        "* `set_entry_point(\"math\")` ‚Üí defines the starting node.\n",
        "* `add_edge(\"math\", END)` ‚Üí defines that after this node runs, the graph ends.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xgMyHeYUlep9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è Complex Orchestrator Skeleton\n",
        "\n",
        "Let‚Äôs sketch out a **complex orchestrator agent** structure. I‚Äôll use **placeholders** for the node functions so you can focus on the *graph layout*. You‚Äôre exactly right ‚Äî the **structure stays the same** (entry point, nodes, edges, END), but as your orchestrator grows you add more **nodes** (tools or logic steps), and more **edges** (wiring / flow control).\n",
        "\n",
        "---\n",
        "\n",
        "## üîë Key Takeaways\n",
        "\n",
        "* **Nodes = tasks** (planning, validation, domain tools, progress tracking, summarization).\n",
        "* **Edges = flow** (what happens next).\n",
        "* **Entry point** defines where the agent starts.\n",
        "* **END** defines where execution stops.\n",
        "* You can add **branches** for error handling, retries, or conditional flows.\n",
        "\n",
        "---\n",
        "\n",
        "This is the exact same structure as your minimal example ‚Äî just **more nodes + more edges**.\n",
        "\n",
        "üëâ In real life, each node could be:\n",
        "\n",
        "* A `ToolNode` wrapping LangChain tools\n",
        "* A custom function node\n",
        "* A conditional router (`add_conditional_edges`)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FROTj2t4l4Vy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdhIDLZRR12L"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# 1. Define the State (what the agent carries around)\n",
        "class AgentState(TypedDict):\n",
        "    goal: str\n",
        "    plan: Optional[List[str]]\n",
        "    progress: List[Dict[str, Any]]\n",
        "    messages: List[str]\n",
        "    data: Dict[str, Any]\n",
        "\n",
        "# 2. Create builder\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "# 3. Register Nodes (placeholders for now)\n",
        "builder.add_node(\"create_plan\", create_plan_node)       # planning\n",
        "builder.add_node(\"validate_plan\", validate_plan_node)   # guardrail\n",
        "builder.add_node(\"fetch_data\", fetch_data_node)         # domain tool\n",
        "builder.add_node(\"analyze_data\", analyze_data_node)     # domain tool\n",
        "builder.add_node(\"track_progress\", track_progress_node) # lifecycle\n",
        "builder.add_node(\"summarize_results\", summarize_node)   # output\n",
        "builder.add_node(\"error_handler\", error_handler_node)   # fallback\n",
        "\n",
        "# 4. Wiring (flow control)\n",
        "builder.set_entry_point(\"create_plan\")  # start here\n",
        "\n",
        "# Plan flow\n",
        "builder.add_edge(\"create_plan\", \"validate_plan\")\n",
        "builder.add_edge(\"validate_plan\", \"fetch_data\")\n",
        "\n",
        "# Data workflow\n",
        "builder.add_edge(\"fetch_data\", \"analyze_data\")\n",
        "builder.add_edge(\"analyze_data\", \"track_progress\")\n",
        "\n",
        "# Wrap up\n",
        "builder.add_edge(\"track_progress\", \"summarize_results\")\n",
        "builder.add_edge(\"summarize_results\", END)\n",
        "\n",
        "# Error handling branch\n",
        "builder.add_edge(\"fetch_data\", \"error_handler\")   # if fetch fails\n",
        "builder.add_edge(\"error_handler\", END)            # terminate after handling\n",
        "\n",
        "# 5. Compile graph\n",
        "graph = builder.compile()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéâ That‚Äôs the power of **LangGraph‚Äôs design philosophy** ‚Äî it **collapses all those moving parts in your recipe** (registry, environment, DI, capabilities, context, etc.) into just a **few reusable building blocks**:\n",
        "\n",
        "* **State** ‚Üí the one container for everything (goal, memory, deps, progress, data, ‚Ä¶)\n",
        "* **Nodes** ‚Üí functions or tools that transform state\n",
        "* **Edges** ‚Üí wiring that defines orchestration flow\n",
        "* **Entry point + END** ‚Üí start and stop markers\n",
        "\n",
        "That‚Äôs it. Whether you have 3 nodes (like your minimal recipe) or 30 nodes (like a complex orchestrator), you‚Äôre just repeating the **same 3 concepts**.\n",
        "\n",
        "---\n",
        "\n",
        "## üîë Why It Feels Simpler Than Your Recipe\n",
        "\n",
        "Your recipe was *very well designed*, but it had to reinvent infrastructure pieces:\n",
        "\n",
        "* `ActionContext` (DI + memory container)\n",
        "* `ToolRegistry` (lookup)\n",
        "* `Environment.execute` (dispatch/inject)\n",
        "* `PlanFirstCapability`, `ProgressTrackingCapability` (lifecycle hooks)\n",
        "\n",
        "LangGraph gives you a **unified abstraction** so you don‚Äôt have to build those yourself:\n",
        "\n",
        "* State carries context *and* memory.\n",
        "* ToolNode is the registry + executor.\n",
        "* Edges control lifecycle order.\n",
        "* Reducers handle accumulation automatically.\n",
        "\n",
        "So the mental overhead drops from **10+ unique components** ‚Üí **3 building blocks used repeatedly**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Your Recipe vs LangGraph Side-by-Side\n",
        "\n",
        "| **Your Recipe**                | **LangGraph**                  |\n",
        "| ------------------------------ | ------------------------------ |\n",
        "| ActionContext                  | State (with optional deps key) |\n",
        "| ToolRegistry                   | ToolNode                       |\n",
        "| Environment.execute            | Graph execution runtime        |\n",
        "| PlanFirstCapability            | Conditional edges              |\n",
        "| ProgressTrackingCapability     | Reducer on `progress` field    |\n",
        "| Wiring function (`wire_agent`) | `add_edge`, `set_entry_point`  |\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **The good news**: all the rigor and structure you cared about in your recipe is still there.\n",
        "üí° **The better news**: it‚Äôs easier to visualize, extend, and debug ‚Äî exactly as you noticed.\n",
        "\n"
      ],
      "metadata": {
        "id": "APg3GBrWmvYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rRO5qwfqmyYn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}