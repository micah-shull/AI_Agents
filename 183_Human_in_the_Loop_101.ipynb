{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNnvbudFclwAc5C0MfAeSve",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/183_Human_in_the_Loop_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Human-in-the-Loop (HITL)?\n",
        "\n",
        "HITL lets an agent pause execution to request approval, input, or corrections from a human at critical steps. It decouples planning from execution, introducing checkpoints where human judgment is required.\n",
        "\n",
        "## Why HITL Matters for AI Agents\n",
        "\n",
        "- Trust: enables human review and veto at decision points\n",
        "- Error reduction: catches mistakes before execution (e.g., deleting data or costly API calls)\n",
        "- Risk management: keeps a human in control of high-stakes actions\n",
        "- Regulatory compliance: meets requirements for human oversight\n",
        "- Learning/calibration: provides feedback to improve agent behavior\n",
        "\n",
        "## How HITL Works in AI Agents\n",
        "\n",
        "- Pause-and-approval: ask a human before executing high-risk actions, then either:\n",
        "  - Approve to continue\n",
        "  - Reject to abort\n",
        "  - Modify to execute with changes\n",
        "- Input requests: request missing information from a human\n",
        "- Error recovery: on errors or ambiguous states, ask a human\n",
        "- Periodic check-ins: alerts/notifications at milestones\n",
        "- Escalation workflows: route complex cases to a human\n",
        "\n",
        "## Common HITL Patterns in LangGraph\n",
        "\n",
        "- Tool call authorization: require human OK before using tools\n",
        "- State inspection: expose state for review/editing\n",
        "- Iterative refinement: loop to converge on the outcome\n",
        "- Parallel execution with gates: run some paths while holding others for review\n",
        "\n",
        "This improves confidence and provides oversight on what the agent will execute."
      ],
      "metadata": {
        "id": "q5eVUfCTNIC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Human-in-the-Loop Review Agent"
      ],
      "metadata": {
        "id": "QRvc7PN_S5Oz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_cg02DM7dcz"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Human-in-the-Loop Review Agent\n",
        "\n",
        "This agent demonstrates a simple HITL pattern where:\n",
        "1. Agent generates content using an LLM\n",
        "2. Pauses for human review\n",
        "3. Human can approve, modify, or reject\n",
        "4. Agent proceeds based on human decision\n",
        "\"\"\"\n",
        "\n",
        "from typing import TypedDict, Literal\n",
        "from typing_extensions import Annotated\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "class ReviewAgentState(TypedDict):\n",
        "    \"\"\"State for the Human-in-the-Loop Review Agent\"\"\"\n",
        "    # Input\n",
        "    task: str  # The user's task request\n",
        "\n",
        "    # Generation\n",
        "    generated_content: str  # Content generated by the agent\n",
        "    generation_timestamp: str  # When generation occurred\n",
        "\n",
        "    # Human feedback\n",
        "    human_decision: Literal[\"approve\", \"modify\", \"reject\"]  # What the human decided\n",
        "    human_modifications: str  # Modified content if human chose to modify\n",
        "    review_timestamp: str  # When review occurred\n",
        "\n",
        "    # Output\n",
        "    final_content: str  # Final approved content\n",
        "    status: Literal[\"pending_review\", \"approved\", \"modified\", \"rejected\", \"published\"]  # Current status\n",
        "\n",
        "\n",
        "def generate_content(state: ReviewAgentState) -> ReviewAgentState:\n",
        "    \"\"\"\n",
        "    Generate content based on the user's task\n",
        "    This is where the LLM creates the initial content\n",
        "    \"\"\"\n",
        "    print(f\"\\n🤖 Agent is generating content for task: '{state['task']}'\")\n",
        "\n",
        "    # Initialize the LLM\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "    # Create the system prompt\n",
        "    system_prompt = \"\"\"You are a helpful assistant that generates high-quality content based on user requests.\n",
        "Create comprehensive, accurate, and well-structured responses.\"\"\"\n",
        "\n",
        "    # Create the user prompt\n",
        "    user_prompt = f\"Please help with this task: {state['task']}\"\n",
        "\n",
        "    # Generate the content\n",
        "    messages = [\n",
        "        SystemMessage(content=system_prompt),\n",
        "        HumanMessage(content=user_prompt)\n",
        "    ]\n",
        "\n",
        "    response = llm.invoke(messages)\n",
        "    generated_content = response.content\n",
        "\n",
        "    # Update state\n",
        "    state[\"generated_content\"] = generated_content\n",
        "    state[\"generation_timestamp\"] = datetime.now().isoformat()\n",
        "    state[\"status\"] = \"pending_review\"\n",
        "\n",
        "    print(f\"✅ Content generated! Length: {len(generated_content)} characters\")\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def human_review_required(state: ReviewAgentState) -> ReviewAgentState:\n",
        "    \"\"\"\n",
        "    This node requires human interaction\n",
        "    In a real application, this would send the content to a UI for review\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"👤 HUMAN REVIEW REQUIRED\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nGenerated Content:\")\n",
        "    print(\"-\"*80)\n",
        "    print(state[\"generated_content\"])\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    # In a real application, this would be handled by a web UI or API\n",
        "    # For this demo, we simulate human input\n",
        "    print(\"\\nWhat would you like to do?\")\n",
        "    print(\"1. approve - Use this content as-is\")\n",
        "    print(\"2. modify - Make changes to the content\")\n",
        "    print(\"3. reject - Discard and start over\")\n",
        "\n",
        "    # Simulate human decision (in real app, this comes from UI)\n",
        "    decision = input(\"\\nEnter your decision (approve/modify/reject): \").lower().strip()\n",
        "\n",
        "    while decision not in [\"approve\", \"modify\", \"reject\"]:\n",
        "        print(\"Invalid choice. Please enter 'approve', 'modify', or 'reject'\")\n",
        "        decision = input(\"Enter your decision (approve/modify/reject): \").lower().strip()\n",
        "\n",
        "    state[\"human_decision\"] = decision\n",
        "    state[\"review_timestamp\"] = datetime.now().isoformat()\n",
        "\n",
        "    if decision == \"modify\":\n",
        "        print(\"\\nEnter your modifications (or press Enter to keep original):\")\n",
        "        modifications = input(\"Modifications: \").strip()\n",
        "        state[\"human_modifications\"] = modifications if modifications else state[\"generated_content\"]\n",
        "        state[\"final_content\"] = modifications if modifications else state[\"generated_content\"]\n",
        "        state[\"status\"] = \"modified\"\n",
        "    elif decision == \"approve\":\n",
        "        state[\"final_content\"] = state[\"generated_content\"]\n",
        "        state[\"status\"] = \"approved\"\n",
        "    else:  # reject\n",
        "        state[\"status\"] = \"rejected\"\n",
        "        state[\"final_content\"] = \"\"\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def publish_content(state: ReviewAgentState) -> ReviewAgentState:\n",
        "    \"\"\"\n",
        "    Publish the final content\n",
        "    In a real application, this would save to database, send to CMS, etc.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📤 PUBLISHING CONTENT\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nFinal Content:\")\n",
        "    print(\"-\"*80)\n",
        "    print(state[\"final_content\"])\n",
        "    print(\"-\"*80)\n",
        "    print(\"\\n✅ Content has been published!\")\n",
        "\n",
        "    state[\"status\"] = \"published\"\n",
        "    return state\n",
        "\n",
        "\n",
        "def route_after_review(state: ReviewAgentState) -> str:\n",
        "    \"\"\"\n",
        "    Route based on human decision\n",
        "    \"\"\"\n",
        "    decision = state[\"human_decision\"]\n",
        "\n",
        "    if decision == \"reject\":\n",
        "        return \"reject_flow\"\n",
        "    elif decision == \"modify\":\n",
        "        return \"publish\"\n",
        "    else:  # approve\n",
        "        return \"publish\"\n",
        "\n",
        "\n",
        "def handle_rejection(state: ReviewAgentState) -> ReviewAgentState:\n",
        "    \"\"\"\n",
        "    Handle rejected content\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"❌ CONTENT REJECTED\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nThe generated content was rejected and will not be published.\")\n",
        "    print(\"You can start the process again with a new task.\")\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def create_hitl_review_agent():\n",
        "    \"\"\"\n",
        "    Create and compile the Human-in-the-Loop Review Agent\n",
        "    \"\"\"\n",
        "    # Create the graph\n",
        "    workflow = StateGraph(ReviewAgentState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"generate\", generate_content)\n",
        "    workflow.add_node(\"human_review\", human_review_required)\n",
        "    workflow.add_node(\"publish\", publish_content)\n",
        "    workflow.add_node(\"handle_rejection\", handle_rejection)\n",
        "\n",
        "    # Add edges\n",
        "    workflow.add_edge(\"generate\", \"human_review\")\n",
        "\n",
        "    # Conditional edge based on human decision\n",
        "    workflow.add_conditional_edges(\n",
        "        \"human_review\",\n",
        "        route_after_review,\n",
        "        {\n",
        "            \"publish\": \"publish\",\n",
        "            \"reject_flow\": \"handle_rejection\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Both publish and handle_rejection lead to END\n",
        "    workflow.add_edge(\"publish\", END)\n",
        "    workflow.add_edge(\"handle_rejection\", END)\n",
        "\n",
        "    # Set entry point\n",
        "    workflow.set_entry_point(\"generate\")\n",
        "\n",
        "    # Compile with memory for state persistence\n",
        "    memory = MemorySaver()\n",
        "    compiled_workflow = workflow.compile(checkpointer=memory)\n",
        "\n",
        "    return compiled_workflow\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Demo the HITL Review Agent\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🚀 Human-in-the-Loop Review Agent Demo\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Create the agent\n",
        "    agent = create_hitl_review_agent()\n",
        "\n",
        "    # Get user task\n",
        "    print(\"\\nWhat would you like the agent to help you with?\")\n",
        "    print(\"Example: 'Write a professional email to request a meeting'\")\n",
        "    task = input(\"\\nEnter your task: \").strip()\n",
        "\n",
        "    if not task:\n",
        "        print(\"No task provided. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Initial state\n",
        "    initial_state = {\n",
        "        \"task\": task,\n",
        "        \"generated_content\": \"\",\n",
        "        \"generation_timestamp\": \"\",\n",
        "        \"human_decision\": \"approve\",\n",
        "        \"human_modifications\": \"\",\n",
        "        \"review_timestamp\": \"\",\n",
        "        \"final_content\": \"\",\n",
        "        \"status\": \"pending_review\"\n",
        "    }\n",
        "\n",
        "    # Run the agent\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"Starting agent workflow...\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    result = agent.invoke(initial_state)\n",
        "\n",
        "    # Display final results\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"📊 FINAL RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Status: {result['status']}\")\n",
        "    print(f\"Task: {result['task']}\")\n",
        "    if result[\"status\"] in [\"approved\", \"modified\", \"published\"]:\n",
        "        print(f\"Final Content: {result['final_content'][:100]}...\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Human-in-the-Loop Review Agent - Workflow\n",
        "\n",
        "## Visual Flow\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────┐\n",
        "│                        START                                │\n",
        "│              User provides task                             │\n",
        "└────────────────────┬────────────────────────────────────────┘\n",
        "                     │\n",
        "                     ▼\n",
        "        ┌────────────────────────┐\n",
        "        │   STATE CREATED         │\n",
        "        │   - task: \"...\"         │\n",
        "        │   - status: pending     │\n",
        "        └────────────┬────────────┘\n",
        "                     │\n",
        "                     ▼\n",
        "      ┌──────────────────────────────────┐\n",
        "      │   NODE: generate_content()       │\n",
        "      │                                   │\n",
        "      │   🤖 LLM generates content        │\n",
        "      │   📝 Updates state:               │\n",
        "      │      - generated_content          │\n",
        "      │      - generation_timestamp       │\n",
        "      │      - status: pending_review     │\n",
        "      └────────────┬───────────────────────┘\n",
        "                   │\n",
        "                   ▼\n",
        "      ┌──────────────────────────────────┐\n",
        "      │   NODE: human_review_required()   │\n",
        "      │                                   │\n",
        "      │   👤 HUMAN INTERACTION            │\n",
        "      │   Shows generated content         │\n",
        "      │   Asks for decision:              │\n",
        "      │     - approve                     │\n",
        "      │     - modify                      │\n",
        "      │     - reject                      │\n",
        "      │                                   │\n",
        "      │   📝 Updates state:               │\n",
        "      │      - human_decision             │\n",
        "      │      - human_modifications        │\n",
        "      │      - review_timestamp           │\n",
        "      └──────┬────────────────────────────┘\n",
        "             │\n",
        "             ├──────────────────────────────────┬──────────────┐\n",
        "             │                                  │              │\n",
        "             ▼                                  ▼              ▼\n",
        "      ┌──────────────┐                  ┌───────────────┐  ┌──────────────┐\n",
        "      │   APPROVE    │                  │   MODIFY      │  │   REJECT     │\n",
        "      │              │                  │               │  │              │\n",
        "      │ Sets:        │                  │ Sets:         │  │ Sets:        │\n",
        "      │ - final_content │               │ - final_content│ │ - status:    │\n",
        "      │ - status:    │                  │ - status:     │ │   rejected   │\n",
        "      │   approved   │                  │   modified    │ │ - final: \"\"   │\n",
        "      └──────┬───────┘                  └───────┬───────┘  └──────┬───────┘\n",
        "             │                                  │                  │\n",
        "             └──────────────┬───────────────────┘                  │\n",
        "                            │                                      │\n",
        "                            ▼                                      ▼\n",
        "      ┌────────────────────────────────────────┐    ┌──────────────────────────┐\n",
        "      │   ROUTE: route_after_review()           │    │   NODE:                  │\n",
        "      │                                          │    │   handle_rejection()     │\n",
        "      │   Returns:                              │    │                          │\n",
        "      │   - \"publish\" (if approve/modify)       │    │   Shows rejection msg    │\n",
        "      │   - \"reject_flow\" (if reject)           │    │   Updates status         │\n",
        "      └──────┬──────────────────┬───────────────┘    └─────────────┬────────────┘\n",
        "             │                  │                                  │\n",
        "             │                  │                                  │\n",
        "             ▼                  ▼                                  │\n",
        "      ┌──────────────────┐  ┌───────────────────────────────┐    │\n",
        "      │   NODE:          │  │   NODE:                       │    │\n",
        "      │   publish()      │  │   publish()                   │    │\n",
        "      │                  │  │                               │    │\n",
        "      │   📤 Publishes   │  │   📤 Publishes modified       │    │\n",
        "      │   approved content│  │   content                     │    │\n",
        "      │                  │  │                               │    │\n",
        "      │   Updates:       │  │   Updates:                    │    │\n",
        "      │   - status:      │  │   - status:                   │    │\n",
        "      │     published    │  │     published                 │    │\n",
        "      └────────┬─────────┘  └───────┬───────────────────────┘    │\n",
        "               │                    │                            │\n",
        "               └────────────────────┴────────────────────────────┘\n",
        "                                    │\n",
        "                                    ▼\n",
        "                            ┌───────────────┐\n",
        "                            │      END      │\n",
        "                            └───────────────┘\n",
        "```\n",
        "\n",
        "## State Transitions\n",
        "\n",
        "```\n",
        "PENDING → PENDING_REVIEW → APPROVED/MODIFIED/REJECTED → PUBLISHED/REJECTED\n",
        "```\n",
        "\n",
        "## Files Created\n",
        "\n",
        "- `agents/hitl_review_agent.py` - Main agent implementation\n",
        "- `config.py` - Configuration and API key loading\n",
        "- `demo_hitl.py` - Demo script to run the agent\n",
        "- `agents/README.md` - Detailed documentation\n",
        "- `verify_setup.py` - Setup verification script\n"
      ],
      "metadata": {
        "id": "uwof4Bl1TSow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is exactly the kind of **minimal Human-in-the-Loop (HITL) prototype** that lets you *learn the core interaction mechanics* before layering on risk logic or adaptive automation.\n",
        "\n",
        "Here’s what you should focus on now while working with this simplified agent in **Cursor** 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 1. Understand the Core HITL Lifecycle\n",
        "\n",
        "This version isolates the essence of HITL:\n",
        "\n",
        "| Stage                     | Who Acts | Focus                                           |\n",
        "| ------------------------- | -------- | ----------------------------------------------- |\n",
        "| `generate_content()`      | 🤖 AI    | Creates a draft response                        |\n",
        "| `human_review_required()` | 👤 Human | Reviews, approves, modifies, or rejects         |\n",
        "| `publish_content()`       | 🤖 AI    | Executes next step (publishing) based on review |\n",
        "| `handle_rejection()`      | 🤖 AI    | Stops workflow and logs outcome                 |\n",
        "\n",
        "👉 **Lesson:** This pattern is the “atomic unit” of HITL — a clear *handoff → review → return* loop.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧱 2. Focus on the *State Transitions*\n",
        "\n",
        "Your `ReviewAgentState` drives everything.\n",
        "Notice that **every node updates state** and uses it for the next decision.\n",
        "\n",
        "Key transitions:\n",
        "\n",
        "```\n",
        "pending_review → (approve/modify/reject) → published or rejected\n",
        "```\n",
        "\n",
        "🧩 **Why it matters:**\n",
        "State management is how multi-turn workflows (AI ↔ Human) stay consistent.\n",
        "Focus on ensuring:\n",
        "\n",
        "* Each node writes all required fields.\n",
        "* Transitions never skip required data (e.g., timestamps, decisions).\n",
        "* “Status” is always truthful — useful for audit or UI later.\n",
        "\n",
        "---\n",
        "\n",
        "## ⚙️ 3. Separate *AI Output Generation* from *Human Governance*\n",
        "\n",
        "Even in this tiny agent, keep a mental boundary:\n",
        "\n",
        "* **AI = producer**\n",
        "* **Human = regulator**\n",
        "\n",
        "Focus on:\n",
        "\n",
        "* The *moment of control transfer* — when human input is required.\n",
        "* How the system pauses, captures, and resumes.\n",
        "\n",
        "👉 **Exercise:** Add a `print()` or log after each state transition to visualize when control passes between AI and human.\n",
        "This helps you see the flow of authority — a foundational HITL pattern.\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 4. Experiment with Different Human Decisions\n",
        "\n",
        "Run several test passes in Cursor:\n",
        "\n",
        "| Decision  | Expected Path                        | What to Observe                     |\n",
        "| --------- | ------------------------------------ | ----------------------------------- |\n",
        "| `approve` | generate → review → publish          | Simple auto-flow                    |\n",
        "| `modify`  | generate → review → modify → publish | State gets updated with new content |\n",
        "| `reject`  | generate → review → handle_rejection | Stops workflow cleanly              |\n",
        "\n",
        "Watch for:\n",
        "\n",
        "* Proper routing via `route_after_review()`\n",
        "* Status consistency (`modified` → `published`)\n",
        "* That no path leaves the state incomplete\n",
        "\n",
        "🧩 **Why:**\n",
        "Debugging these transitions teaches you how conditional routing (via LangGraph) mirrors *decision matrices* in full HITL systems.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 5. Strengthen the Human Interface Layer\n",
        "\n",
        "Right now, human review happens via console `input()`.\n",
        "This is the perfect time to experiment with:\n",
        "\n",
        "* **Replacing CLI input with a UI or API endpoint** (e.g., Flask, FastAPI)\n",
        "* **Storing decisions** in a small database or JSON log\n",
        "* **Tracking timestamps** to measure review latency\n",
        "\n",
        "🧩 **Goal:**\n",
        "Understand the engineering of the “pause and wait for human” moment — it’s the hardest part to scale later.\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 6. Add Lightweight Observability\n",
        "\n",
        "Before adding risk or confidence metrics, instrument the basics:\n",
        "\n",
        "```python\n",
        "print(f\"[{datetime.now()}] Status changed to {state['status']} by {state['human_decision']}\")\n",
        "```\n",
        "\n",
        "Optionally, append to a `hitl_log.json` file for later review.\n",
        "\n",
        "🧩 **Goal:**\n",
        "Build the muscle of **auditing and visibility**, even for toy systems.\n",
        "In real HITL pipelines, this becomes compliance-critical.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧩 7. Prepare for Next-Level Learning\n",
        "\n",
        "Once you fully grasp this simple loop, you’ll be ready to extend it with:\n",
        "\n",
        "| Upgrade                | Why                                                |\n",
        "| ---------------------- | -------------------------------------------------- |\n",
        "| Add confidence scoring | To trigger HITL automatically based on uncertainty |\n",
        "| Add risk categories    | To simulate financial/security sensitivity         |\n",
        "| Add feedback logging   | To train model or tune thresholds later            |\n",
        "| Parallel human review  | To simulate queue-based workflows                  |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Summary — What to Focus On *Right Now*\n",
        "\n",
        "1. **Trace state transitions** and confirm data flow is consistent.\n",
        "2. **Observe the control handoff** between AI and human.\n",
        "3. **Experiment** with each review decision to validate routing logic.\n",
        "4. **Instrument logging** to watch the workflow in action.\n",
        "5. **Plan the next layer** (confidence/risk scoring) once this loop feels intuitive.\n",
        "\n"
      ],
      "metadata": {
        "id": "tBdDthfBUFfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Results\n"
      ],
      "metadata": {
        "id": "9XCwPTsskBn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac LG_Cursor_007_HITL % python3 demo_hitl.py\n",
        "🔍 LangSmith tracing is enabled\n",
        "📊 Project: my_project_name\n",
        "🌐 View traces at: https://smith.langchain.com\n",
        "\n",
        "================================================================================\n",
        "🚀 Human-in-the-Loop Review Agent Demo\n",
        "================================================================================\n",
        "\n",
        "What would you like the agent to help you with?\n",
        "Example: 'Write a professional email to request a meeting'\n",
        "\n",
        "Can you tell me why human in the loop agents are becoming more valued by companies trying to adopt agentic AI?\n",
        "\n",
        "================================================================================\n",
        "Starting agent workflow...\n",
        "================================================================================\n",
        "\n",
        "\n",
        "🤖 Agent is generating content for task: 'Can you tell me why human in the loop agents are becoming more valued by companies trying to adopt agentic AI?Can you tell me why human in the loop agents are becoming more valued by companies trying to adopt agentic AI?'\n",
        "✅ Content generated! Length: 4000 characters\n",
        "\n",
        "================================================================================\n",
        "👤 HUMAN REVIEW REQUIRED\n",
        "================================================================================\n",
        "\n",
        "Generated Content:\n",
        "--------------------------------------------------------------------------------\n",
        "Certainly! The concept of human-in-the-loop (HITL) agents is gaining traction in the realm of agentic AI, where autonomous systems are designed to perform tasks typically associated with human intelligence. Here are several reasons why companies are increasingly valuing HITL agents in their AI adoption strategies:\n",
        "\n",
        "### 1. **Quality Control and Accuracy**\n",
        "Human-in-the-loop systems enable continuous oversight and intervention by human operators, which can significantly enhance the accuracy and reliability of AI outputs. In tasks that require nuanced understanding or complex decision-making, human involvement helps mitigate errors that purely automated systems might make.\n",
        "\n",
        "### 2. **Ethical Oversight**\n",
        "As AI becomes more integrated into critical decision-making processes, ethical considerations become paramount. HITL systems allow for human judgment to guide AI behavior, ensuring that decisions are made in accordance with ethical standards and societal norms. This is particularly important in sensitive areas such as healthcare, finance, and law enforcement.\n",
        "\n",
        "### 3. **Improved Learning and Adaptation**\n",
        "HITL agents facilitate better machine learning processes by providing feedback that helps refine AI models. Humans can identify edge cases or unexpected scenarios that the AI might not have been trained on, thus improving the system’s learning and adaptability over time. This is essential for developing robust AI systems capable of functioning in dynamic environments.\n",
        "\n",
        "### 4. **User Trust and Acceptance**\n",
        "The involvement of humans in the decision-making loop can enhance user trust in AI systems. When users know that a human is overseeing AI decisions, they are more likely to feel comfortable relying on these technologies. This is especially crucial in sectors where public trust is vital, such as healthcare and autonomous vehicles.\n",
        "\n",
        "### 5. **Handling Complex Situations**\n",
        "AI systems often struggle with ambiguity and complexity. Human-in-the-loop frameworks allow for intervention when the AI encounters situations that it cannot adequately handle on its own. This flexibility is key to maintaining operational effectiveness, especially in unpredictable or rapidly changing contexts.\n",
        "\n",
        "### 6. **Regulatory Compliance**\n",
        "Many industries face strict regulatory requirements concerning data handling, decision-making processes, and accountability. HITL agents can help ensure compliance by providing a clear audit trail and accountability for decisions made by AI systems, thus reducing legal and compliance risks for organizations.\n",
        "\n",
        "### 7. **Enhanced Customization and Personalization**\n",
        "Human input can guide AI systems to better understand individual user needs, preferences, and contexts. This is particularly valuable in customer service, marketing, and personalized healthcare, where tailored interactions can lead to significantly improved outcomes.\n",
        "\n",
        "### 8. **Crisis Management and Contingency Planning**\n",
        "In scenarios involving crisis management or high-stakes decisions, having a human in the loop can be crucial. Humans can apply judgment and experience to make decisions that an AI might not be equipped to handle alone, ensuring better outcomes in critical situations.\n",
        "\n",
        "### 9. **Collaboration Between Humans and AI**\n",
        "HITL systems promote a collaborative approach between humans and AI, leveraging the strengths of both. While AI excels at processing large amounts of data quickly, humans bring creativity, empathy, and contextual understanding to the table. This synergy can lead to innovative solutions and improved performance.\n",
        "\n",
        "### Conclusion\n",
        "As companies increasingly recognize the complexities and ethical implications of deploying AI, the value of human-in-the-loop agents has become more apparent. By combining human oversight with the efficiency of AI, organizations can create more reliable, ethical, and effective systems. This hybrid approach not only enhances operational capabilities but also addresses the multifaceted challenges associated with agentic AI.\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "What would you like to do?\n",
        "1. approve - Use this content as-is\n",
        "2. modify - Make changes to the content\n",
        "3. reject - Discard and start over\n",
        "\n",
        "Enter your decision (approve/modify/reject): approve\n",
        "\n",
        "================================================================================\n",
        "📤 PUBLISHING CONTENT\n",
        "================================================================================\n",
        "\n",
        "Final Content:\n",
        "--------------------------------------------------------------------------------\n",
        "Certainly! The concept of human-in-the-loop (HITL) agents is gaining traction in the realm of agentic AI, where autonomous systems are designed to perform tasks typically associated with human intelligence. Here are several reasons why companies are increasingly valuing HITL agents in their AI adoption strategies:\n",
        "\n",
        "### 1. **Quality Control and Accuracy**\n",
        "Human-in-the-loop systems enable continuous oversight and intervention by human operators, which can significantly enhance the accuracy and reliability of AI outputs. In tasks that require nuanced understanding or complex decision-making, human involvement helps mitigate errors that purely automated systems might make.\n",
        "\n",
        "### 2. **Ethical Oversight**\n",
        "As AI becomes more integrated into critical decision-making processes, ethical considerations become paramount. HITL systems allow for human judgment to guide AI behavior, ensuring that decisions are made in accordance with ethical standards and societal norms. This is particularly important in sensitive areas such as healthcare, finance, and law enforcement.\n",
        "\n",
        "### 3. **Improved Learning and Adaptation**\n",
        "HITL agents facilitate better machine learning processes by providing feedback that helps refine AI models. Humans can identify edge cases or unexpected scenarios that the AI might not have been trained on, thus improving the system’s learning and adaptability over time. This is essential for developing robust AI systems capable of functioning in dynamic environments.\n",
        "\n",
        "### 4. **User Trust and Acceptance**\n",
        "The involvement of humans in the decision-making loop can enhance user trust in AI systems. When users know that a human is overseeing AI decisions, they are more likely to feel comfortable relying on these technologies. This is especially crucial in sectors where public trust is vital, such as healthcare and autonomous vehicles.\n",
        "\n",
        "### 5. **Handling Complex Situations**\n",
        "AI systems often struggle with ambiguity and complexity. Human-in-the-loop frameworks allow for intervention when the AI encounters situations that it cannot adequately handle on its own. This flexibility is key to maintaining operational effectiveness, especially in unpredictable or rapidly changing contexts.\n",
        "\n",
        "### 6. **Regulatory Compliance**\n",
        "Many industries face strict regulatory requirements concerning data handling, decision-making processes, and accountability. HITL agents can help ensure compliance by providing a clear audit trail and accountability for decisions made by AI systems, thus reducing legal and compliance risks for organizations.\n",
        "\n",
        "### 7. **Enhanced Customization and Personalization**\n",
        "Human input can guide AI systems to better understand individual user needs, preferences, and contexts. This is particularly valuable in customer service, marketing, and personalized healthcare, where tailored interactions can lead to significantly improved outcomes.\n",
        "\n",
        "### 8. **Crisis Management and Contingency Planning**\n",
        "In scenarios involving crisis management or high-stakes decisions, having a human in the loop can be crucial. Humans can apply judgment and experience to make decisions that an AI might not be equipped to handle alone, ensuring better outcomes in critical situations.\n",
        "\n",
        "### 9. **Collaboration Between Humans and AI**\n",
        "HITL systems promote a collaborative approach between humans and AI, leveraging the strengths of both. While AI excels at processing large amounts of data quickly, humans bring creativity, empathy, and contextual understanding to the table. This synergy can lead to innovative solutions and improved performance.\n",
        "\n",
        "### Conclusion\n",
        "As companies increasingly recognize the complexities and ethical implications of deploying AI, the value of human-in-the-loop agents has become more apparent. By combining human oversight with the efficiency of AI, organizations can create more reliable, ethical, and effective systems. This hybrid approach not only enhances operational capabilities but also addresses the multifaceted challenges associated with agentic AI.\n",
        "--------------------------------------------------------------------------------\n",
        "\n",
        "✅ Content has been published!\n",
        "\n",
        "================================================================================\n",
        "📊 FINAL RESULTS\n",
        "================================================================================\n",
        "Status: published\n",
        "Task: Can you tell me why human in the loop agents are becoming more valued by companies trying to adopt agentic AI?Can you tell me why human in the loop agents are becoming more valued by companies trying to adopt agentic AI?\n",
        "Final Content: Certainly! The concept of human-in-the-loop (HITL) agents is gaining traction in the realm of agenti...\n",
        "================================================================================\n",
        "\n"
      ],
      "metadata": {
        "id": "C_H7TlssUSv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the separation of concerns principle. Every file has a single, clear job.\n",
        "\n",
        "Single responsibility per file\n",
        "Consider a data science workflow:\n",
        "\n",
        "```python\n",
        "# BAD: Everything in one file\n",
        "analysis.py  # 500 lines doing EVERYTHING\n",
        "# - Loads data\n",
        "# - Cleans data\n",
        "# - Runs ML models\n",
        "# - Creates visualizations\n",
        "# - Generates reports\n",
        "# - Handles errors\n",
        "# - Configures database\n",
        "```\n",
        "\n",
        "Hard to:\n",
        "- Find where something happens\n",
        "- Test individual steps\n",
        "- Reuse pieces elsewhere\n",
        "- Fix one part without risking another\n",
        "\n",
        "```python\n",
        "# GOOD: Separated by responsibility\n",
        "config.py          # Only configuration settings\n",
        "data_loader.py     # Only loads data\n",
        "data_cleaner.py   # Only cleans data\n",
        "model_trainer.py   # Only trains models\n",
        "visualizer.py      # Only creates plots\n",
        "report_generator.py # Only generates reports\n",
        "```\n",
        "\n",
        "Our HITL files in detail\n",
        "\n",
        "\n",
        "Benefits of separation:\n",
        "\n",
        "1) config.py — environment setup\n",
        "```python\n",
        "# Job: ONLY setup and configuration\n",
        "# Size: ~26 lines\n",
        "# Analogy: Like a data_pipeline.py that ONLY loads credentials\n",
        "```\n",
        "Purpose: Load secrets without executing logic. Why separate? Allows updating credentials without changing application code.\n",
        "\n",
        "2) agents/hitl_review_agent.py — core logic\n",
        "```python\n",
        "# Job: The actual agent implementation\n",
        "# Size: ~269 lines\n",
        "# Analogy: Like your main analysis notebook with all the business logic\n",
        "```\n",
        "Purpose: Houses agent nodes, state, and workflow. Why separate? Reusable, testable, and easy to navigate.\n",
        "\n",
        "3) demo_hitl.py — entry point\n",
        "```python\n",
        "# Job: ONLY runs the agent\n",
        "# Size: ~22 lines\n",
        "# Analogy: Like a \"Run Analysis\" script that imports your functions\n",
        "```\n",
        "Purpose: Minimal entry point; keep orchestration separate from logic.\n",
        "\n",
        "4) verify_setup.py — diagnostics\n",
        "```python\n",
        "# Job: Check if everything is installed correctly\n",
        "# Size: ~60 lines\n",
        "# Analogy: Like checking your libraries before running analysis\n",
        "```\n",
        "Purpose: Validate environment before running the agent.\n",
        "\n",
        "Data Science Analogy\n",
        "In a project like a model training pipeline, split by role:\n",
        "\n",
        "```\n",
        "project/\n",
        "├── config.py                    # Data paths, model parameters\n",
        "├── data_loader.py               # Load raw data\n",
        "├── data_cleaner.py             # Clean/preprocess data\n",
        "├── feature_engineering.py     # Create features\n",
        "├── model_trainer.py            # Train models\n",
        "├── evaluator.py                # Evaluate performance\n",
        "├── visualizer.py               # Create plots\n",
        "└── run_pipeline.py             # Main script to run everything\n",
        "```\n",
        "\n",
        "When to separate\n",
        "- Behavior: different functions\n",
        "- Change cadence: config changes, logic stays\n",
        "- Reuse: share across scripts\n",
        "- Size: >100 lines or wide responsibility; split\n",
        "- Testing: isolate tests\n",
        "- Debugging: keep concerns clean\n",
        "\n",
        "\n",
        "## Summary for Data Scientists\n",
        "\n",
        "### The Core Idea:\n",
        "\n",
        "**Think of code organization like organizing a data science project:**\n",
        "\n",
        "```\n",
        "❌ BAD: One notebook for EVERYTHING\n",
        "    analysis.ipynb (does EDA, modeling, viz, reports, everything!)\n",
        "\n",
        "✅ GOOD: Separate notebooks for each purpose\n",
        "    eda.ipynb       # Only exploratory data analysis\n",
        "    modeling.ipynb  # Only model training\n",
        "    visualization.ipynb  # Only plotting\n",
        "    report.ipynb    # Only generating reports\n",
        "```\n",
        "\n",
        "### Applied to Our HITL Agent:\n",
        "\n",
        "```\n",
        "❌ BAD: Everything in hitl.py (500+ lines)\n",
        "    - Load API keys\n",
        "    - Check dependencies  \n",
        "    - Define agent state\n",
        "    - Run agent logic\n",
        "    - Main entry point\n",
        "\n",
        "✅ GOOD: Separated by purpose\n",
        "    config.py         → Load API keys (like loading data paths)\n",
        "    verify_setup.py  → Check deps (like checking data quality)\n",
        "    hitl_agent.py    → Agent logic (like your model training)\n",
        "    demo_hitl.py     → Entry point (like run_experiment.py)\n",
        "```\n",
        "\n",
        "### Decision Rules:\n",
        "\n",
        "Create a new file if:\n",
        "1. It serves a different purpose (config vs logic vs entry point)\n",
        "2. It changes for different reasons (credentials vs algorithm)\n",
        "3. You might reuse it elsewhere\n",
        "4. It’s getting long (>150 lines or hard to scan)\n",
        "\n",
        "Keep in the same file if:\n",
        "1. Related functions (helpers for a main function)\n",
        "2. Small and cohesive\n",
        "3. Tightly coupled (shouldn’t be separated)\n",
        "\n",
        "### Files I Created:\n",
        "\n",
        "1. `CODING_ORGANIZATION.md` — when to split vs keep files together\n",
        "2. `FILE_ARCHITECTURE.md` — how our files connect and import\n",
        "\n",
        "Principles follow the Python adage: “One file, one clear purpose.”"
      ],
      "metadata": {
        "id": "lZ5DqwnEjxQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Lessons: Building Agents with Multiple Files\n",
        "\n",
        "## 🎯 The Top 5 Lessons You Should Learn\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 1: **Separate Configuration from Logic** 🗂️\n",
        "\n",
        "### ❌ DON'T DO THIS:\n",
        "```python\n",
        "# agents/hitl_review_agent.py\n",
        "OPENAI_API_KEY = \"sk-...\"  # API key in code!\n",
        "\n",
        "def generate_content():\n",
        "    llm = ChatOpenAI(api_key=OPENAI_API_KEY)  # Hard-coded\n",
        "    ...\n",
        "```\n",
        "\n",
        "### ✅ DO THIS:\n",
        "```python\n",
        "# config.py\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('API_KEYS.env')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# agents/hitl_review_agent.py  \n",
        "from config import OPENAI_API_KEY  # Import, don't hard-code\n",
        "\n",
        "def generate_content():\n",
        "    llm = ChatOpenAI(api_key=OPENAI_API_KEY)\n",
        "    ...\n",
        "```\n",
        "\n",
        "**Why?**\n",
        "- Secrets stay out of code\n",
        "- Change config without touching agent logic\n",
        "- Different configs for dev/prod\n",
        "- Credentials in `.gitignore`\n",
        "\n",
        "**Analogy:** Like keeping your data paths in `config.json` not in your analysis code.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 2: **Keep Entry Points Simple** 🚀\n",
        "\n",
        "### ❌ DON'T DO THIS:\n",
        "```python\n",
        "# demo_hitl.py (100 lines!)\n",
        "import os\n",
        "from dotenv import load_dotenv  # Config setup\n",
        "load_dotenv('API_KEYS.env')\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "class ReviewAgentState:  # State definition\n",
        "    ...\n",
        "\n",
        "def generate_content():  # Agent logic\n",
        "    ...\n",
        "\n",
        "def main():  # Actually run it\n",
        "    ...\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "### ✅ DO THIS:\n",
        "```python\n",
        "# config.py (26 lines) - ONLY config\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# agents/hitl_review_agent.py (269 lines) - ONLY agent logic\n",
        "class ReviewAgentState: ...\n",
        "def generate_content(): ...\n",
        "def main(): ...\n",
        "\n",
        "# demo_hitl.py (22 lines) - ONLY entry point\n",
        "from config import *\n",
        "from agents.hitl_review_agent import main\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "```\n",
        "\n",
        "**Why?**\n",
        "- Each file has ONE job\n",
        "- Easy to find things\n",
        "- Easy to test each part\n",
        "- Easy to reuse agent in APIs/tests\n",
        "\n",
        "**Analogy:** `run_experiment.py` imports from `model.py`, doesn't contain all the logic.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 3: **Build Reusable Components** 🔄\n",
        "\n",
        "### ❌ DON'T DO THIS:\n",
        "```python\n",
        "# Everything tied to one specific use case\n",
        "def demo_agent():\n",
        "    print(\"Demo mode\")\n",
        "    llm = ChatOpenAI(model=\"gpt-4\")\n",
        "    # Everything hard-coded for demo\n",
        "    ...\n",
        "```\n",
        "\n",
        "### ✅ DO THIS:\n",
        "```python\n",
        "# agents/hitl_review_agent.py\n",
        "def create_hitl_review_agent():  # Returns agent\n",
        "    workflow = StateGraph(ReviewAgentState)\n",
        "    workflow.add_node(\"generate\", generate_content)\n",
        "    # ...\n",
        "    return workflow.compile()\n",
        "\n",
        "def main():  # Demo entry point\n",
        "    agent = create_hitl_review_agent()\n",
        "    # Run it\n",
        "    ...\n",
        "\n",
        "# Used in:\n",
        "# - demo_hitl.py\n",
        "# - api_service.py  \n",
        "# - test_agent.py\n",
        "# - batch_process.py\n",
        "```\n",
        "\n",
        "**Why?**\n",
        "- Same agent, multiple uses\n",
        "- Test without running demo\n",
        "- Use in APIs, batch jobs, etc.\n",
        "- More professional architecture\n",
        "\n",
        "**Analogy:** Like having a `train_model()` function you can import anywhere.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 4: **One File = One Clear Purpose** 🎯\n",
        "\n",
        "### The Question to Ask:\n",
        "\n",
        "**\"What is this file's ONE main job?\"**\n",
        "\n",
        "| File | Main Job | OK? |\n",
        "|------|----------|-----|\n",
        "| `config.py` | Load environment variables | ✅ YES |\n",
        "| `config.py` | Load env vars + train model | ❌ NO - Too many jobs |\n",
        "| `agent.py` | Define agent logic | ✅ YES |\n",
        "| `agent.py` | Define logic + API setup + test | ❌ NO - Too many jobs |\n",
        "| `demo.py` | Run the agent | ✅ YES |\n",
        "| `demo.py` | Run agent + configure everything | ❌ NO - Too many jobs |\n",
        "\n",
        "### The Size Test:\n",
        "\n",
        "```python\n",
        "# If your file is >150 lines...\n",
        "# Ask: \"Does this still serve ONE purpose?\"\n",
        "\n",
        "# agents/hitl_review_agent.py (269 lines)\n",
        "# BUT it only does ONE thing: Agent logic\n",
        "# ✅ Still OK - that's its job\n",
        "\n",
        "# If it did: config + agent + demo + tests\n",
        "# ❌ Too many purposes - split it!\n",
        "```\n",
        "\n",
        "**Why?**\n",
        "- Easy to understand\n",
        "- Easy to find bugs\n",
        "- Easy to modify\n",
        "- Easy to test\n",
        "\n",
        "**Analogy:** One notebook for EDA, one for modeling - don't mix them.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 5: **Use the Import Chain** 🔗\n",
        "\n",
        "### How Files Import Each Other:\n",
        "\n",
        "```\n",
        "User runs demo_hitl.py\n",
        "           ↓\n",
        "    ┌─────────────────┐\n",
        "    │  demo_hitl.py    │  Entry point\n",
        "    │  Import config   │  ← Loads environment\n",
        "    │  Import agent    │  ← Gets agent logic\n",
        "    │  Call main()     │  ← Runs the agent\n",
        "    └────────┬─────────┘\n",
        "             ↓\n",
        "    ┌─────────────────┐\n",
        "    │   config.py     │  Configuration\n",
        "    │   (imports)     │  ← Sets up environment\n",
        "    └────────┬────────┘\n",
        "             ↓\n",
        "    ┌─────────────────┐\n",
        "    │  agent.py       │  Agent logic\n",
        "    │  Uses config    │  ← Gets OPENAI_API_KEY\n",
        "    │  Defines state  │  ← Defines structure\n",
        "    │  Returns agent  │  ← Returns compilable graph\n",
        "    └─────────────────┘\n",
        "```\n",
        "\n",
        "### The Import Flow:\n",
        "\n",
        "```python\n",
        "# 1. demo_hitl.py imports\n",
        "from config import *              # Loads environment\n",
        "from agents.hitl_review_agent import main  # Gets agent\n",
        "\n",
        "# 2. When agent.py imports, it gets:\n",
        "from config import OPENAI_API_KEY  # Already loaded by demo\n",
        "\n",
        "# 3. Clean separation:\n",
        "#    demo → config (environment setup)\n",
        "#    demo → agent (business logic)\n",
        "#    agent → config (uses credentials)\n",
        "```\n",
        "\n",
        "**Why?**\n",
        "- Clear dependencies\n",
        "- One place to load config\n",
        "- Prevents circular imports\n",
        "- Easier debugging\n",
        "\n",
        "**Analogy:** Like importing pandas in your notebook - it's loaded once, everyone uses it.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎓 The Mental Model\n",
        "\n",
        "Think of your agent files like a team:\n",
        "\n",
        "```\n",
        "demo_hitl.py      → The Manager\n",
        "  │                 (orchestrates everything)\n",
        "  ├─ config.py     → The Setup Guy  \n",
        "  │                 (makes sure credentials work)\n",
        "  │\n",
        "  └─ agent.py      → The Worker\n",
        "                     (does the actual job)\n",
        "```\n",
        "\n",
        "Each person has ONE job to do.\n",
        "\n",
        "---\n",
        "\n",
        "## 🚨 Common Mistakes to Avoid\n",
        "\n",
        "### Mistake 1: Mixing Concerns\n",
        "```python\n",
        "# ❌ BAD\n",
        "agent.py:\n",
        "  - Load API keys\n",
        "  - Define state\n",
        "  - Run agent\n",
        "  - Print results\n",
        "  - Handle errors\n",
        "  - Save to database\n",
        "  # TOO MUCH IN ONE FILE!\n",
        "```\n",
        "\n",
        "```python\n",
        "# ✅ GOOD  \n",
        "config.py:\n",
        "  - Load API keys\n",
        "\n",
        "agent.py:\n",
        "  - Define state + logic\n",
        "  \n",
        "demo_hitl.py:\n",
        "  - Run agent\n",
        "  \n",
        "database.py:\n",
        "  - Save results\n",
        "```\n",
        "\n",
        "### Mistake 2: Hard-Coding Values\n",
        "```python\n",
        "# ❌ BAD\n",
        "llm = ChatOpenAI(model=\"gpt-4\", api_key=\"sk-...\")\n",
        "\n",
        "# ✅ GOOD\n",
        "from config import OPENAI_API_KEY\n",
        "llm = ChatOpenAI(model=\"gpt-4\", api_key=OPENAI_API_KEY)\n",
        "```\n",
        "\n",
        "### Mistake 3: No Separation of Entry Points\n",
        "```python\n",
        "# ❌ BAD\n",
        "# Everything in agent.py\n",
        "# Can only run one way\n",
        "\n",
        "# ✅ GOOD\n",
        "# agent.py → Reusable logic\n",
        "# demo_hitl.py → Interactive entry\n",
        "# api_service.py → API entry\n",
        "# test_agent.py → Test entry\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 📋 Quick Checklist\n",
        "\n",
        "When building an agent with multiple files:\n",
        "\n",
        "- [ ] **Config separate?** (API keys in config.py)\n",
        "- [ ] **Agent reusable?** (Can import `from agent import ...`)\n",
        "- [ ] **Entry point simple?** (< 30 lines, just imports + runs)\n",
        "- [ ] **Each file has ONE job?** (Easy to describe in one sentence)\n",
        "- [ ] **Can test without running demo?** (Import agent independently)\n",
        "- [ ] **Can use in different contexts?** (API, batch, interactive)\n",
        "- [ ] **No hard-coded values?** (Use config)\n",
        "- [ ] **Clear imports?** (Easy to understand dependencies)\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 The Bottom Line\n",
        "\n",
        "### The Golden Rule:\n",
        "\n",
        "**\"One file, one purpose. Import to compose.\"**\n",
        "\n",
        "### How to Apply It:\n",
        "\n",
        "1. **Config** → Setup and environment\n",
        "2. **Agent** → The actual logic (reusable)\n",
        "3. **Entry Points** → How to run it (demo, API, test)\n",
        "\n",
        "### The Benefits:\n",
        "\n",
        "✅ **Maintainable** - Easy to find and fix bugs  \n",
        "✅ **Testable** - Can test each part independently  \n",
        "✅ **Reusable** - Import agent in different contexts  \n",
        "✅ **Professional** - Real-world best practices  \n",
        "✅ **Scalable** - Easy to add features without chaos\n",
        "\n",
        "### Think Like a Data Scientist:\n",
        "\n",
        "Just like you separate your analysis into:\n",
        "- `eda.ipynb` → Exploratory data analysis\n",
        "- `modeling.ipynb` → Model training  \n",
        "- `visualization.ipynb` → Plotting\n",
        "- `report.ipynb` → Generate report\n",
        "\n",
        "Separate your agent code into:\n",
        "- `config.py` → Environment setup\n",
        "- `agent.py` → Agent logic\n",
        "- `demo.py` → How to run it\n",
        "\n",
        "**Same principle, different domain!**\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Next Steps\n",
        "\n",
        "1. ✅ You learned WHY to separate files\n",
        "2. ✅ You learned HOW to organize them\n",
        "3. ✅ You learned WHAT goes where\n",
        "4. ✅ You have a working HITL agent as example\n",
        "\n",
        "**Now apply this to YOUR next agent!**\n",
        "\n",
        "Start with this structure:\n",
        "```\n",
        "your_agent/\n",
        "  ├── config.py        # Credentials, settings\n",
        "  ├── your_agent.py    # Agent logic (reusable)\n",
        "  └── run.py           # Entry point\n",
        "```\n",
        "\n",
        "Keep it simple, keep it separate, keep it professional! 🚀\n",
        "\n"
      ],
      "metadata": {
        "id": "dfSWZtFivuib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Lessons: Human-in-the-Loop Agents\n",
        "\n",
        "## 🎯 What You Built & Why It Matters\n",
        "\n",
        "You built a **post-generation review** HITL agent that:\n",
        "1. 🤖 LLM generates content automatically\n",
        "2. 👤 **Pauses for human review** (the HITL part!)\n",
        "3. ✅ Human approves, modifies, or rejects\n",
        "4. 📤 Agent continues based on human decision\n",
        "\n",
        "This pattern is becoming **essential** for enterprise AI adoption.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 1: **HITL is About Control & Trust** 🎛️\n",
        "\n",
        "### Why Companies Want HITL:\n",
        "\n",
        "```\n",
        "Pure Automation (No HITL):\n",
        "Customer: \"AI made a mistake and cost us $50k\"\n",
        "Company: 😱\n",
        "\n",
        "HITL Enabled:\n",
        "Customer: \"AI generated content, human reviewed and approved it\"\n",
        "Company: 😌 \"We have audit trail and human oversight\"\n",
        "\n",
        "Result: Companies TRUST and ADOPT HITL agents\n",
        "```\n",
        "\n",
        "### The Risk Problem:\n",
        "\n",
        "**Without HITL:**\n",
        "- AI might make errors\n",
        "- No human oversight\n",
        "- High risk → slow adoption\n",
        "\n",
        "**With HITL:**\n",
        "- Human reviews before action\n",
        "- Reduces errors\n",
        "- Low risk → faster adoption\n",
        "\n",
        "**Key Insight:** HITL reduces risk, which increases trust, which enables adoption.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 2: **Interrupts = State + Wait** ⏸️\n",
        "\n",
        "### How HITL Works in LangGraph:\n",
        "\n",
        "```python\n",
        "def human_review_required(state: ReviewAgentState) -> ReviewAgentState:\n",
        "    \"\"\"\n",
        "    This is where the magic happens!\n",
        "    \n",
        "    1. Agent PAUSES execution\n",
        "    2. Shows content to human\n",
        "    3. WAITS for human decision\n",
        "    4. Updates state based on decision\n",
        "    5. Returns - agent continues\n",
        "    \"\"\"\n",
        "    print(\"Generated Content:\")\n",
        "    print(state[\"generated_content\"])  # Show to human\n",
        "    \n",
        "    # THIS IS THE HITL MOMENT\n",
        "    decision = input(\"approve/modify/reject: \")  # Wait for human!\n",
        "    \n",
        "    state[\"human_decision\"] = decision  # Update state\n",
        "    return state  # Agent continues based on updated state\n",
        "```\n",
        "\n",
        "### The Flow:\n",
        "\n",
        "```\n",
        "START → Generate → [PAUSE: Show to Human] → Wait for Decision → Continue\n",
        "                                ⬆️\n",
        "                           HITL Happens Here!\n",
        "```\n",
        "\n",
        "**Key Insight:** HITL = Agent pauses → Human decides → State updates → Agent continues\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 3: **Conditional Routing = Different Paths** 🛤️\n",
        "\n",
        "### Without HITL:\n",
        "\n",
        "```python\n",
        "# Simple linear flow\n",
        "START → Generate → Publish → END\n",
        "```\n",
        "\n",
        "### With HITL:\n",
        "\n",
        "```python\n",
        "# Branch based on human decision\n",
        "START → Generate → Human Review → {\n",
        "    Approve  → Publish → END\n",
        "    Modify   → Publish → END  \n",
        "    Reject   → Handle Rejection → END\n",
        "}\n",
        "```\n",
        "\n",
        "### The Code:\n",
        "\n",
        "```python\n",
        "def route_after_review(state: ReviewAgentState) -> str:\n",
        "    \"\"\"Route based on human decision\"\"\"\n",
        "    decision = state[\"human_decision\"]\n",
        "    \n",
        "    if decision == \"reject\":\n",
        "        return \"reject_flow\"\n",
        "    elif decision == \"modify\":\n",
        "        return \"publish\"\n",
        "    else:  # approve\n",
        "        return \"publish\"\n",
        "```\n",
        "\n",
        "**Key Insight:** HITL enables different paths - the agent adapts based on human decision.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 4: **State Captures the Decision** 📝\n",
        "\n",
        "### Why State Matters in HITL:\n",
        "\n",
        "```python\n",
        "class ReviewAgentState(TypedDict):\n",
        "    # INPUT (before HITL)\n",
        "    task: str\n",
        "    generated_content: str\n",
        "    \n",
        "    # HITL HAPPENS HERE\n",
        "    human_decision: Literal[\"approve\", \"modify\", \"reject\"]  # ← Capture decision\n",
        "    human_modifications: str  # ← Capture changes\n",
        "    \n",
        "    # OUTPUT (after HITL)\n",
        "    final_content: str\n",
        "    status: Literal[...]  # ← Current state\n",
        "```\n",
        "\n",
        "### The Decision Flow:\n",
        "\n",
        "```python\n",
        "# 1. Generate content\n",
        "state[\"generated_content\"] = llm_output\n",
        "state[\"status\"] = \"pending_review\"  # ← Waiting for human\n",
        "\n",
        "# 2. HUMAN DECIDES\n",
        "state[\"human_decision\"] = \"modify\"  # ← Human's choice\n",
        "state[\"human_modifications\"] = \"...changes...\"\n",
        "\n",
        "# 3. Agent continues based on decision\n",
        "if state[\"human_decision\"] == \"modify\":\n",
        "    state[\"final_content\"] = state[\"human_modifications\"]\n",
        "    state[\"status\"] = \"modified\"\n",
        "```\n",
        "\n",
        "**Key Insight:** State is the \"memory\" that carries the human decision through the workflow.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 5: **Design the HITL Experience** 👤\n",
        "\n",
        "### ❌ BAD HITL:\n",
        "\n",
        "```python\n",
        "# Confusing!\n",
        "decision = input(\"Enter 1, 2, or 3: \")  # What do these mean?!\n",
        "```\n",
        "\n",
        "### ✅ GOOD HITL:\n",
        "\n",
        "```python\n",
        "# Clear and helpful\n",
        "print(\"Generated Content:\")\n",
        "print(\"-\"*80)\n",
        "print(state[\"generated_content\"])  # Show full context\n",
        "print(\"-\"*80)\n",
        "print(\"\\nWhat would you like to do?\")\n",
        "print(\"1. approve - Use this content as-is\")\n",
        "print(\"2. modify - Make changes to the content\")\n",
        "print(\"3. reject - Discard and start over\")\n",
        "decision = input(\"\\nEnter your decision (approve/modify/reject): \").lower().strip()\n",
        "```\n",
        "\n",
        "### The Experience Matters:\n",
        "\n",
        "- ✅ **Show full context** (what's being reviewed)\n",
        "- ✅ **Clear options** (what can human do)\n",
        "- ✅ **Validate input** (catch typos, handle gracefully)\n",
        "- ✅ **Confirm action** (show what will happen)\n",
        "\n",
        "**Key Insight:** Good HITL = Clear questions + Full context + Simple choices\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 6: **When to Use HITL** 🎯\n",
        "\n",
        "### Use HITL When:\n",
        "\n",
        "✅ **High Stakes** (financial decisions, legal docs)  \n",
        "✅ **Customer-Facing** (published content, customer emails)  \n",
        "✅ **New/Untested Models** (uncertain if output is correct)  \n",
        "✅ **Regulatory Requirements** (need human approval)  \n",
        "✅ **Low Confidence** (AI unsure, human should verify)  \n",
        "✅ **Learning/Improvement** (collect human feedback for training)\n",
        "\n",
        "### Don't Use HITL When:\n",
        "\n",
        "❌ **Low Stakes** (internal tool for quick tasks)  \n",
        "❌ **High Volume** (would overwhelm humans)  \n",
        "❌ **Real-Time Requirements** (can't pause)  \n",
        "❌ **Highly Confident AI** (AI is 99%+ accurate already)\n",
        "\n",
        "### Example Decision Matrix:\n",
        "\n",
        "```\n",
        "Task                    Stakes      Volume     Use HITL?\n",
        "────────────────────────────────────────────────────────\n",
        "Email draft             Medium      High       ✅ Yes\n",
        "Bank transfer           High        Low        ✅ Yes  \n",
        "Data backup             Low         High       ❌ No\n",
        "Content moderation      High        High       ✅ Yes (batch review)\n",
        "Code generation         Low         High       ❌ No\n",
        "```\n",
        "\n",
        "**Key Insight:** HITL should be strategically placed, not everywhere.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 7: **HITL Patterns to Know** 🎨\n",
        "\n",
        "### Pattern 1: Pre-Action Approval (Your Next Build!)\n",
        "\n",
        "```python\n",
        "# Ask BEFORE executing risky action\n",
        "START → Plan Action → [HITL: Approve Action?] → Execute or Cancel\n",
        "```\n",
        "\n",
        "**Use for:** Database writes, API calls, deletions\n",
        "\n",
        "### Pattern 2: Post-Generation Review (What you built!)\n",
        "\n",
        "```python\n",
        "# Ask AFTER generating content\n",
        "START → Generate Content → [HITL: Review Content] → Publish or Reject\n",
        "```\n",
        "\n",
        "**Use for:** Content creation, document generation\n",
        "\n",
        "### Pattern 3: Confidence-Based Escalation\n",
        "\n",
        "```python\n",
        "# Only ask if confidence is low\n",
        "START → Generate → Check Confidence → {\n",
        "    High (>=0.8)   → Auto-approve → Publish\n",
        "    Medium (0.5-0.8) → [HITL Review] → Decision\n",
        "    Low (<0.5)     → [HITL Review] → Decision\n",
        "}\n",
        "```\n",
        "\n",
        "**Use for:** Reducing interruptions when AI is confident\n",
        "\n",
        "### Pattern 4: Multi-Step Review\n",
        "\n",
        "```python\n",
        "# Multiple checkpoints\n",
        "START → Draft → [HITL Review] → Revise → [HITL Review] → Final\n",
        "```\n",
        "\n",
        "**Use for:** Complex documents, important decisions\n",
        "\n",
        "### Pattern 5: Parallel Execution with Gates\n",
        "\n",
        "```python\n",
        "# Some paths can continue, others wait\n",
        "START → Split into paths\n",
        "   ├─ Safe Path → Continue (no HITL)\n",
        "   └─ Risky Path → [HITL Approval] → Continue\n",
        "```\n",
        "\n",
        "**Use for:** Running multiple operations in parallel\n",
        "\n",
        "**Key Insight:** Different tasks need different HITL patterns - choose based on your use case.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 8: **State Management for HITL** 📊\n",
        "\n",
        "### What State Needs to Track:\n",
        "\n",
        "```python\n",
        "class ReviewAgentState(TypedDict):\n",
        "    # BEFORE HITL\n",
        "    task: str\n",
        "    generated_content: str\n",
        "    \n",
        "    # HITL ITSELF (what human sees/decides)\n",
        "    human_decision: Literal[...]\n",
        "    human_modifications: str\n",
        "    human_review_timestamp: str\n",
        "    \n",
        "    # AFTER HITL\n",
        "    final_content: str\n",
        "    status: Literal[\"pending_review\", \"approved\", \"rejected\"]\n",
        "    \n",
        "    # AUDIT TRAIL (important!)\n",
        "    approval_chain: List[Dict]  # Who approved when\n",
        "```\n",
        "\n",
        "### The Audit Trail:\n",
        "\n",
        "```python\n",
        "# Track decisions for compliance\n",
        "state[\"approval_chain\"] = [\n",
        "    {\"timestamp\": \"2025-01-20T10:00:00\", \"action\": \"generated\", \"by\": \"AI\"},\n",
        "    {\"timestamp\": \"2025-01-20T10:05:00\", \"action\": \"modified\", \"by\": \"human\"},\n",
        "    {\"timestamp\": \"2025-01-20T10:06:00\", \"action\": \"approved\", \"by\": \"human\"},\n",
        "]\n",
        "```\n",
        "\n",
        "**Key Insight:** State should capture the full decision journey for auditability.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 9: **Production HITL is Different** 🏭\n",
        "\n",
        "### Your Current Agent (Demo):\n",
        "\n",
        "```python\n",
        "# CLI interaction\n",
        "decision = input(\"Approve/modify/reject: \")\n",
        "```\n",
        "\n",
        "### Production HITL (Real Deployment):\n",
        "\n",
        "```python\n",
        "# Web UI with state persistence\n",
        "@app.post(\"/review/{workflow_id}\")\n",
        "async def review_endpoint(decision: str, modifications: str):\n",
        "    # Resume workflow with decision\n",
        "    workflow.update_state(workflow_id, {\n",
        "        \"human_decision\": decision,\n",
        "        \"human_modifications\": modifications\n",
        "    })\n",
        "    # Continue agent\n",
        "    result = workflow.invoke(None, config={\"configurable\": {\"thread_id\": workflow_id}})\n",
        "    return result\n",
        "```\n",
        "\n",
        "### Production Considerations:\n",
        "\n",
        "- **Async Execution** (agent pauses, waits for web UI)\n",
        "- **State Persistence** (save state in database, not memory)\n",
        "- **Notifications** (alert human when review needed)\n",
        "- **Timeouts** (what if human doesn't respond?)\n",
        "- **Permissions** (who can approve?)\n",
        "- **Audit Logs** (track all decisions)\n",
        "\n",
        "**Key Insight:** Demo HITL is simple; production HITL requires infrastructure.\n",
        "\n",
        "---\n",
        "\n",
        "## Lesson 10: **Testing HITL Agents** 🧪\n",
        "\n",
        "### Test with Mock Decisions:\n",
        "\n",
        "```python\n",
        "def test_approval_flow():\n",
        "    agent = create_hitl_review_agent()\n",
        "    state = {\n",
        "        \"task\": \"test\",\n",
        "        \"generated_content\": \"test content\",\n",
        "        \"human_decision\": \"approve\",  # Mock decision\n",
        "        \"human_modifications\": \"\",\n",
        "        \"status\": \"pending_review\"\n",
        "    }\n",
        "    \n",
        "    result = agent.invoke(state)\n",
        "    assert result[\"status\"] == \"published\"\n",
        "    assert result[\"final_content\"] == \"test content\"\n",
        "\n",
        "def test_modification_flow():\n",
        "    state = {\n",
        "        ...\n",
        "        \"human_decision\": \"modify\",\n",
        "        \"human_modifications\": \"modified content\"\n",
        "    }\n",
        "    result = agent.invoke(state)\n",
        "    assert result[\"final_content\"] == \"modified content\"\n",
        "```\n",
        "\n",
        "**Key Insight:** Test each decision path independently with mock data.\n",
        "\n",
        "---\n",
        "\n",
        "## 🎓 Summary: The Core HITL Lessons\n",
        "\n",
        "1. **HITL reduces risk** → Enables adoption\n",
        "2. **Interrupts pause execution** → Human decides → Continue\n",
        "3. **Conditional routing** → Different paths based on decision\n",
        "4. **State captures decisions** → Carries through workflow\n",
        "5. **Design the experience** → Clear, helpful, validated\n",
        "6. **Use strategically** → Not everywhere, not nowhere\n",
        "7. **Know the patterns** → Pre-approval, post-review, confidence-based\n",
        "8. **State tracks everything** → Including audit trail\n",
        "9. **Production is different** → UI, async, persistence, notifications\n",
        "10. **Test each path** → Mock human decisions\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 Your Next HITL Project\n",
        "\n",
        "Try building:\n",
        "\n",
        "1. **Pre-Action Approval Agent**\n",
        "   - Ask before calling APIs or modifying data\n",
        "   \n",
        "2. **Confidence-Based Agent**\n",
        "   - Auto-approve high confidence, ask for low\n",
        "\n",
        "3. **Multi-Step Review Agent**\n",
        "   - Draft → Review → Revise → Review → Final\n",
        "\n",
        "4. **Batch Review Agent**\n",
        "   - Generate 10 items → Human reviews all → Approve in bulk\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 The Big Picture\n",
        "\n",
        "**Why HITL Matters:**\n",
        "- Reduces errors → Builds trust → Enables adoption\n",
        "\n",
        "**How HITL Works:**\n",
        "- Pause → Human decides → State updates → Continue\n",
        "\n",
        "**Where to Use HITL:**\n",
        "- High stakes, low confidence, regulatory needs\n",
        "\n",
        "**How to Build HITL:**\n",
        "- Interrupts + Conditional routing + State management\n",
        "\n",
        "**What to Remember:**\n",
        "- Design the experience well\n",
        "- Track decisions in state\n",
        "- Test each path\n",
        "- Production needs infrastructure\n",
        "\n",
        "**You now know how to build trusted AI agents that companies will adopt!** 🎉\n",
        "\n"
      ],
      "metadata": {
        "id": "Fu6tlKVzwqyC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qOhMOrIvxn5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}