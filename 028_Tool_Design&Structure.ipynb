{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPRZ+9ZVmrmHO/NnJlWmxia",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/028_Tool_Design%26Structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### üõ†Ô∏è **Tool Design & Structure**\n",
        "\n",
        "In this lecture, we learned that **tool descriptions** are essential for agents to understand and apply tools effectively. Instead of relying on vague commands, agents need clear, structured information about the tools they will use. Here are the core concepts we need to grasp:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Tool Definitions Are Essential for Action**\n",
        "\n",
        "* **Agents cannot perform tasks** unless they understand the **tools** at their disposal.\n",
        "* Each tool must be **described with clear metadata** that specifies:\n",
        "\n",
        "  * **Tool name**: What does the tool do?\n",
        "  * **Arguments (inputs)**: What does the tool require in order to function?\n",
        "  * **Outputs**: What results or changes can we expect after the tool runs?\n",
        "\n",
        "### **2. Tool Descriptions Enable Clear Interfacing**\n",
        "\n",
        "* **JSON Schema** is a structured way of defining tool properties (inputs, outputs, constraints).\n",
        "\n",
        "  * **Inputs** can be basic data types (e.g., strings, numbers) or more complex (e.g., arrays, enums).\n",
        "  * **Outputs** can be validated for consistency and expected results.\n",
        "\n",
        "### **3. Tools Need to Be Interpretable by the LLM**\n",
        "\n",
        "* The **LLM** must understand when and how to use each tool.\n",
        "* We need to provide **examples** and clear definitions so that the LLM can **recognize tool requirements** and **apply the correct logic**.\n",
        "\n",
        "### **4. JSON Schema as a Tool ‚ÄúContract‚Äù**\n",
        "\n",
        "* By using JSON Schema, we define the **contract** between the agent and the tool:\n",
        "\n",
        "  * What the tool is called\n",
        "  * What it needs to function (parameters)\n",
        "  * What it outputs (results)\n",
        "\n",
        "  This contract allows the **LLM to execute the tool without confusion**, knowing what the inputs are, and how to apply them.\n",
        "\n",
        "### **5. Extensibility and Flexibility of Tool Design**\n",
        "\n",
        "* Tools can be **simple** (like listing files) or **complex** (e.g., analyzing sentiment in documents).\n",
        "* As tools grow in complexity, you can introduce more advanced features:\n",
        "\n",
        "  * **Enums** (for predefined options)\n",
        "  * **Booleans** (e.g., active/inactive states)\n",
        "  * **Arrays** (lists of files, multiple parameters)\n",
        "\n",
        "  Flexibility in tool design ensures that your agent can evolve over time and handle a variety of tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### **Objectives for This Notebook:**\n",
        "\n",
        "1. **Understand the structure of tool descriptions** using JSON.\n",
        "2. **Build several examples** of tools with varied complexity:\n",
        "\n",
        "   * Basic tools with simple inputs/outputs\n",
        "   * Tools requiring lists, boolean flags, and enums\n",
        "3. **Understand how to format and define each tool clearly** to make it LLM-friendly and executable.\n",
        "\n",
        "By the end of this notebook, we‚Äôll have a solid foundation for building tools, and we‚Äôll be ready to integrate them into an agent in the next notebook.\n"
      ],
      "metadata": {
        "id": "_dXGmNl-gk2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ Example 1: list_files\n",
        "A simple tool that requires no input. It just lists files in a folder."
      ],
      "metadata": {
        "id": "NtDknYbOg6Dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"name\": \"list_files\",\n",
        "  \"description\": \"Lists all files in the current working directory.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {},\n",
        "    \"required\": []\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "4FDCCOsoeBia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç Python Code Version"
      ],
      "metadata": {
        "id": "YnY47Vm7iNAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# üîπ Step 1: Imports and Setup\n",
        "source_dir = \"/content/docs_folder\"\n",
        "\n",
        "# Make sure the directory exists\n",
        "if not os.path.exists(source_dir):\n",
        "    raise FileNotFoundError(f\"üìÅ Directory not found: {source_dir}\")\n",
        "\n",
        "# List and build full file paths\n",
        "file_list = [\n",
        "    os.path.join(source_dir, f)\n",
        "    for f in os.listdir(source_dir)\n",
        "    if os.path.isfile(os.path.join(source_dir, f))\n",
        "]"
      ],
      "metadata": {
        "id": "3Y5NqeLwhC7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† These Aren‚Äôt One-to-One\n",
        "\n",
        "Python code **does** the task.\n",
        "Tool JSON **describes** the task in a way the LLM can recognize and invoke it.\n",
        "\n",
        "Think of the tool JSON as **an API spec**, not an implementation.\n",
        "\n",
        "You're uncovering some of the most important (and often misunderstood) differences between *traditional code* and *tool design for agents*. Let‚Äôs walk through your points and connect the dots:\n",
        "\n",
        "---\n",
        "\n",
        "## üß© 1. Why `\"type\"`, `\"properties\"`, `\"required\"`?\n",
        "\n",
        "These fields come from **JSON Schema**, which is a standard format used to describe data structures.\n",
        "OpenAI uses JSON Schema so the LLM can:\n",
        "\n",
        "* understand what arguments a tool accepts,\n",
        "* validate them,\n",
        "* and generate calls in the correct structure.\n",
        "\n",
        "Let‚Äôs explain each:\n",
        "\n",
        "| JSON Schema Field  | What It Means                                                | Python Equivalent                                                 |\n",
        "| ------------------ | ------------------------------------------------------------ | ----------------------------------------------------------------- |\n",
        "| `\"type\": \"object\"` | This tool expects an object (i.e., a dictionary) as input    | A function that takes named arguments                             |\n",
        "| `\"properties\"`     | Lists the possible fields/parameters inside the input object | Function parameters like `file_name: str`                         |\n",
        "| `\"required\"`       | Specifies which parameters must be included                  | Equivalent to **non-default function args** (i.e. not `**kwargs`) |\n",
        "\n",
        "### Why not use `\"args\"`?\n",
        "\n",
        "Because `\"args\"` and `\"kwargs\"` are Python-specific.\n",
        "JSON Schema is **language-agnostic**, and OpenAI tools aim to be platform-neutral.\n",
        "\n",
        "---\n",
        "\n",
        "## üìÅ 2. Where‚Äôs `source_dir` in the tool?\n",
        "\n",
        "Great observation. It‚Äôs **abstracted away**.\n",
        "\n",
        "The tool description:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"list_files\",\n",
        "  \"description\": \"Lists all files in the current working directory.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {},\n",
        "    \"required\": []\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "...assumes that:\n",
        "\n",
        "* The **agent runtime environment** has already defined a `source_dir`.\n",
        "* Or, the tool itself (on the backend) is **hardcoded** to know where to look.\n",
        "* Or the agent is *managing context* so `cwd = /content/docs_folder`.\n",
        "\n",
        "So yes, you‚Äôre right: **the LLM is trusting that the tool does what it says**.\n",
        "It doesn‚Äôt see `os.listdir()` or `source_dir` ‚Äî it just learns:\n",
        "\n",
        "> ‚ÄúWhen I want to get a list of files, call `list_files` with no parameters.‚Äù\n",
        "\n",
        "The *developer* is responsible for wiring up the actual behavior.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 3. Isn't This Asking Too Much of the LLM?\n",
        "\n",
        "That‚Äôs an insightful concern, and here‚Äôs the truth:\n",
        "\n",
        "### ‚úÖ Yes, we're asking a lot ‚Äî but intentionally.\n",
        "\n",
        "Think of it like this:\n",
        "\n",
        "| Traditional Code                  | Agent-Oriented Approach                            |\n",
        "| --------------------------------- | -------------------------------------------------- |\n",
        "| You define everything             | You *describe* capabilities                        |\n",
        "| You write imperative instructions | You delegate tool selection to the LLM             |\n",
        "| Focus is on implementation        | Focus is on *orchestration* and intent recognition |\n",
        "| LLM is a text generator           | LLM is a **planner** and **dispatcher**            |\n",
        "\n",
        "The LLM is **not building the tool on the fly** ‚Äî it‚Äôs choosing **which tool** to call and **what arguments** to provide. That‚Äôs a very different job than execution.\n",
        "\n",
        "The actual execution still happens in your backend Python code ‚Äî the LLM just produces a JSON like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"list_files\",\n",
        "  \"args\": {}\n",
        "}\n",
        "```\n",
        "\n",
        "Then your app does:\n",
        "\n",
        "```python\n",
        "if tool_name == \"list_files\":\n",
        "    return list_files()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why All This?\n",
        "\n",
        "Because this pattern **scales**.\n",
        "\n",
        "Once you define tools:\n",
        "\n",
        "* The LLM can choose, combine, and sequence them\n",
        "* You can add, update, or swap tools without retraining anything\n",
        "* You separate **intelligence** (LLM) from **execution** (tools)\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ TL;DR ‚Äì What‚Äôs Going On?\n",
        "\n",
        "You're designing a **modular architecture** where:\n",
        "\n",
        "* The **LLM plans** (\"What should I do?\")\n",
        "* The **tools act** (\"Do this\")\n",
        "* Your **code glues them together**\n",
        "\n",
        "So yes ‚Äî it‚Äôs different from writing raw Python.\n",
        "But it enables automation that‚Äôs general, adaptive, and reusable.\n",
        "\n"
      ],
      "metadata": {
        "id": "q6QJNOJTkvAg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ‚úÖ What‚Äôs Happening at Each Layer\n",
        "\n",
        "### 1. **JSON Tool Schema** (For the LLM)\n",
        "\n",
        "This is:\n",
        "\n",
        "* **Not Python**\n",
        "* A **structured description** of what a tool *does*\n",
        "* What the **LLM reads** to understand:\n",
        "\n",
        "  * \"What tools are available?\"\n",
        "  * \"What arguments can I provide?\"\n",
        "  * \"What is this tool used for?\"\n",
        "\n",
        "üí° Think of this as an *API contract* between the LLM and your Python code.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Python Tool Function** (For Execution)\n",
        "\n",
        "This is:\n",
        "\n",
        "* Real Python code (your actual tool logic)\n",
        "* Executes the task ‚Äî e.g., list files, read a file, summarize content\n",
        "* Matches the interface defined in the JSON\n",
        "\n",
        "üß© Your job is to **make sure the Python function accepts the inputs** the LLM defines via the JSON schema.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **LLM Role**\n",
        "\n",
        "The LLM:\n",
        "\n",
        "* Reads the available tool schemas (via prompt)\n",
        "* Decides: ‚ÄúAh, based on the user request, I should call `read_file` with `filename: 'lecture_01.txt'`‚Äù\n",
        "* Outputs a **JSON invocation** like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"read_file\",\n",
        "  \"args\": { \"filename\": \"lecture_01.txt\" }\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Your Agent Runtime**\n",
        "\n",
        "Your agent:\n",
        "\n",
        "* Parses the LLM‚Äôs output\n",
        "* Extracts `tool_name` and `args`\n",
        "* Calls the corresponding Python function like:\n",
        "\n",
        "```python\n",
        "read_file(filename=\"lecture_01.txt\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† In Summary:\n",
        "\n",
        "| Layer       | Role          | Format                    | Purpose                     |\n",
        "| ----------- | ------------- | ------------------------- | --------------------------- |\n",
        "| Tool Schema | For the LLM   | JSON (JSON Schema format) | Describe tool structure     |\n",
        "| Tool Code   | For your app  | Python                    | Actually does the work      |\n",
        "| Tool Call   | From the LLM  | JSON (tool\\_name + args)  | Tells your code what to run |\n",
        "| Execution   | By your agent | Python                    | Calls the real function     |\n",
        "\n"
      ],
      "metadata": {
        "id": "FAlKM1wElsv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Who Builds the Tool?\n",
        "\n",
        "**You build the actual tool** (in Python), and the **LLM simply chooses when and how to use it.**\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Your Role:\n",
        "\n",
        "You are the **tool builder**. This means:\n",
        "\n",
        "* Writing the actual Python functions that do the work (`read_file()`, `summarize_text()`, etc.)\n",
        "* Defining JSON schema metadata to describe the tool to the LLM\n",
        "* Making sure the inputs the LLM is allowed to use (via JSON) align with the parameters your function accepts\n",
        "\n",
        "---\n",
        "\n",
        "## ü§ñ The LLM‚Äôs Role:\n",
        "\n",
        "The LLM is the **tool orchestrator**. It:\n",
        "\n",
        "* Reads your schema definitions\n",
        "* Interprets the user request\n",
        "* Decides: ‚ÄúAh, I should call `read_file` with `filename='foo.txt'`‚Äù\n",
        "* Outputs a structured call\n",
        "* Doesn‚Äôt know or care *how* the tool works ‚Äî just what it‚Äôs allowed to do\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ Example Flow\n",
        "\n",
        "You write this:\n",
        "\n",
        "```python\n",
        "def read_file(filename: str):\n",
        "    with open(filename, \"r\") as f:\n",
        "        return f.read()\n",
        "```\n",
        "\n",
        "You define this JSON:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"read_file\",\n",
        "  \"description\": \"Reads the content of a file from disk.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"filename\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The name of the file to read\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\"filename\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "The LLM sees this and says:\n",
        "\n",
        "> \"To answer the user, I should use `read_file` with `filename='doc_001.txt'`.\"\n",
        "\n",
        "Then your agent calls:\n",
        "\n",
        "```python\n",
        "read_file(filename=\"doc_001.txt\")\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CwK_RVhEl-rB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's walk through building a complete tool, step-by-step ‚Äî **both the Python code and the JSON schema**, side-by-side.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Build a `count_words` tool\n",
        "\n",
        "It will take a text file and return the number of words in it.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Step 1: Define the Python Tool (the actual function)\n",
        "\n",
        "```python\n",
        "def count_words(filename: str) -> int:\n",
        "    with open(filename, 'r') as f:\n",
        "        content = f.read()\n",
        "    return len(content.split())\n",
        "```\n",
        "\n",
        "‚úÖ **What this does**:\n",
        "\n",
        "* Takes in a file path\n",
        "* Reads the file content\n",
        "* Splits it into words\n",
        "* Returns the word count\n",
        "\n",
        "---\n",
        "\n",
        "### üîß Step 2: Define the Tool Schema (what the LLM sees)\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"count_words\",\n",
        "  \"description\": \"Counts the number of words in a specified text file.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"filename\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The name of the file to count words in\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\"filename\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "‚úÖ **What this tells the LLM**:\n",
        "\n",
        "* The tool is called `count_words`\n",
        "* It expects a single parameter called `filename` (a string)\n",
        "* It doesn‚Äôt know how it works, just what it does and what it needs\n",
        "\n",
        "---\n",
        "\n",
        "### üîÅ Step 3: What the LLM Might Output (based on a user request)\n",
        "\n",
        "If the user says:\n",
        "\n",
        "> ‚ÄúHow many words are in `lecture_notes.txt`?‚Äù\n",
        "\n",
        "The LLM might output:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"count_words\",\n",
        "  \"args\": {\n",
        "    \"filename\": \"lecture_notes.txt\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "Your orchestrator would then call:\n",
        "\n",
        "```python\n",
        "count_words(\"lecture_notes.txt\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Recap\n",
        "\n",
        "| Component          | Your Responsibility        | LLM‚Äôs Responsibility           |\n",
        "| ------------------ | -------------------------- | ------------------------------ |\n",
        "| Python function    | Write real logic in Python | ‚Äî                              |\n",
        "| JSON schema        | Describe inputs + purpose  | Understand how to use the tool |\n",
        "| Agent orchestrator | Handle tool execution      | ‚Äî                              |\n",
        "| LLM                | Decide when to use tool    | Choose tool and fill arguments |\n",
        "\n"
      ],
      "metadata": {
        "id": "QopYJHZNmYKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ü§ñ LLM-Orchestrated Agents = **Chat UX + Code API**\n",
        "\n",
        "### üî∑ What *you* do (as the developer):\n",
        "\n",
        "1. **Write the tools** ‚Üí Python functions that do specific things well\n",
        "2. **Describe the tools** ‚Üí JSON specs that help the LLM understand what they are and how to use them\n",
        "3. **Build the agent loop** ‚Üí A system that routes LLM requests into function calls\n",
        "\n",
        "### üî∑ What the *LLM* does (as the orchestrator):\n",
        "\n",
        "1. **Understands the user request**\n",
        "2. **Chooses the right tool(s)** based on natural language and schema\n",
        "3. **Fills in the tool arguments** using reasoning\n",
        "4. **Delegates execution to code** (it doesn‚Äôt run the tool ‚Äî it just picks and preps)\n",
        "5. **Processes the output** and continues the conversation\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Why it works so well\n",
        "\n",
        "* **LLMs are good at reasoning and language**, but not running code\n",
        "* **Python is good at execution**, but not interpreting vague instructions\n",
        "* This pattern **bridges both worlds**, letting each do what it does best\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Your takeaway\n",
        "\n",
        "> You're not making the LLM do everything.\n",
        ">\n",
        "> You're building a system where **LLM = brain**, **Python = hands**.\n",
        "\n",
        "This separation of concerns is what makes agents:\n",
        "\n",
        "* Cheaper üí∏ (LLM doesn‚Äôt have to learn to do everything)\n",
        "* Faster ‚ö° (code runs tools directly)\n",
        "* Safer ‚úÖ (tools are verified, tested, limited in scope)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b2Ah_oNhoEEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let‚Äôs build a slightly more advanced tool next ‚Äî one that:\n",
        "\n",
        "‚úÖ Has multiple parameters\n",
        "‚úÖ Expects inputs from the LLM\n",
        "‚úÖ Could be conditionally used depending on the user request\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Tool Concept: `search_documents`\n",
        "\n",
        "This tool searches for a keyword or phrase in a set of documents and returns matching filenames.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ Step 1: Write the **actual Python function**\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "def search_documents(query: str, folder: str = \"/content/docs_folder\"):\n",
        "    results = []\n",
        "    for filename in os.listdir(folder):\n",
        "        filepath = os.path.join(folder, filename)\n",
        "        if os.path.isfile(filepath):\n",
        "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "                content = f.read()\n",
        "                if query.lower() in content.lower():\n",
        "                    results.append(filename)\n",
        "    return results\n",
        "```\n",
        "\n",
        "* ‚úÖ This code works.\n",
        "* ‚úÖ It's testable independently of the LLM.\n",
        "* ‚úÖ It only does one thing well ‚Äî that‚Äôs what you want from tools.\n",
        "\n",
        "---\n",
        "\n",
        "### üßæ Step 2: Define the **tool schema** in JSON format\n",
        "\n",
        "This tells the LLM **what** the tool does, and what arguments it needs:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"search_documents\",\n",
        "  \"description\": \"Searches all documents in the folder for a given keyword or phrase.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"query\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The keyword or phrase to search for in the documents.\"\n",
        "      },\n",
        "      \"folder\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The folder path to search in (default is '/content/docs_folder').\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\"query\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### üîç Notice:\n",
        "\n",
        "* `query` is **required**\n",
        "* `folder` is **optional** (we‚Äôll default to a value in the Python code)\n",
        "* The LLM now understands how to **call this tool** like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"search_documents\",\n",
        "  \"args\": {\n",
        "    \"query\": \"vector database\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why this matters\n",
        "\n",
        "You now have a tool that the LLM can choose to use when a user asks things like:\n",
        "\n",
        "* ‚ÄúWhich files talk about vector databases?‚Äù\n",
        "* ‚ÄúSearch all my notes for mentions of LangChain.‚Äù\n",
        "* ‚ÄúDo any documents explain agent loops?‚Äù\n",
        "\n",
        "You‚Äôre not manually mapping user intent ‚Üí tool calls anymore.\n",
        "**The LLM handles that orchestration.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YtzgSxq1sFwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let‚Äôs now build a tool that accepts **multiple argument types**, including a **boolean** and a **list**. This adds more flexibility and reflects real-world use cases agents often need.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Tool Concept: `filter_documents`\n",
        "\n",
        "This tool filters documents based on their filename and/or content, optionally returning only those that include **all** the keywords provided.\n",
        "\n",
        "---\n",
        "\n",
        "### üß™ Step 1: Python Function\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "def filter_documents(keywords: list, require_all: bool = False, folder: str = \"/content/docs_folder\"):\n",
        "    matched_files = []\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        if not filename.endswith(\".txt\"):\n",
        "            continue\n",
        "        path = os.path.join(folder, filename)\n",
        "        if not os.path.isfile(path):\n",
        "            continue\n",
        "\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read().lower()\n",
        "\n",
        "        checks = [kw.lower() in content for kw in keywords]\n",
        "\n",
        "        if (require_all and all(checks)) or (not require_all and any(checks)):\n",
        "            matched_files.append(filename)\n",
        "\n",
        "    return matched_files\n",
        "```\n",
        "\n",
        "* ‚úÖ `keywords`: list of strings to match\n",
        "* ‚úÖ `require_all`: a boolean for AND vs OR matching\n",
        "* ‚úÖ Flexible and simple\n",
        "\n",
        "---\n",
        "\n",
        "### üßæ Step 2: Tool Schema for the LLM\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"filter_documents\",\n",
        "  \"description\": \"Filters documents based on one or more keywords in their content. Can match all or any.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"keywords\": {\n",
        "        \"type\": \"array\",\n",
        "        \"items\": {\n",
        "          \"type\": \"string\"\n",
        "        },\n",
        "        \"description\": \"List of keywords to match in the document content.\"\n",
        "      },\n",
        "      \"require_all\": {\n",
        "        \"type\": \"boolean\",\n",
        "        \"description\": \"If true, all keywords must match; if false, any match is accepted.\"\n",
        "      },\n",
        "      \"folder\": {\n",
        "        \"type\": \"string\",\n",
        "        \"description\": \"The folder path to search in (default is '/content/docs_folder').\"\n",
        "      }\n",
        "    },\n",
        "    \"required\": [\"keywords\"]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "### üîç Now the LLM can do things like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"tool_name\": \"filter_documents\",\n",
        "  \"args\": {\n",
        "    \"keywords\": [\"agent\", \"action\", \"memory\"],\n",
        "    \"require_all\": true\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why this is powerful\n",
        "\n",
        "* The LLM gets **structured control**: it knows how to call this tool correctly.\n",
        "* You get to **enforce safety and input types** through schema.\n",
        "* Booleans and lists open up a whole new level of query logic.\n",
        "\n"
      ],
      "metadata": {
        "id": "HBHl7bZrsl96"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Izi_241pmX7F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}