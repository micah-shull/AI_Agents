{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7I7S6QUFM/FOqzeQapGtd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/102_TxtSummarizerAgent_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Progress tracking is one of those â€œagent hygieneâ€ habits** that seems optional at first but becomes critical as agents grow more complex.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§­ Why Track Progress?\n",
        "\n",
        "When you run an agent, it doesnâ€™t just â€œjumpâ€ from goal â†’ result.\n",
        "It goes through a series of **steps** (plan, read file, generate prompt, summarize, save, etc.).\n",
        "\n",
        "Without progress tracking:\n",
        "\n",
        "* You donâ€™t know *where it failed* if something breaks.\n",
        "* You canâ€™t easily **re-run from the last completed step**.\n",
        "* You lose the ability to **audit** what the agent did.\n",
        "\n",
        "With progress tracking:\n",
        "\n",
        "* You get a running â€œlogbookâ€ of what steps have started, completed, or errored.\n",
        "* You can debug and improve your agent much faster.\n",
        "* You have a structured record you can export, display in a UI, or analyze later.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”§ The Functions\n",
        "\n",
        "### 1. `track_progress(ctx, step, status, note=\"\")`\n",
        "\n",
        "This is the **logger** function.\n",
        "\n",
        "* It creates or updates a `progress_log` list stored in memory.\n",
        "* Each entry is a dictionary like:\n",
        "\n",
        "  ```python\n",
        "  {\"step\": \"read_txt_file\", \"status\": \"completed\", \"note\": \"File length: 5530\"}\n",
        "  ```\n",
        "* The `status` tells you whether the step started, completed, or failed.\n",
        "* The `note` can carry any extra info (like error messages or metadata).\n",
        "\n",
        "**Why needed?**\n",
        "It gives you a **structured trace** of the agentâ€™s journey â€” like breadcrumbs you can inspect later.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `print_progress(ctx)`\n",
        "\n",
        "This is a **convenience viewer**.\n",
        "\n",
        "* It takes the structured log in memory and prints it in a nice format.\n",
        "* Example output:\n",
        "\n",
        "  ```\n",
        "  ðŸ“Š Progress Log:\n",
        "  - [started] create_plan (2025-08-26) Planning the steps\n",
        "  - [completed] create_plan (2025-08-26) 7 steps created\n",
        "  - [completed] read_txt_file (2025-08-26) File length: 5530\n",
        "  - [completed] summarize (2025-08-26) Summary saved in memory\n",
        "  ```\n",
        "\n",
        "**Why needed?**\n",
        "Makes debugging and reviewing agent runs much easier (especially in notebooks).\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Summary\n",
        "\n",
        "* **`track_progress`** = *writes progress updates into memory*\n",
        "* **`print_progress`** = *reads and displays the log nicely*\n",
        "\n",
        "Theyâ€™re not strictly required for a minimal agent, but they make your framework:\n",
        "\n",
        "* More debuggable\n",
        "* More user-friendly\n",
        "* Easier to extend into production agents\n"
      ],
      "metadata": {
        "id": "L-jVssidckoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "\n",
        "def track_progress(ctx, step, status, note=\"\"):\n",
        "    if status not in VALID_STATUSES:\n",
        "        raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "\n",
        "    progress = ctx.memory.get(\"progress_log\") or []\n",
        "    progress.append({\n",
        "        \"step\": step,\n",
        "        \"status\": status,\n",
        "        \"note\": note,\n",
        "        \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    })\n",
        "    ctx.memory.set(\"progress_log\", progress)\n",
        "\n",
        "def print_progress(ctx):\n",
        "    log = ctx.memory.get(\"progress_log\") or []\n",
        "    print(\"\\nðŸ“Š Progress Log:\")\n",
        "    for entry in log:\n",
        "        print(f\"- [{entry['status']}] {entry['step']} ({entry.get('time','')}) {entry['note']}\")\n"
      ],
      "metadata": {
        "id": "CIdJt8-2ciY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add to ActionContext?\n",
        "\n",
        "## option A â€” keep them as free functions (what you have)\n",
        "\n",
        "* pros: simple, easy to unit-test in isolation; no class changes\n",
        "* cons: slightly noisier call sites (`track_progress(ctx, ...)`), functions must know the ctx shape\n",
        "\n",
        "## option B â€” make them **methods on `ActionContext`**\n",
        "\n",
        "* pros: nicer ergonomics, discoverable (`ctx.track_progress(...)`), keeps all â€œbackpack opsâ€ together\n",
        "* cons: `ActionContext` takes on more responsibility (still fine for a small framework)\n",
        "\n",
        "given your goal of a reusable *template*, iâ€™d fold them into `ActionContext`. hereâ€™s a tidy refactor:\n",
        "\n",
        "\n",
        "### Why I recommend it (now)\n",
        "\n",
        "* **Cohesion:** `ctx` is already â€œthe backpack.â€ Goal, plan, raw\\_text, summary all live there; progress about those things belongs there too.\n",
        "* **Ergonomics:** `ctx.track_progress(...)` is cleaner and discoverable vs free functions that take `ctx`.\n",
        "* **Encapsulation:** Tools donâ€™t need to know *how* logging worksâ€”only that `ctx` can log. If you change the logging strategy, tools donâ€™t change.\n",
        "* **Testability:** You can unit-test logging by inspecting `ctx.memory[\"progress_log\"]` without extra globals.\n",
        "\n",
        "### When Iâ€™d *not* put it on `ActionContext`\n",
        "\n",
        "* If you anticipate **multiple sinks** (console + file + DB + telemetry) or structured logging needs, graduate to:\n",
        "\n",
        "  * `class ProgressLogger` (strategy) and inject as `ctx.logger`\n",
        "  * `ctx.track_progress(...)` simply delegates to `ctx.logger.log(...)`\n",
        "* If you want **cross-cutting policies** (PII redaction, correlation IDs, span tracing), a dedicated logger service is better.\n",
        "\n",
        "### Pragmatic path\n",
        "\n",
        "1. Put methods on `ActionContext` now (simple, clean).\n",
        "2. If/when needs grow, refactor `ActionContext.track_progress` to call an injected `logger` without changing any tool code.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "saZhyky0h1hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "\n",
        "class ActionContext:\n",
        "    def __init__(self, memory, llm, config=None):\n",
        "        self.memory = memory\n",
        "        self.llm = llm\n",
        "        self.config = config or {}\n",
        "\n",
        "    # --- progress helpers ---\n",
        "    def track_progress(self, step, status, note=\"\"):\n",
        "        if status not in VALID_STATUSES:\n",
        "            raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        log.append({\n",
        "            \"step\": step,\n",
        "            \"status\": status,\n",
        "            \"note\": note,\n",
        "            \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        })\n",
        "        self.memory.set(\"progress_log\", log)\n",
        "\n",
        "    def print_progress(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        print(\"\\nðŸ“Š Progress Log:\")\n",
        "        for e in log:\n",
        "            t = f\" ({e.get('time')})\" if e.get(\"time\") else \"\"\n",
        "            note = f\" â€” {e['note']}\" if e.get(\"note\") else \"\"\n",
        "            print(f\"- [{e['status']}] {e['step']}{t}{note}\")\n",
        "\n",
        "    def last_completed_step(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in reversed(log):\n",
        "            if e.get(\"status\") == \"completed\":\n",
        "                return e.get(\"step\")\n",
        "        return None\n",
        "\n",
        "    def first_error(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in log:\n",
        "            if e.get(\"status\") == \"error\":\n",
        "                return e\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "7Cf483XBhjnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ§  Why `ActionContext`?\n",
        "\n",
        "Think of `ActionContext` (`ctx`) as the **backpack** your agent carries around.\n",
        "Inside that backpack:\n",
        "\n",
        "* **Memory (`ctx.memory`)** â†’ stores all â€œstateâ€ (goal, plan, raw\\_text, summary, progress log, etc.)\n",
        "* **LLM (`ctx.llm`)** â†’ the brain/mind access point\n",
        "* **Config (`ctx.config`)** â†’ fixed environment details (like input/output folders)\n",
        "* Potentially more (like dependencies or external APIs later)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Š Where Progress Goes\n",
        "\n",
        "When you call `track_progress(ctx, ...)`, it just writes to:\n",
        "\n",
        "```python\n",
        "ctx.memory.set(\"progress_log\", [...])\n",
        "```\n",
        "\n",
        "So the **progress log is part of memory**, and memory is carried inside `ctx`.\n",
        "That means at any point in execution you can inspect progress by peeking into memory:\n",
        "\n",
        "```python\n",
        "ctx.memory.get(\"progress_log\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Why This Matters\n",
        "\n",
        "1. **Single Source of Truth**\n",
        "   Everything the agent generates or needs to remember lives inside `ctx.memory`.\n",
        "   No scattered globals, no hidden state.\n",
        "\n",
        "2. **Reusability**\n",
        "   Since tools only ever interact with `ctx`, you can swap in different memory implementations later (e.g. in-memory dict â†’ Redis â†’ database) without rewriting tools.\n",
        "\n",
        "3. **Inspectability**\n",
        "   Because progress, goal, plan, and outputs are *all in memory*, you can always log, debug, or export them easily.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ So yes\n",
        "\n",
        "You are tracking progress â€œthroughâ€ ActionContext, because **ActionContext carries memory, and memory holds the log** (alongside the goal, plan, prompt, etc.).\n",
        "\n"
      ],
      "metadata": {
        "id": "vk0LnG2mev23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”‘ â€” Understanding *state* is a huge step toward â€œthinking like an agent builder.â€ Letâ€™s lock it in.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Formal Definition of **State**\n",
        "\n",
        "In computing (and in agents specifically):\n",
        "\n",
        "> **State** is the collection of all information an agent/system remembers at a given moment, which can affect its future decisions or actions.\n",
        "\n",
        "* Itâ€™s the **snapshot of memory and context** at a specific time.\n",
        "* If you ran the same code *without state*, it would start â€œfrom scratchâ€ each time.\n",
        "* With state, the agent â€œknows what happened beforeâ€ and can adapt accordingly.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© State in Your Agent\n",
        "\n",
        "In your design, **state = everything inside `ctx.memory`**:\n",
        "\n",
        "* `goal` â†’ what the agent is trying to achieve\n",
        "* `plan` â†’ the step-by-step breakdown\n",
        "* `raw_text` â†’ the text of the file being summarized\n",
        "* `summary_prompt` â†’ the LLM-ready summarization prompt\n",
        "* `summary` â†’ the final LLM output\n",
        "* `progress_log` â†’ the history of what steps have run and their status\n",
        "\n",
        "At any point, if you printed `ctx.memory.store`, youâ€™d see the *current state* of the agent.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŒ Inside vs Outside State\n",
        "\n",
        "* **Inside state (memory):** Anything the agent must *remember and use later* in its reasoning or actions (goal, plan, raw text, summary text, progress log).\n",
        "* **Outside state (environment):** Things the agent *doesnâ€™t carry in memory but interacts with*, like:\n",
        "\n",
        "  * A summary file written to disk (`summary.txt`)\n",
        "  * An API call to fetch weather\n",
        "  * A database update\n",
        "\n",
        "ðŸ’¡ The agent may *store a reference* to these external things in its state (like â€œfile saved at path: `/content/output/summary.txt`â€), but the actual file itself lives in the environment.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Example to Tie It Together\n",
        "\n",
        "Imagine you tell the agent: *â€œSummarize `article.txt` and save the summary.â€*\n",
        "\n",
        "1. **State Before Running**\n",
        "\n",
        "   ```\n",
        "   goal = \"Summarize article.txt\"\n",
        "   plan = None\n",
        "   raw_text = None\n",
        "   summary = None\n",
        "   progress_log = []\n",
        "   ```\n",
        "\n",
        "2. **After Reading File**\n",
        "\n",
        "   ```\n",
        "   raw_text = \"Article text...\"\n",
        "   progress_log = [{\"step\":\"read_txt_file\", \"status\":\"completed\"}]\n",
        "   ```\n",
        "\n",
        "3. **After Summarizing**\n",
        "\n",
        "   ```\n",
        "   summary = \"- Bullet points...\"\n",
        "   progress_log = [..., {\"step\":\"summarize\", \"status\":\"completed\"}]\n",
        "   ```\n",
        "\n",
        "4. **After Saving**\n",
        "\n",
        "   ```\n",
        "   summary_file = \"/content/output/article_summary.txt\"\n",
        "   progress_log = [..., {\"step\":\"save_summary\", \"status\":\"completed\"}]\n",
        "   ```\n",
        "\n",
        "ðŸ‘‰ Here the **text** is inside state, but the **file** is outside state (though the path to it might be remembered).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Short Definition (for your guidebook)\n",
        "\n",
        "> **State is the total collection of remembered information (in memory) that an agent uses to decide what to do next.**\n",
        ">\n",
        "> It includes goals, plans, inputs, outputs, and logs. External actions (like writing to a file) happen outside of state, but references to them can be stored inside state.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9DAdikvtgHaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai python-dotenv\n",
        "\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import textwrap\n",
        "\n",
        "# ---- Setup ----\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found in /content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "j1uqmFudtECd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replace ActionContext"
      ],
      "metadata": {
        "id": "xmkdtJqHrK9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "\n",
        "# ---------------- Memory + Context ----------------\n",
        "class ScratchMemory:\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "\n",
        "    def get(self, key):\n",
        "        return self.store.get(key)\n",
        "\n",
        "    def set(self, key, value):\n",
        "        self.store[key] = value\n",
        "\n",
        "# we replace our original ActionContext\n",
        "# class ActionContext:\n",
        "#     def __init__(self, memory, llm):\n",
        "#         self.memory = memory\n",
        "#         self.llm = llm\n",
        "\n",
        "import time\n",
        "\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "\n",
        "class ActionContext:\n",
        "    def __init__(self, memory, llm, config=None):\n",
        "        self.memory = memory\n",
        "        self.llm = llm\n",
        "        self.config = config or {}\n",
        "\n",
        "    # --- progress helpers ---\n",
        "    def track_progress(self, step, status, note=\"\"):\n",
        "        if status not in VALID_STATUSES:\n",
        "            raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        log.append({\n",
        "            \"step\": step,\n",
        "            \"status\": status,\n",
        "            \"note\": note,\n",
        "            \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        })\n",
        "        self.memory.set(\"progress_log\", log)\n",
        "\n",
        "    def print_progress(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        print(\"\\nðŸ“Š Progress Log:\")\n",
        "        for e in log:\n",
        "            t = f\" ({e.get('time')})\" if e.get(\"time\") else \"\"\n",
        "            note = f\" â€” {e['note']}\" if e.get(\"note\") else \"\"\n",
        "            print(f\"- [{e['status']}] {e['step']}{t}{note}\")\n",
        "\n",
        "    def last_completed_step(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in reversed(log):\n",
        "            if e.get(\"status\") == \"completed\":\n",
        "                return e.get(\"step\")\n",
        "        return None\n",
        "\n",
        "    def first_error(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in log:\n",
        "            if e.get(\"status\") == \"error\":\n",
        "                return e\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "Af2hg9yPq5w3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- LLM Wrapper ----------------\n",
        "class OpenAILLM:\n",
        "    def __init__(self, client, model=\"gpt-4o-mini\"):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "\n",
        "    def complete(self, prompt):\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# ---------------- Tool: create_plan ----------------\n",
        "def create_plan(ctx):\n",
        "    goal = ctx.memory.get(\"goal\")\n",
        "    if not goal:\n",
        "        return {\"error\": \"No goal provided in memory.\"}\n",
        "\n",
        "    prompt = f\"\"\"You are an expert task planner. Given the goal below, break it down into a clear, short list of steps.\n",
        "\n",
        "Goal: {goal}\n",
        "\n",
        "Respond with a numbered list of steps.\"\"\"\n",
        "\n",
        "    response = ctx.llm.complete(prompt)\n",
        "    steps = response.strip().split(\"\\n\")\n",
        "\n",
        "    ctx.memory.set(\"plan\", steps)\n",
        "    return {\"message\": \"Plan created from goal.\", \"steps\": steps}\n",
        "\n",
        "# ---------------- Tool: read_txt_file ----------------\n",
        "def read_txt_file(ctx, file_name):\n",
        "    folder = ctx.config.get(\"input_folder\")\n",
        "    path = os.path.join(folder, file_name)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        return {\"error\": f\"File not found: {path}\"}\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    ctx.memory.set(\"raw_text\", text)\n",
        "    return {\"message\": \"File read successfully.\", \"length\": len(text)}"
      ],
      "metadata": {
        "id": "sNXB8GP2sLW8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Setup + Test ----------------\n",
        "# Set up memory and config\n",
        "memory = ScratchMemory()\n",
        "memory.set(\"goal\", \"Summarize the content of a text file.\")\n",
        "config = {\n",
        "    \"input_folder\": \"/content/files\",\n",
        "    \"output_folder\": \"/content/output\"\n",
        "}\n",
        "\n",
        "# Set up LLM and context (inject config)\n",
        "llm = OpenAILLM(client)\n",
        "ctx = ActionContext(memory=memory, llm=llm, config=config)\n",
        "\n",
        "os.makedirs(ctx.config[\"input_folder\"], exist_ok=True)\n",
        "os.makedirs(ctx.config[\"output_folder\"], exist_ok=True)\n",
        "ctx.track_progress(\"setup\", \"completed\", \"goal + config injected\")"
      ],
      "metadata": {
        "id": "uOjBaB4LriJM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run planning tool\n",
        "ctx.track_progress(\"create_plan\", \"started\", \"generating steps\")\n",
        "plan_result = create_plan(ctx)\n",
        "if \"error\" in plan_result:\n",
        "    ctx.track_progress(\"create_plan\", \"error\", plan_result[\"error\"])\n",
        "    print(\"âŒ create_plan:\", plan_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"create_plan\", \"completed\", f\"steps={len(plan_result['steps'])}\")\n",
        "    print(plan_result[\"message\"])\n",
        "    print(\"\\nPlan:\")\n",
        "    for step in plan_result[\"steps\"]:\n",
        "        wrapped = textwrap.fill(step, width=80, subsequent_indent=\"  \")\n",
        "        print(f\"- {wrapped}\")\n",
        "\n",
        "# ---------------- Print Goal ----------------\n",
        "print(\"\\n\\nðŸŽ¯ Goal:\")\n",
        "print(ctx.memory.get(\"goal\"))\n",
        "print()\n",
        "\n",
        "# Run file reader tool\n",
        "file_name = \"004_AGENT_Tools.txt\"\n",
        "ctx.track_progress(\"read_txt_file\", \"started\", f\"file={file_name}\")\n",
        "file_result = read_txt_file(ctx, file_name)\n",
        "if \"error\" in file_result:\n",
        "    ctx.track_progress(\"read_txt_file\", \"error\", file_result[\"error\"])\n",
        "    print(\"âŒ Error:\", file_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"read_txt_file\", \"completed\", f\"length={file_result['length']}\")\n",
        "    print(\"\\nâœ…\", file_result[\"message\"])\n",
        "    print(f\"Character count: {file_result['length']}\\n\")\n",
        "\n",
        "    raw_text = ctx.memory.get(\"raw_text\")\n",
        "    preview = raw_text[:600]\n",
        "    wrapped_preview = textwrap.fill(preview, width=80, subsequent_indent=\"  \")\n",
        "    print(\"ðŸ“„ File Preview:\\n\")\n",
        "    print(wrapped_preview)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rsDqTr1wFLZ",
        "outputId": "8100089d-f433-4e23-ee14-3da1afb0a2d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan created from goal.\n",
            "\n",
            "Plan:\n",
            "- 1. **Open the Text File**: Use a text editor or programming tool to access the\n",
            "  file you want to summarize.\n",
            "- \n",
            "- 2. **Read the Content**: Carefully read through the entire text to understand\n",
            "  the main ideas and themes.\n",
            "- \n",
            "- 3. **Identify Key Points**: Highlight or note down the most important concepts,\n",
            "  arguments, and facts presented in the text.\n",
            "- \n",
            "- 4. **Determine the Structure**: Organize the key points into a logical\n",
            "  structure, such as introduction, main ideas, and conclusion.\n",
            "- \n",
            "- 5. **Draft the Summary**: Write a concise summary using your identified key\n",
            "  points, ensuring to capture the essence of the original text.\n",
            "- \n",
            "- 6. **Review and Edit**: Read through your summary to ensure clarity and\n",
            "  coherence, making any necessary adjustments for brevity and accuracy.\n",
            "- \n",
            "- 7. **Finalize the Summary**: Save or export the summary in the desired format\n",
            "  for future reference or sharing.\n",
            "\n",
            "\n",
            "ðŸŽ¯ Goal:\n",
            "Summarize the content of a text file.\n",
            "\n",
            "\n",
            "âœ… File read successfully.\n",
            "Character count: 3107\n",
            "\n",
            "ðŸ“„ File Preview:\n",
            "\n",
            " #===========AI-Agent Tool Descriptions and Naming  Describing Tools to the\n",
            "  Agent  When developing an agentic AI system, one of the most critical aspects\n",
            "  is ensuring that the agent understands the tools it has access to. In our\n",
            "  previous tutorial, we explored how an AI agent interacts with an environment.\n",
            "  Now, we extend that discussion to focus on tool definition, particularly the\n",
            "  importance of naming, parameters, and structured metadata.  Example:\n",
            "  Automating Documentation for Python Code Imagine we are building an AI agent\n",
            "  that scans through all Python files in a src/ directory and automatical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQEIbnDocF3F",
        "outputId": "ae6013bb-93f6-49aa-c5b6-5ddfc7cc6c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ› ï¸ Summary prompt created.\n",
            "\n",
            "ðŸ§¾ Prompt Preview:\n",
            "\n",
            "You are an expert technical writer.  Summarize the following content into a set\n",
            "  of clear, concise bullet points. Focus on the main ideas, and skip boilerplate\n",
            "  or excessive detail.  Text: \"\"\"  #===========AI-Agent Tool Descriptions and\n",
            "  Naming  Describing Tools to the Agent  When developing an agentic AI system,\n",
            "  one of the most critical aspects is ensuring that the agent understands the\n",
            "  tools it has access to. In our previous tutorial, we explored how an AI agent\n",
            "  interacts with an environment. Now, we extend that discussion to focus on tool\n",
            "  definition, particularly the importance of naming, para\n",
            "\n",
            "ðŸ§  LLM Output:\n",
            "âœ… Summary completed.\n",
            "\n",
            "ðŸ“ Summary Preview:\n",
            "\n",
            "- **Importance of Tool Understanding**: AI agents must clearly understand the\n",
            "  tools available to them for effective operation. - **Example Use Case**: An AI\n",
            "  agent automates documentation generation for Python code by scanning files in\n",
            "  a `src/` directory and creating documentation in a `docs/` directory. - **Tool\n",
            "  Definition**: Basic functions (e.g., listing Python files) need structured\n",
            "  definitions for AI comprehension. - **Structured Metadata**: Tool definitions\n",
            "  should include structured metadata to clarify usage for AI systems. - **JSON\n",
            "  Schema for Parameters**: JSON Schema is recommended for defining API\n",
            "  parameters, ensuring clarity on expected inputs and outputs for AI tools.\n",
            "\n",
            "================================================================================\n",
            "ðŸ“¦ ActionContext Snapshot\n",
            "\n",
            "ðŸ§  Memory:\n",
            "  goal: Summarize the content of a text file.\n",
            "  progress_log: [{'step': 'setup', 'status': 'completed', 'note': 'goal + config injected', 'time': '2025-08-26 14:19:43'}, {'step': 'create_plan', 'status': 'started', 'note': 'generating steps', 'time': '2025-08-26 14:21:13'}, {'step': 'create_plan', 'status': 'completed', 'note': 'steps=13', 'time': '2025-08-26 14:21:19'}, {'step': 'read_txt_file', 'status': 'started', 'note': 'file=000_Prompting for Agents -GAIL.txt', 'time': '2025-08-26 14:21:19'}, {'step': 'read_txt_file', 'status': 'error', 'note': 'File not found: /content/files/000_Prompting for Agents -GAIL.txt', 'time': '2025-08-26 14:21:19'}, {'step': 'create_plan', 'status': 'started', 'note': 'generating steps', 'time': '2025-08-26 14:21:59'}, {'step': 'create_plan', 'status': 'completed', 'note': 'steps=13', 'time': '2025-08-26 14:22:04'}, {'step': 'read_txt_file', 'status': 'started', 'note': 'file=004_AGENT_Tools.txt', 'time': '2025-08-26 14:22:04'}, {'step': 'read_txt_file', 'status': 'completed', 'note': 'length=3107', 'time': '2025-08-26 14:22:04'}, {'step': 'generate_summary_prompt', 'status': 'started', 'note': '', 'time': '2025-08-26 14:23:03'}, {'step': 'generate_summary_prompt', 'status': 'completed', 'note': '', 'time': '2025-08-26 14:23:03'}, {'step': 'summarize', 'status': 'started', 'note': '', 'time': '2025-08-26 14:23:03'}, {'step': 'summarize', 'status': 'completed', 'note': '', 'time': '2025-08-26 14:23:07'}]\n",
            "  plan: ['1. **Open the Text File**: Use a text editor or programming tool to access the file you want to summarize.', '', '2. **Read the Content**: Carefully read through the entire text to understand the main ideas and themes.', '', '3. **Identify Key Points**: Highlight or note down the most important concepts, arguments, and facts presented in the text.', '', '4. **Determine the Structure**: Organize the key points into a logical structure, such as introduction, main ideas, and conclusion.', '', '5. **Draft the Summary**: Write a concise summary using your identified key points, ensuring to capture the essence of the original text.', '', '6. **Review and Edit**: Read through your summary to ensure clarity and coherence, making any necessary adjustments for brevity and accuracy.', '', '7. **Finalize the Summary**: Save or export the summary in the desired format for future reference or sharing.']\n",
            "  raw_text: \n",
            "#===========AI-Agent Tool Descriptions and Naming\n",
            "\n",
            "Describing Tools to the Agent\n",
            "\n",
            "When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has access to. In our previous tutorial, we explored how an AI agent interacts with an environment. Now, we extend that discussion to focus on tool definition, particularly the importance of nam...\n",
            "  summary_prompt: You are an expert technical writer.\n",
            "\n",
            "Summarize the following content into a set of clear, concise bullet points. Focus on the main ideas, and skip boilerplate or excessive detail.\n",
            "\n",
            "Text:\n",
            "\"\"\"\n",
            "\n",
            "#===========AI-Agent Tool Descriptions and Naming\n",
            "\n",
            "Describing Tools to the Agent\n",
            "\n",
            "When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has...\n",
            "  summary: - **Importance of Tool Understanding**: AI agents must clearly understand the tools available to them for effective operation.\n",
            "- **Example Use Case**: An AI agent automates documentation generation for Python code by scanning files in a `src/` directory and creating documentation in a `docs/` directory.\n",
            "- **Tool Definition**: Basic functions (e.g., listing Python files) need structured definitions...\n",
            "\n",
            "âš™ï¸ Config:\n",
            "  {'input_folder': '/content/files', 'output_folder': '/content/output'}\n",
            "\n",
            "ðŸ§© LLM:\n",
            "  Type: OpenAILLM\n",
            "  Model: gpt-4o-mini\n",
            "\n",
            "ðŸ“Š Progress Log:\n",
            "- [completed] setup (2025-08-26 14:19:43) â€” goal + config injected\n",
            "- [started] create_plan (2025-08-26 14:21:13) â€” generating steps\n",
            "- [completed] create_plan (2025-08-26 14:21:19) â€” steps=13\n",
            "- [started] read_txt_file (2025-08-26 14:21:19) â€” file=000_Prompting for Agents -GAIL.txt\n",
            "- [error] read_txt_file (2025-08-26 14:21:19) â€” File not found: /content/files/000_Prompting for Agents -GAIL.txt\n",
            "- [started] create_plan (2025-08-26 14:21:59) â€” generating steps\n",
            "- [completed] create_plan (2025-08-26 14:22:04) â€” steps=13\n",
            "- [started] read_txt_file (2025-08-26 14:22:04) â€” file=004_AGENT_Tools.txt\n",
            "- [completed] read_txt_file (2025-08-26 14:22:04) â€” length=3107\n",
            "- [started] generate_summary_prompt (2025-08-26 14:23:03)\n",
            "- [completed] generate_summary_prompt (2025-08-26 14:23:03)\n",
            "- [started] summarize (2025-08-26 14:23:03)\n",
            "- [completed] summarize (2025-08-26 14:23:07)\n"
          ]
        }
      ],
      "source": [
        "# ---------------- Tool: generate_summary_prompt ----------------\n",
        "def generate_summary_prompt(ctx):\n",
        "    text = ctx.memory.get(\"raw_text\")\n",
        "    if not text:\n",
        "        return {\"error\": \"No raw text found in memory.\"}\n",
        "\n",
        "    # Optional: truncate text if it's too long\n",
        "    max_len = 2000\n",
        "    short_text = text[:max_len]\n",
        "\n",
        "    prompt = f\"\"\"You are an expert technical writer.\n",
        "\n",
        "Summarize the following content into a set of clear, concise bullet points. Focus on the main ideas, and skip boilerplate or excessive detail.\n",
        "\n",
        "Text:\n",
        "\\\"\\\"\\\"\n",
        "{short_text}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "    ctx.memory.set(\"summary_prompt\", prompt)\n",
        "    return {\"message\": \"Summary prompt created.\", \"prompt_preview\": prompt[:600]}\n",
        "\n",
        "# ---------------- Run Prompt Generator ----------------\n",
        "ctx.track_progress(\"generate_summary_prompt\", \"started\")\n",
        "prompt_result = generate_summary_prompt(ctx)\n",
        "if \"error\" in prompt_result:\n",
        "    ctx.track_progress(\"generate_summary_prompt\", \"error\", prompt_result[\"error\"])\n",
        "    print(\"âŒ\", prompt_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"generate_summary_prompt\", \"completed\")\n",
        "    print(\"ðŸ› ï¸\", prompt_result[\"message\"])\n",
        "    print(\"\\nðŸ§¾ Prompt Preview:\\n\")\n",
        "    print(textwrap.fill(prompt_result[\"prompt_preview\"], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "# ---------------- Tool: summarize ----------------\n",
        "def summarize(ctx):\n",
        "    prompt = ctx.memory.get(\"summary_prompt\")\n",
        "    if not prompt:\n",
        "        return {\"error\": \"No summary prompt found in memory.\"}\n",
        "    try:\n",
        "        response = ctx.llm.complete(prompt)\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"LLM error: {e}\"}\n",
        "\n",
        "    ctx.memory.set(\"summary\", response)\n",
        "    return {\"message\": \"Summary completed.\", \"summary_preview\": response[:1000]}\n",
        "\n",
        "# ---------------- Run summarization ----------------\n",
        "ctx.track_progress(\"summarize\", \"started\")\n",
        "summary_result = summarize(ctx)\n",
        "\n",
        "print(\"\\nðŸ§  LLM Output:\")\n",
        "if \"error\" in summary_result:\n",
        "    ctx.track_progress(\"summarize\", \"error\", summary_result[\"error\"])\n",
        "    print(\"âŒ Error:\", summary_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"summarize\", \"completed\")\n",
        "    print(\"âœ…\", summary_result[\"message\"])\n",
        "    print(\"\\nðŸ“ Summary Preview:\\n\")\n",
        "    print(textwrap.fill(summary_result[\"summary_preview\"], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "# ---------------- Print ActionContext Overview ----------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“¦ ActionContext Snapshot\")\n",
        "\n",
        "# Memory contents\n",
        "print(\"\\nðŸ§  Memory:\")\n",
        "for key, value in ctx.memory.store.items():\n",
        "    display = str(value)\n",
        "    if isinstance(value, str) and len(display) > 400:\n",
        "        display = display[:400] + \"...\"\n",
        "    print(f\"  {key}: {display}\")\n",
        "\n",
        "# Config\n",
        "print(\"\\nâš™ï¸ Config:\")\n",
        "print(f\"  {ctx.config}\")\n",
        "\n",
        "# LLM Info\n",
        "print(\"\\nðŸ§© LLM:\")\n",
        "if ctx.llm:\n",
        "    print(f\"  Type: {ctx.llm.__class__.__name__}\")\n",
        "    print(f\"  Model: {ctx.llm.model}\")\n",
        "else:\n",
        "    print(\"  No LLM connected.\")\n",
        "\n",
        "# Progress log (optional)\n",
        "ctx.print_progress()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks great â€” youâ€™ve got a clean end-to-end run:\n",
        "\n",
        "* âœ… Goal, plan, raw\\_text, summary\\_prompt, and summary are all present in memory.\n",
        "* âœ… Progress log tells a clear story (first file missing â†’ retried with another â†’ success).\n",
        "* âœ… Prompt â†’ summary flow is working as intended.\n",
        "\n",
        "A few small, high-leverage tweaks:\n",
        "\n",
        "1. Plan parsing (youâ€™ve got blank lines)\n",
        "\n",
        "* Your plan array includes empty strings because we split on `\\n`.\n",
        "* Quick fix: normalize to a clean list of steps.\n",
        "\n",
        "```python\n",
        "import re\n",
        "raw_steps = plan_result[\"steps\"]\n",
        "clean_steps = [s.strip(\"-â€¢ \").strip() for s in raw_steps if s.strip()]\n",
        "# or, if you store raw text: steps = re.findall(r\"\\d+\\.\\s+(.*)\", response, re.M)\n",
        "ctx.memory.set(\"plan\", clean_steps)\n",
        "```\n",
        "\n",
        "2. Keep the file name in memory\n",
        "\n",
        "* Helps with saving and provenance:\n",
        "\n",
        "```python\n",
        "ctx.memory.set(\"file_name\", file_name)\n",
        "```\n",
        "\n",
        "3. Flag when you truncate the source\n",
        "\n",
        "* You cap at 2,000 chars; record that for transparency.\n",
        "\n",
        "```python\n",
        "max_len = 2000\n",
        "text = ctx.memory.get(\"raw_text\")\n",
        "truncated = len(text) > max_len\n",
        "short_text = text[:max_len]\n",
        "ctx.memory.set(\"was_truncated\", truncated)\n",
        "```\n",
        "\n",
        "4. (Optional) Slightly lower temperature for consistency\n",
        "\n",
        "* `temperature=0.2` often yields tighter bullets for summarization.\n",
        "\n",
        "5. Next step: save the summary to disk (close the loop)\n",
        "   Hereâ€™s a tiny, robust `save_summary` that uses your injected `output_folder` and the input `file_name`:\n",
        "\n",
        "```python\n",
        "import os\n",
        "\n",
        "def save_summary(ctx, out_name=None):\n",
        "    ctx.track_progress(\"save_summary\", \"started\")\n",
        "    summary = ctx.memory.get(\"summary\")\n",
        "    if not summary:\n",
        "        err = \"No summary in memory.\"\n",
        "        ctx.track_progress(\"save_summary\", \"error\", err)\n",
        "        return {\"error\": err}\n",
        "\n",
        "    output_folder = ctx.config.get(\"output_folder\")\n",
        "    if not output_folder:\n",
        "        err = \"No output_folder in config.\"\n",
        "        ctx.track_progress(\"save_summary\", \"error\", err)\n",
        "        return {\"error\": err}\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    base = out_name\n",
        "    if not base:\n",
        "        src = ctx.memory.get(\"file_name\", \"summary.txt\")\n",
        "        root, _ = os.path.splitext(os.path.basename(src))\n",
        "        base = f\"{root}_summary.txt\"\n",
        "\n",
        "    path = os.path.join(output_folder, base)\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    ctx.track_progress(\"save_summary\", \"completed\", f\"path={path}\")\n",
        "    ctx.memory.set(\"summary_path\", path)\n",
        "    return {\"message\": \"Summary saved.\", \"path\": path}\n",
        "```\n",
        "\n",
        "Usage right after `summarize(ctx)`:\n",
        "\n",
        "```python\n",
        "res = save_summary(ctx)\n",
        "print(res.get(\"message\", res.get(\"error\")))\n",
        "```\n",
        "\n",
        "6. Tiny inspection helpers you can use anytime\n",
        "\n",
        "```python\n",
        "print(\"Last completed:\", ctx.last_completed_step())\n",
        "ctx.print_progress()\n",
        "```\n",
        "\n",
        "If you want, we can drop `save_summary` into your notebook now and do one final run so your agent goes goal â†’ plan â†’ read â†’ prompt â†’ summarize â†’ **save** â†’ log.\n"
      ],
      "metadata": {
        "id": "-UlDbFsoxAh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Code (Working Copy)\n"
      ],
      "metadata": {
        "id": "D77ZyX7Gx7eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai python-dotenv\n",
        "\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import textwrap\n",
        "import time\n",
        "import re\n",
        "\n",
        "# ---- Setup ----\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found in /content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# ---------------- Memory + Context ----------------\n",
        "class ScratchMemory:\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "\n",
        "    def get(self, key):\n",
        "        return self.store.get(key)\n",
        "\n",
        "    def set(self, key, value):\n",
        "        self.store[key] = value\n",
        "\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "\n",
        "class ActionContext:\n",
        "    def __init__(self, memory, llm, config=None):\n",
        "        self.memory = memory\n",
        "        self.llm = llm\n",
        "        self.config = config or {}\n",
        "\n",
        "    # --- progress helpers ---\n",
        "    def track_progress(self, step, status, note=\"\"):\n",
        "        if status not in VALID_STATUSES:\n",
        "            raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        log.append({\n",
        "            \"step\": step,\n",
        "            \"status\": status,\n",
        "            \"note\": note,\n",
        "            \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        })\n",
        "        self.memory.set(\"progress_log\", log)\n",
        "\n",
        "    def print_progress(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        print(\"\\nðŸ“Š Progress Log:\")\n",
        "        for e in log:\n",
        "            t = f\" ({e.get('time')})\" if e.get(\"time\") else \"\"\n",
        "            note = f\" â€” {e['note']}\" if e.get(\"note\") else \"\"\n",
        "            print(f\"- [{e['status']}] {e['step']}{t}{note}\")\n",
        "\n",
        "    def last_completed_step(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in reversed(log):\n",
        "            if e.get(\"status\") == \"completed\":\n",
        "                return e.get(\"step\")\n",
        "        return None\n",
        "\n",
        "    def first_error(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in log:\n",
        "            if e.get(\"status\") == \"error\":\n",
        "                return e\n",
        "        return None\n",
        "\n",
        "# ---------------- LLM Wrapper ----------------\n",
        "class OpenAILLM:\n",
        "    def __init__(self, client, model=\"gpt-4o-mini\"):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "\n",
        "    def complete(self, prompt):\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.3\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# ---------------- Tool: create_plan ----------------\n",
        "# def create_plan(ctx):\n",
        "#     goal = ctx.memory.get(\"goal\")\n",
        "#     if not goal:\n",
        "#         return {\"error\": \"No goal provided in memory.\"}\n",
        "\n",
        "#     prompt = f\"\"\"You are an expert task planner. Given the goal below, break it down into a clear, short list of steps.\n",
        "\n",
        "# Goal: {goal}\n",
        "\n",
        "# Respond with a numbered list of steps.\"\"\"\n",
        "\n",
        "#     response = ctx.llm.complete(prompt)\n",
        "#     steps = response.strip().split(\"\\n\")\n",
        "\n",
        "#     ctx.memory.set(\"plan\", steps)\n",
        "#     return {\"message\": \"Plan created from goal.\", \"steps\": steps}\n",
        "\n",
        "\n",
        "def create_plan(ctx):\n",
        "    goal = ctx.memory.get(\"goal\")\n",
        "    if not goal:\n",
        "        return {\"error\": \"No goal provided in memory.\"}\n",
        "\n",
        "    prompt = f\"\"\"You are an expert task planner. Given the goal below, break it down into a clear, short list of steps.\n",
        "\n",
        "Goal: {goal}\n",
        "\n",
        "Respond with a numbered list of steps.\"\"\"\n",
        "    raw = ctx.llm.complete(prompt).strip()\n",
        "\n",
        "    # Prefer numbered steps like \"1. ...\", \"2) ...\"\n",
        "    numbered = re.findall(r'^\\s*(?:\\d+[\\).\\s-]+)\\s*(.+)$', raw, flags=re.M)\n",
        "\n",
        "    if numbered:\n",
        "        steps = numbered\n",
        "    else:\n",
        "        # Fallback to bullets like \"- ...\", \"* ...\", \"â€¢ ...\"\n",
        "        bullets = re.findall(r'^\\s*(?:[-*â€¢]\\s+)(.+)$', raw, flags=re.M)\n",
        "        steps = bullets if bullets else [ln.strip() for ln in raw.splitlines() if ln.strip()]\n",
        "\n",
        "    # Normalize: collapse spaces, trim punctuation, drop empties/dupes\n",
        "    norm = []\n",
        "    seen = set()\n",
        "    for s in steps:\n",
        "        s = re.sub(r'\\s+', ' ', s).strip(' .')\n",
        "        if s and s.lower() not in seen:\n",
        "            seen.add(s.lower())\n",
        "            norm.append(s)\n",
        "\n",
        "    ctx.memory.set(\"plan\", norm)\n",
        "    return {\"message\": \"Plan created from goal.\", \"steps\": norm}\n",
        "\n",
        "'''\n",
        "What changed\n",
        "\n",
        "We parse the modelâ€™s text into clean steps (regex for numbered/bulleted lines).\n",
        "We normalize: trim, collapse whitespace, drop blanks/dupes.\n",
        "\n",
        "What didnâ€™t change\n",
        "\n",
        "The prompt text and the LLM call are the same.\n",
        "The modelâ€™s reasoning/content isnâ€™t alteredâ€”just formatted for reliable downstream use.\n",
        "'''\n",
        "\n",
        "# ---------------- Tool: read_txt_file ----------------\n",
        "# def read_txt_file(ctx, file_name):\n",
        "#     folder = ctx.config.get(\"input_folder\")\n",
        "#     path = os.path.join(folder, file_name)\n",
        "\n",
        "#     if not os.path.exists(path):\n",
        "#         return {\"error\": f\"File not found: {path}\"}\n",
        "\n",
        "#     with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "#         text = f.read()\n",
        "\n",
        "#     ctx.memory.set(\"raw_text\", text)\n",
        "#     return {\"message\": \"File read successfully.\", \"length\": len(text)}\n",
        "\n",
        "def read_txt_file(ctx, file_name):\n",
        "    ctx.track_progress(\"read_txt_file\", \"started\", f\"file={file_name}\")\n",
        "\n",
        "    folder = ctx.config.get(\"input_folder\")\n",
        "    path = os.path.join(folder, file_name)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        ctx.track_progress(\"read_txt_file\", \"error\", f\"missing={path}\")\n",
        "        return {\"error\": f\"File not found: {path}\"}\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # Record state\n",
        "    ctx.memory.set(\"file_name\", file_name)\n",
        "    ctx.memory.set(\"raw_text\", text)\n",
        "\n",
        "    ctx.track_progress(\"read_txt_file\", \"completed\", f\"length={len(text)}\")\n",
        "    return {\"message\": \"File read successfully.\", \"length\": len(text)}\n",
        "\n",
        "''' file_name is run-time state (it can change per task), not static environment.\n",
        "So it belongs in memory (ctx.memory), not in config (which is for constants like folders).'''\n",
        "\n",
        "# ---------------- Setup + Test ----------------\n",
        "# Set up memory and config\n",
        "memory = ScratchMemory()\n",
        "memory.set(\"goal\", \"Summarize the content of a text file.\")\n",
        "config = {\n",
        "    \"input_folder\": \"/content/files\",\n",
        "    \"output_folder\": \"/content/output\"\n",
        "}\n",
        "\n",
        "# Set up LLM and context (inject config)\n",
        "llm = OpenAILLM(client)\n",
        "ctx = ActionContext(memory=memory, llm=llm, config=config)\n",
        "\n",
        "os.makedirs(ctx.config[\"input_folder\"], exist_ok=True)\n",
        "os.makedirs(ctx.config[\"output_folder\"], exist_ok=True)\n",
        "ctx.track_progress(\"setup\", \"completed\", \"goal + config injected\")\n",
        "\n",
        "# Run planning tool\n",
        "ctx.track_progress(\"create_plan\", \"started\", \"generating steps\")\n",
        "plan_result = create_plan(ctx)\n",
        "if \"error\" in plan_result:\n",
        "    ctx.track_progress(\"create_plan\", \"error\", plan_result[\"error\"])\n",
        "    print(\"âŒ create_plan:\", plan_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"create_plan\", \"completed\", f\"steps={len(plan_result['steps'])}\")\n",
        "    print(plan_result[\"message\"])\n",
        "    print(\"\\nPlan:\")\n",
        "    for step in plan_result[\"steps\"]:\n",
        "        wrapped = textwrap.fill(step, width=80, subsequent_indent=\"  \")\n",
        "        print(f\"- {wrapped}\")\n",
        "\n",
        "# ---------------- Print Goal ----------------\n",
        "print(\"\\n\\nðŸŽ¯ Goal:\")\n",
        "print(ctx.memory.get(\"goal\"))\n",
        "print()\n",
        "\n",
        "# Run file reader tool\n",
        "file_name = \"004_AGENT_Tools.txt\"\n",
        "ctx.track_progress(\"read_txt_file\", \"started\", f\"file={file_name}\")\n",
        "file_result = read_txt_file(ctx, file_name)\n",
        "if \"error\" in file_result:\n",
        "    ctx.track_progress(\"read_txt_file\", \"error\", file_result[\"error\"])\n",
        "    print(\"âŒ Error:\", file_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"read_txt_file\", \"completed\", f\"length={file_result['length']}\")\n",
        "    print(\"\\nâœ…\", file_result[\"message\"])\n",
        "    print(f\"Character count: {file_result['length']}\\n\")\n",
        "\n",
        "    raw_text = ctx.memory.get(\"raw_text\")\n",
        "    preview = raw_text[:600]\n",
        "    wrapped_preview = textwrap.fill(preview, width=80, subsequent_indent=\"  \")\n",
        "    print(\"ðŸ“„ File Preview:\\n\")\n",
        "    print(wrapped_preview)\n",
        "\n",
        "# ---------------- Tool: generate_summary_prompt ----------------\n",
        "# def generate_summary_prompt(ctx):\n",
        "#     text = ctx.memory.get(\"raw_text\")\n",
        "#     if not text:\n",
        "#         return {\"error\": \"No raw text found in memory.\"}\n",
        "\n",
        "#     # Optional: truncate text if it's too long\n",
        "#     max_len = 2000\n",
        "#     short_text = text[:max_len]\n",
        "\n",
        "#     prompt = f\"\"\"You are an expert technical writer.\n",
        "\n",
        "# Summarize the following content into a set of clear, concise bullet points. Focus on the main ideas, and skip boilerplate or excessive detail.\n",
        "\n",
        "# Text:\n",
        "# \\\"\\\"\\\"\n",
        "# {short_text}\n",
        "# \\\"\\\"\\\"\n",
        "\n",
        "# Summary:\"\"\"\n",
        "\n",
        "#     ctx.memory.set(\"summary_prompt\", prompt)\n",
        "#     return {\"message\": \"Summary prompt created.\", \"prompt_preview\": prompt[:600]}\n",
        "\n",
        "def generate_summary_prompt(ctx, max_len=2000):\n",
        "    text = ctx.memory.get(\"raw_text\")\n",
        "    if not text:\n",
        "        return {\"error\": \"No raw text found in memory.\"}\n",
        "\n",
        "    # Truncate + record bookkeeping\n",
        "    truncated = len(text) > max_len\n",
        "    short_text = text[:max_len]\n",
        "    ctx.memory.set(\"was_truncated\", truncated)\n",
        "    ctx.memory.set(\"source_length\", len(text))\n",
        "    ctx.memory.set(\"used_length\", len(short_text))\n",
        "\n",
        "    prompt = f\"\"\"You are an expert technical writer.\n",
        "\n",
        "Summarize the following content into a set of clear, concise bullet points. Focus on the main ideas, and skip boilerplate or excessive detail.\n",
        "\n",
        "Text:\n",
        "\\\"\\\"\\\"\n",
        "{short_text}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "    ctx.memory.set(\"summary_prompt\", prompt)\n",
        "    return {\n",
        "        \"message\": \"Summary prompt created.\",\n",
        "        \"prompt_preview\": prompt[:600],\n",
        "        \"truncated\": truncated,\n",
        "        \"used\": len(short_text),\n",
        "        \"total\": len(text),\n",
        "    }\n",
        "\n",
        "\n",
        "# ---------------- Run Prompt Generator ----------------\n",
        "ctx.track_progress(\"generate_summary_prompt\", \"started\")\n",
        "prompt_result = generate_summary_prompt(ctx)\n",
        "if \"error\" in prompt_result:\n",
        "    ctx.track_progress(\"generate_summary_prompt\", \"error\", prompt_result[\"error\"])\n",
        "    print(\"âŒ\", prompt_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"generate_summary_prompt\", \"completed\")\n",
        "    print(\"ðŸ› ï¸\", prompt_result[\"message\"])\n",
        "    print(\"\\nðŸ§¾ Prompt Preview:\\n\")\n",
        "    print(textwrap.fill(prompt_result[\"prompt_preview\"], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "# ---------------- Tool: summarize ----------------\n",
        "def summarize(ctx):\n",
        "    prompt = ctx.memory.get(\"summary_prompt\")\n",
        "    if not prompt:\n",
        "        return {\"error\": \"No summary prompt found in memory.\"}\n",
        "    try:\n",
        "        response = ctx.llm.complete(prompt)\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"LLM error: {e}\"}\n",
        "\n",
        "    ctx.memory.set(\"summary\", response)\n",
        "    return {\"message\": \"Summary completed.\", \"summary_preview\": response[:1000]}\n",
        "\n",
        "# ---------------- Run summarization ----------------\n",
        "ctx.track_progress(\"summarize\", \"started\")\n",
        "summary_result = summarize(ctx)\n",
        "\n",
        "print(\"\\nðŸ§  LLM Output:\")\n",
        "if \"error\" in summary_result:\n",
        "    ctx.track_progress(\"summarize\", \"error\", summary_result[\"error\"])\n",
        "    print(\"âŒ Error:\", summary_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"summarize\", \"completed\")\n",
        "    print(\"âœ…\", summary_result[\"message\"])\n",
        "    print(\"\\nðŸ“ Summary Preview:\\n\")\n",
        "    print(textwrap.fill(summary_result[\"summary_preview\"], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "# ---------------- Print ActionContext Overview ----------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“¦ ActionContext Snapshot\")\n",
        "\n",
        "# Memory contents\n",
        "print(\"\\nðŸ§  Memory:\")\n",
        "for key, value in ctx.memory.store.items():\n",
        "    display = str(value)\n",
        "    if isinstance(value, str) and len(display) > 400:\n",
        "        display = display[:400] + \"...\"\n",
        "    print(f\"  {key}: {display}\")\n",
        "\n",
        "# Config\n",
        "print(\"\\nâš™ï¸ Config:\")\n",
        "print(f\"  {ctx.config}\")\n",
        "\n",
        "# LLM Info\n",
        "print(\"\\nðŸ§© LLM:\")\n",
        "if ctx.llm:\n",
        "    print(f\"  Type: {ctx.llm.__class__.__name__}\")\n",
        "    print(f\"  Model: {ctx.llm.model}\")\n",
        "else:\n",
        "    print(\"  No LLM connected.\")\n",
        "\n",
        "# Progress log (optional)\n",
        "ctx.print_progress()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU0Rv65TxDb_",
        "outputId": "003984da-3709-45de-c6aa-ab211df6a7d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan created from goal.\n",
            "\n",
            "Plan:\n",
            "- **Open the Text File**: Use a text editor or programming tool to access the file\n",
            "  containing the content you want to summarize\n",
            "- **Read the Content**: Carefully read through the entire text to understand the\n",
            "  main ideas and themes\n",
            "- **Identify Key Points**: Highlight or note down the main arguments, concepts,\n",
            "  and any important details that support them\n",
            "- **Organize Information**: Group similar ideas together and determine the logical\n",
            "  flow of the content\n",
            "- **Draft the Summary**: Write a concise summary that captures the essence of the\n",
            "  text, focusing on the key points identified\n",
            "- **Review and Edit**: Reread the summary to ensure clarity and coherence, making\n",
            "  any necessary adjustments for conciseness and accuracy\n",
            "- **Finalize the Summary**: Save or present the summary in the desired format,\n",
            "  ensuring it is easy to understand and free of errors\n",
            "\n",
            "\n",
            "ðŸŽ¯ Goal:\n",
            "Summarize the content of a text file.\n",
            "\n",
            "\n",
            "âœ… File read successfully.\n",
            "Character count: 3107\n",
            "\n",
            "ðŸ“„ File Preview:\n",
            "\n",
            " #===========AI-Agent Tool Descriptions and Naming  Describing Tools to the\n",
            "  Agent  When developing an agentic AI system, one of the most critical aspects\n",
            "  is ensuring that the agent understands the tools it has access to. In our\n",
            "  previous tutorial, we explored how an AI agent interacts with an environment.\n",
            "  Now, we extend that discussion to focus on tool definition, particularly the\n",
            "  importance of naming, parameters, and structured metadata.  Example:\n",
            "  Automating Documentation for Python Code Imagine we are building an AI agent\n",
            "  that scans through all Python files in a src/ directory and automatical\n",
            "ðŸ› ï¸ Summary prompt created.\n",
            "\n",
            "ðŸ§¾ Prompt Preview:\n",
            "\n",
            "You are an expert technical writer.  Summarize the following content into a set\n",
            "  of clear, concise bullet points. Focus on the main ideas, and skip boilerplate\n",
            "  or excessive detail.  Text: \"\"\"  #===========AI-Agent Tool Descriptions and\n",
            "  Naming  Describing Tools to the Agent  When developing an agentic AI system,\n",
            "  one of the most critical aspects is ensuring that the agent understands the\n",
            "  tools it has access to. In our previous tutorial, we explored how an AI agent\n",
            "  interacts with an environment. Now, we extend that discussion to focus on tool\n",
            "  definition, particularly the importance of naming, para\n",
            "\n",
            "ðŸ§  LLM Output:\n",
            "âœ… Summary completed.\n",
            "\n",
            "ðŸ“ Summary Preview:\n",
            "\n",
            "- **Understanding Tool Definitions**: Essential for AI agents to effectively\n",
            "  utilize available tools. - **Example Use Case**: AI agent automates\n",
            "  documentation generation for Python code by:   - Listing Python files in a\n",
            "  `src/` directory.   - Reading content from each file.   - Writing\n",
            "  documentation to a `docs/` directory. - **Importance of Clarity**: Clear tool\n",
            "  definitions are necessary for AI to interpret file operations accurately. -\n",
            "  **Structured Metadata**: Basic tool definitions should be enhanced with\n",
            "  structured metadata for better clarity. - **JSON Schema for Parameters**:    -\n",
            "  Structured documentation (like JSON Schema) is crucial for defining APIs.   -\n",
            "  Example: A tool to read a file should specify a `file_path` parameter of type\n",
            "  string using JSON Schema.\n",
            "\n",
            "================================================================================\n",
            "ðŸ“¦ ActionContext Snapshot\n",
            "\n",
            "ðŸ§  Memory:\n",
            "  goal: Summarize the content of a text file.\n",
            "  progress_log: [{'step': 'setup', 'status': 'completed', 'note': 'goal + config injected', 'time': '2025-08-26 18:38:07'}, {'step': 'create_plan', 'status': 'started', 'note': 'generating steps', 'time': '2025-08-26 18:38:07'}, {'step': 'create_plan', 'status': 'completed', 'note': 'steps=7', 'time': '2025-08-26 18:38:11'}, {'step': 'read_txt_file', 'status': 'started', 'note': 'file=004_AGENT_Tools.txt', 'time': '2025-08-26 18:38:11'}, {'step': 'read_txt_file', 'status': 'started', 'note': 'file=004_AGENT_Tools.txt', 'time': '2025-08-26 18:38:11'}, {'step': 'read_txt_file', 'status': 'completed', 'note': 'length=3107', 'time': '2025-08-26 18:38:11'}, {'step': 'read_txt_file', 'status': 'completed', 'note': 'length=3107', 'time': '2025-08-26 18:38:11'}, {'step': 'generate_summary_prompt', 'status': 'started', 'note': '', 'time': '2025-08-26 18:38:11'}, {'step': 'generate_summary_prompt', 'status': 'completed', 'note': '', 'time': '2025-08-26 18:38:11'}, {'step': 'summarize', 'status': 'started', 'note': '', 'time': '2025-08-26 18:38:11'}, {'step': 'summarize', 'status': 'completed', 'note': '', 'time': '2025-08-26 18:38:17'}]\n",
            "  plan: ['**Open the Text File**: Use a text editor or programming tool to access the file containing the content you want to summarize', '**Read the Content**: Carefully read through the entire text to understand the main ideas and themes', '**Identify Key Points**: Highlight or note down the main arguments, concepts, and any important details that support them', '**Organize Information**: Group similar ideas together and determine the logical flow of the content', '**Draft the Summary**: Write a concise summary that captures the essence of the text, focusing on the key points identified', '**Review and Edit**: Reread the summary to ensure clarity and coherence, making any necessary adjustments for conciseness and accuracy', '**Finalize the Summary**: Save or present the summary in the desired format, ensuring it is easy to understand and free of errors']\n",
            "  file_name: 004_AGENT_Tools.txt\n",
            "  raw_text: \n",
            "#===========AI-Agent Tool Descriptions and Naming\n",
            "\n",
            "Describing Tools to the Agent\n",
            "\n",
            "When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has access to. In our previous tutorial, we explored how an AI agent interacts with an environment. Now, we extend that discussion to focus on tool definition, particularly the importance of nam...\n",
            "  was_truncated: True\n",
            "  source_length: 3107\n",
            "  used_length: 2000\n",
            "  summary_prompt: You are an expert technical writer.\n",
            "\n",
            "Summarize the following content into a set of clear, concise bullet points. Focus on the main ideas, and skip boilerplate or excessive detail.\n",
            "\n",
            "Text:\n",
            "\"\"\"\n",
            "\n",
            "#===========AI-Agent Tool Descriptions and Naming\n",
            "\n",
            "Describing Tools to the Agent\n",
            "\n",
            "When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has...\n",
            "  summary: - **Understanding Tool Definitions**: Essential for AI agents to effectively utilize available tools.\n",
            "- **Example Use Case**: AI agent automates documentation generation for Python code by:\n",
            "  - Listing Python files in a `src/` directory.\n",
            "  - Reading content from each file.\n",
            "  - Writing documentation to a `docs/` directory.\n",
            "- **Importance of Clarity**: Clear tool definitions are necessary for AI to ...\n",
            "\n",
            "âš™ï¸ Config:\n",
            "  {'input_folder': '/content/files', 'output_folder': '/content/output'}\n",
            "\n",
            "ðŸ§© LLM:\n",
            "  Type: OpenAILLM\n",
            "  Model: gpt-4o-mini\n",
            "\n",
            "ðŸ“Š Progress Log:\n",
            "- [completed] setup (2025-08-26 18:38:07) â€” goal + config injected\n",
            "- [started] create_plan (2025-08-26 18:38:07) â€” generating steps\n",
            "- [completed] create_plan (2025-08-26 18:38:11) â€” steps=7\n",
            "- [started] read_txt_file (2025-08-26 18:38:11) â€” file=004_AGENT_Tools.txt\n",
            "- [started] read_txt_file (2025-08-26 18:38:11) â€” file=004_AGENT_Tools.txt\n",
            "- [completed] read_txt_file (2025-08-26 18:38:11) â€” length=3107\n",
            "- [completed] read_txt_file (2025-08-26 18:38:11) â€” length=3107\n",
            "- [started] generate_summary_prompt (2025-08-26 18:38:11)\n",
            "- [completed] generate_summary_prompt (2025-08-26 18:38:11)\n",
            "- [started] summarize (2025-08-26 18:38:11)\n",
            "- [completed] summarize (2025-08-26 18:38:17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FINAL CODE"
      ],
      "metadata": {
        "id": "xQDTlsGOrzyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai python-dotenv\n",
        "\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import textwrap\n",
        "import time\n",
        "import re\n",
        "\n",
        "# ---- Setup ----\n",
        "load_dotenv('/content/API_KEYS.env')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"OPENAI_API_KEY not found in /content/API_KEYS.env\")\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "# ---------------- Memory + Context ----------------\n",
        "class ScratchMemory:\n",
        "    def __init__(self):\n",
        "        self.store = {}\n",
        "\n",
        "    def get(self, key):\n",
        "        return self.store.get(key)\n",
        "\n",
        "    def set(self, key, value):\n",
        "        self.store[key] = value\n",
        "\n",
        "VALID_STATUSES = {\"started\", \"completed\", \"error\"}\n",
        "\n",
        "class ActionContext:\n",
        "    def __init__(self, memory, llm, config=None):\n",
        "        self.memory = memory\n",
        "        self.llm = llm\n",
        "        self.config = config or {}\n",
        "\n",
        "    # --- progress helpers ---\n",
        "    def track_progress(self, step, status, note=\"\"):\n",
        "        if status not in VALID_STATUSES:\n",
        "            raise ValueError(f\"Invalid status '{status}'. Use {VALID_STATUSES}.\")\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        log.append({\n",
        "            \"step\": step,\n",
        "            \"status\": status,\n",
        "            \"note\": note,\n",
        "            \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        })\n",
        "        self.memory.set(\"progress_log\", log)\n",
        "\n",
        "    def print_progress(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        print(\"\\nðŸ“Š Progress Log:\")\n",
        "        for e in log:\n",
        "            t = f\" ({e.get('time')})\" if e.get(\"time\") else \"\"\n",
        "            note = f\" â€” {e['note']}\" if e.get(\"note\") else \"\"\n",
        "            print(f\"- [{e['status']}] {e['step']}{t}{note}\")\n",
        "\n",
        "    def last_completed_step(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in reversed(log):\n",
        "            if e.get(\"status\") == \"completed\":\n",
        "                return e.get(\"step\")\n",
        "        return None\n",
        "\n",
        "    def first_error(self):\n",
        "        log = self.memory.get(\"progress_log\") or []\n",
        "        for e in log:\n",
        "            if e.get(\"status\") == \"error\":\n",
        "                return e\n",
        "        return None\n",
        "\n",
        "# ---------------- LLM Wrapper ----------------\n",
        "class OpenAILLM:\n",
        "    def __init__(self, client, model=\"gpt-4o-mini\", temperature=0.2):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def complete(self, prompt, **kwargs):\n",
        "        temp = kwargs.get(\"temperature\", self.temperature)\n",
        "        resp = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temp,\n",
        "        )\n",
        "        return resp.choices[0].message.content\n",
        "\n",
        "# ---------------- Tool: create_plan ----------------\n",
        "def create_plan(ctx):\n",
        "    goal = ctx.memory.get(\"goal\")\n",
        "    if not goal:\n",
        "        return {\"error\": \"No goal provided in memory.\"}\n",
        "\n",
        "    prompt = f\"\"\"You are an expert task planner. Given the goal below, break it down into a clear, short list of steps.\n",
        "\n",
        "Goal: {goal}\n",
        "\n",
        "Respond ONLY with a numbered list, one step per line. No extra prose.\"\"\"\n",
        "    raw = ctx.llm.complete(prompt).strip()\n",
        "\n",
        "    # Prefer numbered steps like \"1. ...\", \"2) ...\"\n",
        "    numbered = re.findall(r'^\\s*(?:\\d+[\\).\\s-]+)\\s*(.+)$', raw, flags=re.M)\n",
        "\n",
        "    if numbered:\n",
        "        steps = numbered\n",
        "    else:\n",
        "        # Fallback to bullets like \"- ...\", \"* ...\", \"â€¢ ...\"\n",
        "        bullets = re.findall(r'^\\s*(?:[-*â€¢]\\s+)(.+)$', raw, flags=re.M)\n",
        "        steps = bullets if bullets else [ln.strip() for ln in raw.splitlines() if ln.strip()]\n",
        "\n",
        "    # Normalize: collapse spaces, trim punctuation, drop empties/dupes\n",
        "    norm = []\n",
        "    seen = set()\n",
        "    for s in steps:\n",
        "        s = re.sub(r'\\s+', ' ', s).strip(' .')\n",
        "        if s and s.lower() not in seen:\n",
        "            seen.add(s.lower())\n",
        "            norm.append(s)\n",
        "\n",
        "    ctx.memory.set(\"plan\", norm)\n",
        "    return {\"message\": \"Plan created from goal.\", \"steps\": norm}\n",
        "\n",
        "# ---------------- Tool: read_txt_file ----------------\n",
        "def read_txt_file(ctx, file_name):\n",
        "    ctx.track_progress(\"read_txt_file\", \"started\", f\"file={file_name}\")\n",
        "\n",
        "    folder = ctx.config.get(\"input_folder\")\n",
        "    path = os.path.join(folder, file_name)\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        msg = f\"File not found: {path}\"\n",
        "        ctx.track_progress(\"read_txt_file\", \"error\", msg)\n",
        "        return {\"error\": msg}\n",
        "\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        text = f.read()\n",
        "\n",
        "    ctx.memory.set(\"file_name\", file_name)\n",
        "    ctx.memory.set(\"raw_text\", text)\n",
        "\n",
        "    ctx.track_progress(\"read_txt_file\", \"completed\", f\"length={len(text)}\")\n",
        "    return {\"message\": \"File read successfully.\", \"length\": len(text)}\n",
        "\n",
        "# ---------------- Setup + Test ----------------\n",
        "# Set up memory and config\n",
        "memory = ScratchMemory()\n",
        "memory.set(\"goal\", \"Summarize the content of a text file.\")\n",
        "config = {\n",
        "    \"input_folder\": \"/content/files\",\n",
        "    \"output_folder\": \"/content/output\"\n",
        "}\n",
        "\n",
        "# Set up LLM and context (inject config)\n",
        "# Setup\n",
        "llm = OpenAILLM(\n",
        "    client,\n",
        "    model=config.get(\"model\", \"gpt-4o-mini\"),\n",
        "    temperature=config.get(\"temperature\", 0.2),\n",
        ")\n",
        "\n",
        "# Set up ActionContext\n",
        "ctx = ActionContext(memory=memory, llm=llm, config=config)\n",
        "\n",
        "os.makedirs(ctx.config[\"input_folder\"], exist_ok=True)\n",
        "os.makedirs(ctx.config[\"output_folder\"], exist_ok=True)\n",
        "ctx.track_progress(\"setup\", \"completed\", \"goal + config injected\")\n",
        "\n",
        "# Run planning tool\n",
        "ctx.track_progress(\"create_plan\", \"started\", \"generating steps\")\n",
        "plan_result = create_plan(ctx)\n",
        "if \"error\" in plan_result:\n",
        "    ctx.track_progress(\"create_plan\", \"error\", plan_result[\"error\"])\n",
        "    print(\"âŒ create_plan:\", plan_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"create_plan\", \"completed\", f\"steps={len(plan_result['steps'])}\")\n",
        "    print(plan_result[\"message\"])\n",
        "    print(\"\\nPlan:\")\n",
        "    for step in plan_result[\"steps\"]:\n",
        "        wrapped = textwrap.fill(step, width=80, subsequent_indent=\"  \")\n",
        "        print(f\"- {wrapped}\")\n",
        "\n",
        "# ---------------- Print Goal ----------------\n",
        "print(\"\\n\\nðŸŽ¯ Goal:\")\n",
        "print(ctx.memory.get(\"goal\"))\n",
        "print()\n",
        "\n",
        "# Run file reader tool\n",
        "file_name = \"004_AGENT_Tools.txt\"\n",
        "\n",
        "file_result = read_txt_file(ctx, file_name)\n",
        "\n",
        "if \"error\" in file_result:\n",
        "    print(\"âŒ Error:\", file_result[\"error\"])\n",
        "else:\n",
        "    print(\"\\nâœ…\", file_result[\"message\"])\n",
        "    print(f\"Character count: {file_result['length']}\\n\")\n",
        "\n",
        "    raw_text = ctx.memory.get(\"raw_text\")\n",
        "    preview = raw_text[:600]\n",
        "    print(\"ðŸ“„ File Preview:\\n\")\n",
        "    print(textwrap.fill(preview, width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "\n",
        "# ---------------- Tool: generate_summary_prompt ----------------\n",
        "def generate_summary_prompt(ctx, max_len=2000):\n",
        "    text = ctx.memory.get(\"raw_text\")\n",
        "    if not text:\n",
        "        return {\"error\": \"No raw text found in memory.\"}\n",
        "\n",
        "    # Truncate + record bookkeeping\n",
        "    truncated = len(text) > max_len\n",
        "    short_text = text[:max_len]\n",
        "    ctx.memory.set(\"was_truncated\", truncated)\n",
        "    ctx.memory.set(\"source_length\", len(text))\n",
        "    ctx.memory.set(\"used_length\", len(short_text))\n",
        "\n",
        "    prompt = f\"\"\"You are an expert technical writer.\n",
        "\n",
        "Summarize the following content into a set of clear, concise bullet points. Focus on the main ideas, and skip boilerplate or excessive detail.\n",
        "\n",
        "Text:\n",
        "\\\"\\\"\\\"\n",
        "{short_text}\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "    ctx.memory.set(\"summary_prompt\", prompt)\n",
        "    return {\n",
        "        \"message\": \"Summary prompt created.\",\n",
        "        \"prompt_preview\": prompt[:600],\n",
        "        \"truncated\": truncated,\n",
        "        \"used\": len(short_text),\n",
        "        \"total\": len(text),\n",
        "    }\n",
        "\n",
        "# ---------------- Tool: save_summary ----------------\n",
        "def save_summary(ctx, out_name=None):\n",
        "    ctx.track_progress(\"save_summary\", \"started\")\n",
        "    summary = ctx.memory.get(\"summary\")\n",
        "    if not summary:\n",
        "        err = \"No summary in memory.\"\n",
        "        ctx.track_progress(\"save_summary\", \"error\", err)\n",
        "        return {\"error\": err}\n",
        "\n",
        "    out_dir = ctx.config.get(\"output_folder\")\n",
        "    if not out_dir:\n",
        "        err = \"No output_folder in config.\"\n",
        "        ctx.track_progress(\"save_summary\", \"error\", err)\n",
        "        return {\"error\": err}\n",
        "\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    base = out_name\n",
        "    if not base:\n",
        "        src = ctx.memory.get(\"file_name\", \"summary.txt\")\n",
        "        root, _ = os.path.splitext(os.path.basename(src))\n",
        "        base = f\"{root}_summary.txt\"\n",
        "    path = os.path.join(out_dir, base)\n",
        "\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(summary)\n",
        "\n",
        "    ctx.memory.set(\"summary_path\", path)\n",
        "    ctx.track_progress(\"save_summary\", \"completed\", f\"path={path}\")\n",
        "    return {\"message\": \"Summary saved.\", \"path\": path}\n",
        "\n",
        "# ---------------- Run Prompt Generator ----------------\n",
        "ctx.track_progress(\"generate_summary_prompt\", \"started\")\n",
        "prompt_result = generate_summary_prompt(ctx)\n",
        "if \"error\" in prompt_result:\n",
        "    ctx.track_progress(\"generate_summary_prompt\", \"error\", prompt_result[\"error\"])\n",
        "    print(\"âŒ\", prompt_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"generate_summary_prompt\", \"completed\")\n",
        "    print(\"ðŸ› ï¸\", prompt_result[\"message\"])\n",
        "    if prompt_result.get(\"truncated\"):\n",
        "        print(f\"(note) Prompt truncated to {prompt_result['used']} / {prompt_result['total']} chars.\")\n",
        "    print(\"\\nðŸ§¾ Prompt Preview:\\n\")\n",
        "    print(textwrap.fill(prompt_result[\"prompt_preview\"], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "# ---------------- Tool: summarize ----------------\n",
        "def summarize(ctx):\n",
        "    prompt = ctx.memory.get(\"summary_prompt\")\n",
        "    if not prompt:\n",
        "        return {\"error\": \"No summary prompt found in memory.\"}\n",
        "    try:\n",
        "        response = ctx.llm.complete(prompt)\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"LLM error: {e}\"}\n",
        "\n",
        "    ctx.memory.set(\"summary\", response)\n",
        "    return {\"message\": \"Summary completed.\", \"summary_preview\": response[:1000]}\n",
        "\n",
        "res = save_summary(ctx)\n",
        "print(res.get(\"message\", res.get(\"error\")))\n",
        "\n",
        "# ---------------- Run summarization ----------------\n",
        "ctx.track_progress(\"summarize\", \"started\")\n",
        "summary_result = summarize(ctx)\n",
        "if \"error\" in summary_result:\n",
        "    ctx.track_progress(\"summarize\", \"error\", summary_result[\"error\"])\n",
        "    print(\"âŒ Error:\", summary_result[\"error\"])\n",
        "else:\n",
        "    ctx.track_progress(\"summarize\", \"completed\")\n",
        "    print(\"\\nâœ…\", summary_result[\"message\"])\n",
        "    print(\"\\nðŸ“ Summary Preview:\\n\")\n",
        "    print(textwrap.fill(summary_result[\"summary_preview\"], width=80, subsequent_indent=\"  \"))\n",
        "\n",
        "\n",
        "# ---------------- Print ActionContext Overview ----------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“¦ ActionContext Snapshot\")\n",
        "\n",
        "# Memory contents\n",
        "print(\"\\nðŸ§  Memory:\")\n",
        "for key, value in ctx.memory.store.items():\n",
        "    display = str(value)\n",
        "    if isinstance(value, str) and len(display) > 400:\n",
        "        display = display[:400] + \"...\"\n",
        "    print(f\"  {key}: {display}\")\n",
        "\n",
        "# Config\n",
        "print(\"\\nâš™ï¸ Config:\")\n",
        "print(f\"  {ctx.config}\")\n",
        "\n",
        "# LLM Info\n",
        "print(\"\\nðŸ§© LLM:\")\n",
        "if ctx.llm:\n",
        "    print(f\"  Type: {ctx.llm.__class__.__name__}\")\n",
        "    print(f\"  Model: {ctx.llm.model}\")\n",
        "else:\n",
        "    print(\"  No LLM connected.\")\n",
        "\n",
        "# Progress log (optional)\n",
        "ctx.print_progress()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBV0tDcurxw8",
        "outputId": "ac0bbd4f-748f-48c3-be24-59153f6da0cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan created from goal.\n",
            "\n",
            "Plan:\n",
            "- Open the text file using a text editor or programming tool\n",
            "- Read the content of the text file\n",
            "- Identify the main ideas and key points in the text\n",
            "- Take notes on important details and supporting information\n",
            "- Organize the notes into a coherent structure\n",
            "- Write a concise summary based on the organized notes\n",
            "- Review and edit the summary for clarity and accuracy\n",
            "\n",
            "\n",
            "ðŸŽ¯ Goal:\n",
            "Summarize the content of a text file.\n",
            "\n",
            "\n",
            "âœ… File read successfully.\n",
            "Character count: 3107\n",
            "\n",
            "ðŸ“„ File Preview:\n",
            "\n",
            " #===========AI-Agent Tool Descriptions and Naming  Describing Tools to the\n",
            "  Agent  When developing an agentic AI system, one of the most critical aspects\n",
            "  is ensuring that the agent understands the tools it has access to. In our\n",
            "  previous tutorial, we explored how an AI agent interacts with an environment.\n",
            "  Now, we extend that discussion to focus on tool definition, particularly the\n",
            "  importance of naming, parameters, and structured metadata.  Example:\n",
            "  Automating Documentation for Python Code Imagine we are building an AI agent\n",
            "  that scans through all Python files in a src/ directory and automatical\n",
            "ðŸ› ï¸ Summary prompt created.\n",
            "(note) Prompt truncated to 2000 / 3107 chars.\n",
            "\n",
            "ðŸ§¾ Prompt Preview:\n",
            "\n",
            "You are an expert technical writer.  Summarize the following content into a set\n",
            "  of clear, concise bullet points. Focus on the main ideas, and skip boilerplate\n",
            "  or excessive detail.  Text: \"\"\"  #===========AI-Agent Tool Descriptions and\n",
            "  Naming  Describing Tools to the Agent  When developing an agentic AI system,\n",
            "  one of the most critical aspects is ensuring that the agent understands the\n",
            "  tools it has access to. In our previous tutorial, we explored how an AI agent\n",
            "  interacts with an environment. Now, we extend that discussion to focus on tool\n",
            "  definition, particularly the importance of naming, para\n",
            "No summary in memory.\n",
            "\n",
            "âœ… Summary completed.\n",
            "\n",
            "ðŸ“ Summary Preview:\n",
            "\n",
            "- **Importance of Tool Understanding**: AI agents must clearly understand the\n",
            "  tools available to them for effective operation.    - **Example Use Case**: An\n",
            "  AI agent automates documentation generation for Python code by:   - Listing\n",
            "  Python files in a `src/` directory.   - Reading the content of each file.   -\n",
            "  Writing documentation files in a `docs/` directory.  - **Tool Definition**:\n",
            "  Basic tool definitions should be enhanced with structured metadata for\n",
            "  clarity.  - **Structured Metadata**: A simple Python function can retrieve\n",
            "  files, but AI requires a more structured approach to tool definitions.  -\n",
            "  **JSON Schema for Parameters**:    - JSON Schema is used to define APIs and is\n",
            "  suitable for AI agents.   - It standardizes the description of tools,\n",
            "  including expected parameters and their types (e.g., a `read_file` tool\n",
            "  requiring a `file_path` parameter of type string).\n",
            "\n",
            "================================================================================\n",
            "ðŸ“¦ ActionContext Snapshot\n",
            "\n",
            "ðŸ§  Memory:\n",
            "  goal: Summarize the content of a text file.\n",
            "  progress_log: [{'step': 'setup', 'status': 'completed', 'note': 'goal + config injected', 'time': '2025-08-26 18:52:47'}, {'step': 'create_plan', 'status': 'started', 'note': 'generating steps', 'time': '2025-08-26 18:52:47'}, {'step': 'create_plan', 'status': 'completed', 'note': 'steps=7', 'time': '2025-08-26 18:52:49'}, {'step': 'read_txt_file', 'status': 'started', 'note': 'file=004_AGENT_Tools.txt', 'time': '2025-08-26 18:52:49'}, {'step': 'read_txt_file', 'status': 'completed', 'note': 'length=3107', 'time': '2025-08-26 18:52:49'}, {'step': 'generate_summary_prompt', 'status': 'started', 'note': '', 'time': '2025-08-26 18:52:49'}, {'step': 'generate_summary_prompt', 'status': 'completed', 'note': '', 'time': '2025-08-26 18:52:49'}, {'step': 'save_summary', 'status': 'started', 'note': '', 'time': '2025-08-26 18:52:49'}, {'step': 'save_summary', 'status': 'error', 'note': 'No summary in memory.', 'time': '2025-08-26 18:52:49'}, {'step': 'summarize', 'status': 'started', 'note': '', 'time': '2025-08-26 18:52:49'}, {'step': 'summarize', 'status': 'completed', 'note': '', 'time': '2025-08-26 18:52:53'}]\n",
            "  plan: ['Open the text file using a text editor or programming tool', 'Read the content of the text file', 'Identify the main ideas and key points in the text', 'Take notes on important details and supporting information', 'Organize the notes into a coherent structure', 'Write a concise summary based on the organized notes', 'Review and edit the summary for clarity and accuracy']\n",
            "  file_name: 004_AGENT_Tools.txt\n",
            "  raw_text: \n",
            "#===========AI-Agent Tool Descriptions and Naming\n",
            "\n",
            "Describing Tools to the Agent\n",
            "\n",
            "When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has access to. In our previous tutorial, we explored how an AI agent interacts with an environment. Now, we extend that discussion to focus on tool definition, particularly the importance of nam...\n",
            "  was_truncated: True\n",
            "  source_length: 3107\n",
            "  used_length: 2000\n",
            "  summary_prompt: You are an expert technical writer.\n",
            "\n",
            "Summarize the following content into a set of clear, concise bullet points. Focus on the main ideas, and skip boilerplate or excessive detail.\n",
            "\n",
            "Text:\n",
            "\"\"\"\n",
            "\n",
            "#===========AI-Agent Tool Descriptions and Naming\n",
            "\n",
            "Describing Tools to the Agent\n",
            "\n",
            "When developing an agentic AI system, one of the most critical aspects is ensuring that the agent understands the tools it has...\n",
            "  summary: - **Importance of Tool Understanding**: AI agents must clearly understand the tools available to them for effective operation.\n",
            "  \n",
            "- **Example Use Case**: An AI agent automates documentation generation for Python code by:\n",
            "  - Listing Python files in a `src/` directory.\n",
            "  - Reading the content of each file.\n",
            "  - Writing documentation files in a `docs/` directory.\n",
            "\n",
            "- **Tool Definition**: Basic tool de...\n",
            "\n",
            "âš™ï¸ Config:\n",
            "  {'input_folder': '/content/files', 'output_folder': '/content/output'}\n",
            "\n",
            "ðŸ§© LLM:\n",
            "  Type: OpenAILLM\n",
            "  Model: gpt-4o-mini\n",
            "\n",
            "ðŸ“Š Progress Log:\n",
            "- [completed] setup (2025-08-26 18:52:47) â€” goal + config injected\n",
            "- [started] create_plan (2025-08-26 18:52:47) â€” generating steps\n",
            "- [completed] create_plan (2025-08-26 18:52:49) â€” steps=7\n",
            "- [started] read_txt_file (2025-08-26 18:52:49) â€” file=004_AGENT_Tools.txt\n",
            "- [completed] read_txt_file (2025-08-26 18:52:49) â€” length=3107\n",
            "- [started] generate_summary_prompt (2025-08-26 18:52:49)\n",
            "- [completed] generate_summary_prompt (2025-08-26 18:52:49)\n",
            "- [started] save_summary (2025-08-26 18:52:49)\n",
            "- [error] save_summary (2025-08-26 18:52:49) â€” No summary in memory.\n",
            "- [started] summarize (2025-08-26 18:52:49)\n",
            "- [completed] summarize (2025-08-26 18:52:53)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTFNlZjHunnX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}