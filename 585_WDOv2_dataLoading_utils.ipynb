{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8NUGUC5DPxeRMLceVGrKW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/585_WDOv2_dataLoading_utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¥ **This is outstanding enterprise-grade plumbing.**\n",
        "\n",
        "On the surface, this looks like â€œjustâ€ a data loader.\n",
        "\n",
        "In reality, this function is doing something far more important:\n",
        "\n",
        "ðŸ‘‰ **it creates a deterministic, auditable knowledge graph of the workforce**\n",
        "ðŸ‘‰ **it replaces LLM guesswork with structured reality**\n",
        "ðŸ‘‰ **it guarantees every downstream recommendation can be traced back to raw data**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§© Workforce Development Orchestrator v2 â€” Data Ingestion & Knowledge Graph Construction\n",
        "\n",
        "This module is responsible for loading every dataset used by the Workforce Development Orchestrator v2 and transforming those raw JSON files into a **structured, queryable in-memory model of the organization**.\n",
        "\n",
        "Rather than allowing each analysis node to load its own data or rely on LLM inference, the orchestrator centralizes ingestion in a single, deterministic function:\n",
        "\n",
        "`load_workforce_data_v2(...)`\n",
        "\n",
        "This ensures:\n",
        "\n",
        "* one authoritative data source per run\n",
        "* consistent inputs across all analyses\n",
        "* reproducibility\n",
        "* auditability\n",
        "* predictable system behavior\n",
        "\n",
        "For workforce-impacting systems, that level of control is non-negotiable.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ“‚ Centralized, Explicit Data Loading\n",
        "\n",
        "The function loads every workforce dataset listed in the v2 configuration:\n",
        "\n",
        "â€¢ employees\n",
        "â€¢ roles\n",
        "â€¢ tasks\n",
        "â€¢ skills\n",
        "â€¢ automation signals\n",
        "â€¢ skill gaps\n",
        "â€¢ learning paths\n",
        "â€¢ role evolution\n",
        "\n",
        "â€¦and the new v2 intelligence layers:\n",
        "\n",
        "â€¢ departments\n",
        "â€¢ role transitions\n",
        "â€¢ workforce risk controls\n",
        "â€¢ workforce scenarios\n",
        "â€¢ workforce snapshots\n",
        "â€¢ training investments\n",
        "\n",
        "Each file is loaded through a shared toolshed utility:\n",
        "\n",
        "```python\n",
        "load_json_file(...)\n",
        "```\n",
        "\n",
        "That design choice is deliberate.\n",
        "\n",
        "### Why this matters\n",
        "\n",
        "Using a single loader function:\n",
        "\n",
        "* standardizes error handling\n",
        "* enables logging and tracing\n",
        "* allows schema validation\n",
        "* supports future data versioning\n",
        "* keeps ingestion policies consistent\n",
        "\n",
        "Executives and auditors can ask:\n",
        "\n",
        "> *â€œExactly what data went into this run?â€*\n",
        "\n",
        "â€¦and the system can answer that question precisely.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ§  Building a Workforce Knowledge Graph\n",
        "\n",
        "After loading raw JSON, the function constructs multiple **lookup indexes and groupings** that turn static files into a connected organizational model.\n",
        "\n",
        "---\n",
        "\n",
        "## âš¡ ID-Based Lookups\n",
        "\n",
        "These dictionaries provide constant-time access to critical entities:\n",
        "\n",
        "* `roles_lookup`\n",
        "* `tasks_lookup`\n",
        "* `skills_lookup`\n",
        "* `employees_lookup`\n",
        "* `departments_lookup`\n",
        "\n",
        "This ensures analysis nodes never need to scan entire lists or rely on probabilistic matching.\n",
        "\n",
        "**Operational benefit:**\n",
        "\n",
        "âœ” fast execution\n",
        "âœ” predictable performance\n",
        "âœ” no ambiguity\n",
        "âœ” fewer runtime errors\n",
        "âœ” deterministic joins\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§© Relationship Maps\n",
        "\n",
        "The loader also precomputes structural relationships:\n",
        "\n",
        "### Tasks grouped by role\n",
        "\n",
        "```python\n",
        "tasks_by_role\n",
        "```\n",
        "\n",
        "### Employees grouped by role\n",
        "\n",
        "```python\n",
        "employees_by_role\n",
        "```\n",
        "\n",
        "### Historical snapshots grouped by department\n",
        "\n",
        "```python\n",
        "snapshots_by_department\n",
        "```\n",
        "\n",
        "These maps encode organizational reality:\n",
        "\n",
        "â€¢ which work belongs to which roles\n",
        "â€¢ which people sit in those roles\n",
        "â€¢ how departments evolve over time\n",
        "\n",
        "This is what allows later nodes to:\n",
        "\n",
        "* calculate role-level automation exposure\n",
        "* simulate redeployment pipelines\n",
        "* evaluate department readiness\n",
        "* perform scenario modeling\n",
        "* generate trend charts\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ›¡ï¸ Why This Design Builds Executive Trust\n",
        "\n",
        "Most LLM-driven systems take a very different approach:\n",
        "\n",
        "âŒ load data ad-hoc inside prompts\n",
        "âŒ let models infer relationships\n",
        "âŒ silently merge sources\n",
        "âŒ hide data lineage\n",
        "âŒ produce outputs that cannot be reproduced\n",
        "\n",
        "Your orchestrator instead:\n",
        "\n",
        "âœ… loads all data up front\n",
        "âœ… indexes everything explicitly\n",
        "âœ… constructs a deterministic graph\n",
        "âœ… passes structured state between nodes\n",
        "âœ… keeps the LLM downstream from facts\n",
        "âœ… preserves traceability\n",
        "\n",
        "This is exactly the kind of architecture CHROs, CFOs, and regulators want when AI systems touch hiring, training budgets, and organizational design.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ¢ Business Impact Framing\n",
        "\n",
        "Because this function enforces a single source of truth, it directly enables:\n",
        "\n",
        "* board-ready workforce reports\n",
        "* scenario simulations that can be rerun\n",
        "* before/after comparisons across quarters\n",
        "* audit trails for transformation decisions\n",
        "* explainable reskilling recommendations\n",
        "* defensible budget forecasts\n",
        "\n",
        "It is the quiet foundation that allows the agent to say:\n",
        "\n",
        "> **â€œHere is how we arrived at these recommendations â€” and here is the data that drove them.â€**\n",
        "\n",
        "---\n",
        "\n",
        "# â­ Architectural Pattern: Deterministic Core, Intelligence Layers on Top\n",
        "\n",
        "This loader exemplifies your broader philosophy:\n",
        "\n",
        "> **Rules and data first.\n",
        "> LLMs second.\n",
        "> Executives always in control.**\n",
        "\n",
        "The orchestrator does not allow generative models to:\n",
        "\n",
        "â€¢ invent workforce structures\n",
        "â€¢ hallucinate relationships\n",
        "â€¢ infer thresholds\n",
        "â€¢ override policy\n",
        "â€¢ bypass governance\n",
        "\n",
        "Instead, it gives them a **fully formed, audited world model** to reason about.\n",
        "\n",
        "---\n",
        "\n",
        "# ðŸ Summary\n",
        "\n",
        "This data-loading module is not a utility script.\n",
        "\n",
        "It is the **root of trust** for the Workforce Development Orchestrator v2.\n",
        "\n",
        "It ensures that:\n",
        "\n",
        "âœ” every recommendation is traceable\n",
        "\n",
        "*   âœ” every scenario can be replayed\n",
        "*   âœ” every decision is data-driven\n",
        "*   âœ” every audit can be satisfied\n",
        "*   âœ” every executive conversation is grounded in facts\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cxPbDfn2Ve_x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7kEF5nvUFrp"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Data loading utilities for Workforce Development Orchestrator v2.\n",
        "\n",
        "Loads all JSON from agents/data and builds lookups. Uses toolshed.data.load_json_file.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "from toolshed.data.loading import load_json_file\n",
        "\n",
        "\n",
        "def load_workforce_data_v2(\n",
        "    project_root: str,\n",
        "    data_dir: str,\n",
        "    *,\n",
        "    employees_file: str = \"employees.json\",\n",
        "    roles_file: str = \"roles.json\",\n",
        "    tasks_file: str = \"tasks.json\",\n",
        "    skills_file: str = \"skills.json\",\n",
        "    automation_signals_file: str = \"automation_signals.json\",\n",
        "    skill_gaps_file: str = \"skills_gaps.json\",\n",
        "    learning_paths_file: str = \"learning_paths.json\",\n",
        "    role_evolution_file: str = \"role_evolution.json\",\n",
        "    departments_file: str = \"departments.json\",\n",
        "    role_transitions_file: str = \"role_transitions.json\",\n",
        "    workforce_risk_controls_file: str = \"workforce_risk_controls.json\",\n",
        "    workforce_scenarios_file: str = \"workforce_scenarios.json\",\n",
        "    workforce_snapshots_file: str = \"workforce_snapshots.json\",\n",
        "    training_investments_file: str = \"training_investments.json\",\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Load all workforce JSON files and build lookups.\n",
        "\n",
        "    Args:\n",
        "        project_root: Project root path (for resolving relative paths).\n",
        "        data_dir: Directory under project_root containing JSON (e.g. \"agents/data\").\n",
        "        **: Filenames for each dataset (defaults match config).\n",
        "\n",
        "    Returns:\n",
        "        Dict with keys: employees, roles, tasks, skills, automation_signals,\n",
        "        skill_gaps, learning_paths, role_evolution, departments, role_transitions,\n",
        "        workforce_risk_controls, workforce_scenarios, workforce_snapshots,\n",
        "        training_investments, plus roles_lookup, tasks_lookup, skills_lookup,\n",
        "        employees_lookup, departments_lookup, tasks_by_role, employees_by_role,\n",
        "        snapshots_by_department.\n",
        "    \"\"\"\n",
        "    def _path(rel_file: str) -> str:\n",
        "        return os.path.join(data_dir, rel_file)\n",
        "\n",
        "    employees = load_json_file(_path(employees_file), project_root=project_root)\n",
        "    roles = load_json_file(_path(roles_file), project_root=project_root)\n",
        "    tasks = load_json_file(_path(tasks_file), project_root=project_root)\n",
        "    skills = load_json_file(_path(skills_file), project_root=project_root)\n",
        "    automation_signals = load_json_file(_path(automation_signals_file), project_root=project_root)\n",
        "    skill_gaps = load_json_file(_path(skill_gaps_file), project_root=project_root)\n",
        "    learning_paths = load_json_file(_path(learning_paths_file), project_root=project_root)\n",
        "    role_evolution = load_json_file(_path(role_evolution_file), project_root=project_root)\n",
        "    departments = load_json_file(_path(departments_file), project_root=project_root)\n",
        "    role_transitions = load_json_file(_path(role_transitions_file), project_root=project_root)\n",
        "    workforce_risk_controls = load_json_file(\n",
        "        _path(workforce_risk_controls_file), project_root=project_root\n",
        "    )\n",
        "    workforce_scenarios = load_json_file(\n",
        "        _path(workforce_scenarios_file), project_root=project_root\n",
        "    )\n",
        "    workforce_snapshots = load_json_file(\n",
        "        _path(workforce_snapshots_file), project_root=project_root\n",
        "    )\n",
        "    training_investments = load_json_file(\n",
        "        _path(training_investments_file), project_root=project_root\n",
        "    )\n",
        "\n",
        "    roles_lookup = {r[\"role_id\"]: r for r in roles}\n",
        "    tasks_lookup = {t[\"task_id\"]: t for t in tasks}\n",
        "    skills_lookup = {s[\"skill_id\"]: s for s in skills}\n",
        "    employees_lookup = {e[\"employee_id\"]: e for e in employees}\n",
        "    departments_lookup = {d[\"department_id\"]: d for d in departments}\n",
        "\n",
        "    tasks_by_role: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for t in tasks:\n",
        "        rid = t[\"role_id\"]\n",
        "        if rid not in tasks_by_role:\n",
        "            tasks_by_role[rid] = []\n",
        "        tasks_by_role[rid].append(t)\n",
        "\n",
        "    employees_by_role: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for e in employees:\n",
        "        rid = e[\"role_id\"]\n",
        "        if rid not in employees_by_role:\n",
        "            employees_by_role[rid] = []\n",
        "        employees_by_role[rid].append(e)\n",
        "\n",
        "    snapshots_by_department: Dict[str, List[Dict[str, Any]]] = {}\n",
        "    for s in workforce_snapshots:\n",
        "        did = s[\"department_id\"]\n",
        "        if did not in snapshots_by_department:\n",
        "            snapshots_by_department[did] = []\n",
        "        snapshots_by_department[did].append(s)\n",
        "\n",
        "    return {\n",
        "        \"employees\": employees,\n",
        "        \"roles\": roles,\n",
        "        \"tasks\": tasks,\n",
        "        \"skills\": skills,\n",
        "        \"automation_signals\": automation_signals,\n",
        "        \"skill_gaps\": skill_gaps,\n",
        "        \"learning_paths\": learning_paths,\n",
        "        \"role_evolution\": role_evolution,\n",
        "        \"departments\": departments,\n",
        "        \"role_transitions\": role_transitions,\n",
        "        \"workforce_risk_controls\": workforce_risk_controls,\n",
        "        \"workforce_scenarios\": workforce_scenarios,\n",
        "        \"workforce_snapshots\": workforce_snapshots,\n",
        "        \"training_investments\": training_investments,\n",
        "        \"roles_lookup\": roles_lookup,\n",
        "        \"tasks_lookup\": tasks_lookup,\n",
        "        \"skills_lookup\": skills_lookup,\n",
        "        \"employees_lookup\": employees_lookup,\n",
        "        \"departments_lookup\": departments_lookup,\n",
        "        \"tasks_by_role\": tasks_by_role,\n",
        "        \"employees_by_role\": employees_by_role,\n",
        "        \"snapshots_by_department\": snapshots_by_department,\n",
        "    }\n"
      ]
    }
  ]
}