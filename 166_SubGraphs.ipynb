{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOkKdUY4p9ZlKb7ufyudfJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/166_SubGraphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unoZF-V_6gra"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üîπ What is a Graph in LangGraph?\n",
        "\n",
        "* A **graph** is the main workflow definition (`StateGraph`), where you define nodes (functions, models, tools, etc.) and edges (flow between nodes).\n",
        "* It is your **orchestrator** at the top level.\n",
        "\n",
        "Example (simplified):\n",
        "\n",
        "```python\n",
        "graph = StateGraph(MyState)\n",
        "graph.add_node(\"step1\", func1)\n",
        "graph.add_node(\"step2\", func2)\n",
        "graph.add_edge(\"step1\", \"step2\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ What is a Subgraph?\n",
        "\n",
        "A **subgraph** is a *graph inside a graph*.\n",
        "\n",
        "* It behaves like a **single node** in the parent graph, but internally it has its own nodes and edges.\n",
        "* In this example:\n",
        "\n",
        "  * `insurance_graph` is defined independently (its own nodes: `verify_insurance_check`, `verify_insurance_confirm`).\n",
        "  * Then it‚Äôs added into the main `appointment_graph` as a node:\n",
        "\n",
        "    ```python\n",
        "    appointment_graph.add_node(\"insurance_verification\", insurance_graph)\n",
        "    ```\n",
        "* This means the parent graph sees only one step `\"insurance_verification\"`, but inside, there‚Äôs a whole verification flow.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ When to Use Graph vs Subgraph\n",
        "\n",
        "### ‚úÖ Use a plain graph when:\n",
        "\n",
        "* Your workflow is **small** (5‚Äì10 nodes).\n",
        "* All steps belong to the same logical layer.\n",
        "* You don‚Äôt expect to reuse the workflow elsewhere.\n",
        "\n",
        "### ‚úÖ Use subgraphs when:\n",
        "\n",
        "1. **Modularity / Reuse**\n",
        "\n",
        "   * E.g., `insurance_graph` could be reused in different workflows (appointments, billing, claims).\n",
        "   * You build it once, plug it into many parent graphs.\n",
        "\n",
        "2. **Abstraction / Readability**\n",
        "\n",
        "   * Keeps the parent graph clean by hiding internal details.\n",
        "   * Instead of showing 10 insurance-check nodes, the parent just shows `\"insurance_verification\"`.\n",
        "\n",
        "3. **Testing in isolation**\n",
        "\n",
        "   * You can compile and run the subgraph on its own (just like `insurance_graph.invoke(inputs)`).\n",
        "\n",
        "4. **Team collaboration**\n",
        "\n",
        "   * Different teams can own different subgraphs and then integrate them into a bigger pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è Analogy\n",
        "\n",
        "* **Graph** = Whole workflow.\n",
        "* **Subgraph** = A module or function you import into the workflow.\n",
        "\n",
        "Think of it like functions in normal Python:\n",
        "\n",
        "* For small scripts, you can inline logic.\n",
        "* For bigger systems, you split into reusable functions/classes.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ So:\n",
        "\n",
        "* **Graphs** are the building blocks.\n",
        "* **Subgraphs** are how you keep things modular and reusable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FsgY4yHk6lz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END, START\n",
        "from typing import TypedDict\n",
        "\n",
        "\n",
        "# Define Shared State\n",
        "class InsuranceState(TypedDict):\n",
        "    patient_id: str\n",
        "    insurance_verified: bool\n",
        "\n",
        "\n",
        "def verify_insurance_check(state: InsuranceState):\n",
        "    print(\"verify_insurance_check\")\n",
        "    if state[\"patient_id\"] is not None:\n",
        "        return {\"insurance_verified\": True, \"appointment_status\": \"Insurance verification in progress\"}\n",
        "    else:\n",
        "        return {\"insurance_verified\": False, \"appointment_status\": \"Insurance verification pending\"}\n",
        "\n",
        "\n",
        "def verify_insurance_confirm(state: InsuranceState):\n",
        "    print(\"verify_insurance_confirm\")\n",
        "    if state[\"insurance_verified\"]:\n",
        "        return {\"appointment_status\": \"Insurance verified\"}\n",
        "    else:\n",
        "        return {\"appointment_status\": \"Insurance verification failed\"}\n",
        "\n",
        "\n",
        "# Insurance Verification Subgraph\n",
        "insurance_graph = StateGraph(InsuranceState)\n",
        "insurance_graph.add_node(\"verify_insurance_check\", verify_insurance_check)\n",
        "insurance_graph.add_node(\"verify_insurance_confirm\", verify_insurance_confirm)\n",
        "insurance_graph.add_edge(START, \"verify_insurance_check\")\n",
        "insurance_graph.add_edge(\"verify_insurance_check\", \"verify_insurance_confirm\")\n",
        "insurance_graph.add_edge(\"verify_insurance_confirm\", END)\n",
        "insurance_graph = insurance_graph.compile()\n",
        "\n",
        "\n",
        "# Define Shared State\n",
        "class AppointmentState(TypedDict):\n",
        "    patient_id: str\n",
        "    appointment_status: str\n",
        "    insurance_verified: bool\n",
        "    appointment_scheduled: bool\n",
        "\n",
        "\n",
        "def schedule_appointment(state: AppointmentState):\n",
        "    print(\"schedule_appointment\")\n",
        "    if state[\"insurance_verified\"]:\n",
        "        return {\"appointment_scheduled\": True, \"appointment_status\": \"Appointment scheduled\"}\n",
        "    else:\n",
        "        return {\"appointment_scheduled\": False, \"appointment_status\": \"Appointment scheduling failed: Insurance issue\"}\n",
        "\n",
        "\n",
        "# Main Appointment Management Graph\n",
        "appointment_graph = StateGraph(AppointmentState)\n",
        "# TODO: Add Sub Graph as a node\n",
        "appointment_graph.add_node(\"insurance_verification\",insurance_graph)\n",
        "appointment_graph.add_node(\"schedule_appointment\", schedule_appointment)\n",
        "\n",
        "# Define edges\n",
        "# TODO: Add the subgraph edge\n",
        "appointment_graph.add_edge(START,\"insurance_verification\")\n",
        "appointment_graph.add_edge(\"insurance_verification\", \"schedule_appointment\")\n",
        "appointment_graph.add_edge(\"schedule_appointment\", END)\n",
        "\n",
        "appointment_graph = appointment_graph.compile()\n",
        "\n",
        "# Invoke main workflow\n",
        "inputs = {\n",
        "    \"patient_id\": \"PT-2025\",\n",
        "}\n",
        "output = appointment_graph.invoke(inputs)\n",
        "\n",
        "# TODO: Print the final output\n",
        "print(output)"
      ],
      "metadata": {
        "id": "jc6IlcaN6zOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "For a healthcare provider, **insurance verification is a reusable, domain-specific step** that almost every patient-facing workflow needs:\n",
        "\n",
        "* Booking an appointment\n",
        "* Scheduling a surgery\n",
        "* Handling billing / claims\n",
        "* Even some telehealth triage flows\n",
        "\n",
        "If you build it once as a **subgraph**, you can drop it into all of those workflows like a Lego brick.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Why a Subgraph is Perfect Here\n",
        "\n",
        "* **Reusability** ‚Üí you don‚Äôt have to copy-paste the insurance check logic into every agent.\n",
        "* **Consistency** ‚Üí every workflow calls the same insurance module, so you don‚Äôt risk one agent verifying differently than another.\n",
        "* **Maintainability** ‚Üí if the insurance process changes (say new verification APIs), you update the subgraph once, and every agent using it is instantly updated.\n",
        "* **Abstraction** ‚Üí the parent graph doesn‚Äôt get cluttered with details. At the top level, it just says:\n",
        "\n",
        "  ```\n",
        "  intake ‚Üí insurance_verification ‚Üí schedule_appointment\n",
        "  ```\n",
        "\n",
        "  while inside `insurance_verification` you might have multiple checks and confirmations.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è Rule of Thumb\n",
        "\n",
        "* If a step is **common across many workflows** ‚Üí make it a **subgraph**.\n",
        "* If a step is **unique to one workflow** ‚Üí just keep it as a node in that graph.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ So yes, in healthcare, things like *insurance verification*, *consent check*, *identity verification*, etc. are **natural candidates for subgraphs**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5xYHrjrG7oGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° you‚Äôre thinking about the trade-off between **static subgraphs** and a **dynamic RAG-powered module**. Let‚Äôs unpack it:\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Subgraph Approach\n",
        "\n",
        "* **Pros**\n",
        "\n",
        "  * Hard-coded workflow ‚Üí predictable, deterministic flow.\n",
        "  * Great for **process steps** (e.g., ‚Äúcall API A, then confirm with API B‚Äù).\n",
        "  * One update propagates everywhere.\n",
        "* **Cons**\n",
        "\n",
        "  * If rules change often (e.g., compliance wording, insurer policy), you must **update code** or **retrain/test** the flow.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ RAG Agent Approach\n",
        "\n",
        "Imagine your ‚Äúinsurance_verification‚Äù isn‚Äôt a hardwired flow, but an agent that:\n",
        "\n",
        "1. Looks up the latest insurer/compliance documents in a vector store.\n",
        "2. Reads the patient‚Äôs insurance info.\n",
        "3. Generates a decision/recommendation based on the most up-to-date docs.\n",
        "\n",
        "* **Pros**\n",
        "\n",
        "  * Automatically stays current with changing policies, as long as your doc store is updated.\n",
        "  * Lower maintenance ‚Äî you don‚Äôt need to tweak workflow code every time rules shift.\n",
        "  * Transparent: you can log *which passages* were retrieved for auditing.\n",
        "* **Cons**\n",
        "\n",
        "  * Higher variability (model outputs can drift if prompts are loose).\n",
        "  * More expensive per call (retrieval + LLM reasoning).\n",
        "  * Compliance teams sometimes want **deterministic workflows**, not probabilistic answers.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ The Sweet Spot: **Hybrid**\n",
        "\n",
        "Many orgs do **both**:\n",
        "\n",
        "* **Subgraph** for the skeleton (e.g., *always do identity check ‚Üí always do insurance verification ‚Üí always do scheduling*).\n",
        "* Inside the **insurance verification node**, you embed a **RAG agent** that consults compliance docs to decide whether to approve, deny, or escalate.\n",
        "\n",
        "That way:\n",
        "\n",
        "* ‚úÖ Workflow structure stays **consistent and auditable**.\n",
        "* ‚úÖ Content / compliance rules stay **dynamic and updateable**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è Rule of Thumb\n",
        "\n",
        "* If you need **strictly repeatable process steps** ‚Üí subgraph.\n",
        "* If you need **up-to-date knowledge and flexible reasoning** ‚Üí RAG agent.\n",
        "* If you need **both** ‚Üí wrap the RAG inside a subgraph node.\n",
        "\n"
      ],
      "metadata": {
        "id": "aO4OZTeC8cgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üôå let‚Äôs reimagine your  **`insurance_verification`** subgraph with a **RAG-powered agent inside**.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Step 1. Set up the RAG\n",
        "\n",
        "We‚Äôll assume you already have compliance docs indexed in a vector store (Chroma, Pinecone, Weaviate, etc.). Retrieval step pulls the top-k most relevant docs.\n",
        "\n",
        "```python\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Load embeddings + vectorstore\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = Chroma(persist_directory=\"compliance_docs\", embedding_function=embeddings)\n",
        "\n",
        "retriever = db.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "# Define compliance-aware prompt\n",
        "compliance_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an insurance compliance agent. \"\n",
        "               \"Given the patient insurance info and compliance docs, \"\n",
        "               \"decide if coverage is valid and return one of: APPROVED, DENIED, ESCALATE.\"),\n",
        "    (\"human\", \"Patient Insurance: {insurance_info}\\n\\n\"\n",
        "              \"Relevant Docs: {context}\")\n",
        "])\n",
        "\n",
        "# Wrap into chain\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "rag_chain = LLMChain(llm=llm, prompt=compliance_prompt)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Step 2. Insurance Verification Node\n",
        "\n",
        "This node now *retrieves docs dynamically* before asking the LLM to decide.\n",
        "\n",
        "```python\n",
        "def insurance_verification(state):\n",
        "    insurance_info = state[\"insurance_info\"]\n",
        "\n",
        "    # retrieve compliance docs\n",
        "    docs = retriever.get_relevant_documents(insurance_info)\n",
        "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    # run through compliance chain\n",
        "    decision = rag_chain.run({\"insurance_info\": insurance_info, \"context\": context})\n",
        "\n",
        "    return {\"insurance_status\": decision.strip()}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Step 3. Insert into Subgraph\n",
        "\n",
        "Inside your **patient_appointment** workflow:\n",
        "\n",
        "```python\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "builder = StateGraph(dict)\n",
        "builder.add_node(\"insurance_verification\", insurance_verification)\n",
        "\n",
        "# Example: route based on insurance outcome\n",
        "def route_insurance(state):\n",
        "    if state[\"insurance_status\"] == \"APPROVED\":\n",
        "        return \"schedule\"\n",
        "    else:\n",
        "        return END\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    \"insurance_verification\",\n",
        "    route_insurance,\n",
        "    {\"schedule\": \"schedule_appointment\"}\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Key Benefits\n",
        "\n",
        "* **Reusable subgraph** still exists (drop it into any healthcare workflow).\n",
        "* **Dynamic compliance logic**: updates as soon as new docs are ingested, no code changes needed.\n",
        "* **Auditable**: you can log the retrieved docs with each decision for regulators.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Do you want me to also add an **audit log step** so that every insurance verification automatically saves:\n",
        "\n",
        "* Patient insurance info\n",
        "* Retrieved compliance passages\n",
        "* Final decision\n",
        "\n",
        "‚Ä¶so the provider has a compliance trail for every run?\n"
      ],
      "metadata": {
        "id": "gqd1a3O88omm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëç let‚Äôs revisit what `add_edge` does in **LangGraph**.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ `add_edge`\n",
        "\n",
        "This is how you connect **one node** to **the next** in the workflow.\n",
        "It tells the graph: ‚Äúwhen node A finishes, pass the updated state to node B.‚Äù\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "builder.add_node(\"verify\", verify_insurance)\n",
        "builder.add_node(\"schedule\", schedule_appointment)\n",
        "\n",
        "builder.add_edge(\"verify\", \"schedule\")\n",
        "```\n",
        "\n",
        "This means:\n",
        "\n",
        "1. The graph will run `verify_insurance`.\n",
        "2. Whatever state comes out of that node is passed directly into `schedule_appointment`.\n",
        "3. Execution continues in a straight line.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ `add_conditional_edges`\n",
        "\n",
        "Sometimes you don‚Äôt always want to go to the same next step. That‚Äôs where **conditional edges** come in.\n",
        "\n",
        "```python\n",
        "def route_insurance(state):\n",
        "    if state[\"insurance_status\"] == \"APPROVED\":\n",
        "        return \"schedule\"\n",
        "    else:\n",
        "        return \"END\"\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    \"verify\",\n",
        "    route_insurance,\n",
        "    {\"schedule\": \"schedule\"}\n",
        ")\n",
        "```\n",
        "\n",
        "Here:\n",
        "\n",
        "* If status is **APPROVED** ‚Üí go to `schedule`.\n",
        "* Otherwise ‚Üí stop (`END`).\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è Rule of Thumb\n",
        "\n",
        "* Use **`add_edge`** for **fixed, linear flows**.\n",
        "* Use **`add_conditional_edges`** when the next step depends on the state (branching logic).\n",
        "\n"
      ],
      "metadata": {
        "id": "OvWazPOl97C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üîπ RAG Agent\n",
        "\n",
        "This script builds a **Retrieval-Augmented Generation (RAG) agent** for **current affairs news**. It pulls news from live websites, embeds them, retrieves relevant chunks for a query, and then has an LLM summarize the results into a human-friendly answer.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Key Components\n",
        "\n",
        "### 1. **Document Loading**\n",
        "\n",
        "It fetches articles from major outlets (BBC, CNN, NYT, Reuters, Al Jazeera) via `WebBaseLoader` and flattens them into a list of documents.\n",
        "\n",
        "### 2. **Splitting and Embedding**\n",
        "\n",
        "* Splits text into chunks (`chunk_size=300`, `chunk_overlap=20`) for embedding.\n",
        "* Stores these chunks in **ChromaDB** with **Ollama embeddings (llama3.2)**.\n",
        "* Makes a retriever with `.as_retriever()` for queries.\n",
        "\n",
        "### 3. **First Graph (RAG Retrieval)**\n",
        "\n",
        "Defines a tiny graph:\n",
        "\n",
        "* **State:** `RAGGraphState` has `input` and `data`.\n",
        "* **Node:** `retrieve_data` ‚Üí runs the retriever against user input and stores results.\n",
        "* **Edges:** linear flow: `START ‚Üí retrieve_data ‚Üí END`.\n",
        "\n",
        "So `rag_workflow.invoke({\"input\": question})` returns retrieved documents.\n",
        "\n",
        "### 4. **Prompt + LLM Chain**\n",
        "\n",
        "Uses a `ChatPromptTemplate`:\n",
        "\n",
        "```python\n",
        "\"You are a news analyst summarizing the latest current affairs...\"\n",
        "```\n",
        "\n",
        "Bound to `ChatOllama(model=\"llama3.2\")` and parsed with `StrOutputParser()`. This ensures the model outputs clean text summaries.\n",
        "\n",
        "### 5. **Second Graph (Summarization Workflow)**\n",
        "\n",
        "* **State:** `CurrentAffairsGraphState` with `question`, `retrieved_news`, `generation`.\n",
        "* **Node:** `generate_current_affairs_summary`:\n",
        "\n",
        "  * Calls the RAG workflow to get relevant news.\n",
        "  * Feeds results into the summarization chain.\n",
        "  * Returns both raw retrieved docs and the generated summary.\n",
        "* **Edges:** simple linear: `START ‚Üí generate_current_affairs_summary ‚Üí END`.\n",
        "\n",
        "### 6. **Execution**\n",
        "\n",
        "Runs with:\n",
        "\n",
        "```python\n",
        "inputs = {\"question\": \"What are the top global headlines today?\"}\n",
        "response = current_affairs_graph.invoke(inputs)\n",
        "print(response[\"generation\"])\n",
        "```\n",
        "\n",
        "‚Üí Prints a concise news digest from retrieved sources.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ What to Learn From It\n",
        "\n",
        "1. **Separation of Concerns:**\n",
        "   They broke it into two graphs:\n",
        "\n",
        "   * A retrieval-only graph (modular, reusable).\n",
        "   * A summarization graph that *calls* the retrieval graph.\n",
        "\n",
        "2. **Composable Workflows:**\n",
        "   Notice how `rag_workflow` is invoked inside another node. This shows how **graphs can be nested like functions**, making complex RAG pipelines cleaner.\n",
        "\n",
        "3. **End-to-End RAG Agent:**\n",
        "   Classic pattern: **retrieve ‚Üí inject into prompt ‚Üí generate answer**.\n",
        "   This is the same structure you could use for compliance docs, medical knowledge bases, etc.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ In short: your teacher‚Äôs RAG demo is a **current events summarizer**, built from modular graphs ‚Äî one for retrieval, one for summarization, stitched together.\n",
        "\n"
      ],
      "metadata": {
        "id": "cosfQ8hqB7bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, TypedDict\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_ollama import ChatOllama\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Current Affairs News Sources\n",
        "news_urls = [\n",
        "    \"https://www.bbc.com/news\",\n",
        "    \"https://www.cnn.com/world\",\n",
        "    \"https://www.nytimes.com/section/world\",\n",
        "    \"https://www.reuters.com/world/\",\n",
        "    \"https://www.aljazeera.com/news/\"\n",
        "]\n",
        "\n",
        "# Load Current Affairs Documents\n",
        "docs = [WebBaseLoader(url).load() for url in news_urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Split the articles for embeddings\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300, chunk_overlap=20\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# Store and Retrieve Current Affairs with ChromaDB\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"current-affairs-news\",\n",
        "    embedding=OllamaEmbeddings(model=\"llama3.2\"),\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "\n",
        "class RAGGraphState(TypedDict):\n",
        "    input: str\n",
        "    data: str\n",
        "\n",
        "\n",
        "# TODO: Use the retriever and retrieve the matching news\n",
        "def retrieve_data(state: RAGGraphState):\n",
        "    print(\"---Retrieve Data\")\n",
        "    input = state[\"input\"]\n",
        "    data = retriever.invoke(input)\n",
        "    return {\"data\": data}\n",
        "\n",
        "\n",
        "def create_rag_workflow():\n",
        "    workflow = StateGraph(RAGGraphState)\n",
        "    workflow.add_node(\"retrieve_data\", retrieve_data)\n",
        "    workflow.add_edge(START, \"retrieve_data\")\n",
        "    workflow.add_edge(\"retrieve_data\", END)\n",
        "    return workflow.compile()\n",
        "\n",
        "\n",
        "rag_workflow = create_rag_workflow()\n",
        "\n",
        "\n",
        "# Prompt for Current Affairs News Summarization\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are a news analyst summarizing the latest current affairs.\n",
        "    Use the retrieved articles to provide a concise summary.\n",
        "    Highlight key global events and developments.\n",
        "\n",
        "    Question: {question}\n",
        "    News Articles: {context}\n",
        "    Summary:\n",
        "    \"\"\"\n",
        ")\n",
        "model = ChatOllama(model=\"llama3.2\")\n",
        "current_affairs_chain = (\n",
        "        prompt | model | StrOutputParser()\n",
        ")\n",
        "\n",
        "\n",
        "class CurrentAffairsGraphState(TypedDict):\n",
        "    question: str\n",
        "    retrieved_news: List[str]\n",
        "    generation: str\n",
        "\n",
        "\n",
        "# TODO: Summarize the news\n",
        "# News Summary Generation Node\n",
        "def generate_current_affairs_summary(state):\n",
        "    print(\"---GENERATE CURRENT AFFAIRS SUMMARY---\")\n",
        "    question = state[\"question\"]\n",
        "    # TODO: Invoke the rag workflow\n",
        "    retrieved_news = rag_workflow.invoke({\"input\": question})\n",
        "    generation = current_affairs_chain.invoke({\"question\": question,\"context\": retrieved_news[\"data\"]})\n",
        "    return {\"question\": question, \"retrieved_news\": retrieved_news,\"generation\": generation}\n",
        "\n",
        "\n",
        "# Current Affairs News Workflow Definition\n",
        "def create_current_affairs_workflow():\n",
        "    workflow = StateGraph(CurrentAffairsGraphState)\n",
        "    workflow.add_node(\"generate_current_affairs_summary\", generate_current_affairs_summary)\n",
        "    workflow.add_edge(START, \"generate_current_affairs_summary\")\n",
        "    workflow.add_edge(\"generate_current_affairs_summary\", END)\n",
        "    return workflow.compile()\n",
        "\n",
        "\n",
        "# Execute the Current Affairs News Workflow\n",
        "current_affairs_graph = create_current_affairs_workflow()\n",
        "\n",
        "inputs = {\"question\": \"What are the top global headlines today?\"}\n",
        "\n",
        "response = current_affairs_graph.invoke(inputs)\n",
        "\n",
        "print(\"\\n--- CURRENT AFFAIRS SUMMARY ---\")\n",
        "print(response[\"generation\"])\n"
      ],
      "metadata": {
        "id": "MSnrc62z7qnd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}