{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWfr6yyjZe+gE8G630bn+k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/379_GCO_PolicyEval_Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xQIdkMlmDEM"
      },
      "outputs": [],
      "source": [
        "\"\"\"Policy evaluation utilities for Governance & Compliance Orchestrator\n",
        "\n",
        "Evaluates agent action log events against policy rules to detect violations.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Any, List, Optional\n",
        "\n",
        "\n",
        "def check_condition(\n",
        "    event: Dict[str, Any],\n",
        "    condition_key: str,\n",
        "    condition_value: Any\n",
        ") -> bool:\n",
        "    \"\"\"\n",
        "    Check if an event matches a policy condition.\n",
        "\n",
        "    Args:\n",
        "        event: Agent action log event\n",
        "        condition_key: Condition key (e.g., \"region\", \"confidence_score_lt\")\n",
        "        condition_value: Condition value to match against\n",
        "\n",
        "    Returns:\n",
        "        True if condition matches, False otherwise\n",
        "    \"\"\"\n",
        "    # Handle special condition keys\n",
        "    if condition_key == \"confidence_score_lt\":\n",
        "        confidence = event.get(\"confidence_score\", 1.0)\n",
        "        return confidence < condition_value\n",
        "\n",
        "    if condition_key == \"deal_size_gt\":\n",
        "        input_data = event.get(\"input_data\", {})\n",
        "        deal_size = input_data.get(\"deal_size\", 0)\n",
        "        return deal_size > condition_value\n",
        "\n",
        "    if condition_key == \"input_contains_protected_attribute\":\n",
        "        # Check if input_data contains common protected attributes\n",
        "        input_data = event.get(\"input_data\", {})\n",
        "        protected_attrs = [\"gender\", \"age\", \"race\", \"religion\", \"nationality\", \"disability\"]\n",
        "        return any(attr in input_data for attr in protected_attrs)\n",
        "\n",
        "    if condition_key == \"explanation_missing\":\n",
        "        # Check if output lacks explanation\n",
        "        output = event.get(\"output\", {})\n",
        "        return \"explanation\" not in output and \"reasoning\" not in output\n",
        "\n",
        "    # Handle array conditions (e.g., action_type: [\"recommendation_generated\", \"decision_made\"])\n",
        "    if isinstance(condition_value, list):\n",
        "        event_value = event.get(condition_key)\n",
        "        return event_value in condition_value\n",
        "\n",
        "    # Handle nested conditions (e.g., region in input_data)\n",
        "    if condition_key in [\"region\", \"customer_segment\"]:\n",
        "        input_data = event.get(\"input_data\", {})\n",
        "        return input_data.get(condition_key) == condition_value\n",
        "\n",
        "    # Direct match\n",
        "    return event.get(condition_key) == condition_value\n",
        "\n",
        "\n",
        "def evaluate_event_against_policy(\n",
        "    event: Dict[str, Any],\n",
        "    policy: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Evaluate a single event against a single policy rule.\n",
        "\n",
        "    Args:\n",
        "        event: Agent action log event\n",
        "        policy: Policy rule to evaluate against\n",
        "\n",
        "    Returns:\n",
        "        Evaluation result with matched and violation status\n",
        "    \"\"\"\n",
        "    conditions = policy.get(\"conditions\", {})\n",
        "    required_action = policy.get(\"required_action\")\n",
        "    severity = policy.get(\"severity\", \"medium\")\n",
        "\n",
        "    # Check all conditions\n",
        "    all_conditions_match = True\n",
        "    matched_conditions = []\n",
        "\n",
        "    for condition_key, condition_value in conditions.items():\n",
        "        matches = check_condition(event, condition_key, condition_value)\n",
        "        matched_conditions.append({\n",
        "            \"condition\": condition_key,\n",
        "            \"value\": condition_value,\n",
        "            \"matches\": matches\n",
        "        })\n",
        "        if not matches:\n",
        "            all_conditions_match = False\n",
        "\n",
        "    # Determine if this is a violation\n",
        "    # A violation occurs when:\n",
        "    # 1. All conditions match (policy applies)\n",
        "    # 2. The required action was NOT taken\n",
        "    violation = False\n",
        "    reason = \"\"\n",
        "\n",
        "    if all_conditions_match:\n",
        "        if required_action == \"human_approval\" and not event.get(\"human_in_the_loop\", False):\n",
        "            violation = True\n",
        "            reason = f\"Policy requires human approval but event had human_in_the_loop=false\"\n",
        "        elif required_action == \"human_review\" and not event.get(\"human_in_the_loop\", False):\n",
        "            violation = True\n",
        "            reason = f\"Policy requires human review but event had human_in_the_loop=false\"\n",
        "        elif required_action == \"block_and_escalate\":\n",
        "            violation = True\n",
        "            reason = f\"Policy requires blocking and escalation (protected attribute detected)\"\n",
        "        elif required_action == \"request_explanation\":\n",
        "            output = event.get(\"output\", {})\n",
        "            if \"explanation\" not in output and \"reasoning\" not in output:\n",
        "                violation = True\n",
        "                reason = f\"Policy requires explanation but event output lacks explanation\"\n",
        "\n",
        "    return {\n",
        "        \"event_id\": event.get(\"event_id\"),\n",
        "        \"policy_id\": policy.get(\"policy_id\"),\n",
        "        \"matched\": all_conditions_match,\n",
        "        \"violation\": violation,\n",
        "        \"severity\": severity,\n",
        "        \"required_action\": required_action,\n",
        "        \"reason\": reason if violation else \"Policy conditions matched but no violation detected\",\n",
        "        \"matched_conditions\": matched_conditions\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate_all_events(\n",
        "    events: List[Dict[str, Any]],\n",
        "    policies: List[Dict[str, Any]]\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Evaluate all events against all policies.\n",
        "\n",
        "    Args:\n",
        "        events: List of agent action log events\n",
        "        policies: List of policy rules\n",
        "\n",
        "    Returns:\n",
        "        List of policy evaluations (one per event-policy combination)\n",
        "    \"\"\"\n",
        "    evaluations = []\n",
        "\n",
        "    for event in events:\n",
        "        for policy in policies:\n",
        "            evaluation = evaluate_event_against_policy(event, policy)\n",
        "            evaluations.append(evaluation)\n",
        "\n",
        "    return evaluations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Policy Evaluation Engine ‚Äî Turning Rules into Enforceable Governance\n",
        "\n",
        "## What This Code Does\n",
        "\n",
        "This module is the **decision enforcement core** of the Governance & Compliance Orchestrator.\n",
        "\n",
        "Its job is simple, but critical:\n",
        "\n",
        "> **Take real agent actions and objectively evaluate them against explicit governance rules to determine whether a violation occurred.**\n",
        "\n",
        "No LLM judgment.\n",
        "No ambiguity.\n",
        "No hidden logic.\n",
        "\n",
        "Every outcome is deterministic, explainable, and auditable.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Why Policy Evaluation Is Separated from the Orchestrator\n",
        "\n",
        "A key design choice here is that **policy logic lives outside the main agent flow**.\n",
        "\n",
        "This creates three important advantages:\n",
        "\n",
        "1. **Clarity** ‚Äî policies are enforced consistently, not implicitly\n",
        "2. **Testability** ‚Äî policy behavior can be validated independently\n",
        "3. **Governance credibility** ‚Äî rules can be reviewed by legal, compliance, or leadership without reading the entire agent\n",
        "\n",
        "This mirrors how real enterprises implement governance:\n",
        "policy engines are isolated, controlled, and heavily scrutinized.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. How Policy Conditions Are Interpreted\n",
        "\n",
        "### `check_condition(...)`\n",
        "\n",
        "This function is the **policy interpreter**.\n",
        "\n",
        "Instead of hardcoding business logic into the agent, policies express conditions declaratively (e.g., `\"confidence_score_lt\": 0.6`), and this function translates those conditions into concrete checks against real events.\n",
        "\n",
        "### What This Enables\n",
        "\n",
        "* Policies are **data**, not code\n",
        "* New conditions can be added without rewriting the orchestrator\n",
        "* Rules remain readable and explainable\n",
        "\n",
        "### Practical Examples\n",
        "\n",
        "This function supports:\n",
        "\n",
        "* Threshold checks (low confidence, large deal size)\n",
        "* Ethical safeguards (protected attributes in HR decisions)\n",
        "* Transparency enforcement (missing explanations)\n",
        "* List-based matching (multiple action types)\n",
        "* Nested inputs (region, customer segment)\n",
        "\n",
        "This is exactly how you scale governance safely ‚Äî by **expanding rule vocabulary, not agent behavior**.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Evaluating an Event Against a Policy\n",
        "\n",
        "### `evaluate_event_against_policy(...)`\n",
        "\n",
        "This function answers one very specific question:\n",
        "\n",
        "> *‚ÄúDoes this policy apply to this event, and if so, was it violated?‚Äù*\n",
        "\n",
        "It does this in three clear steps:\n",
        "\n",
        "#### Step 1: Condition Matching\n",
        "\n",
        "All policy conditions are evaluated and recorded ‚Äî not just whether the policy matched, but *why*.\n",
        "\n",
        "This produces:\n",
        "\n",
        "* A clear audit trail\n",
        "* Debuggable evaluations\n",
        "* Human-readable reasoning\n",
        "\n",
        "#### Step 2: Violation Determination\n",
        "\n",
        "A violation is **not** assumed just because a policy applies.\n",
        "\n",
        "Instead, the code checks whether the **required governance action** was actually taken:\n",
        "\n",
        "* Human approval\n",
        "* Human review\n",
        "* Explanation provided\n",
        "* Blocking and escalation\n",
        "\n",
        "This distinction is subtle but critical:\n",
        "**policy applicability ‚â† policy violation**.\n",
        "\n",
        "#### Step 3: Structured Evaluation Output\n",
        "\n",
        "The result is a clean, structured evaluation object that downstream systems can rely on.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Why This Violation Logic Is Trustworthy\n",
        "\n",
        "Several design decisions here are especially strong from a governance perspective:\n",
        "\n",
        "### üîπ Explicit Required Actions\n",
        "\n",
        "Policies don‚Äôt vaguely say ‚Äúbe careful‚Äù ‚Äî they specify concrete safeguards.\n",
        "\n",
        "### üîπ Conservative Defaults\n",
        "\n",
        "Violations only occur when:\n",
        "\n",
        "* All conditions match **and**\n",
        "* The required safeguard is missing\n",
        "\n",
        "This avoids over-flagging and builds trust with operators.\n",
        "\n",
        "### üîπ Human Oversight Is First-Class\n",
        "\n",
        "Human involvement is treated as a measurable control, not a soft concept.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Evaluating the Entire System at Scale\n",
        "\n",
        "### `evaluate_all_events(...)`\n",
        "\n",
        "This function performs a **complete governance sweep**:\n",
        "\n",
        "* Every event\n",
        "* Against every policy\n",
        "* With deterministic outcomes\n",
        "\n",
        "While simple in structure, this creates a powerful capability:\n",
        "\n",
        "* Organization-wide audits\n",
        "* Time-window reviews\n",
        "* Agent-by-agent risk analysis\n",
        "\n",
        "And because every evaluation is structured, results can be:\n",
        "\n",
        "* Scored\n",
        "* Prioritized\n",
        "* Summarized for executives\n",
        "* Logged for compliance\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Business Impact of This Design\n",
        "\n",
        "This policy evaluation layer is where AI governance becomes **real**.\n",
        "\n",
        "It transforms abstract concerns like:\n",
        "\n",
        "* ‚ÄúIs the AI behaving responsibly?‚Äù\n",
        "* ‚ÄúAre we exposed to regulatory risk?‚Äù\n",
        "* ‚ÄúCan we explain our decisions?‚Äù\n",
        "\n",
        "Into concrete, defensible answers backed by evidence.\n",
        "\n",
        "### For Executives\n",
        "\n",
        "* Clear rules\n",
        "* Measurable compliance\n",
        "* Actionable violations\n",
        "\n",
        "### For Compliance & Legal\n",
        "\n",
        "* Deterministic enforcement\n",
        "* Full audit trails\n",
        "* Policy-driven controls\n",
        "\n",
        "### For Engineers\n",
        "\n",
        "* Testable logic\n",
        "* Extensible conditions\n",
        "* Separation of concerns\n",
        "\n",
        "---\n",
        "\n",
        "## Bottom Line\n",
        "\n",
        "This code does not *suggest* governance ‚Äî it **enforces it**.\n",
        "\n",
        "By translating human-readable policies into machine-enforced rules, this module creates the foundation for:\n",
        "\n",
        "* Trustworthy AI\n",
        "* Scalable oversight\n",
        "* Executive confidence\n",
        "\n",
        "It‚Äôs exactly the kind of system organizations need before they can safely rely on AI at scale.\n",
        "\n"
      ],
      "metadata": {
        "id": "zYz5hs8ZwV_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWAxZnVfwaSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}