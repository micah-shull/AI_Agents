{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMdX9uRjgrb4H7+QlVYQ6V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/149_Agent_02_Context_Management.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Code"
      ],
      "metadata": {
        "id": "Af8H3OGLHbQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Any\n",
        "import json\n",
        "\n",
        "class Agent:\n",
        "    \"\"\"Base class for all agents\"\"\"\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "\n",
        "    def execute(self, task: str, context: Dict = None) -> Dict:\n",
        "        \"\"\"Override this method in specific agents\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "class ResearchAgent(Agent):\n",
        "    \"\"\"Simple research agent\"\"\"\n",
        "    def execute(self, task: str, context: Dict = None) -> Dict:\n",
        "        # Simulate research work\n",
        "        return {\n",
        "            \"agent\": self.name,\n",
        "            \"result\": f\"Research completed for: {task}\",\n",
        "            \"data\": {\"findings\": [\"fact1\", \"fact2\", \"fact3\"]},\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "\n",
        "class WriterAgent(Agent):\n",
        "    \"\"\"Simple writing agent\"\"\"\n",
        "    def execute(self, task: str, context: Dict = None) -> Dict:\n",
        "        # Use context from previous agents if available\n",
        "        research_data = context.get(\"research_data\", []) if context else []\n",
        "        return {\n",
        "            \"agent\": self.name,\n",
        "            \"result\": f\"Article written about: {task}\",\n",
        "            \"data\": {\"article\": f\"Based on research {research_data}, here's the article...\"},\n",
        "            \"status\": \"success\"\n",
        "        }\n",
        "\n",
        "class BasicOrchestrator:\n",
        "    \"\"\"The simplest possible orchestrator\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # 1. AGENT REGISTRY - catalog of available agents\n",
        "        self.agents: Dict[str, Agent] = {}\n",
        "\n",
        "        # 2. EXECUTION CONTEXT - shared state between agents\n",
        "        self.context: Dict[str, Any] = {}\n",
        "\n",
        "    def register_agent(self, agent: Agent):\n",
        "        \"\"\"Add an agent to our toolshed\"\"\"\n",
        "        self.agents[agent.name] = agent\n",
        "        print(f\"Registered agent: {agent.name}\")\n",
        "\n",
        "    def execute_workflow(self, workflow: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        3. WORKFLOW EXECUTION - the core orchestration logic\n",
        "\n",
        "        workflow format: [\n",
        "            {\"agent\": \"research\", \"task\": \"Find info about AI\"},\n",
        "            {\"agent\": \"writer\", \"task\": \"Write article about AI\"}\n",
        "        ]\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        for step in workflow:\n",
        "            agent_name = step[\"agent\"]\n",
        "            task = step[\"task\"]\n",
        "\n",
        "            # Get the agent from our registry\n",
        "            if agent_name not in self.agents:\n",
        "                results.append({\n",
        "                    \"error\": f\"Agent '{agent_name}' not found\",\n",
        "                    \"status\": \"failed\"\n",
        "                })\n",
        "                break\n",
        "\n",
        "            agent = self.agents[agent_name]\n",
        "\n",
        "            # Execute the agent with current context\n",
        "            try:\n",
        "                result = agent.execute(task, self.context)\n",
        "                results.append(result)\n",
        "\n",
        "                # 4. CONTEXT MANAGEMENT - update shared state\n",
        "                # Pass results to next agents\n",
        "                if result[\"status\"] == \"success\":\n",
        "                    if \"data\" in result:\n",
        "                        key = f\"{agent_name}_data\"\n",
        "                        self.context[key] = result[\"data\"]\n",
        "\n",
        "                print(f\"✓ {agent_name}: {result['result']}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                error_result = {\n",
        "                    \"agent\": agent_name,\n",
        "                    \"error\": str(e),\n",
        "                    \"status\": \"failed\"\n",
        "                }\n",
        "                results.append(error_result)\n",
        "                print(f\"✗ {agent_name}: {str(e)}\")\n",
        "                break  # Stop on first failure\n",
        "\n",
        "        return results\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Create orchestrator\n",
        "    orchestrator = BasicOrchestrator()\n",
        "\n",
        "    # Register agents (build our toolshed)\n",
        "    orchestrator.register_agent(ResearchAgent(\"research\"))\n",
        "    orchestrator.register_agent(WriterAgent(\"writer\"))\n",
        "\n",
        "    # Define a simple workflow\n",
        "    workflow = [\n",
        "        {\"agent\": \"research\", \"task\": \"Find information about AI orchestration\"},\n",
        "        {\"agent\": \"writer\", \"task\": \"Write an article about AI orchestration\"}\n",
        "    ]\n",
        "\n",
        "    # Execute workflow\n",
        "    print(\"\\n--- Executing Workflow ---\")\n",
        "    results = orchestrator.execute_workflow(workflow)\n",
        "\n",
        "    # Show results\n",
        "    print(\"\\n--- Results ---\")\n",
        "    for i, result in enumerate(results):\n",
        "        print(f\"Step {i+1}: {json.dumps(result, indent=2)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "yryEmf4rHZ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Here's the most basic orchestrator that demonstrates the core concepts:This bare-bones orchestrator demonstrates the **4 critical components** that every orchestrator must have:\n",
        "\n",
        "## **1. Agent Registry**\n",
        "- A catalog of available agents (your \"toolshed\")\n",
        "- Allows dynamic discovery and selection of agents\n",
        "- Makes the system modular and extensible\n",
        "\n",
        "## **2. Workflow Execution Engine**\n",
        "- The core logic that runs agents in sequence\n",
        "- Handles the \"what happens next\" decisions\n",
        "- This is where orchestration actually happens\n",
        "\n",
        "## **3. Context Management**\n",
        "- Shared state that flows between agents\n",
        "- Allows agents to build on each other's work\n",
        "- Critical for multi-step workflows\n",
        "\n",
        "## **4. Error Handling**\n",
        "- What happens when an agent fails\n",
        "- Determines if workflow continues or stops\n",
        "- Essential for reliability\n",
        "\n",
        "**Why this is the foundation:**\n",
        "- **Simple**: Only ~100 lines but contains all core concepts\n",
        "- **Extensible**: Easy to add new agents without changing orchestrator\n",
        "- **Testable**: Each component can be tested independently\n",
        "- **Understandable**: Clear separation of concerns\n",
        "\n",
        "**What's missing (we'll add later):**\n",
        "- Parallel execution\n",
        "- Conditional logic\n",
        "- Agent selection strategies  \n",
        "- Sophisticated error recovery\n",
        "- State persistence\n",
        "- Monitoring/observability\n",
        "\n",
        "Try running this code! You can easily add new agents by inheriting from the `Agent` class and registering them. The workflow format is dead simple but powerful.\n",
        "\n"
      ],
      "metadata": {
        "id": "6CeKTTZxHSEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect! **Context Management** is where workflows become truly intelligent - it's the \"memory system\" that allows steps to build on each other's work and enables complex reasoning across the entire workflow.## **What You Should Focus On & Learn:**\n",
        "\n",
        "### **🧠 Context as the \"Workflow Brain\"**\n",
        "\n",
        "Context Management is what transforms a simple sequence of steps into an **intelligent reasoning system**. It enables:\n",
        "\n",
        "1. **Memory**: \"What did we learn in previous steps?\"\n",
        "2. **Communication**: \"How do steps share information?\"\n",
        "3. **Intelligence**: \"Should we branch differently based on what we found?\"\n",
        "4. **Efficiency**: \"Can we reuse previous computations?\"\n",
        "\n",
        "### **🔑 Critical Concepts to Master:**\n",
        "\n",
        "#### **1. Context Scopes** - The Visibility System\n",
        "```python\n",
        "ContextScope.STEP      # Only this step can see it\n",
        "ContextScope.WORKFLOW  # All steps in workflow can see it  \n",
        "ContextScope.SESSION   # All workflows in user session\n",
        "ContextScope.GLOBAL    # System-wide data\n",
        "```\n",
        "**Why this matters:** Controls data visibility and prevents information leakage between unrelated workflows.\n",
        "\n",
        "#### **2. Context Flow** - The Information Pipeline\n",
        "```python\n",
        "# Step 1 produces data\n",
        "research_result = {\"market_size\": 1.2B, \"confidence\": 0.9}\n",
        "\n",
        "# Step 2 automatically gets access to Step 1's results\n",
        "step2_context = {\n",
        "    \"research_result\": research_result,  # Direct access\n",
        "    \"dependencies\": {\"research\": research_result},  # Structured access\n",
        "    \"confidence_score\": 0.9  # Named outputs for easy reference\n",
        "}\n",
        "```\n",
        "**Why this matters:** This is how steps \"build on each other\" instead of working in isolation.\n",
        "\n",
        "#### **3. Conditional Logic** - Dynamic Workflow Branching\n",
        "```python\n",
        "# Workflow can adapt based on intermediate results\n",
        "if context.evaluate_condition(\"confidence_score >= 0.8\"):\n",
        "    execute_step(\"detailed_analysis\")\n",
        "else:\n",
        "    execute_step(\"gather_more_data\")\n",
        "```\n",
        "**Why this matters:** Enables workflows that adapt intelligently to what they discover.\n",
        "\n",
        "#### **4. Memory Management** - Intelligent Resource Usage\n",
        "```python\n",
        "# Automatic cleanup of expired data\n",
        "# LRU eviction when memory gets full\n",
        "# Size tracking to prevent memory bloat\n",
        "```\n",
        "**Why this matters:** Prevents workflows from consuming unlimited memory as they run.\n",
        "\n",
        "## **🎯 The Key Intelligence Features:**\n",
        "\n",
        "### **A. Smart Context Building**\n",
        "Before each step executes, the context manager:\n",
        "1. **Gathers relevant data** from previous steps\n",
        "2. **Provides dependency results** in easily accessible format\n",
        "3. **Includes workflow metadata** for agent awareness\n",
        "4. **Manages memory efficiently** to prevent bloat\n",
        "\n",
        "### **B. Automatic Result Processing**\n",
        "After each step completes, the context manager:\n",
        "1. **Stores complete results** for debugging/auditing\n",
        "2. **Extracts key outputs** for easy access by later steps\n",
        "3. **Creates named references** for intuitive data access\n",
        "4. **Tracks execution metadata** for performance analysis\n",
        "\n",
        "### **C. Dynamic Condition Evaluation**\n",
        "The context manager enables:\n",
        "1. **Path-based conditions**: `\"research_result.confidence > 0.8\"`\n",
        "2. **Boolean flags**: `\"user_approved\"`\n",
        "3. **Complex logic**: `\"threat_level < 0.5 AND budget > 100000\"`\n",
        "\n",
        "## **🚀 Why This Creates Emergent Intelligence:**\n",
        "\n",
        "### **From Simple Steps to Complex Reasoning:**\n",
        "```python\n",
        "# Without context: Isolated steps\n",
        "step1: research_topic()      # → result thrown away\n",
        "step2: analyze_data()        # → starts from scratch\n",
        "step3: write_report()        # → no awareness of findings\n",
        "\n",
        "# With context: Intelligent flow\n",
        "step1: research_topic()      # → stores findings in context\n",
        "step2: analyze_data()        # → uses research findings, stores insights  \n",
        "step3: write_report()        # → synthesizes all previous work\n",
        "```\n",
        "\n",
        "### **Dynamic Adaptation:**\n",
        "```python\n",
        "# Workflow can change behavior based on what it discovers\n",
        "if research_confidence > 0.8:\n",
        "    # High confidence: proceed with advanced analysis\n",
        "    workflow.add_step(\"deep_analysis\")\n",
        "else:\n",
        "    # Low confidence: gather more data first\n",
        "    workflow.add_step(\"additional_research\")\n",
        "```\n",
        "\n",
        "## **🔧 The Technical Beauty:**\n",
        "\n",
        "### **Intelligent Memory Management:**\n",
        "- **TTL (Time To Live)**: Data expires when no longer needed\n",
        "- **LRU Eviction**: Removes least-used data when memory is full  \n",
        "- **Size Tracking**: Prevents any single piece of data from dominating memory\n",
        "- **Access Patterns**: Optimizes based on how data is actually used\n",
        "\n",
        "### **Multi-Level Context Hierarchy:**\n",
        "```python\n",
        "# Agent sees consolidated view:\n",
        "{\n",
        "    \"global_user_preferences\": {...},     # System-wide settings\n",
        "    \"session_data\": {...},                # User session context\n",
        "    \"workflow_config\": {...},             # Workflow-specific data\n",
        "    \"research_result\": {...},             # Previous step output\n",
        "    \"dependencies\": {\"step1\": {...}},     # Structured dependency access\n",
        "    \"_workflow_meta\": {...}               # System information\n",
        "}\n",
        "```\n",
        "\n",
        "## **🎪 Real-World Impact:**\n",
        "\n",
        "### **Example: Market Analysis Workflow**\n",
        "1. **Research step** finds market size = $1.2B, confidence = 90%\n",
        "2. **Context manager** stores this data with metadata\n",
        "3. **Analysis step** gets research data, determines threat level = 40%\n",
        "4. **Context manager** evaluates: `\"confidence >= 0.8 AND threat_level < 0.5\"`\n",
        "5. **Strategy step** executes \"aggressive expansion\" branch instead of \"cautious approach\"\n",
        "\n",
        "**The workflow literally becomes smarter** as it progresses!\n",
        "\n",
        "## **🎯 Key Learning Points:**\n",
        "\n",
        "1. **Context enables workflows to \"remember\"** what they've learned\n",
        "2. **Scoped visibility** prevents data leakage between workflows\n",
        "3. **Automatic memory management** keeps the system efficient\n",
        "4. **Conditional logic** enables dynamic workflow adaptation\n",
        "5. **Rich metadata** provides debugging and optimization insights\n",
        "\n",
        "\n",
        "\n",
        "Context Management is where your orchestrator becomes **truly intelligent** - it's the difference between a task runner and a reasoning system! 🧠✨"
      ],
      "metadata": {
        "id": "mqdyMjVAWEAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Any, Optional, Union\n",
        "from dataclasses import dataclass, field\n",
        "from enum import Enum\n",
        "import json\n",
        "import time\n",
        "from copy import deepcopy\n",
        "\n",
        "class ContextScope(Enum):\n",
        "    \"\"\"Different levels of context visibility\"\"\"\n",
        "    STEP = \"step\"           # Only visible to current step\n",
        "    WORKFLOW = \"workflow\"   # Visible to entire workflow\n",
        "    GLOBAL = \"global\"       # Visible across all workflows\n",
        "    SESSION = \"session\"     # Visible for user session\n",
        "\n",
        "@dataclass\n",
        "class ContextEntry:\n",
        "    \"\"\"Individual piece of context data with metadata\"\"\"\n",
        "    key: str                    # Unique identifier\n",
        "    value: Any                  # The actual data\n",
        "    scope: ContextScope         # Visibility level\n",
        "    created_at: float           # When it was created\n",
        "    created_by: str             # Which step/agent created it\n",
        "\n",
        "    # Data management\n",
        "    ttl: Optional[int] = None   # Time to live in seconds\n",
        "    size_bytes: int = 0         # Memory usage tracking\n",
        "    access_count: int = 0       # Usage tracking\n",
        "    last_accessed: float = field(default_factory=time.time)\n",
        "\n",
        "    # Metadata\n",
        "    data_type: str = \"unknown\"  # Type hint for agents\n",
        "    description: str = \"\"       # Human-readable description\n",
        "    sensitive: bool = False     # Contains sensitive data?\n",
        "\n",
        "class ContextManager:\n",
        "    \"\"\"\n",
        "    CRITICAL COMPONENT: The workflow's memory and communication system\n",
        "\n",
        "    This is what enables:\n",
        "    1. Steps to access results from previous steps\n",
        "    2. Complex reasoning across multiple steps\n",
        "    3. Dynamic workflow adaptation based on intermediate results\n",
        "    4. Efficient data sharing without redundant computation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_memory_mb: int = 100):\n",
        "        # Core storage - hierarchical by scope\n",
        "        self._contexts: Dict[ContextScope, Dict[str, ContextEntry]] = {\n",
        "            scope: {} for scope in ContextScope\n",
        "        }\n",
        "\n",
        "        # Memory management\n",
        "        self.max_memory_bytes = max_memory_mb * 1024 * 1024\n",
        "        self.current_memory_usage = 0\n",
        "\n",
        "        # Access tracking for optimization\n",
        "        self._access_patterns: Dict[str, List[float]] = {}\n",
        "\n",
        "        # Context history for debugging\n",
        "        self._context_history: List[Dict] = []\n",
        "\n",
        "    def set_context(self, key: str, value: Any, scope: ContextScope = ContextScope.WORKFLOW,\n",
        "                   created_by: str = \"system\", **metadata) -> bool:\n",
        "        \"\"\"\n",
        "        CORE METHOD: Store data in context with intelligent management\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Calculate memory usage\n",
        "            size_bytes = self._calculate_size(value)\n",
        "\n",
        "            # Check memory limits\n",
        "            if not self._check_memory_capacity(size_bytes):\n",
        "                self._cleanup_expired_context()\n",
        "                if not self._check_memory_capacity(size_bytes):\n",
        "                    self._evict_least_used_context(size_bytes)\n",
        "\n",
        "            # Create context entry\n",
        "            entry = ContextEntry(\n",
        "                key=key,\n",
        "                value=value,\n",
        "                scope=scope,\n",
        "                created_at=time.time(),\n",
        "                created_by=created_by,\n",
        "                size_bytes=size_bytes,\n",
        "                data_type=type(value).__name__,\n",
        "                description=metadata.get('description', ''),\n",
        "                sensitive=metadata.get('sensitive', False),\n",
        "                ttl=metadata.get('ttl')\n",
        "            )\n",
        "\n",
        "            # Store the entry\n",
        "            self._contexts[scope][key] = entry\n",
        "            self.current_memory_usage += size_bytes\n",
        "\n",
        "            # Record the change\n",
        "            self._record_context_change(\"set\", key, scope, created_by)\n",
        "\n",
        "            print(f\"📝 Context set: {key} ({scope.value}) by {created_by}\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to set context {key}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_context(self, key: str, requestor: str = \"system\",\n",
        "                   scope_priority: List[ContextScope] = None) -> Any:\n",
        "        \"\"\"\n",
        "        INTELLIGENT RETRIEVAL: Get context with scope-aware lookup\n",
        "        \"\"\"\n",
        "        if scope_priority is None:\n",
        "            # Default priority: most specific to most general\n",
        "            scope_priority = [ContextScope.STEP, ContextScope.WORKFLOW,\n",
        "                            ContextScope.SESSION, ContextScope.GLOBAL]\n",
        "\n",
        "        for scope in scope_priority:\n",
        "            if key in self._contexts[scope]:\n",
        "                entry = self._contexts[scope][key]\n",
        "\n",
        "                # Check if expired\n",
        "                if self._is_expired(entry):\n",
        "                    self._remove_context(key, scope)\n",
        "                    continue\n",
        "\n",
        "                # Update access tracking\n",
        "                entry.access_count += 1\n",
        "                entry.last_accessed = time.time()\n",
        "                self._track_access(key, requestor)\n",
        "\n",
        "                print(f\"📖 Context retrieved: {key} ({scope.value}) by {requestor}\")\n",
        "                return entry.value\n",
        "\n",
        "        print(f\"🔍 Context not found: {key} (requested by {requestor})\")\n",
        "        return None\n",
        "\n",
        "    def build_step_context(self, workflow_id: str, step_id: str,\n",
        "                          dependencies: List[str] = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        STEP PREPARATION: Build complete context for step execution\n",
        "        This is what gets passed to agents when they execute\n",
        "        \"\"\"\n",
        "        context = {}\n",
        "\n",
        "        # 1. Include global context (system-wide data)\n",
        "        for key, entry in self._contexts[ContextScope.GLOBAL].items():\n",
        "            if not self._is_expired(entry):\n",
        "                context[f\"global_{key}\"] = entry.value\n",
        "\n",
        "        # 2. Include workflow context (shared across steps)\n",
        "        for key, entry in self._contexts[ContextScope.WORKFLOW].items():\n",
        "            if not self._is_expired(entry):\n",
        "                context[key] = entry.value\n",
        "\n",
        "        # 3. Include dependency results (outputs from previous steps)\n",
        "        if dependencies:\n",
        "            context[\"dependencies\"] = {}\n",
        "            for dep_step_id in dependencies:\n",
        "                dep_result = self.get_context(f\"step_{dep_step_id}_result\")\n",
        "                if dep_result:\n",
        "                    context[\"dependencies\"][dep_step_id] = dep_result\n",
        "                    # Also add direct access for convenience\n",
        "                    context[f\"{dep_step_id}_result\"] = dep_result\n",
        "\n",
        "        # 4. Add workflow metadata\n",
        "        context[\"_workflow_meta\"] = {\n",
        "            \"workflow_id\": workflow_id,\n",
        "            \"current_step\": step_id,\n",
        "            \"timestamp\": time.time(),\n",
        "            \"available_data\": list(context.keys())\n",
        "        }\n",
        "\n",
        "        # 5. Add memory usage info for agents\n",
        "        context[\"_system_info\"] = {\n",
        "            \"memory_usage_mb\": self.current_memory_usage / (1024 * 1024),\n",
        "            \"context_size\": len(context),\n",
        "            \"high_memory_usage\": self.current_memory_usage > (self.max_memory_bytes * 0.8)\n",
        "        }\n",
        "\n",
        "        print(f\"🧠 Built context for {step_id}: {len(context)} entries\")\n",
        "        return context\n",
        "\n",
        "    def store_step_result(self, workflow_id: str, step_id: str, result: Dict,\n",
        "                         agent_name: str) -> bool:\n",
        "        \"\"\"\n",
        "        RESULT PROCESSING: Store step results in context intelligently\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Store the complete result\n",
        "            result_key = f\"step_{step_id}_result\"\n",
        "            self.set_context(\n",
        "                result_key,\n",
        "                result,\n",
        "                ContextScope.WORKFLOW,\n",
        "                created_by=f\"{agent_name}@{step_id}\",\n",
        "                description=f\"Complete result from step {step_id}\",\n",
        "                ttl=3600  # Results expire after 1 hour\n",
        "            )\n",
        "\n",
        "            # Extract and store key outputs for easy access\n",
        "            if \"data\" in result:\n",
        "                data_key = f\"{step_id}_data\"\n",
        "                self.set_context(\n",
        "                    data_key,\n",
        "                    result[\"data\"],\n",
        "                    ContextScope.WORKFLOW,\n",
        "                    created_by=f\"{agent_name}@{step_id}\",\n",
        "                    description=f\"Data output from step {step_id}\"\n",
        "                )\n",
        "\n",
        "            # Store named outputs if provided\n",
        "            if \"outputs\" in result:\n",
        "                for output_name, output_value in result[\"outputs\"].items():\n",
        "                    self.set_context(\n",
        "                        output_name,\n",
        "                        output_value,\n",
        "                        ContextScope.WORKFLOW,\n",
        "                        created_by=f\"{agent_name}@{step_id}\",\n",
        "                        description=f\"Named output '{output_name}' from step {step_id}\"\n",
        "                    )\n",
        "\n",
        "            # Store execution metadata\n",
        "            exec_meta_key = f\"step_{step_id}_meta\"\n",
        "            execution_metadata = {\n",
        "                \"agent\": agent_name,\n",
        "                \"execution_time\": result.get(\"execution_time\", 0),\n",
        "                \"status\": result.get(\"status\", \"unknown\"),\n",
        "                \"timestamp\": time.time(),\n",
        "                \"step_id\": step_id,\n",
        "                \"workflow_id\": workflow_id\n",
        "            }\n",
        "            self.set_context(\n",
        "                exec_meta_key,\n",
        "                execution_metadata,\n",
        "                ContextScope.WORKFLOW,\n",
        "                created_by=\"system\",\n",
        "                description=f\"Execution metadata for step {step_id}\"\n",
        "            )\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to store result for {step_id}: {e}\")\n",
        "            return False\n",
        "\n",
        "    def create_context_summary(self, workflow_id: str) -> Dict:\n",
        "        \"\"\"\n",
        "        WORKFLOW INTELLIGENCE: Create summary of available context\n",
        "        This helps agents understand what data they have access to\n",
        "        \"\"\"\n",
        "        summary = {\n",
        "            \"workflow_context\": {},\n",
        "            \"step_results\": {},\n",
        "            \"global_data\": {},\n",
        "            \"memory_usage\": {\n",
        "                \"current_mb\": self.current_memory_usage / (1024 * 1024),\n",
        "                \"max_mb\": self.max_memory_bytes / (1024 * 1024),\n",
        "                \"utilization\": (self.current_memory_usage / self.max_memory_bytes) * 100\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Categorize context by type\n",
        "        for scope, context_dict in self._contexts.items():\n",
        "            for key, entry in context_dict.items():\n",
        "                if self._is_expired(entry):\n",
        "                    continue\n",
        "\n",
        "                entry_info = {\n",
        "                    \"data_type\": entry.data_type,\n",
        "                    \"size_mb\": entry.size_bytes / (1024 * 1024),\n",
        "                    \"created_by\": entry.created_by,\n",
        "                    \"created_at\": entry.created_at,\n",
        "                    \"access_count\": entry.access_count,\n",
        "                    \"description\": entry.description\n",
        "                }\n",
        "\n",
        "                if scope == ContextScope.WORKFLOW:\n",
        "                    if key.startswith(\"step_\") and key.endswith(\"_result\"):\n",
        "                        summary[\"step_results\"][key] = entry_info\n",
        "                    else:\n",
        "                        summary[\"workflow_context\"][key] = entry_info\n",
        "                elif scope == ContextScope.GLOBAL:\n",
        "                    summary[\"global_data\"][key] = entry_info\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def evaluate_context_condition(self, condition: str, workflow_id: str) -> bool:\n",
        "        \"\"\"\n",
        "        CONDITIONAL LOGIC: Evaluate conditions based on context\n",
        "        This enables dynamic workflow branching\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Build evaluation context\n",
        "            eval_context = {}\n",
        "\n",
        "            # Add workflow context for evaluation\n",
        "            for key, entry in self._contexts[ContextScope.WORKFLOW].items():\n",
        "                if not self._is_expired(entry):\n",
        "                    eval_context[key] = entry.value\n",
        "\n",
        "            # Simple condition evaluation (could be much more sophisticated)\n",
        "            # Examples:\n",
        "            # \"step_analysis_result.confidence > 0.8\"\n",
        "            # \"research_data.source_count >= 5\"\n",
        "            # \"user_approval == true\"\n",
        "\n",
        "            # For demo, use a simple path-based evaluation\n",
        "            if \".\" in condition:\n",
        "                # Handle dotted path like \"step_result.confidence > 0.8\"\n",
        "                parts = condition.split()\n",
        "                if len(parts) == 3:  # \"path operator value\"\n",
        "                    path, operator, value_str = parts\n",
        "\n",
        "                    # Navigate the path\n",
        "                    path_parts = path.split(\".\")\n",
        "                    current = eval_context\n",
        "                    for part in path_parts:\n",
        "                        if isinstance(current, dict) and part in current:\n",
        "                            current = current[part]\n",
        "                        else:\n",
        "                            return False\n",
        "\n",
        "                    # Evaluate condition\n",
        "                    try:\n",
        "                        expected_value = float(value_str) if value_str.replace(\".\", \"\").isdigit() else value_str.strip('\"\\'')\n",
        "                        if operator == \">\":\n",
        "                            return float(current) > float(expected_value)\n",
        "                        elif operator == \"<\":\n",
        "                            return float(current) < float(expected_value)\n",
        "                        elif operator == \">=\":\n",
        "                            return float(current) >= float(expected_value)\n",
        "                        elif operator == \"<=\":\n",
        "                            return float(current) <= float(expected_value)\n",
        "                        elif operator == \"==\":\n",
        "                            return str(current) == str(expected_value)\n",
        "                        elif operator == \"!=\":\n",
        "                            return str(current) != str(expected_value)\n",
        "                    except:\n",
        "                        return False\n",
        "            else:\n",
        "                # Simple boolean check\n",
        "                return bool(eval_context.get(condition, False))\n",
        "\n",
        "            return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to evaluate condition '{condition}': {e}\")\n",
        "            return False\n",
        "\n",
        "    def _calculate_size(self, value: Any) -> int:\n",
        "        \"\"\"Estimate memory usage of a value\"\"\"\n",
        "        try:\n",
        "            return len(json.dumps(value, default=str).encode('utf-8'))\n",
        "        except:\n",
        "            return len(str(value).encode('utf-8'))\n",
        "\n",
        "    def _check_memory_capacity(self, required_bytes: int) -> bool:\n",
        "        \"\"\"Check if we have enough memory for new data\"\"\"\n",
        "        return (self.current_memory_usage + required_bytes) <= self.max_memory_bytes\n",
        "\n",
        "    def _cleanup_expired_context(self):\n",
        "        \"\"\"Remove expired context entries\"\"\"\n",
        "        for scope in self._contexts:\n",
        "            expired_keys = []\n",
        "            for key, entry in self._contexts[scope].items():\n",
        "                if self._is_expired(entry):\n",
        "                    expired_keys.append(key)\n",
        "\n",
        "            for key in expired_keys:\n",
        "                self._remove_context(key, scope)\n",
        "\n",
        "    def _is_expired(self, entry: ContextEntry) -> bool:\n",
        "        \"\"\"Check if context entry has expired\"\"\"\n",
        "        if entry.ttl is None:\n",
        "            return False\n",
        "        return (time.time() - entry.created_at) > entry.ttl\n",
        "\n",
        "    def _evict_least_used_context(self, required_bytes: int):\n",
        "        \"\"\"Remove least-used context to free memory\"\"\"\n",
        "        # Collect all entries with usage info\n",
        "        all_entries = []\n",
        "        for scope in self._contexts:\n",
        "            for key, entry in self._contexts[scope].items():\n",
        "                all_entries.append((key, scope, entry))\n",
        "\n",
        "        # Sort by access count and last access time (LRU-like)\n",
        "        all_entries.sort(key=lambda x: (x[2].access_count, x[2].last_accessed))\n",
        "\n",
        "        # Remove entries until we have enough space\n",
        "        freed_bytes = 0\n",
        "        for key, scope, entry in all_entries:\n",
        "            if freed_bytes >= required_bytes:\n",
        "                break\n",
        "\n",
        "            # Don't evict very recently created entries\n",
        "            if (time.time() - entry.created_at) < 60:  # Don't evict entries < 1 minute old\n",
        "                continue\n",
        "\n",
        "            freed_bytes += entry.size_bytes\n",
        "            self._remove_context(key, scope)\n",
        "            print(f\"🗑️ Evicted context: {key} ({scope.value}) to free memory\")\n",
        "\n",
        "    def _remove_context(self, key: str, scope: ContextScope):\n",
        "        \"\"\"Remove context entry and update memory tracking\"\"\"\n",
        "        if key in self._contexts[scope]:\n",
        "            entry = self._contexts[scope][key]\n",
        "            self.current_memory_usage -= entry.size_bytes\n",
        "            del self._contexts[scope][key]\n",
        "            self._record_context_change(\"remove\", key, scope, \"system\")\n",
        "\n",
        "    def _track_access(self, key: str, requestor: str):\n",
        "        \"\"\"Track access patterns for optimization\"\"\"\n",
        "        if key not in self._access_patterns:\n",
        "            self._access_patterns[key] = []\n",
        "        self._access_patterns[key].append(time.time())\n",
        "\n",
        "        # Keep only recent access history\n",
        "        cutoff_time = time.time() - 3600  # Last hour\n",
        "        self._access_patterns[key] = [t for t in self._access_patterns[key] if t > cutoff_time]\n",
        "\n",
        "    def _record_context_change(self, action: str, key: str, scope: ContextScope, actor: str):\n",
        "        \"\"\"Record context changes for debugging and auditing\"\"\"\n",
        "        self._context_history.append({\n",
        "            \"action\": action,\n",
        "            \"key\": key,\n",
        "            \"scope\": scope.value,\n",
        "            \"actor\": actor,\n",
        "            \"timestamp\": time.time(),\n",
        "            \"memory_usage_mb\": self.current_memory_usage / (1024 * 1024)\n",
        "        })\n",
        "\n",
        "        # Keep only recent history\n",
        "        if len(self._context_history) > 1000:\n",
        "            self._context_history = self._context_history[-500:]  # Keep last 500 changes\n",
        "\n",
        "# Example usage showing context flow in a real workflow\n",
        "def demo_context_management():\n",
        "    \"\"\"Demonstrate how context enables intelligent workflows\"\"\"\n",
        "\n",
        "    context_manager = ContextManager(max_memory_mb=50)\n",
        "\n",
        "    print(\"=== Context Management Demo ===\")\n",
        "\n",
        "    # Simulate workflow execution with context flow\n",
        "    workflow_id = \"market_analysis_001\"\n",
        "\n",
        "    # Step 1: Research phase\n",
        "    print(\"\\n--- Step 1: Market Research ---\")\n",
        "    research_result = {\n",
        "        \"status\": \"success\",\n",
        "        \"data\": {\n",
        "            \"market_size\": 1200000000,\n",
        "            \"growth_rate\": 0.15,\n",
        "            \"key_players\": [\"Company A\", \"Company B\", \"Company C\"],\n",
        "            \"trends\": [\"AI adoption\", \"Cloud migration\", \"Sustainability\"]\n",
        "        },\n",
        "        \"outputs\": {\n",
        "            \"market_analysis\": \"Market shows strong growth potential\",\n",
        "            \"confidence_score\": 0.9\n",
        "        },\n",
        "        \"execution_time\": 45.2\n",
        "    }\n",
        "\n",
        "    context_manager.store_step_result(workflow_id, \"research\", research_result, \"research_agent\")\n",
        "\n",
        "    # Step 2: Competitive analysis (depends on research)\n",
        "    print(\"\\n--- Step 2: Competitive Analysis ---\")\n",
        "    step2_context = context_manager.build_step_context(\n",
        "        workflow_id, \"competitive_analysis\", dependencies=[\"research\"]\n",
        "    )\n",
        "\n",
        "    print(\"Context available to competitive analysis:\")\n",
        "    for key in step2_context.keys():\n",
        "        if not key.startswith(\"_\"):\n",
        "            print(f\"  - {key}: {type(step2_context[key]).__name__}\")\n",
        "\n",
        "    # Competitive analysis uses research data\n",
        "    competitive_result = {\n",
        "        \"status\": \"success\",\n",
        "        \"data\": {\n",
        "            \"competitive_landscape\": \"Fragmented market with opportunities\",\n",
        "            \"market_share_analysis\": {\"Company A\": 0.3, \"Company B\": 0.25, \"Others\": 0.45},\n",
        "            \"threat_assessment\": \"Medium threat level\"\n",
        "        },\n",
        "        \"outputs\": {\n",
        "            \"competitive_summary\": \"Good positioning opportunity exists\",\n",
        "            \"threat_level\": 0.4\n",
        "        },\n",
        "        \"execution_time\": 32.1\n",
        "    }\n",
        "\n",
        "    context_manager.store_step_result(workflow_id, \"competitive_analysis\", competitive_result, \"analysis_agent\")\n",
        "\n",
        "    # Step 3: Strategic recommendation (conditional based on results)\n",
        "    print(\"\\n--- Step 3: Strategic Recommendation ---\")\n",
        "\n",
        "    # Check if conditions are met for aggressive strategy\n",
        "    aggressive_condition = \"competitive_analysis_data.threat_assessment == 'Medium threat level'\"\n",
        "    should_be_aggressive = context_manager.evaluate_context_condition(aggressive_condition, workflow_id)\n",
        "    print(f\"Should use aggressive strategy: {should_be_aggressive}\")\n",
        "\n",
        "    # Check confidence threshold\n",
        "    confidence_condition = \"confidence_score >= 0.8\"\n",
        "    high_confidence = context_manager.evaluate_context_condition(confidence_condition, workflow_id)\n",
        "    print(f\"High confidence in analysis: {high_confidence}\")\n",
        "\n",
        "    # Build context for strategy step\n",
        "    strategy_context = context_manager.build_step_context(\n",
        "        workflow_id, \"strategy\", dependencies=[\"research\", \"competitive_analysis\"]\n",
        "    )\n",
        "\n",
        "    print(f\"\\nFinal strategy context contains {len(strategy_context)} elements\")\n",
        "\n",
        "    # Show context summary\n",
        "    print(\"\\n--- Context Summary ---\")\n",
        "    summary = context_manager.create_context_summary(workflow_id)\n",
        "    print(f\"Workflow context entries: {len(summary['workflow_context'])}\")\n",
        "    print(f\"Step results stored: {len(summary['step_results'])}\")\n",
        "    print(f\"Memory usage: {summary['memory_usage']['current_mb']:.2f} MB\")\n",
        "\n",
        "    print(\"\\nStep results available:\")\n",
        "    for key, info in summary['step_results'].items():\n",
        "        print(f\"  - {key}: {info['data_type']} by {info['created_by']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo_context_management()"
      ],
      "metadata": {
        "id": "sFZAsO4BTIxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}