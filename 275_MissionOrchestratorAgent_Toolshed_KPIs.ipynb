{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr/TY+LnTIUxwJC53oc2Q9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/275_MissionOrchestratorAgent_Toolshed_KPIs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KPI metric calculation utilities"
      ],
      "metadata": {
        "id": "q9GCfejBrtrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"KPI metric calculation utilities\"\"\"\n",
        "\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "\n",
        "def calculate_kpi_metrics(\n",
        "    executed_tasks: List[Dict[str, Any]],\n",
        "    kpi_definitions: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculate current KPI metrics based on executed tasks.\n",
        "\n",
        "    This is a generic implementation that works with any KPI structure.\n",
        "    It calculates:\n",
        "    - Total duration (in minutes, hours, days)\n",
        "    - Number of completed items\n",
        "    - Improvement percentages (if baselines provided)\n",
        "\n",
        "    Args:\n",
        "        executed_tasks: List of completed task execution results\n",
        "        kpi_definitions: KPI definitions dictionary (mission-specific structure)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of calculated KPI metrics\n",
        "    \"\"\"\n",
        "    metrics = {}\n",
        "\n",
        "    # Calculate total time (sum of all task durations)\n",
        "    total_duration_minutes = sum(\n",
        "        task.get(\"duration_minutes\", 0) for task in executed_tasks\n",
        "        if task.get(\"status\") == \"completed\"\n",
        "    )\n",
        "\n",
        "    # Convert to different time units\n",
        "    total_duration_days = total_duration_minutes / (60 * 24)\n",
        "    total_duration_hours = total_duration_minutes / 60.0\n",
        "\n",
        "    # Calculate number of steps (completed tasks)\n",
        "    steps_completed = len([\n",
        "        task for task in executed_tasks\n",
        "        if task.get(\"status\") == \"completed\"\n",
        "    ])\n",
        "\n",
        "    # Map to KPI definitions (generic approach)\n",
        "    # This handles common KPI patterns:\n",
        "    # - target_*_time_days -> actual_*_time_days\n",
        "    # - target_*_time_hours -> actual_*_time_hours\n",
        "    # - max_steps -> actual_steps\n",
        "    # - min_touchpoints -> actual_touchpoints\n",
        "\n",
        "    for key in kpi_definitions.keys():\n",
        "        if key.startswith(\"target_\") and key.endswith(\"_days\"):\n",
        "            metric_name = key.replace(\"target_\", \"actual_\")\n",
        "            metrics[metric_name] = round(total_duration_days, 2)\n",
        "\n",
        "        elif key.startswith(\"target_\") and key.endswith(\"_hours\"):\n",
        "            metric_name = key.replace(\"target_\", \"actual_\")\n",
        "            metrics[metric_name] = round(total_duration_hours, 2)\n",
        "\n",
        "        elif key == \"max_steps\":\n",
        "            metrics[\"actual_steps\"] = steps_completed\n",
        "\n",
        "        elif key == \"min_touchpoints\":\n",
        "            metrics[\"actual_touchpoints\"] = steps_completed\n",
        "\n",
        "    # Calculate improvement percentage if baseline exists\n",
        "    # Look for baseline_* keys and calculate improvement\n",
        "    for key in kpi_definitions.keys():\n",
        "        if key.startswith(\"baseline_\"):\n",
        "            baseline = kpi_definitions[key]\n",
        "\n",
        "            # Find corresponding actual metric\n",
        "            # baseline_onboarding_time_days -> actual_onboarding_time_days\n",
        "            actual_key = key.replace(\"baseline_\", \"actual_\")\n",
        "            actual_value = metrics.get(actual_key, 0)\n",
        "\n",
        "            if baseline > 0 and actual_value is not None:\n",
        "                improvement = ((baseline - actual_value) / baseline) * 100\n",
        "                metrics[\"improvement_percentage\"] = round(improvement, 2)\n",
        "                break  # Only calculate one improvement percentage\n",
        "\n",
        "    return metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "PESrRHxDrrvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ‚úÖ KPI Metric Calculation Utility ‚Äî Summary\n",
        "\n",
        "This utility takes all the **completed task results** and uses them to compute the **actual KPI values** the mission cares about.\n",
        "\n",
        "Think of it like the agent saying:\n",
        "\n",
        "> ‚ÄúLet me total up my performance so far.‚Äù\n",
        "\n",
        "It doesn‚Äôt judge the performance ‚Äî it just **calculates the numbers**, like a scoreboard.\n",
        "The *next* utility interprets those numbers.\n",
        "\n",
        "This function produces values such as:\n",
        "\n",
        "* actual time spent\n",
        "* actual steps taken\n",
        "* actual touchpoints\n",
        "* improvement percentage compared to baseline\n",
        "\n",
        "These become inputs to:\n",
        "\n",
        "* progress tracking\n",
        "* KPI assessment\n",
        "* reporting\n",
        "* mission summaries\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê What It Calculates\n",
        "\n",
        "The function computes the following:\n",
        "\n",
        "---\n",
        "\n",
        "## **1Ô∏è‚É£ Total duration across all completed tasks**\n",
        "\n",
        "It sums all `duration_minutes` fields:\n",
        "\n",
        "* total minutes\n",
        "* total hours\n",
        "* total days\n",
        "\n",
        "These values become the basis for time-based KPIs like:\n",
        "\n",
        "* `actual_onboarding_time_days`\n",
        "* `actual_pipeline_days`\n",
        "* `actual_resolution_time_hours`\n",
        "\n",
        "---\n",
        "\n",
        "## **2Ô∏è‚É£ Total number of completed steps**\n",
        "\n",
        "It counts every task with:\n",
        "\n",
        "```python\n",
        "status == \"completed\"\n",
        "```\n",
        "\n",
        "This value is used for KPIs like:\n",
        "\n",
        "* `actual_steps` (when `max_steps` is defined)\n",
        "* `actual_touchpoints` (when `min_touchpoints` is defined)\n",
        "\n",
        "In many business workflows, ‚Äústeps completed‚Äù or ‚Äútouchpoints‚Äù is a key measure of efficiency.\n",
        "\n",
        "---\n",
        "\n",
        "## **3Ô∏è‚É£ Automatic mapping to KPI definitions**\n",
        "\n",
        "This part is especially clever.\n",
        "\n",
        "Instead of hardcoding KPIs, the function does pattern matching:\n",
        "\n",
        "* if a key is `target_*_days` ‚Üí produce `actual_*_days`\n",
        "* if a key is `target_*_hours` ‚Üí produce `actual_*_hours`\n",
        "* if KPI is `max_steps` ‚Üí produce `actual_steps`\n",
        "* if KPI is `min_touchpoints` ‚Üí produce `actual_touchpoints`\n",
        "\n",
        "This means:\n",
        "\n",
        "> You can define ANY KPI structure in your mission file,\n",
        "> and this utility will adapt automatically.\n",
        "\n",
        "This is a huge win for flexibility.\n",
        "\n",
        "---\n",
        "\n",
        "## **4Ô∏è‚É£ Improvement percentage**\n",
        "\n",
        "If a baseline exists (like baseline times or baseline steps), it computes:\n",
        "\n",
        "```python\n",
        "((baseline - actual) / baseline) * 100\n",
        "```\n",
        "\n",
        "This tells you:\n",
        "\n",
        "> ‚ÄúHow much better did we perform compared to the old way of doing things?‚Äù\n",
        "\n",
        "It stops after the first baseline match, which keeps things simple.\n",
        "\n",
        "---\n",
        "\n",
        "# üéØ Big Picture\n",
        "\n",
        "This utility turns **raw execution data** into **meaningful KPI metrics**:\n",
        "\n",
        "* It is *generic*, so every mission can define its own KPIs\n",
        "* It is *automatic*, so you don‚Äôt need custom logic for each orchestrator\n",
        "* It is *simple*, requiring only task durations + definitions\n",
        "* It is *compatible* with the KPI assessment utility you summarized earlier\n",
        "* It is *report-ready*, giving clean numbers for your mission reports\n",
        "\n",
        "It is essentially the **math engine** of your KPI subsystem.\n",
        "\n",
        "You now have:\n",
        "\n",
        "* KPI metric calculation (this function)\n",
        "* KPI status interpretation (previous utility)\n",
        "\n",
        "Together, they form a complete, reusable KPI module in your toolshed.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f2EDdXhetCOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ROI calculation utilities"
      ],
      "metadata": {
        "id": "8tTL04zlsoNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ROI calculation utilities\"\"\"\n",
        "\n",
        "\n",
        "def calculate_roi_improvement(baseline: float, actual: float) -> float:\n",
        "    \"\"\"\n",
        "    Calculate ROI improvement percentage.\n",
        "\n",
        "    Args:\n",
        "        baseline: Baseline value\n",
        "        actual: Actual value\n",
        "\n",
        "    Returns:\n",
        "        Improvement percentage (positive = improvement, negative = degradation)\n",
        "    \"\"\"\n",
        "    if baseline == 0:\n",
        "        return 0.0\n",
        "\n",
        "    improvement = ((baseline - actual) / baseline) * 100.0\n",
        "    return round(improvement, 2)\n"
      ],
      "metadata": {
        "id": "ZpWrF0durxgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# üìà ROI Improvement Utility ‚Äî Summary\n",
        "\n",
        "This is a tiny function, but it's surprisingly powerful because it gives your agent the ability to measure **how much better (or worse)** the new workflow performed compared to the old one.\n",
        "\n",
        "At its core it answers one question:\n",
        "\n",
        "> **‚ÄúDid we improve compared to the baseline?‚Äù**\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê What It Does\n",
        "\n",
        "It takes two values:\n",
        "\n",
        "* **baseline** ‚Üí how things *used* to be\n",
        "* **actual** ‚Üí how things turned out this time\n",
        "\n",
        "And it returns a simple percentage showing improvement.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úîÔ∏è How it works\n",
        "\n",
        "It uses the universal ROI formula:\n",
        "\n",
        "```\n",
        "(baseline - actual) / baseline * 100\n",
        "```\n",
        "\n",
        "If actual < baseline ‚Üí **positive improvement**\n",
        "If actual > baseline ‚Üí **negative improvement** (you got worse)\n",
        "\n",
        "Example:\n",
        "\n",
        "* Baseline time: 10 days\n",
        "* Actual time: 5 days\n",
        "\n",
        "ROI = 50% improvement üéâ\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê Why it‚Äôs useful\n",
        "\n",
        "Even though the function is small, it's valuable because:\n",
        "\n",
        "* It gives **simple, clear performance signals**\n",
        "* It works for any numeric KPI (time, steps, cost, effort, etc.)\n",
        "* It can be reused across missions, agents, and orchestrators\n",
        "* It gives stakeholders a metric they instantly understand\n",
        "\n",
        "It also plugs neatly into:\n",
        "\n",
        "* KPI metrics\n",
        "* KPI status\n",
        "* Reporting\n",
        "* ROI dashboards\n",
        "* Mission performance summaries\n",
        "\n",
        "---\n",
        "\n",
        "# üéØ Takeaway\n",
        "\n",
        "This utility is like the **magnesium spark** in a chemistry set:\n",
        "\n",
        "Small, lightweight, but it triggers the ‚ÄúWow, we improved!‚Äù moment.\n",
        "\n",
        "It's a perfect example of why reusable tools in your toolshed are so powerful‚Äîeven tiny ones can dramatically increase clarity in your agent ecosystem.\n",
        "\n"
      ],
      "metadata": {
        "id": "YJB8Exb6to9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KPI status assessment utilities"
      ],
      "metadata": {
        "id": "7nHk8e_eroIE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOzNdrRWrfsF"
      },
      "outputs": [],
      "source": [
        "\"\"\"KPI status assessment utilities\"\"\"\n",
        "\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "def assess_kpi_status(\n",
        "    kpi_metrics: Dict[str, Any],\n",
        "    kpi_definitions: Dict[str, Any],\n",
        "    warning_threshold: float = 0.8,\n",
        "    critical_threshold: float = 0.5\n",
        ") -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Assess KPI status (on_track, at_risk, exceeded).\n",
        "\n",
        "    Generic implementation that works with any KPI structure.\n",
        "\n",
        "    Args:\n",
        "        kpi_metrics: Calculated KPI metrics\n",
        "        kpi_definitions: KPI definitions with targets\n",
        "        warning_threshold: Warning threshold (0.8 = 80% of target)\n",
        "        critical_threshold: Critical threshold (0.5 = 50% of target)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary mapping KPI names to status strings\n",
        "    \"\"\"\n",
        "    status = {}\n",
        "\n",
        "    # Generic assessment for time-based KPIs (target_*_time_days, target_*_time_hours)\n",
        "    for target_key in kpi_definitions.keys():\n",
        "        if target_key.startswith(\"target_\") and (target_key.endswith(\"_days\") or target_key.endswith(\"_hours\")):\n",
        "            target = kpi_definitions[target_key]\n",
        "            actual_key = target_key.replace(\"target_\", \"actual_\")\n",
        "            actual = kpi_metrics.get(actual_key)\n",
        "\n",
        "            if actual is not None:\n",
        "                kpi_name = target_key.replace(\"target_\", \"\").replace(\"_days\", \"\").replace(\"_hours\", \"\")\n",
        "\n",
        "                if actual <= target:\n",
        "                    status[kpi_name] = \"exceeded\"  # Better than target\n",
        "                elif actual <= target / critical_threshold:\n",
        "                    status[kpi_name] = \"on_track\"\n",
        "                elif actual <= target / warning_threshold:\n",
        "                    status[kpi_name] = \"at_risk\"\n",
        "                else:\n",
        "                    status[kpi_name] = \"at_risk\"\n",
        "\n",
        "        # Generic assessment for max_* KPIs (e.g., max_steps)\n",
        "        elif target_key.startswith(\"max_\"):\n",
        "            target = kpi_definitions[target_key]\n",
        "            metric_key = target_key.replace(\"max_\", \"actual_\")\n",
        "            actual = kpi_metrics.get(metric_key)\n",
        "\n",
        "            if actual is not None:\n",
        "                kpi_name = target_key.replace(\"max_\", \"\")\n",
        "\n",
        "                if actual <= target:\n",
        "                    status[kpi_name] = \"on_track\"\n",
        "                else:\n",
        "                    status[kpi_name] = \"at_risk\"\n",
        "\n",
        "        # Generic assessment for min_* KPIs (e.g., min_touchpoints)\n",
        "        elif target_key.startswith(\"min_\"):\n",
        "            target = kpi_definitions[target_key]\n",
        "            metric_key = target_key.replace(\"min_\", \"actual_\")\n",
        "            actual = kpi_metrics.get(metric_key)\n",
        "\n",
        "            if actual is not None:\n",
        "                kpi_name = target_key.replace(\"min_\", \"\")\n",
        "\n",
        "                if actual >= target:\n",
        "                    status[kpi_name] = \"on_track\"\n",
        "                else:\n",
        "                    status[kpi_name] = \"at_risk\"\n",
        "\n",
        "    return status\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# ‚úÖ KPI Status Assessment Utility ‚Äî Summary\n",
        "\n",
        "This utility takes the **raw KPI measurements** your orchestrator has calculated (e.g., actual time, actual steps, actual touchpoints) and compares them to your **KPI goals** (targets, minimums, maximums).\n",
        "Its job is to decide:\n",
        "\n",
        "> ‚ÄúIs this KPI looking good, okay, or risky?‚Äù\n",
        "\n",
        "It returns labels like:\n",
        "\n",
        "* `\"exceeded\"` ‚Üí doing better than the goal\n",
        "* `\"on_track\"` ‚Üí meeting expectations\n",
        "* `\"at_risk\"` ‚Üí falling behind or not hitting the metric\n",
        "\n",
        "This gives the orchestrator a **quick health check** on performance.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê What It Checks\n",
        "\n",
        "This function supports three common KPI types:\n",
        "\n",
        "---\n",
        "\n",
        "## **1Ô∏è‚É£ Time-based KPIs: `target_*_days` or `target_*_hours`**\n",
        "\n",
        "Example:\n",
        "\n",
        "* `target_pipeline_days`\n",
        "* `target_resolution_time_hours`\n",
        "\n",
        "The rules:\n",
        "\n",
        "* If the agent finishes faster than the target ‚Üí `\"exceeded\"`\n",
        "* If the actual time is within reasonable range ‚Üí `\"on_track\"`\n",
        "* If the actual time is drifting higher ‚Üí `\"at_risk\"`\n",
        "\n",
        "The warning and critical thresholds (80% and 50%) help classify how close we are to slipping behind.\n",
        "\n",
        "In simple terms:\n",
        "\n",
        "> ‚ÄúThe quicker the agent finishes, the better the status.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## **2Ô∏è‚É£ Maximum KPIs: `max_*`**\n",
        "\n",
        "Example:\n",
        "\n",
        "* `max_steps`\n",
        "* `max_touchpoints`\n",
        "\n",
        "The rule is simple:\n",
        "\n",
        "* If actual ‚â§ max ‚Üí `\"on_track\"`\n",
        "* If actual > max ‚Üí `\"at_risk\"`\n",
        "\n",
        "This is used for things where **less is better**.\n",
        "\n",
        "---\n",
        "\n",
        "## **3Ô∏è‚É£ Minimum KPIs: `min_*`**\n",
        "\n",
        "Example:\n",
        "\n",
        "* `min_touchpoints`\n",
        "* `min_engagement_score`\n",
        "\n",
        "Rule:\n",
        "\n",
        "* If actual ‚â• min ‚Üí `\"on_track\"`\n",
        "* Otherwise ‚Üí `\"at_risk\"`\n",
        "\n",
        "Used when **more is better**.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê Why This Utility Matters\n",
        "\n",
        "This function is important because it allows your orchestrator to:\n",
        "\n",
        "* summarize mission performance\n",
        "* detect problems early\n",
        "* feed clear performance signals to humans\n",
        "* include KPI status in the final report\n",
        "* adjust routing in more advanced frameworks (future)\n",
        "\n",
        "It turns raw numbers into **understandable judgments**.\n",
        "\n",
        "Instead of:\n",
        "\n",
        "> ‚ÄúActual pipeline days = 3.2, target = 5‚Äù\n",
        "\n",
        "You get:\n",
        "\n",
        "> `\"pipeline\": \"exceeded\"`\n",
        "\n",
        "Which is much easier to read, visualize, and react to.\n",
        "\n",
        "---\n",
        "\n",
        "# üéØ The Big Picture\n",
        "\n",
        "You now have:\n",
        "\n",
        "* utilities that **calculate KPIs** (actual values)\n",
        "* utilities that **compute improvement vs baseline**\n",
        "* **this utility**, which converts numbers into easy-to-understand labels\n",
        "\n",
        "Together, these form a **complete KPI module** that:\n",
        "\n",
        "* informs the report\n",
        "* informs the progress tracker\n",
        "* gives humans instant performance insight\n",
        "\n",
        "This is exactly the kind of reusable logic you *want* in the toolshed ‚Äî\n",
        "every orchestrator benefits from clean, consistent KPI assessments.\n",
        "\n"
      ],
      "metadata": {
        "id": "H0gmC74psSsp"
      }
    }
  ]
}