{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCWmc/h4dbDjrXLQy0xzMZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/337_SalesEnab_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Summary Generation Utilities"
      ],
      "metadata": {
        "id": "FOpzPv_TTqAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"LLM Summary Generation Utilities\n",
        "\n",
        "Generate concise executive summaries using LLM.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, Any, Optional\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from config import SalesEnablementOrchestratorConfig\n",
        "\n",
        "\n",
        "def generate_executive_summary(\n",
        "    state: Dict[str, Any],\n",
        "    config: SalesEnablementOrchestratorConfig\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Generate an LLM-powered executive summary of the sales enablement report.\n",
        "\n",
        "    Args:\n",
        "        state: Complete orchestrator state with all insights\n",
        "        config: Configuration with LLM settings\n",
        "\n",
        "    Returns:\n",
        "        Executive summary string, or None if LLM fails\n",
        "    \"\"\"\n",
        "    if not config.enable_llm_summary:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Extract key metrics from state\n",
        "        pipeline_summary = state.get(\"pipeline_summary\", {})\n",
        "        rep_performance = state.get(\"rep_performance_summary\", [])\n",
        "        top_leads = state.get(\"top_priority_leads\", [])\n",
        "        rep_nudges = state.get(\"rep_nudges\", [])\n",
        "        stalled_deals = state.get(\"stalled_deals\", [])\n",
        "        at_risk_deals = state.get(\"at_risk_deals\", [])\n",
        "        win_patterns = state.get(\"win_patterns\", [])\n",
        "        loss_patterns = state.get(\"loss_patterns\", [])\n",
        "\n",
        "        # Build context for LLM\n",
        "        context = f\"\"\"Sales Enablement Report Data:\n",
        "\n",
        "Pipeline Health:\n",
        "- Total Deals: {pipeline_summary.get('total_deals', 0)}\n",
        "- Active Deals: {pipeline_summary.get('active_deals', 0)}\n",
        "- Pipeline Value: ${pipeline_summary.get('total_pipeline_value', 0):,.0f}\n",
        "- Weighted Pipeline Value: ${pipeline_summary.get('weighted_pipeline_value', 0):,.0f}\n",
        "- Win Rate: {pipeline_summary.get('win_rate', 0)*100:.1f}%\n",
        "- Stalled Deals: {pipeline_summary.get('stalled_deals_count', 0)}\n",
        "- At-Risk Deals: {pipeline_summary.get('at_risk_deals_count', 0)}\n",
        "\n",
        "Rep Performance:\n",
        "\"\"\"\n",
        "        for rep in rep_performance[:3]:  # Top 3 reps\n",
        "            context += f\"- {rep.get('rep_name', 'Unknown')}: {rep.get('active_deals', 0)} deals, ${rep.get('pipeline_value', 0):,.0f} pipeline, {rep.get('quota_achievement', 0)*100:.1f}% quota\"\n",
        "            if rep.get('needs_coaching'):\n",
        "                context += \" (‚ö†Ô∏è Needs Coaching)\"\n",
        "            context += \"\\n\"\n",
        "\n",
        "        context += f\"\"\"\n",
        "Top Priority Leads: {len(top_leads)} leads identified\n",
        "Rep Nudges: {len(rep_nudges)} total nudges\n",
        "Win Patterns: {len(win_patterns)} patterns identified\n",
        "Loss Patterns: {len(loss_patterns)} patterns identified\n",
        "\"\"\"\n",
        "\n",
        "        # Create prompt\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are a sales operations executive assistant. Your job is to create concise, actionable executive summaries of sales enablement reports.\n",
        "\n",
        "Focus on:\n",
        "1. Key metrics and their business implications\n",
        "2. Critical issues requiring immediate attention\n",
        "3. Top opportunities to pursue\n",
        "4. Strategic recommendations\n",
        "\n",
        "Keep it brief (3-4 paragraphs max), professional, and action-oriented.\"\"\"),\n",
        "            (\"human\", \"\"\"Create an executive summary based on this sales enablement data:\n",
        "\n",
        "{context}\n",
        "\n",
        "Generate a concise summary that highlights:\n",
        "- Overall pipeline health and key metrics\n",
        "- Critical issues (stalled deals, at-risk deals, rep performance concerns)\n",
        "- Top opportunities (high-priority leads, win patterns)\n",
        "- Strategic recommendations\n",
        "\n",
        "Format as clear, professional prose suitable for executive review.\"\"\")\n",
        "        ])\n",
        "\n",
        "        # Initialize LLM\n",
        "        llm = ChatOpenAI(\n",
        "            model=config.llm_model,\n",
        "            temperature=config.temperature\n",
        "        )\n",
        "\n",
        "        # Generate summary\n",
        "        chain = prompt | llm\n",
        "        response = chain.invoke({\"context\": context})\n",
        "\n",
        "        return response.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        # Graceful fallback - return None if LLM fails\n",
        "        print(f\"‚ö†Ô∏è LLM summary generation failed: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "dTJejM8oTnpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_summary_node(state: SalesEnablementOrchestratorState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    LLM Summary Node: Generate executive summary using LLM.\n",
        "\n",
        "    Creates a concise, executive-friendly summary of the sales enablement insights.\n",
        "    Falls back gracefully if LLM is unavailable.\n",
        "    \"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    config = SalesEnablementOrchestratorConfig()\n",
        "\n",
        "    try:\n",
        "        # Generate LLM summary\n",
        "        summary = generate_executive_summary(state, config)\n",
        "\n",
        "        if summary:\n",
        "            # Save summary to separate file\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            summary_file_path = save_report(\n",
        "                report_content=summary,\n",
        "                report_id=timestamp,\n",
        "                reports_dir=config.reports_dir,\n",
        "                prefix=\"executive_summary\"\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"executive_summary\": summary,\n",
        "                \"summary_file_path\": summary_file_path,\n",
        "                \"errors\": errors\n",
        "            }\n",
        "        else:\n",
        "            # LLM failed or disabled - that's okay, we still have the full report\n",
        "            return {\n",
        "                \"executive_summary\": None,\n",
        "                \"summary_file_path\": None,\n",
        "                \"errors\": errors\n",
        "            }\n",
        "    except Exception as e:\n",
        "        # Graceful fallback - don't fail the workflow if LLM fails\n",
        "        return {\n",
        "            \"executive_summary\": None,\n",
        "            \"summary_file_path\": None,\n",
        "            \"errors\": errors + [f\"llm_summary_node: {str(e)} (non-critical)\"]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "xSpmDh-RTxx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Suite for Phase 7: Orchestrator Workflow\""
      ],
      "metadata": {
        "id": "PPhXzsF2Tgf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEK-3axZNkVB"
      },
      "outputs": [],
      "source": [
        "\"\"\"Test Suite for Phase 7: Orchestrator Workflow\"\"\"\n",
        "\n",
        "from agents.sales_enablement.orchestrator import (\n",
        "    create_sales_enablement_orchestrator,\n",
        "    run_sales_enablement_orchestrator\n",
        ")\n",
        "from config import SalesEnablementOrchestratorState\n",
        "\n",
        "\n",
        "def test_create_orchestrator():\n",
        "    \"\"\"Test orchestrator creation\"\"\"\n",
        "    print(\"Testing create_orchestrator...\")\n",
        "\n",
        "    orchestrator = create_sales_enablement_orchestrator()\n",
        "\n",
        "    assert orchestrator is not None, \"should create orchestrator\"\n",
        "\n",
        "    print(f\"‚úÖ create_orchestrator test passed!\")\n",
        "    print(f\"   Orchestrator created successfully\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def test_run_orchestrator_full():\n",
        "    \"\"\"Test running the full orchestrator workflow\"\"\"\n",
        "    print(\"Testing run_orchestrator_full...\")\n",
        "\n",
        "    final_state = run_sales_enablement_orchestrator()\n",
        "\n",
        "    # Check that all expected outputs are present\n",
        "    assert \"goal\" in final_state, \"should have goal\"\n",
        "    assert \"plan\" in final_state, \"should have plan\"\n",
        "    assert \"leads\" in final_state, \"should have leads\"\n",
        "    assert \"prioritized_leads\" in final_state, \"should have prioritized_leads\"\n",
        "    assert \"customer_needs_analysis\" in final_state, \"should have customer_needs_analysis\"\n",
        "    assert \"outreach_recommendations\" in final_state, \"should have outreach_recommendations\"\n",
        "    assert \"follow_up_actions\" in final_state, \"should have follow_up_actions\"\n",
        "    assert \"rep_nudges\" in final_state, \"should have rep_nudges\"\n",
        "    assert \"deal_insights\" in final_state, \"should have deal_insights\"\n",
        "    assert \"win_patterns\" in final_state, \"should have win_patterns\"\n",
        "    assert \"pipeline_summary\" in final_state, \"should have pipeline_summary\"\n",
        "    assert \"enablement_report\" in final_state, \"should have enablement_report\"\n",
        "    assert \"report_file_path\" in final_state, \"should have report_file_path\"\n",
        "    assert \"executive_summary\" in final_state, \"should have executive_summary field\"\n",
        "\n",
        "    # Check for errors\n",
        "    errors = final_state.get(\"errors\", [])\n",
        "    assert len(errors) == 0, f\"should have no errors, but got: {errors}\"\n",
        "\n",
        "    print(f\"‚úÖ run_orchestrator_full test passed!\")\n",
        "    print(f\"   Report: {final_state.get('report_file_path', 'N/A')}\")\n",
        "    if final_state.get('summary_file_path'):\n",
        "        print(f\"   Summary: {final_state.get('summary_file_path', 'N/A')}\")\n",
        "    print(f\"   Top leads: {len(final_state.get('top_priority_leads', []))}\")\n",
        "    print(f\"   Nudges: {len(final_state.get('rep_nudges', []))}\")\n",
        "    print(f\"   Pipeline: {final_state.get('pipeline_summary', {}).get('active_deals', 0)} active deals\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def test_run_orchestrator_with_lead_id():\n",
        "    \"\"\"Test running orchestrator with specific lead_id\"\"\"\n",
        "    print(\"Testing run_orchestrator_with_lead_id...\")\n",
        "\n",
        "    final_state = run_sales_enablement_orchestrator(lead_id=\"L-001\")\n",
        "\n",
        "    assert final_state.get(\"lead_id\") == \"L-001\", \"should have lead_id in state\"\n",
        "    assert \"prioritized_leads\" in final_state, \"should have prioritized_leads\"\n",
        "\n",
        "    print(f\"‚úÖ run_orchestrator_with_lead_id test passed!\")\n",
        "    print(f\"   Lead ID: {final_state.get('lead_id')}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def test_run_orchestrator_with_focus_area():\n",
        "    \"\"\"Test running orchestrator with specific focus_area\"\"\"\n",
        "    print(\"Testing run_orchestrator_with_focus_area...\")\n",
        "\n",
        "    final_state = run_sales_enablement_orchestrator(focus_area=\"lead_prioritization\")\n",
        "\n",
        "    assert final_state.get(\"focus_area\") == \"lead_prioritization\", \"should have focus_area in state\"\n",
        "    assert \"goal\" in final_state, \"should have goal\"\n",
        "\n",
        "    print(f\"‚úÖ run_orchestrator_with_focus_area test passed!\")\n",
        "    print(f\"   Focus Area: {final_state.get('focus_area')}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Phase 7: Orchestrator Workflow - Test Suite\")\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "    test_create_orchestrator()\n",
        "    test_run_orchestrator_full()\n",
        "    test_run_orchestrator_with_lead_id()\n",
        "    test_run_orchestrator_with_focus_area()\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"‚úÖ All Phase 7 tests passed!\")\n",
        "    print(\"=\" * 60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_007_TEMPLATE copy % python run_sales_enablement.py\n",
        "============================================================\n",
        "Sales Enablement Orchestrator\n",
        "============================================================\n",
        "\n",
        "üöÄ Starting Sales Enablement Orchestrator...\n",
        "   Lead ID: All leads\n",
        "   Rep ID: All reps\n",
        "   Focus Area: All areas\n",
        "\n",
        "============================================================\n",
        "‚úÖ Orchestrator Execution Complete\n",
        "============================================================\n",
        "\n",
        "üìÑ Full Report saved to: output/sales_enablement_reports/sales_enablement_20251229_175300_20251229_175300.md\n",
        "üìã Executive Summary saved to: output/sales_enablement_reports/executive_summary_20251229_175306_20251229_175306.md\n",
        "üìä Pipeline: 11 active deals, $1,204,000 value\n",
        "üéØ Top Priority Leads: 10\n",
        "üîî Rep Nudges: 24\n",
        "‚è±Ô∏è  Duration: 6.78 seconds\n",
        "\n"
      ],
      "metadata": {
        "id": "rSJ25sDnUXOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Executive Summary: Sales Enablement Report**\n",
        "\n",
        "The current pipeline health reflects a total of 15 deals, with 11 active and a cumulative pipeline value of \\$1,204,000. The weighted pipeline value stands at \\$479,300, indicating a win rate of 50%. However, we are facing critical issues with 2 stalled deals and 5 at-risk deals that require immediate attention to avoid potential revenue loss.\n",
        "\n",
        "Rep performance varies significantly, with Alex Morgan leading with 3 deals and an impressive pipeline of $515,000, achieving 81% of quota. In contrast, Jordan Lee is underperforming with only 4 deals totaling \\$152,000 and only 65.3% of quota, highlighting a need for targeted coaching. Priya Shah is performing well with 2 deals at \\$402,000 and 95% of quota. Addressing the performance gap for Jordan is essential to enhance overall team productivity.\n",
        "\n",
        "There are 10 top-priority leads identified, which present significant opportunities for revenue growth. Additionally, we have recognized 4 win patterns that can be leveraged to replicate success in future deals, as well as 4 loss patterns that should be analyzed to mitigate risks in upcoming negotiations.\n",
        "\n",
        "To optimize pipeline performance, it is recommended to implement immediate coaching for Jordan Lee to improve his sales techniques and close rates. Additionally, focus on converting the identified top-priority leads while addressing the stalled and at-risk deals through strategic follow-ups and resource allocation. Leveraging the identified win patterns will also be crucial in enhancing our overall sales strategy and increasing the win rate moving forward."
      ],
      "metadata": {
        "id": "wOLf_mCnUj6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both reports look good. Here's what stands out:\n",
        "\n",
        "## Full report ‚Äî comprehensive and well-structured\n",
        "\n",
        "Strengths:\n",
        "- Pipeline metrics are accurate ($1,204,000 total, $479,300 weighted)\n",
        "- Rep performance breakdown with clear indicators (‚úì for good, ‚ö†Ô∏è for needs coaching)\n",
        "- Top 10 priority leads ranked by score\n",
        "- Actionable insights: 7 overdue follow-ups, 2 stalled deals, 5 at-risk deals\n",
        "- Historical patterns: win/loss patterns with recommendations\n",
        "- Clear sections for quick scanning\n",
        "\n",
        "## Executive summary ‚Äî concise and actionable\n",
        "\n",
        "Strengths:\n",
        "- 4 focused paragraphs\n",
        "- Highlights critical issues upfront (stalled/at-risk deals)\n",
        "- Rep performance with specific recommendations (Jordan Lee needs coaching)\n",
        "- Strategic opportunities (10 priority leads, win patterns)\n",
        "- Actionable recommendations at the end\n",
        "- Professional tone suitable for executives\n",
        "\n",
        "## What's working well\n",
        "\n",
        "1. Separation of concerns:\n",
        "   - Full report = detailed analysis for operations\n",
        "   - Executive summary = quick insights for leadership\n",
        "\n",
        "2. LLM quality:\n",
        "   - Distills key points effectively\n",
        "   - Maintains accuracy (numbers match the full report)\n",
        "   - Provides actionable recommendations\n",
        "\n",
        "3. Structure:\n",
        "   - Both files are easy to navigate\n",
        "   - Clear formatting and hierarchy\n",
        "   - Professional presentation\n",
        "\n",
        "## Minor observations\n",
        "\n",
        "- The executive summary could include a brief mention of the 24 rep nudges generated (it mentions the leads and patterns but not the nudges)\n",
        "- The full report shows \"Average Days to Close: 0.0 days\" ‚Äî this might be due to data limitations, but it's not critical\n",
        "\n",
        "Overall, the dual-report approach is working well. The full report provides depth, and the executive summary gives leadership a quick, actionable overview. The LLM summary effectively distills the key insights without losing important context."
      ],
      "metadata": {
        "id": "AzdgetrZVEcn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sales Enablement Report\n",
        "\n",
        "**Generated:** 2025-12-29 17:53:00  \n",
        "**Objective:** Enable sales team performance by prioritizing leads, analyzing customer needs, generating outreach, coordinating follow-ups, nudging reps, and surfacing actionable insights\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "### Pipeline Health\n",
        "\n",
        "- **Total Deals:** 15\n",
        "- **Active Deals:** 11\n",
        "- **Won Deals:** 2\n",
        "- **Lost Deals:** 2\n",
        "- **Total Pipeline Value:** \\$1,204,000\n",
        "- **Weighted Pipeline Value:** \\$479,300\n",
        "- **Average Deal Size:** \\$107,667\n",
        "- **Average Days to Close:** 0.0 days\n",
        "- **Win Rate:** 50.0%\n",
        "- **Stalled Deals:** 2\n",
        "- **At-Risk Deals:** 5\n",
        "\n",
        "### Rep Performance\n",
        "\n",
        "‚úì **Alex Morgan** (SR-01)\n",
        "   - Active Deals: 3\n",
        "   - Pipeline Value: $515,000\n",
        "   - Close Rate: 100.0%\n",
        "   - Quota Achievement: 81.0%\n",
        "   - Nudges: 2\n",
        "\n",
        "‚ö†Ô∏è **Jordan Lee** (SR-02)\n",
        "   - Active Deals: 4\n",
        "   - Pipeline Value: $152,000\n",
        "   - Close Rate: 0.0%\n",
        "   - Quota Achievement: 65.3%\n",
        "   - Nudges: 0\n",
        "\n",
        "‚úì **Priya Shah** (SR-03)\n",
        "   - Active Deals: 2\n",
        "   - Pipeline Value: $402,000\n",
        "   - Close Rate: 50.0%\n",
        "   - Quota Achievement: 95.0%\n",
        "   - Nudges: 3\n",
        "\n",
        "‚ö†Ô∏è **Miguel Alvarez** (SR-04)\n",
        "   - Active Deals: 2\n",
        "   - Pipeline Value: $135,000\n",
        "   - Close Rate: 0.0%\n",
        "   - Quota Achievement: 54.0%\n",
        "   - Nudges: 2\n",
        "\n",
        "---\n",
        "\n",
        "## Top Priority Leads\n",
        "\n",
        "1. **Orion Aerospace** (L-020) - Score: 86.6\n",
        "2. **Apex Manufacturing** (L-003) - Score: 85.5\n",
        "3. **Atlas Freight** (L-011) - Score: 83.0\n",
        "4. **NovaEnergy Solutions** (L-006) - Score: 81.8\n",
        "5. **OmniPharma** (L-015) - Score: 77.5\n",
        "6. **Northstar Logistics** (L-001) - Score: 74.5\n",
        "7. **Vertex Consulting** (L-014) - Score: 71.8\n",
        "8. **Skyline Retail Group** (L-005) - Score: 70.2\n",
        "9. **Horizon AgriTech** (L-018) - Score: 69.3\n",
        "10. **ClearWave Health** (L-002) - Score: 62.6\n",
        "\n",
        "---\n",
        "\n",
        "## Customer Needs Analysis\n",
        "\n",
        "### Lead L-001\n",
        "\n",
        "- **Pain Points:** manual reporting, forecast inaccuracy\n",
        "- **Buying Signals:** positive engagement\n",
        "- **Product Fit Score:** 0.00\n",
        "\n",
        "### Lead L-002\n",
        "\n",
        "- **Pain Points:** data silos, slow reporting\n",
        "- **Product Fit Score:** 0.00\n",
        "\n",
        "### Lead L-003\n",
        "\n",
        "- **Pain Points:** cost overruns, margin pressure\n",
        "- **Buying Signals:** proposal requested, positive engagement, pricing discussed\n",
        "- **Product Fit Score:** 0.00\n",
        "\n",
        "### Lead L-004\n",
        "\n",
        "- **Pain Points:** budget forecasting, grant reporting\n",
        "- **Product Fit Score:** 0.00\n",
        "\n",
        "### Lead L-005\n",
        "\n",
        "- **Pain Points:** inventory forecasting, seasonality\n",
        "- **Product Fit Score:** 0.00\n",
        "\n",
        "---\n",
        "\n",
        "## Outreach Recommendations\n",
        "\n",
        "- **L-020** ‚Üí SR-04 via email (N/A)\n",
        "- **L-003** ‚Üí SR-01 via email (N/A)\n",
        "- **L-011** ‚Üí SR-01 via email (N/A)\n",
        "- **L-006** ‚Üí SR-01 via email (N/A)\n",
        "- **L-015** ‚Üí SR-03 via call (N/A)\n",
        "\n",
        "---\n",
        "\n",
        "## Follow-up Actions\n",
        "\n",
        "### ‚ö†Ô∏è Overdue (7)\n",
        "\n",
        "- L-001 ‚Üí SR-01: schedule_call\n",
        "- L-003 ‚Üí SR-01: send_proposal\n",
        "- L-005 ‚Üí SR-03: send_pricing\n",
        "- L-008 ‚Üí SR-04: schedule_call\n",
        "- L-009 ‚Üí SR-04: send_proposal\n",
        "\n",
        "---\n",
        "\n",
        "## Rep Nudges\n",
        "\n",
        "- **Follow Up Due:** 7\n",
        "- **Stalled Deal:** 2\n",
        "- **High Priority Lead:** 10\n",
        "- **Deal At Risk:** 5\n",
        "\n",
        "### Sample Nudges\n",
        "\n",
        "- **SR-01:** ‚ö†Ô∏è Follow-up with Northstar Logistics (L-001) is overdue. You promised to schedule demo 35 days ago....\n",
        "- **SR-01:** ‚ö†Ô∏è Follow-up with Apex Manufacturing (L-003) is overdue. You promised to review proposal internally ...\n",
        "- **SR-03:** ‚ö†Ô∏è Follow-up with Skyline Retail Group (L-005) is overdue. You promised to send pricing comparison 3...\n",
        "- **SR-04:** ‚ö†Ô∏è Follow-up with Helix Biotech (L-008) is overdue. You promised to schedule follow-up 40 days ago....\n",
        "- **SR-04:** ‚ö†Ô∏è Follow-up with Ironclad Construction (L-009) is overdue. You promised to review proposal 43 days ...\n",
        "\n",
        "---\n",
        "\n",
        "## Deal Insights\n",
        "\n",
        "### Stalled Deals (2)\n",
        "\n",
        "- D-004 (L-005): 21 days in current stage\n",
        "- D-008 (L-009): 22 days in current stage\n",
        "\n",
        "### At-Risk Deals (5)\n",
        "\n",
        "- D-002 (L-002): pricing sensitivity\n",
        "- D-004 (L-005): discount pressure, negative sentiment in recent interactions\n",
        "- D-007 (L-008): budget uncertainty\n",
        "- D-008 (L-009): timeline risk\n",
        "- D-014 (L-015): legal review\n",
        "\n",
        "---\n",
        "\n",
        "## Historical Insights\n",
        "\n",
        "### Win Patterns\n",
        "\n",
        "- **Interaction Frequency:** Won deals had 1.0 interactions on average (range: 1-1) (100% frequency)\n",
        "  ‚Üí Recommendation: Aim for 1+ interactions for similar deals\n",
        "- **Positive Sentiment:** 0/2 won deals had 2+ positive interactions (0% frequency)\n",
        "  ‚Üí Recommendation: Focus on building positive engagement early in the sales cycle\n",
        "- **Pricing Discussion:** 0/2 won deals discussed pricing (0% frequency)\n",
        "  ‚Üí Recommendation: Introduce pricing discussion early for qualified leads\n",
        "\n",
        "### Loss Patterns\n",
        "\n",
        "- **Negative Sentiment:** 1/2 lost deals had negative sentiment (50% frequency)\n",
        "  ‚Üí Recommendation: Address negative sentiment immediately when detected\n",
        "- **Risk Flags:** Most common risk flag in lost deals: 'pricing loss' (1 occurrences) (50% frequency)\n",
        "  ‚Üí Recommendation: Monitor and address 'pricing loss' risk flags proactively\n",
        "- **Competition:** Most common competitor in lost deals: 'VendorX' (1 occurrences) (50% frequency)\n",
        "  ‚Üí Recommendation: Develop competitive differentiation strategy against 'VendorX'\n",
        "\n",
        "---\n",
        "\n",
        "*Report generated by Sales Enablement Orchestrator Agent*\n"
      ],
      "metadata": {
        "id": "HwiUURleUcQB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jtWLXHyeUaGa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}