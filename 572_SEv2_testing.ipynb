{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnNGUSBToY0HVOwewLeEN1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/572_SEv2_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for Sales Enablement Orchestrator report generation."
      ],
      "metadata": {
        "id": "Y9AVzFCucH9Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ2INw83bcKR"
      },
      "outputs": [],
      "source": [
        "\"\"\"Tests for Sales Enablement Orchestrator report generation.\"\"\"\n",
        "\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "from config import SalesEnablementOrchestratorConfig\n",
        "from agents.sales_enablement.orchestrator import create_sales_enablement_graph\n",
        "\n",
        "\n",
        "def test_report_is_written_and_contains_sections():\n",
        "    \"\"\"Run full graph; assert report file exists and contains Pipeline, Rep, Top Priority sections.\"\"\"\n",
        "    with tempfile.TemporaryDirectory() as tmp:\n",
        "        config = SalesEnablementOrchestratorConfig(reports_dir=tmp)\n",
        "        graph = create_sales_enablement_graph(config=config)\n",
        "        initial = {\"lead_id\": None, \"rep_id\": None, \"focus_area\": None, \"errors\": []}\n",
        "\n",
        "        report_path = None\n",
        "        for event in graph.stream(initial):\n",
        "            for node_name, node_out in event.items():\n",
        "                if node_name == \"reporting\":\n",
        "                    report_path = node_out.get(\"report_file_path\")\n",
        "                    assert \"enablement_report\" in node_out\n",
        "                    assert node_out.get(\"enablement_report\"), \"enablement_report should be non-empty\"\n",
        "\n",
        "        assert report_path, \"reporting node should set report_file_path\"\n",
        "        path = Path(report_path)\n",
        "        assert path.exists(), f\"Report file should exist: {report_path}\"\n",
        "\n",
        "        content = path.read_text(encoding=\"utf-8\")\n",
        "        assert \"Pipeline Summary\" in content, \"Report should include Pipeline Summary\"\n",
        "        assert \"Rep Performance\" in content, \"Report should include Rep Performance\"\n",
        "        assert \"Top Priority Leads\" in content, \"Report should include Top Priority Leads\"\n",
        "        assert \"Sales Enablement Report\" in content, \"Report should have title\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test results"
      ],
      "metadata": {
        "id": "iQdAZtZtbiVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_023_SalesEnablementOrchestrator % pytest test_sales_enablement_report.py -v\n",
        "============================================================================= test session starts =============================================================================\n",
        "platform darwin -- Python 3.13.7, pytest-9.0.2, pluggy-1.6.0 -- /Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_023_SalesEnablementOrchestrator/.venv/bin/python\n",
        "cachedir: .pytest_cache\n",
        "rootdir: /Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_023_SalesEnablementOrchestrator\n",
        "plugins: anyio-4.12.1, asyncio-1.3.0, langsmith-0.6.6, cov-7.0.0\n",
        "asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n",
        "collected 1 item\n",
        "\n",
        "test_sales_enablement_report.py::test_report_is_written_and_contains_sections PASSED                                                                                    [100%]\n",
        "\n",
        "============================================================================== 1 passed in 0.18s ==============================================================================\n"
      ],
      "metadata": {
        "id": "_C-VcK51bjZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unit tests for Sales Enablement prioritization utility."
      ],
      "metadata": {
        "id": "EU3bRycab5rH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Unit tests for Sales Enablement prioritization utility.\"\"\"\n",
        "\n",
        "from agents.sales_enablement.orchestrator.utilities.prioritization import build_prioritized_leads\n",
        "\n",
        "\n",
        "def test_build_prioritized_leads_returns_sorted_by_score_desc():\n",
        "    \"\"\"Prioritized list should be sorted by priority_score descending.\"\"\"\n",
        "    leads = [\n",
        "        {\"lead_id\": \"L-A\", \"intent_score\": 0.5, \"budget_range\": \"25k-50k\"},\n",
        "        {\"lead_id\": \"L-B\", \"intent_score\": 0.9, \"budget_range\": \"250k+\"},\n",
        "        {\"lead_id\": \"L-C\", \"intent_score\": 0.7, \"budget_range\": \"50k-100k\"},\n",
        "    ]\n",
        "    signals_lookup = {\n",
        "        \"L-A\": {\"engagement_score\": 0.4, \"deal_risk_score\": 0.6, \"urgency\": \"low\"},\n",
        "        \"L-B\": {\"engagement_score\": 0.9, \"deal_risk_score\": 0.1, \"urgency\": \"high\"},\n",
        "        \"L-C\": {\"engagement_score\": 0.7, \"deal_risk_score\": 0.3, \"urgency\": \"medium\"},\n",
        "    }\n",
        "    deals_lookup = {}\n",
        "    weights = {\"intent_score\": 0.3, \"engagement_score\": 0.25, \"deal_risk_score\": 0.2, \"budget_range\": 0.15, \"urgency\": 0.1}\n",
        "\n",
        "    prioritized, top = build_prioritized_leads(leads, signals_lookup, deals_lookup, weights, top_n=10)\n",
        "\n",
        "    scores = [p[\"priority_score\"] for p in prioritized]\n",
        "    assert scores == sorted(scores, reverse=True), \"prioritized should be sorted by score desc\"\n",
        "    assert len(prioritized) == 3\n",
        "    assert top[0][\"lead_id\"] == \"L-B\", \"highest intent+engagement+urgency should rank first\"\n",
        "    assert top[0][\"priority_score\"] >= top[1][\"priority_score\"] >= top[2][\"priority_score\"]\n",
        "\n",
        "\n",
        "def test_build_prioritized_leads_top_n_truncates():\n",
        "    \"\"\"top_priority_leads should have at most top_n items.\"\"\"\n",
        "    leads = [\n",
        "        {\"lead_id\": \"L-1\", \"intent_score\": 0.8, \"budget_range\": \"50k-100k\"},\n",
        "        {\"lead_id\": \"L-2\", \"intent_score\": 0.7, \"budget_range\": \"50k-100k\"},\n",
        "        {\"lead_id\": \"L-3\", \"intent_score\": 0.6, \"budget_range\": \"50k-100k\"},\n",
        "    ]\n",
        "    signals_lookup = {f\"L-{i}\": {\"engagement_score\": 0.5, \"deal_risk_score\": 0.3, \"urgency\": \"medium\"} for i in (1, 2, 3)}\n",
        "    deals_lookup = {}\n",
        "    weights = {\"intent_score\": 0.3, \"engagement_score\": 0.25, \"deal_risk_score\": 0.2, \"budget_range\": 0.15, \"urgency\": 0.1}\n",
        "\n",
        "    prioritized, top = build_prioritized_leads(leads, signals_lookup, deals_lookup, weights, top_n=2)\n",
        "\n",
        "    assert len(prioritized) == 3\n",
        "    assert len(top) == 2\n",
        "    assert top[0][\"lead_id\"] == \"L-1\" and top[1][\"lead_id\"] == \"L-2\"\n",
        "\n",
        "\n",
        "def test_build_prioritized_leads_required_keys():\n",
        "    \"\"\"Each prioritized item should have lead_id, priority_score, urgency, recommended_action, rationale.\"\"\"\n",
        "    leads = [{\"lead_id\": \"L-X\", \"intent_score\": 0.6, \"budget_range\": \"25k-50k\"}]\n",
        "    signals_lookup = {\"L-X\": {\"engagement_score\": 0.5, \"deal_risk_score\": 0.4, \"urgency\": \"high\", \"recommended_action\": \"schedule demo\"}}\n",
        "    deals_lookup = {}\n",
        "    weights = {\"intent_score\": 0.3, \"engagement_score\": 0.25, \"deal_risk_score\": 0.2, \"budget_range\": 0.15, \"urgency\": 0.1}\n",
        "\n",
        "    prioritized, top = build_prioritized_leads(leads, signals_lookup, deals_lookup, weights, top_n=5)\n",
        "\n",
        "    for item in prioritized:\n",
        "        assert \"lead_id\" in item and item[\"lead_id\"] == \"L-X\"\n",
        "        assert \"priority_score\" in item and 0 <= item[\"priority_score\"] <= 100\n",
        "        assert \"urgency\" in item\n",
        "        assert \"recommended_action\" in item\n",
        "        assert \"rationale\" in item and len(item[\"rationale\"]) > 0\n",
        "\n",
        "\n",
        "def test_build_prioritized_leads_skips_leads_without_lead_id():\n",
        "    \"\"\"Leads missing lead_id should be skipped.\"\"\"\n",
        "    leads = [{\"intent_score\": 0.9}]\n",
        "    signals_lookup = {}\n",
        "    deals_lookup = {}\n",
        "    weights = {\"intent_score\": 0.3, \"engagement_score\": 0.25, \"deal_risk_score\": 0.2, \"budget_range\": 0.15, \"urgency\": 0.1}\n",
        "\n",
        "    prioritized, top = build_prioritized_leads(leads, signals_lookup, deals_lookup, weights, top_n=5)\n",
        "\n",
        "    assert len(prioritized) == 0\n",
        "    assert len(top) == 0\n"
      ],
      "metadata": {
        "id": "pZz6Zdcib689"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit tests for Sales Enablement reporting utilities"
      ],
      "metadata": {
        "id": "MqTdUmB0cA9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Unit tests for Sales Enablement reporting utilities.\"\"\"\n",
        "\n",
        "from agents.sales_enablement.orchestrator.utilities.reporting import (\n",
        "    build_enablement_report_md,\n",
        "    build_pipeline_summary,\n",
        "    build_rep_performance_summary,\n",
        ")\n",
        "\n",
        "\n",
        "def test_build_pipeline_summary_counts():\n",
        "    \"\"\"Pipeline summary should reflect active/won/lost counts and values.\"\"\"\n",
        "    deals = [\n",
        "        {\"status\": \"active\", \"deal_value_usd\": 100_000, \"probability\": 0.5, \"days_in_stage\": 5, \"risk_flags\": []},\n",
        "        {\"status\": \"active\", \"deal_value_usd\": 50_000, \"probability\": 0.8, \"days_in_stage\": 25, \"risk_flags\": [\"pricing\"]},\n",
        "        {\"status\": \"won\", \"deal_value_usd\": 75_000},\n",
        "        {\"status\": \"lost\", \"deal_value_usd\": 30_000},\n",
        "    ]\n",
        "    out = build_pipeline_summary(deals, thresholds={\"stalled_deal_days_in_stage\": 21})\n",
        "\n",
        "    assert out[\"total_deals\"] == 4\n",
        "    assert out[\"active_deals\"] == 2\n",
        "    assert out[\"won_deals\"] == 1\n",
        "    assert out[\"lost_deals\"] == 1\n",
        "    assert out[\"total_pipeline_value\"] == 150_000\n",
        "    assert out[\"weighted_pipeline_value\"] == 100_000 * 0.5 + 50_000 * 0.8\n",
        "    assert out[\"win_rate\"] == 0.5\n",
        "    assert out[\"stalled_deals_count\"] == 1\n",
        "    assert out[\"at_risk_deals_count\"] == 1\n",
        "\n",
        "\n",
        "def test_build_pipeline_summary_empty_deals():\n",
        "    \"\"\"Empty deals should yield zero counts and zero values.\"\"\"\n",
        "    out = build_pipeline_summary([], None)\n",
        "    assert out[\"total_deals\"] == 0\n",
        "    assert out[\"active_deals\"] == 0\n",
        "    assert out[\"total_pipeline_value\"] == 0\n",
        "    assert out[\"win_rate\"] == 0\n",
        "    assert out[\"stalled_deals_count\"] == 0\n",
        "\n",
        "\n",
        "def test_build_rep_performance_summary_structure():\n",
        "    \"\"\"Rep summary should have rep_id, active_deals, pipeline_value, quota_achievement, needs_coaching, top_opportunities.\"\"\"\n",
        "    deals = [\n",
        "        {\"rep_id\": \"SR-01\", \"status\": \"active\", \"deal_value_usd\": 100_000, \"probability\": 0.6},\n",
        "        {\"rep_id\": \"SR-01\", \"status\": \"active\", \"deal_value_usd\": 50_000, \"probability\": 0.4},\n",
        "    ]\n",
        "    reps = [\n",
        "        {\"rep_id\": \"SR-01\", \"quota_usd\": 500_000, \"year_to_date_revenue_usd\": 400_000, \"close_rate\": 0.35},\n",
        "    ]\n",
        "    out = build_rep_performance_summary(deals, reps)\n",
        "\n",
        "    assert len(out) == 1\n",
        "    r = out[0]\n",
        "    assert r[\"rep_id\"] == \"SR-01\"\n",
        "    assert r[\"active_deals\"] == 2\n",
        "    assert r[\"pipeline_value\"] == 150_000\n",
        "    assert r[\"quota_achievement\"] == 0.8\n",
        "    assert r[\"needs_coaching\"] is False\n",
        "    assert \"top_opportunities\" in r and len(r[\"top_opportunities\"]) <= 3\n",
        "\n",
        "\n",
        "def test_build_rep_performance_summary_needs_coaching():\n",
        "    \"\"\"needs_coaching should be True when quota_achievement < 0.7.\"\"\"\n",
        "    deals = []\n",
        "    reps = [{\"rep_id\": \"SR-X\", \"quota_usd\": 1_000_000, \"year_to_date_revenue_usd\": 500_000, \"close_rate\": 0.2}]\n",
        "    out = build_rep_performance_summary(deals, reps)\n",
        "    assert out[0][\"quota_achievement\"] == 0.5\n",
        "    assert out[0][\"needs_coaching\"] is True\n",
        "\n",
        "\n",
        "def test_build_enablement_report_md_contains_sections():\n",
        "    \"\"\"Generated markdown should include Pipeline Summary, Rep Performance, Top Priority Leads.\"\"\"\n",
        "    ps = {\"total_deals\": 5, \"active_deals\": 3, \"won_deals\": 1, \"lost_deals\": 1, \"total_pipeline_value\": 200_000,\n",
        "          \"weighted_pipeline_value\": 120_000, \"average_deal_size\": 66_666, \"win_rate\": 0.5,\n",
        "          \"stalled_deals_count\": 1, \"at_risk_deals_count\": 0}\n",
        "    rps = [{\"rep_id\": \"SR-01\", \"active_deals\": 2, \"pipeline_value\": 150_000, \"close_rate\": 0.3,\n",
        "            \"quota_achievement\": 0.8, \"needs_coaching\": False, \"top_opportunities\": [\"D-01\", \"D-02\"]}]\n",
        "    top = [{\"lead_id\": \"L-01\", \"priority_score\": 85, \"urgency\": \"high\", \"recommended_action\": \"schedule demo\"}]\n",
        "\n",
        "    md = build_enablement_report_md(ps, rps, top)\n",
        "\n",
        "    assert \"# Sales Enablement Report\" in md\n",
        "    assert \"## Pipeline Summary\" in md\n",
        "    assert \"## Rep Performance\" in md\n",
        "    assert \"## Top Priority Leads\" in md\n",
        "    assert \"L-01\" in md\n",
        "    assert \"85\" in md\n",
        "    assert \"schedule demo\" in md or \"schedule\" in md\n"
      ],
      "metadata": {
        "id": "jrYwmFDnb_Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_023_SalesEnablementOrchestrator % pytest test_sales_enablement_prioritization.py\n",
        "============================================================================= test session starts =============================================================================\n",
        "platform darwin -- Python 3.13.7, pytest-9.0.2, pluggy-1.6.0\n",
        "rootdir: /Users/micahshull/Documents/AI_AGENTS/AI_AGENTS_023_SalesEnablementOrchestrator\n",
        "plugins: anyio-4.12.1, asyncio-1.3.0, langsmith-0.6.6, cov-7.0.0\n",
        "asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\n",
        "collected 4 items\n",
        "\n",
        "test_sales_enablement_prioritization.py ....                                                                                                                            [100%]\n",
        "\n",
        "============================================================================== 4 passed in 0.14s ==============================================================================\n"
      ],
      "metadata": {
        "id": "qaj6tUiockVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tests for Sales Enablement data loading"
      ],
      "metadata": {
        "id": "8hBNMYAncPDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Tests for Sales Enablement data loading (uses agents/data/ when run from project root).\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from agents.sales_enablement.orchestrator.utilities.data_loading import load_all_sales_data\n",
        "\n",
        "\n",
        "def test_load_all_sales_data_returns_core_keys():\n",
        "    \"\"\"load_all_sales_data should return leads, sales_reps, interactions, deals, signals and lookups.\"\"\"\n",
        "    # Assume run from project root; agents/data lives under project root\n",
        "    project_root = Path(__file__).resolve().parent\n",
        "    data_dir = project_root / \"agents\" / \"data\"\n",
        "\n",
        "    if not data_dir.exists():\n",
        "        return  # skip if data dir not present (e.g. in a minimal checkout)\n",
        "\n",
        "    data = load_all_sales_data(data_dir=data_dir)\n",
        "\n",
        "    assert \"leads\" in data\n",
        "    assert \"sales_reps\" in data\n",
        "    assert \"interactions\" in data\n",
        "    assert \"deals\" in data\n",
        "    assert \"signals\" in data\n",
        "    assert \"leads_lookup\" in data\n",
        "    assert \"reps_lookup\" in data\n",
        "    assert \"signals_lookup\" in data\n",
        "    assert \"interactions_lookup\" in data\n",
        "    assert \"deals_lookup\" in data\n",
        "\n",
        "\n",
        "def test_load_all_sales_data_has_records():\n",
        "    \"\"\"With real agents/data/, we should get non-empty leads and deals.\"\"\"\n",
        "    project_root = Path(__file__).resolve().parent\n",
        "    data_dir = project_root / \"agents\" / \"data\"\n",
        "\n",
        "    if not data_dir.exists():\n",
        "        return\n",
        "\n",
        "    data = load_all_sales_data(data_dir=data_dir)\n",
        "\n",
        "    assert len(data[\"leads\"]) > 0\n",
        "    assert len(data[\"deals\"]) > 0\n",
        "    assert len(data[\"leads_lookup\"]) == len(data[\"leads\"])\n",
        "    assert len(data[\"signals_lookup\"]) == len(data[\"signals\"])\n",
        "\n",
        "\n",
        "def test_load_all_sales_data_mvp2_when_present():\n",
        "    \"\"\"When thresholds/objections/content_assets exist, they should appear in the result.\"\"\"\n",
        "    project_root = Path(__file__).resolve().parent\n",
        "    data_dir = project_root / \"agents\" / \"data\"\n",
        "\n",
        "    if not data_dir.exists():\n",
        "        return\n",
        "\n",
        "    data = load_all_sales_data(data_dir=data_dir)\n",
        "\n",
        "    if (data_dir / \"thresholds.json\").exists():\n",
        "        assert \"thresholds\" in data and data[\"thresholds\"] is not None\n",
        "    if (data_dir / \"objections.json\").exists():\n",
        "        assert \"objections\" in data and isinstance(data[\"objections\"], list)\n",
        "    if (data_dir / \"content_assets.json\").exists():\n",
        "        assert \"content_assets\" in data and isinstance(data[\"content_assets\"], list)\n"
      ],
      "metadata": {
        "id": "sFcNzOo9cMfG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}