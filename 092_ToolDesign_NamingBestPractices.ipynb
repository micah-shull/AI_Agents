{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD06cU6/OQomOp6i07jJ7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/092_ToolDesign_NamingBestPractices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Design and Naming Best Practices for AI Agents\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Specificity Over Generic Tools**\n",
        "\n",
        "* **Why:** Generic tools (like `read_file(path)`) leave more room for errors — the LLM might pick the wrong directory, wrong file type, or unsupported path.\n",
        "* **Best practice:** Make tools narrowly scoped to the domain/problem.\n",
        "  Example:\n",
        "\n",
        "  * Instead of: `list_files(directory)`\n",
        "  * Use: `list_python_files()` (hardcoded to `src/`)\n",
        "    `read_python_file(file_name)` (only `.py` files in `src/`)\n",
        "    `write_documentation(file_name, content)` (only in `docs/`)\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Naming Clarity**\n",
        "\n",
        "* **Why:** The LLM understands better when tool names are self-explanatory.\n",
        "* **Best practice:** Use clear, descriptive names — avoid abbreviations or cryptic labels.\n",
        "\n",
        "  * Poor: `rd_f`\n",
        "  * Good: `read_python_file`\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Robust Error Handling**\n",
        "\n",
        "* **Why:** Agents are more resilient if tools return clear, structured errors instead of failing silently.\n",
        "* **Best practice:**\n",
        "\n",
        "  * Validate inputs (check file type, file existence, etc.).\n",
        "  * Always return structured dictionaries like `{\"error\": \"...\", \"hint\": \"...\"}`.\n",
        "  * Never let the tool crash without returning something the LLM can parse.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. “Just-in-Time” Instructions**\n",
        "\n",
        "* **Why:** Embedding helpful hints in error messages allows the agent to recover immediately without having to memorize special-case rules in the prompt.\n",
        "* **Example:**\n",
        "  If `read_python_file` fails because a file doesn’t exist, return:\n",
        "  `\"error\": \"File not found. Call list_python_files() for valid names.\"`\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Trade-off: Specificity vs. Flexibility**\n",
        "\n",
        "* **Specific tools:** Lower misuse risk, higher reliability, but less general-purpose.\n",
        "* **Generic tools:** More reusable but require better reasoning from the LLM.\n",
        "* **Best practice:** Start **specific** when building a new agent; generalize only if needed later.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Metadata & JSON Schema**\n",
        "\n",
        "* **Why:** Structured metadata tells the LLM exactly what inputs a tool accepts and what it does.\n",
        "* **Best practice:** Always define `parameters` in JSON Schema format so the LLM can reliably generate arguments.\n",
        "\n"
      ],
      "metadata": {
        "id": "dwVPP8GwLapN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JJqObzQKt_F"
      },
      "outputs": [],
      "source": [
        "# Example: Reading a Python File\n",
        "\n",
        "{\n",
        "  \"tool_name\": \"read_python_file\",\n",
        "  \"description\": \"Reads the content of a Python file from the src/ directory.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"file_name\": { \"type\": \"string\" }\n",
        "    },\n",
        "    \"required\": [\"file_name\"]\n",
        "  }\n",
        "}\n",
        "# Example: Writing Documentation\n",
        "{\n",
        "  \"tool_name\": \"write_documentation\",\n",
        "  \"description\": \"Writes a documentation file to the docs/ directory.\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"file_name\": { \"type\": \"string\" },\n",
        "      \"content\": { \"type\": \"string\" }\n",
        "    },\n",
        "    \"required\": [\"file_name\", \"content\"]\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few things jump out immediately — these examples are almost a **perfect embodiment** of the “Agent Tool Design Best Practices” lecture we just discussed.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Highly Specific Tools**\n",
        "\n",
        "* `read_python_file` is **domain-specific** — it’s scoped to *only* read `.py` files from `src/`.\n",
        "* `write_documentation` is **task-specific** — it writes docs only to `docs/`.\n",
        "  ➡️ This reduces the chance of the LLM reading/writing in the wrong place.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Clear Naming**\n",
        "\n",
        "* Tool names directly describe their function:\n",
        "\n",
        "  * `read_python_file`\n",
        "  * `write_documentation`\n",
        "* No ambiguity → the LLM doesn’t have to guess what they do.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. JSON Schema Parameter Definition**\n",
        "\n",
        "* Each tool has a **`parameters`** section:\n",
        "\n",
        "  * Declares `type` = `\"object\"`\n",
        "  * Lists `properties` (argument names + types)\n",
        "  * Defines which ones are `\"required\"`\n",
        "* This structure ensures **function calling** will produce the right arguments in the right format.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Enforced Safety & Structure**\n",
        "\n",
        "* You can validate that the requested `file_name` is in the allowed directory before execution.\n",
        "* The description itself also acts as an **instruction to the model** about constraints.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Easy for the Model to Learn**\n",
        "\n",
        "* The model sees:\n",
        "\n",
        "  * A small set of tools\n",
        "  * Descriptions that make the purpose obvious\n",
        "  * Arguments with clear names and types\n",
        "    ➡️ Makes tool selection and parameter generation more reliable.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Extensible Pattern**\n",
        "\n",
        "* You can add more tools by copying the format:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"tool_name\": \"...\",\n",
        "    \"description\": \"...\",\n",
        "    \"parameters\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        ...\n",
        "      },\n",
        "      \"required\": [...]\n",
        "    }\n",
        "  }\n",
        "  ```\n",
        "* Keeps your toolset **consistent** — the LLM can navigate it better.\n",
        "\n",
        "---\n",
        "\n",
        "Honestly, this looks like the teacher is nudging you toward **a toolbox of safe, specific, schema-driven functions** — which is the perfect setup for reliable agents in production.\n",
        "\n"
      ],
      "metadata": {
        "id": "9nACqFb-QdF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Think of it like **power tools in a workshop**:\n",
        "\n",
        "* If you give someone a **giant Swiss Army knife** with 50 tiny functions, they might use the wrong one, or break something trying to make it fit every job.\n",
        "* If you give them **a hammer for nails, a screwdriver for screws, and a saw for wood**, each one is **purpose-built**, harder to misuse, and easier to master.\n",
        "\n",
        "---\n",
        "\n",
        "### Why **specific > generic** for AI agent tools:\n",
        "\n",
        "1. **Reliability** – The LLM has fewer ways to get the call wrong.\n",
        "2. **Safety** – You can control exactly where and how each tool operates (e.g., no `read_any_file` risk).\n",
        "3. **Easier debugging** – If something fails, you know which exact function caused it.\n",
        "4. **Clearer intent** – Tool names and descriptions leave no ambiguity.\n",
        "5. **Better prompting** – The model doesn't have to reason about *how* to use a tool; it just knows when.\n",
        "\n",
        "---\n",
        "\n",
        "### Trade-off:\n",
        "\n",
        "* **More specific tools** = safer and more stable.\n",
        "* **But** you may need to create more of them to cover all cases.\n",
        "* The payoff: each tool is small, predictable, and easy to extend without breaking others.\n",
        "\n",
        "---\n",
        "\n",
        "This is why in your example:\n",
        "\n",
        "* Instead of one generic `read_file(path)` tool, you might have:\n",
        "\n",
        "  * `read_python_file(file_name)`\n",
        "  * `read_documentation(file_name)`\n",
        "* Each one scoped to a specific directory, file type, and usage pattern.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dpqZMFzsRNH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Why naming matters so much for LLMs\n",
        "\n",
        "1. **LLMs are pattern matchers, not mind readers.**\n",
        "   If a tool name looks cryptic (e.g., `proc_handler`), the model has to guess — and guesses mean errors.\n",
        "   With `process_file`, the action is obvious before it even reads the description.\n",
        "\n",
        "2. **Tool names double as mental shortcuts.**\n",
        "   In a multi-tool environment, the LLM scans the tool list quickly. Descriptive names help it choose correctly without overthinking.\n",
        "\n",
        "3. **Clear naming reduces prompt/token overhead.**\n",
        "   If a name is self-explanatory, you can keep descriptions shorter — the model already has a good clue from the name.\n",
        "\n",
        "4. **Consistency matters.**\n",
        "   If you have `list_python_files`, `read_python_file`, `write_python_file`, the naming pattern reinforces the relationship between tools, making selection easier.\n",
        "\n",
        "---\n",
        "\n",
        "## Best Practices for Tool Naming\n",
        "\n",
        "* **Be explicit** → `read_python_file` > `rd_f`\n",
        "* **Use verbs** → Names should describe the action (`list_`, `read_`, `write_`, `summarize_`).\n",
        "* **Keep a naming convention** → Same tense, structure, and word order across all tools.\n",
        "* **Avoid abbreviations** unless they’re industry standard (e.g., `csv` is fine; `wrt_doc` is not).\n",
        "\n",
        "---\n",
        "\n",
        "## Still need structured descriptions\n",
        "\n",
        "Even with perfect names, the LLM can misunderstand in specialized domains.\n",
        "Example:\n",
        "\n",
        "* `process_image` → could mean *analyze it*, *compress it*, *resize it*, or *apply filters*.\n",
        "  ➡ That’s where the `description` and `parameters` in the tool schema come in — they disambiguate the action.\n",
        "\n",
        "---\n",
        "\n",
        "For your **Agent Design Handbook**, this boils down to:\n",
        "\n",
        "> **Rule:** Use clear, descriptive, verb-based tool names. Keep naming patterns consistent and back them up with structured descriptions for clarity.\n",
        "\n"
      ],
      "metadata": {
        "id": "TcGnPL3SR8UD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduce Cognitive Load\n",
        "\n",
        "When we design for LLMs, we have to remember:\n",
        "\n",
        "* They’re not “logical machines” in the strict programming sense.\n",
        "* They **reason by association**, like a human reading a sentence and guessing meaning from context.\n",
        "\n",
        "---\n",
        "\n",
        "### Why your analogy works so well\n",
        "\n",
        "If you hand a person a tool called `x_gen_sls`:\n",
        "\n",
        "* They burn **mental effort** just trying to figure out what it means.\n",
        "* They may **guess wrong** and misuse it.\n",
        "* They might **ignore it entirely** because it’s too vague.\n",
        "\n",
        "If you hand them a **clearly named, self-explanatory tool**:\n",
        "\n",
        "* They instantly know the likely **purpose**.\n",
        "* They **skip cognitive overhead** about “what is this?” and jump straight to “how do I use it to solve the problem?”\n",
        "* They can focus on **higher-level reasoning** — sequencing steps, achieving the goal.\n",
        "\n",
        "---\n",
        "\n",
        "### Same for LLMs:\n",
        "\n",
        "When the tool is called `leaf_shredder_and_waste_capture_device`:\n",
        "\n",
        "* The **tool name** already narrows the meaning before it even reads the description.\n",
        "* The **description** then confirms and removes ambiguity.\n",
        "* That frees the model to think about the *goal* (“I need to shred leaves and collect waste”) instead of the *mechanics* of guessing what tool does what.\n",
        "\n",
        "---\n",
        "\n",
        "### Design takeaway for your handbook:\n",
        "\n",
        "> **Rule:** Tool names should be self-explanatory enough that both a human and an LLM could correctly guess their purpose without reading the description. This reduces reasoning overhead and improves accuracy in tool selection.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gw5z-LhkT85F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is about making tools **predictable, self-healing, and safe**. A few key ideas I’d add (and a tiny upgrade to the example):\n",
        "\n",
        "## What “robust” really means for agent tools\n",
        "\n",
        "* **Validate early, fail clearly.** Check file type, existence, and allowed paths *before* doing work. Return structured errors the LLM can act on.\n",
        "* **Structured envelopes.** Always return a consistent shape so downstream code never guesses:\n",
        "\n",
        "  * Success: `{\"ok\": true, \"data\": ...}`\n",
        "  * Error: `{\"ok\": false, \"error\": \"...\", \"hint\": \"...\", \"retryable\": true/false, \"next_tool\": \"list_python_files\"}`\n",
        "* **Actionable hints.** Tell the agent what to do next (just-in-time guidance beats bloated prompts).\n",
        "* **Safety limits.** Guard against path traversal, huge files, bad encodings; truncate output and say you did.\n",
        "* **Deterministic outputs.** No mixing prose and data; keep responses machine-friendly.\n",
        "\n",
        "## Slightly stronger version of your example (still minimal)\n",
        "\n",
        "```python\n",
        "import os, io\n",
        "\n",
        "SRC_DIR = \"src\"\n",
        "\n",
        "def read_python_file(file_name):\n",
        "    \"\"\"Read a .py file from src/ with safety + hints.\"\"\"\n",
        "    if not isinstance(file_name, str):\n",
        "        return {\"ok\": False, \"error\": \"file_name must be a string\", \"retryable\": False}\n",
        "    if not file_name.endswith(\".py\"):\n",
        "        return {\"ok\": False, \"error\": \"Only .py files allowed\",\n",
        "                \"hint\": \"Call list_python_files to see valid names\",\n",
        "                \"next_tool\": \"list_python_files\", \"retryable\": True}\n",
        "    file_path = os.path.join(SRC_DIR, file_name)\n",
        "    if not os.path.abspath(file_path).startswith(os.path.abspath(SRC_DIR) + os.sep):\n",
        "        return {\"ok\": False, \"error\": \"Path must stay within src/\", \"retryable\": False}\n",
        "    if not os.path.exists(file_path):\n",
        "        return {\"ok\": False, \"error\": f\"'{file_name}' not found in src/\",\n",
        "                \"hint\": \"Use list_python_files first\", \"next_tool\": \"list_python_files\", \"retryable\": True}\n",
        "    try:\n",
        "        with io.open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "            content = f.read(8000)\n",
        "        if len(content) == 8000:\n",
        "            content += \"\\n... [truncated]\"\n",
        "        return {\"ok\": True, \"data\": content}\n",
        "    except Exception as e:\n",
        "        return {\"ok\": False, \"error\": f\"I/O error: {e}\", \"retryable\": False}\n",
        "```\n",
        "\n",
        "### Why this helps the agent\n",
        "\n",
        "* The **envelope** (`ok/data` vs. `ok/error`) removes ambiguity.\n",
        "* **Hints** + `next_tool` let the model recover autonomously.\n",
        "* **Guards** (path, size, encoding) prevent accidental breakage and keep outputs consistent.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LQ99Blu5SxIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "You want to be the **coach**, not the sideline heckler.\n",
        "\n",
        "* The **coach** removes distractions.\n",
        "* Gives **clear plays** to run.\n",
        "* Ensures the **environment** is set up for success.\n",
        "* Keeps the players focused on the **win condition**, not the logistics.\n",
        "\n",
        "---\n",
        "\n",
        "### In LLM Agent terms:\n",
        "\n",
        "* **Tool naming** → Clear playbook terminology.\n",
        "* **Tool specificity** → Each play is well-rehearsed for a single scenario.\n",
        "* **Error handling** → Instant feedback when something goes wrong, plus the next best move.\n",
        "* **Schema-based parameters** → A clear “form” for every pass — no guessing about what to fill in.\n",
        "* **Context management** → Only the relevant “game history” is on the whiteboard, not the whole season’s stat sheet.\n",
        "\n",
        "---\n",
        "\n",
        "When you **clear the cognitive path**, the LLM can:\n",
        "\n",
        "* Spend less time “thinking about thinking” (meta-reasoning).\n",
        "* Spend more time “thinking about doing” (solving the goal).\n",
        "* Reduce mistakes from ambiguity or misinterpretation.\n",
        "\n",
        "---\n",
        "\n",
        "💡 **Handbook-worthy rule**:\n",
        "\n",
        "> Treat the LLM like a top player — give it a clear playbook, keep its head in the game, and handle the logistics yourself.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LkiZ17U0U2vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is basically teaching you one of the most **underrated best practices** in agent design: **just-in-time guidance**.\n",
        "\n",
        "---\n",
        "\n",
        "### Why this matters\n",
        "\n",
        "If you put all your error-handling instructions up front in the **system prompt**:\n",
        "\n",
        "* The LLM has to **remember** them across the entire conversation.\n",
        "* That eats up **tokens** and **mental bandwidth**.\n",
        "* It can accidentally **apply them in the wrong context**.\n",
        "\n",
        "If you **inject instructions directly into the error response**:\n",
        "\n",
        "* The agent gets the advice **right when it’s relevant**.\n",
        "* No need to “keep it in working memory” — it’s right there in the latest step.\n",
        "* It **reduces cognitive load** and the risk of irrelevant over-generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### Why this improves performance\n",
        "\n",
        "Think about a coach again:\n",
        "\n",
        "* Instead of dumping the entire playbook in the player’s head before the game,\n",
        "* You **call the play at the moment it’s needed** — “We’re doing the double reverse now!”\n",
        "* That way the player isn’t juggling 200 possible plays when they just need 1 right now.\n",
        "\n",
        "---\n",
        "\n",
        "### Example evolution\n",
        "\n",
        "**Without JIT instruction**\n",
        "Error: `\"Invalid file type. Only Python files can be read.\"`\n",
        "→ LLM must figure out “okay, what should I do now?”\n",
        "\n",
        "**With JIT instruction**\n",
        "Error: `\"Invalid file type. Only Python files can be read. Call list_python_files to get valid names.\"`\n",
        "→ LLM instantly knows what to do next without rethinking the plan.\n",
        "\n",
        "---\n",
        "\n",
        "### Handbook takeaway\n",
        "\n",
        "> **Rule:** Deliver “just-in-time” recovery instructions inside error messages instead of frontloading them in the system prompt. This reduces memory burden, keeps prompts clean, and improves the likelihood of correct recovery.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GO1PoDVUWQkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 📝 Summary: Agent Tool Design Best Practices\n",
        "\n",
        "When integrating AI into real-world environments, tool design is **not** an afterthought — it’s the foundation for **stable, safe, and high-performing agents**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Core Principles**\n",
        "\n",
        "1. **Use Descriptive Names**\n",
        "\n",
        "   * Verb-based, explicit, and consistent naming patterns reduce cognitive load for the LLM.\n",
        "   * Example: `read_python_file` > `rd_py`\n",
        "   * *Think like a coach — give clear play names your players (LLMs) instantly understand.*\n",
        "\n",
        "2. **Provide Structured Metadata**\n",
        "\n",
        "   * Include clear descriptions and parameter details.\n",
        "   * Consistency helps the LLM quickly find relevant tools.\n",
        "\n",
        "3. **Leverage JSON Schema for Parameters**\n",
        "\n",
        "   * Standardize input expectations.\n",
        "   * Allows for automated validation and safer execution.\n",
        "\n",
        "4. **Ensure Contextual Understanding**\n",
        "\n",
        "   * Include enough detail in tool descriptions for the model to use them without guessing.\n",
        "   * Avoid frontloading unnecessary rules into the system prompt.\n",
        "\n",
        "5. **Robust Error Handling**\n",
        "\n",
        "   * Validate early, fail clearly, and keep outputs machine-friendly.\n",
        "   * Use a consistent response envelope (e.g., `{\"ok\": true/false, \"data\": ..., \"error\": ...}`).\n",
        "\n",
        "6. **Provide Informative Error Messages**\n",
        "\n",
        "   * Clearly state the cause of the error and its implications.\n",
        "   * Make it obvious whether retrying is possible.\n",
        "\n",
        "7. **Inject Just-In-Time Instructions into Error Messages**\n",
        "\n",
        "   * Give the recovery path *in the moment* instead of bloating the system prompt.\n",
        "   * Example: `\"Invalid file type. Only Python files allowed. Call list_python_files to get valid options.\"`\n",
        "\n",
        "---\n",
        "\n",
        "### **💡 My Added Takeaway**\n",
        "\n",
        "> Good tool design is about **clearing the cognitive path** so the LLM can focus on the *goal* rather than the *mechanics*.\n",
        "> Your job as the agent designer is to be the **coach** — give your model the right plays at the right time, remove distractions, and let it perform at its best.\n",
        "> Specificity, clarity, and just-in-time guidance are the playbook.\n",
        "\n"
      ],
      "metadata": {
        "id": "BAgHdZ83W8FI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EECosOa7QkW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}