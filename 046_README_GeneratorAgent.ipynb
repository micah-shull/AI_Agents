{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM75kFb4jdT2VkpbBeQmASD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/046_README_GeneratorAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## âœ… README Generator Agent (Using the GAME Framework)\n",
        "\n",
        "This lecture demonstrates how to build a real-world agent that analyzes a Python project and generates a `README.md` fileâ€”all by applying the **GAME architecture** (Goals, Actions, Memory, Environment).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Agent Purpose\n",
        "\n",
        "> **Generate a README file by reading and understanding Python files in the project.**\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§± Components Overview\n",
        "\n",
        "#### 1. **Goals**\n",
        "\n",
        "Define the agentâ€™s objectives:\n",
        "\n",
        "```python\n",
        "goals = [\n",
        "    Goal(priority=1, name=\"Gather Information\", description=\"Read each file in the project\"),\n",
        "    Goal(priority=1, name=\"Terminate\", description=\"Call the terminate action when done and include README content\")\n",
        "]\n",
        "```\n",
        "\n",
        "#### 2. **Actions**\n",
        "\n",
        "Defined using the `Action` class:\n",
        "\n",
        "* `list_project_files()`: Lists all `.py` files in the directory.\n",
        "* `read_project_file(name)`: Reads the contents of a given file.\n",
        "* `terminate(message)`: Ends the agent and outputs the README content.\n",
        "\n",
        "Each action has:\n",
        "\n",
        "* a clear name\n",
        "* a function\n",
        "* a parameter schema\n",
        "* a `terminal` flag to stop the loop\n",
        "\n",
        "#### 3. **AgentLanguage**\n",
        "\n",
        "Uses `AgentFunctionCallingActionLanguage()` to:\n",
        "\n",
        "* Format goals/actions for the LLM\n",
        "* Use OpenAI function calling\n",
        "* Parse tool responses\n",
        "\n",
        "#### 4. **Environment**\n",
        "\n",
        "Basic environment using local file system access, no custom execution needed here:\n",
        "\n",
        "```python\n",
        "environment = Environment()\n",
        "```\n",
        "\n",
        "#### 5. **Agent Construction**\n",
        "\n",
        "All pieces are combined in a single modular `Agent` object:\n",
        "\n",
        "```python\n",
        "agent = Agent(goals, agent_language, action_registry, generate_response, environment)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Agent Execution Flow\n",
        "\n",
        "1. **User Prompt** â†’ `\"Write a README for this project.\"`\n",
        "2. Agent chooses to:\n",
        "\n",
        "   * Call `list_project_files`\n",
        "   * Read each file one by one\n",
        "   * Accumulate file contents in memory\n",
        "3. Agent eventually calls `terminate()` and returns a complete README string\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ’¡ Why This Matters\n",
        "\n",
        "This agent:\n",
        "\n",
        "* Demonstrates **modular design**\n",
        "* Requires no change to the main loop to extend capabilities\n",
        "* Makes it easy to swap out LLMs, environments, or actions\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸš€ What You Can Build Next\n",
        "\n",
        "You can now extend this agent to:\n",
        "\n",
        "* Support `Jupyter` or `Markdown` files\n",
        "* Run inside `GitHub Actions`\n",
        "* Use custom environments for remote file reads\n",
        "* Leverage memory for multi-step reasoning across files\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N8qwAI0nkHS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuAnZwmhjp02"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Define the agent's goals\n",
        "    goals = [\n",
        "        Goal(priority=1, name=\"Gather Information\", description=\"Read each file in the project\"),\n",
        "        Goal(priority=1, name=\"Terminate\", description=\"Call the terminate call when you have read all the files \"\n",
        "                                                       \"and provide the content of the README in the terminate message\")\n",
        "    ]\n",
        "\n",
        "    # Define the agent's language\n",
        "    agent_language = AgentFunctionCallingActionLanguage()\n",
        "\n",
        "    def read_project_file(name: str) -> str:\n",
        "        with open(name, \"r\") as f:\n",
        "            return f.read()\n",
        "\n",
        "    def list_project_files() -> List[str]:\n",
        "        return sorted([file for file in os.listdir(\".\") if file.endswith(\".py\")])\n",
        "\n",
        "    # Define the action registry and register some actions\n",
        "    action_registry = ActionRegistry()\n",
        "    action_registry.register(Action(\n",
        "        name=\"list_project_files\",\n",
        "        function=list_project_files,\n",
        "        description=\"Lists all files in the project.\",\n",
        "        parameters={},\n",
        "        terminal=False\n",
        "    ))\n",
        "    action_registry.register(Action(\n",
        "        name=\"read_project_file\",\n",
        "        function=read_project_file,\n",
        "        description=\"Reads a file from the project.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": [\"name\"]\n",
        "        },\n",
        "        terminal=False\n",
        "    ))\n",
        "    action_registry.register(Action(\n",
        "        name=\"terminate\",\n",
        "        function=lambda message: f\"{message}\\nTerminating...\",\n",
        "        description=\"Terminates the session and prints the message to the user.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"message\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": []\n",
        "        },\n",
        "        terminal=True\n",
        "    ))\n",
        "\n",
        "    # Define the environment\n",
        "    environment = Environment()\n",
        "\n",
        "    # Create an agent instance\n",
        "    agent = Agent(goals, agent_language, action_registry, generate_response, environment)\n",
        "\n",
        "    # Run the agent with user input\n",
        "    user_input = \"Write a README for this project.\"\n",
        "    final_memory = agent.run(user_input)\n",
        "\n",
        "    # Print the final memory\n",
        "    print(final_memory.get_memories())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ðŸ§  1. This Is a Full-Stack Agent (In Miniature)\n",
        "\n",
        "This agent brings together every major component youâ€™ve learned:\n",
        "\n",
        "* ðŸŽ¯ Goals: clear intent and prioritization\n",
        "* ðŸ› ï¸ Actions: well-scoped, with clean schemas\n",
        "* ðŸ§  Memory: tracking previous reads and results\n",
        "* ðŸ§± AgentLanguage: OpenAI function calling\n",
        "* ðŸŒ Environment: simple local file access\n",
        "\n",
        "Itâ€™s a perfect end-to-end example of how all the parts work in unison. Itâ€™s also a great **template** for other project agents.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§© 2. Goal-Driven Behavior Reduces Prompt Complexity\n",
        "\n",
        "Instead of relying on a giant prompt template, the agent breaks things down into **goals and tools**, letting the LLM figure out the execution order. This is powerful because:\n",
        "\n",
        "* The LLM stays focused on *why* and *what* instead of *how*.\n",
        "* You reduce brittle prompt engineering.\n",
        "* The loop keeps memory and context tightly scoped.\n",
        "\n",
        "---\n",
        "\n",
        "### âš’ï¸ 3. Small Tools, Big Results\n",
        "\n",
        "The agent only needs three simple tools:\n",
        "\n",
        "* `list_project_files()`\n",
        "* `read_project_file(file_name)`\n",
        "* `terminate(message)`\n",
        "\n",
        "This highlights how **you donâ€™t need a huge toolkit**â€”you just need the right abstractions and structure to let the LLM orchestrate.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§° 4. Extending It Is Easy\n",
        "\n",
        "Because the agent is modular, you can imagine adding:\n",
        "\n",
        "* `summarize_code()`\n",
        "* `extract_dependencies()`\n",
        "* `generate_install_instructions()`\n",
        "* `create_usage_examples()`\n",
        "\n",
        "Each one would be a new action with a schema, and the core logic wouldnâ€™t need to change at all. This is a **major advantage** over procedural or hardcoded agents.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§¼ 5. Termination Is Part of the Conversation\n",
        "\n",
        "The use of a `terminate()` tool ensures that the agent **knows when itâ€™s done** and can wrap up with a helpful output. It also acts as a structured way to signal completionâ€”very helpful in loops.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“¦ 6. Practical Takeaway\n",
        "\n",
        "If you ever need to explain how agent design works in an interview or on your LinkedIn, this is the agent to showcase. Itâ€™s:\n",
        "\n",
        "* Concrete\n",
        "* Useful\n",
        "* Modular\n",
        "* Easy to explain\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "esOmGFMGk-e-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ðŸ§  The Core Idea: Let the LLM Decide *How*\n",
        "\n",
        "In traditional LLM prompting, we often write large prompt templates that:\n",
        "\n",
        "* Outline **every step** the LLM should follow\n",
        "* Include **multi-step examples** (\"few-shot\")\n",
        "* Repeat instructions to try to control behavior\n",
        "\n",
        "This is **brittle**:\n",
        "\n",
        "* If the task slightly changes, the prompt breaks\n",
        "* LLMs can get confused when too many steps are hardcoded\n",
        "* Prompts grow huge and expensive to process\n",
        "\n",
        "This point is *fundamental* to modern agent design, and understanding it deeply will make you a better system designer and collaborator with LLMs.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… With Goal-Driven Agents:\n",
        "\n",
        "You tell the LLM:\n",
        "\n",
        "* â€œHereâ€™s what youâ€™re trying to doâ€ (*Goals*)\n",
        "* â€œHere are the tools you can use to do itâ€ (*Actions*)\n",
        "* â€œHereâ€™s what youâ€™ve already seen or doneâ€ (*Memory*)\n",
        "* â€œIâ€™ll take care of executionâ€”you just tell me what to do nextâ€ (*Agent Loop*)\n",
        "\n",
        "### This radically simplifies prompting:\n",
        "\n",
        "* No more giant templates\n",
        "* No more overfitting behavior through prompt tweaks\n",
        "* You treat the LLM like a *planner*, not a parser or script follower\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Example Comparison\n",
        "\n",
        "#### Traditional Prompt Approach\n",
        "\n",
        "```\n",
        "You are an assistant that generates README files.\n",
        "\n",
        "Step 1: List the files.\n",
        "Step 2: Read the main.py file.\n",
        "Step 3: Generate a README in markdown format.\n",
        "...\n",
        "```\n",
        "\n",
        "â¬‡ï¸ vs.\n",
        "\n",
        "#### Agent Approach (GAME Style)\n",
        "\n",
        "```\n",
        "Goals:\n",
        "- Understand the structure of this Python project\n",
        "- Read the main modules\n",
        "- Generate a concise and clear README.md file\n",
        "\n",
        "Available Tools:\n",
        "- list_project_files()\n",
        "- read_project_file(file_name)\n",
        "- terminate(message)\n",
        "```\n",
        "\n",
        "The LLM now decides *when* to call which tool, based on what it sees in the memory.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Benefits in Practice\n",
        "\n",
        "| ðŸ” Feature                       | âš™ï¸ Result                             |\n",
        "| -------------------------------- | ------------------------------------- |\n",
        "| No step-by-step prompt           | More flexible agent                   |\n",
        "| Small, reusable goals            | Easily extensible tasks               |\n",
        "| Schema-bound tools               | LLM output stays predictable          |\n",
        "| Memory injected only when needed | Smaller token usage, clearer focus    |\n",
        "| Function-calling + planning      | No parsing errors or ambiguous output |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§° Agent Loop = \"Structured Autonomy\"\n",
        "\n",
        "This structure gives you:\n",
        "\n",
        "* Predictability (because tools are structured)\n",
        "* Flexibility (because plans are dynamic)\n",
        "* Control (because execution happens in code, not in text)\n",
        "\n",
        "Youâ€™re no longer relying on *magic prompts* â€” youâ€™re engineering systems with clear responsibilities.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2mhfNXYl1WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## âœ… The GOAL-Based Approach *Delegates Prompting to the LLM*\n",
        "\n",
        "This is one of the most **important mental shifts** in moving from prompt-centric \"agent hype\" to **robust agent systems**.\n",
        "\n",
        "### ðŸ” Traditional Prompt-Centric Design:\n",
        "\n",
        "* You (the developer) write one giant prompt.\n",
        "* You hardcode every instruction.\n",
        "* You try to anticipate *every edge case and step* in advance.\n",
        "* When anything changes â€” new file, new task â€” you have to edit the whole thing.\n",
        "\n",
        "This approach is *fragile* and puts the burden of reasoning and formatting on the developer.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Goal-Based Agent Design (GAME-style):\n",
        "\n",
        "* You define the **intent** (goals).\n",
        "* You define the **capabilities** (actions).\n",
        "* You give the LLM **structured context** (memory + environment).\n",
        "* You let the LLM decide *how* to achieve that intent, step-by-step.\n",
        "\n",
        "Instead of writing a long prompt, you're writing a **system interface** that the LLM uses.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” What does the LLM see?\n",
        "\n",
        "You're sending it a structured message that says:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"goals\": [\n",
        "    \"Generate a README based on the structure of this repo\"\n",
        "  ],\n",
        "  \"actions\": [\n",
        "    { \"name\": \"list_project_files\", \"description\": \"List the files in the directory\" },\n",
        "    { \"name\": \"read_project_file\", \"parameters\": { \"file_name\": \"...\" }, \"description\": \"Read a file\" },\n",
        "    { \"name\": \"terminate\", \"description\": \"Finish the task with a message\" }\n",
        "  ],\n",
        "  \"memory\": [\n",
        "    // Summary of what the LLM already knows\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "That *is* the prompt â€” but itâ€™s dynamically generated, clean, and reusable across tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Benefits of This Delegation\n",
        "\n",
        "| Prompt-Centric        | Goal-Based                  |\n",
        "| --------------------- | --------------------------- |\n",
        "| Rigid templates       | Dynamic goal interpretation |\n",
        "| Fragile to changes    | Extensible + adaptable      |\n",
        "| High developer burden | LLM handles planning        |\n",
        "| Hard to debug         | Modular and testable        |\n",
        "| Easy to forget steps  | Agent loop ensures flow     |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ¤– Final Takeaway\n",
        "\n",
        "The GOAL isn't to write better prompts.\n",
        "The GOAL *is the prompt*.\n",
        "\n",
        "> Youâ€™ve moved from **prompt engineer** to **agent system designer**.\n",
        "\n"
      ],
      "metadata": {
        "id": "ETs-PfKlmw2P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MImYmdltmwpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8Kqz6rrlHq1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}