{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkMgxOshgALFw05OLsYMYM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/070_Selective_Memory_Sharing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook introduces a **powerful memory filtering pattern** that improves multi-agent coordination:\n",
        "\n",
        "### **Selective Memory Sharing: Focusing Agent Attention**\n",
        "\n",
        "Here‚Äôs the jazzed-up Markdown version to help organize your notes:\n",
        "\n",
        "---\n",
        "\n",
        "# üß† Selective Memory Sharing: Using LLMs to Focus Agent Attention\n",
        "\n",
        "In complex multi-agent systems, agents often accumulate large memory histories. But not every downstream task needs the *entire* context ‚Äî just the relevant parts.\n",
        "\n",
        "Instead of relying on rigid rule-based filters (e.g. keyword matches or timestamps), we can use the **LLM itself** to intelligently choose which memories to share.\n",
        "\n",
        "## üéØ The Idea\n",
        "\n",
        "We delegate the memory selection process to the LLM so it can:\n",
        "\n",
        "* ‚úÇÔ∏è **Trim irrelevant content**\n",
        "* üß† **Understand contextual nuance**\n",
        "* üßæ **Justify its reasoning**\n",
        "* üßº **Keep downstream agents focused**\n",
        "\n",
        "This allows one agent to **call another agent with a curated set of relevant memories**, rather than dumping the whole history.\n",
        "\n",
        "---\n",
        "\n",
        "## üîß How It Works\n",
        "\n",
        "The `call_agent_with_selected_context` tool enables this behavior. Here's the workflow:\n",
        "\n",
        "1. **Assign memory IDs**\n",
        "   Every memory item gets a unique ID (`mem_0`, `mem_1`, ...).\n",
        "\n",
        "2. **Present all memories to the LLM**\n",
        "   The LLM sees every memory, formatted clearly with IDs.\n",
        "\n",
        "3. **Ask the LLM to select the most relevant**\n",
        "   Using structured JSON and a thoughtful schema, the LLM returns:\n",
        "\n",
        "   * `selected_memories`: A list of relevant memory IDs\n",
        "   * `reasoning`: Why it selected those items\n",
        "\n",
        "4. **Filter memory for the downstream agent**\n",
        "   Only the selected memory items are passed to the called agent.\n",
        "\n",
        "5. **Preserve transparency**\n",
        "   The original agent logs the LLM‚Äôs selection reasoning for future traceability.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Example\n",
        "\n",
        "Here‚Äôs a quick snapshot of what a memory list might look like:\n",
        "\n",
        "```python\n",
        "memories = [\n",
        "    {\"type\": \"user\", \"content\": \"We need to build a new reporting dashboard\"},\n",
        "    {\"type\": \"assistant\", \"content\": \"Initial cost estimate: $50,000\"},\n",
        "    {\"type\": \"user\", \"content\": \"That seems high\"},\n",
        "    {\"type\": \"assistant\", \"content\": \"Breakdown: $20k development, $15k design...\"},\n",
        "    {\"type\": \"system\", \"content\": \"Project deadline updated to Q3\"},\n",
        "    {\"type\": \"user\", \"content\": \"Can we reduce the cost?\"}\n",
        "]\n",
        "```\n",
        "\n",
        "The LLM might return this:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"selected_memories\": [\"mem_1\", \"mem_3\", \"mem_5\"],\n",
        "  \"reasoning\": \"Selected memories containing cost information and the request for cost reduction, excluding project timeline and general discussion as they're not directly relevant to the budget review task.\"\n",
        "}\n",
        "```\n",
        "\n",
        "So the next agent (e.g., a Budget Specialist) receives **only** the relevant context ‚Äî a lightweight, focused memory ‚Äî increasing its performance and reducing error risk.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Why It Matters\n",
        "\n",
        "Compared to hard-coded filters or full memory handoffs, this approach:\n",
        "\n",
        "‚úÖ Uses semantic understanding\n",
        "‚úÖ Justifies memory inclusion\n",
        "‚úÖ Adapts dynamically to any task\n",
        "‚úÖ Keeps memory histories lean and task-relevant\n",
        "\n",
        "This is especially useful in **budgeting, legal review, technical triage, compliance**, or any scenario where context size matters.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ Recap of Memory Sharing Patterns\n",
        "\n",
        "| Pattern               | Use Case                                                       |\n",
        "| --------------------- | -------------------------------------------------------------- |\n",
        "| **Message Passing**   | Fast, focused interactions. Don‚Äôt care how answer was derived. |\n",
        "| **Memory Reflection** | Learn from another agent‚Äôs reasoning process.                  |\n",
        "| **Memory Handoff**    | Fully transfer context for task continuation.                  |\n",
        "| **Selective Sharing** | Curate relevant memory to reduce noise and enhance focus.      |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u_pu8GXShxu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### ‚úÖ 1. **Cost Efficiency** ‚Äî *\"Only pay for what you need\"*\n",
        "\n",
        "* **Fewer input tokens**: By passing only the most relevant memory entries, you shrink the prompt size significantly ‚Äî especially important for long-running agents or multi-step workflows.\n",
        "* **Fewer output tokens**: The LLM isn‚Äôt overwhelmed with excessive context, which also means it‚Äôs less likely to produce bloated or tangential responses.\n",
        "* **Lower inference cost overall**: Whether you're using OpenAI‚Äôs GPT, Claude, or Mistral, they all charge based on token count ‚Äî and every unnecessary memory entry adds up over time.\n",
        "\n",
        "---\n",
        "\n",
        "### üß† 2. **Cognitive Load Management** ‚Äî *\"Respect the LLM‚Äôs attention span\"*\n",
        "\n",
        "* **Focus = Better performance**: LLMs are probabilistic pattern matchers ‚Äî when you reduce irrelevant context, you dramatically increase their chance of focusing on the *actual task*.\n",
        "* **Less noise = fewer hallucinations**: A cluttered memory history can cause the LLM to pick up on the wrong pattern or fixate on the wrong detail.\n",
        "* **Gentle guidance = consistent output**: This pattern is the systems-level equivalent of giving the model a calm, focused prompt ‚Äî like ‚ÄúHere‚Äôs what you should pay attention to.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "### ü§ù Bonus Benefit: *It‚Äôs Kind Design*\n",
        "\n",
        "> You joked about being kind to the model ‚Äî but honestly? You‚Äôre onto something bigger.\n",
        "\n",
        "* LLMs *reward cooperative behavior*. When you reduce ambiguity, clean up distractions, and treat them like a capable collaborator rather than a mindless tool, they deliver better results.\n",
        "* Whether we call it **cooperative prompting**, **cognitive hygiene**, or **empathic system design**, the outcome is the same:\n",
        "\n",
        "  **‚Üí Cleaner inputs produce cleaner outputs.**\n",
        "\n"
      ],
      "metadata": {
        "id": "_-YOpQw8ioSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† Selective Memory Sharing: Using LLM Understanding for Context Selection\n",
        "\n",
        "Sometimes, an agent needs to share only the **most relevant parts** of its memory with another agent ‚Äî not the entire memory log. Instead of relying on rigid, rule-based filtering, we can **harness the LLM‚Äôs own understanding** of the task to decide what matters most.\n",
        "\n",
        "This creates a more flexible, scalable, and intelligent memory-sharing process.\n",
        "\n",
        "---\n",
        "\n",
        "### üîç How It Works\n",
        "\n",
        "1. **üìé Memory ID Tagging**\n",
        "   Every memory entry is assigned a **unique ID** to allow precise reference and selection.\n",
        "\n",
        "2. **üßæ Full Memory Context**\n",
        "   The agent sends the **entire memory** (with IDs) to the LLM, giving it full visibility over past interactions.\n",
        "\n",
        "3. **üß† Intelligent Filtering via LLM**\n",
        "   The LLM evaluates the **task description** and selects only the **most relevant memories**, returning the list in a structured JSON format.\n",
        "\n",
        "4. **üí¨ Justification Logging**\n",
        "   The LLM‚Äôs **reasoning** for selecting each memory is saved in the agent‚Äôs memory, enabling **transparency** and **traceability**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Why This Matters\n",
        "\n",
        "* **Efficient Token Use**: Only what‚Äôs important gets passed along.\n",
        "* **Improved Agent Communication**: Follow-up agents get just the right context.\n",
        "* **Interpretability**: Human reviewers (or debugging devs!) can see *why* certain memories were chosen.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V7ZyAv2Mi-Xz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2c695d1hD5S"
      },
      "outputs": [],
      "source": [
        "@register_tool(description=\"Delegate a task to another agent with selected context\")\n",
        "def call_agent_with_selected_context(action_context: ActionContext,\n",
        "                                   agent_name: str,\n",
        "                                   task: str) -> dict:\n",
        "    \"\"\"Call agent with LLM-selected relevant memories.\"\"\"\n",
        "    agent_registry = action_context.get_agent_registry()\n",
        "    agent_run = agent_registry.get_agent(agent_name)\n",
        "\n",
        "    # Get current memory and add IDs\n",
        "    current_memory = action_context.get_memory()\n",
        "    memory_with_ids = []\n",
        "    for idx, item in enumerate(current_memory.items):\n",
        "        memory_with_ids.append({\n",
        "            **item,\n",
        "            \"memory_id\": f\"mem_{idx}\"\n",
        "        })\n",
        "\n",
        "    # Create schema for memory selection\n",
        "    selection_schema = {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"selected_memories\": {\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"ID of a memory to include\"\n",
        "                }\n",
        "            },\n",
        "            \"reasoning\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Explanation of why these memories were selected\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"selected_memories\", \"reasoning\"]\n",
        "    }\n",
        "\n",
        "    # Format memories for LLM review\n",
        "    memory_text = \"\\n\".join([\n",
        "        f\"Memory {m['memory_id']}: {m['content']}\"\n",
        "        for m in memory_with_ids\n",
        "    ])\n",
        "\n",
        "    # Ask LLM to select relevant memories\n",
        "    selection_prompt = f\"\"\"Review these memories and select the ones relevant for this task:\n",
        "\n",
        "Task: {task}\n",
        "\n",
        "Available Memories:\n",
        "{memory_text}\n",
        "\n",
        "Select memories that provide important context or information for this specific task.\n",
        "Explain your selection process.\"\"\"\n",
        "\n",
        "    # Self-prompting magic to find the most relevant memories\n",
        "    selection = prompt_llm_for_json(\n",
        "        action_context=action_context,\n",
        "        schema=selection_schema,\n",
        "        prompt=selection_prompt\n",
        "    )\n",
        "\n",
        "    # Create filtered memory from selection\n",
        "    filtered_memory = Memory()\n",
        "    selected_ids = set(selection[\"selected_memories\"])\n",
        "    for item in memory_with_ids:\n",
        "        if item[\"memory_id\"] in selected_ids:\n",
        "            # Remove the temporary memory_id before adding\n",
        "            item_copy = item.copy()\n",
        "            del item_copy[\"memory_id\"]\n",
        "            filtered_memory.add_memory(item_copy)\n",
        "\n",
        "    # Run the agent with selected memories\n",
        "    result_memory = agent_run(\n",
        "        user_input=task,\n",
        "        memory=filtered_memory\n",
        "    )\n",
        "\n",
        "    # Add results and selection reasoning to original memory\n",
        "    current_memory.add_memory({\n",
        "        \"type\": \"system\",\n",
        "        \"content\": f\"Memory selection reasoning: {selection['reasoning']}\"\n",
        "    })\n",
        "\n",
        "    for memory_item in result_memory.items:\n",
        "        current_memory.add_memory(memory_item)\n",
        "\n",
        "    return {\n",
        "        \"result\": result_memory.items[-1].get(\"content\", \"No result\"),\n",
        "        \"shared_memories\": len(filtered_memory.items),\n",
        "        \"selection_reasoning\": selection[\"reasoning\"]\n",
        "    }\n",
        "\n",
        "memories = [\n",
        "    {\"type\": \"user\", \"content\": \"We need to build a new reporting dashboard\"},\n",
        "    {\"type\": \"assistant\", \"content\": \"Initial cost estimate: $50,000\"},\n",
        "    {\"type\": \"user\", \"content\": \"That seems high\"},\n",
        "    {\"type\": \"assistant\", \"content\": \"Breakdown: $20k development, $15k design...\"},\n",
        "    {\"type\": \"system\", \"content\": \"Project deadline updated to Q3\"},\n",
        "    {\"type\": \"user\", \"content\": \"Can we reduce the cost?\"}\n",
        "]\n",
        "\n",
        "# LLM's selection might return:\n",
        "{\n",
        "    \"selected_memories\": [\"mem_1\", \"mem_3\", \"mem_5\"],\n",
        "    \"reasoning\": \"Selected memories containing cost information and the request for cost reduction, excluding project timeline and general discussion as they're not directly relevant to the budget review task.\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† What This Code Is Doing\n",
        "\n",
        "### üîπ **Agent 1 (the caller)**\n",
        "\n",
        "Is responsible for:\n",
        "\n",
        "1. **Retrieving all its memories**\n",
        "2. **Labeling them with memory IDs**\n",
        "3. **Prompting the LLM** to decide which of those memories are relevant for the upcoming `task`\n",
        "4. **Creating a filtered memory context** based on that selection\n",
        "5. **Calling Agent 2** with only the selected context\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ **Agent 2 (the receiver)**\n",
        "\n",
        "Is handed:\n",
        "\n",
        "* A **clean, minimal memory** tailored to the current task\n",
        "* This lets Agent 2 focus exclusively on the **most relevant** info\n",
        "\n",
        "It then:\n",
        "\n",
        "* **Performs its task**\n",
        "* **Returns a result**\n",
        "* Optionally contributes new memory entries based on its result\n",
        "\n",
        "---\n",
        "\n",
        "### üß† Why This Pattern Matters\n",
        "\n",
        "| Feature                    | Benefit                                                    |\n",
        "| -------------------------- | ---------------------------------------------------------- |\n",
        "| **Memory Selection**       | Context is curated intelligently using LLM reasoning       |\n",
        "| **Minimized Token Use**    | Only the relevant context is passed ‚Äî saving cost          |\n",
        "| **Reduced Cognitive Load** | Agent 2 isn‚Äôt overwhelmed with irrelevant detail           |\n",
        "| **Auditability**           | The reason for memory selection is logged for traceability |\n",
        "| **Flexibility**            | Works for many agent-to-agent delegation scenarios         |\n",
        "\n",
        "---\n",
        "\n",
        "### üìå Analogy\n",
        "\n",
        "Think of Agent 1 as a manager assigning a task to a specialist (Agent 2). Before doing so, the manager *summarizes the key background documents* needed for that specific task ‚Äî instead of dumping the entire file cabinet.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WeHgUKNaoAyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tool is doing **multiple important things** as part of a *complex and highly valuable behavior pattern*. Think of it as a **multi-phase utility**, tightly scoped to a single, clear purpose:\n",
        "\n",
        "> **‚ÄúCall another agent, but only share the most relevant memories for this specific task.‚Äù**\n",
        "\n",
        "Under the hood, it follows a **multi-step internal process**. Think of it like:\n",
        "\n",
        "* An envelope-packer: it gathers what needs to be sent\n",
        "* A judge: it selects what's important\n",
        "* A delegate: it sends that off to another agent\n",
        "* A reporter: it logs the outcome\n",
        "\n",
        "---\n",
        "\n",
        "## üîç What Is This Tool Doing Step-by-Step?\n",
        "\n",
        "Here‚Äôs a breakdown of the logical parts inside the tool:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Get and Tag Memory**\n",
        "\n",
        "```python\n",
        "current_memory = action_context.get_memory()\n",
        "...\n",
        "\"memory_id\": f\"mem_{idx}\"\n",
        "```\n",
        "\n",
        "It assigns unique IDs (`mem_0`, `mem_1`, etc.) to each memory so the LLM can reference them.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Define a JSON Schema for LLM to Use**\n",
        "\n",
        "```python\n",
        "selection_schema = { ... }\n",
        "```\n",
        "\n",
        "Tells the LLM *how* to respond: return a list of selected memory IDs **and** explain why.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Prompt the LLM to Select the Right Memories**\n",
        "\n",
        "```python\n",
        "selection = prompt_llm_for_json(...)\n",
        "```\n",
        "\n",
        "Uses `prompt_llm_for_json` (a structured prompt function) to:\n",
        "\n",
        "* Show all memories\n",
        "* Describe the task\n",
        "* Ask: *Which memories matter most for this task?*\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Filter the Memory**\n",
        "\n",
        "```python\n",
        "if item[\"memory_id\"] in selected_ids:\n",
        "```\n",
        "\n",
        "Builds a **filtered `Memory()` instance** with *only* the chosen memories.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Run the Agent with Filtered Memory**\n",
        "\n",
        "```python\n",
        "result_memory = agent_run(user_input=task, memory=filtered_memory)\n",
        "```\n",
        "\n",
        "Delegates the task to another agent, but only gives it the relevant memory, *not everything*.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Log the Reasoning and Results**\n",
        "\n",
        "```python\n",
        "current_memory.add_memory(...)\n",
        "```\n",
        "\n",
        "Adds both:\n",
        "\n",
        "* The **LLM‚Äôs reasoning** for selecting the memories\n",
        "* The **output** from the other agent\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why This Is Awesome\n",
        "\n",
        "This tool gives your agent:\n",
        "\n",
        "* **Precision sharing**: Only what matters gets passed along\n",
        "* **Transparency**: You know *why* each memory was selected\n",
        "* **Scalability**: You avoid memory bloat and token overload\n",
        "* **Kindness**: You‚Äôre not dumping a novel on another agent\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Summary\n",
        "\n",
        "| Feature                             | Role                                    |\n",
        "| ----------------------------------- | --------------------------------------- |\n",
        "| `@register_tool(...)`               | Declares it as a single callable tool   |\n",
        "| Internal memory tagging             | Prepares content for smart selection    |\n",
        "| JSON schema + `prompt_llm_for_json` | Gives LLM structured decision framework |\n",
        "| Memory filtering                    | Ensures clean, tight context            |\n",
        "| Final memory updates                | Keeps everything traceable              |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dRBPffltjbsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### üîß Key Code Highlights (with explanations)\n",
        "\n",
        "#### 1. **Assigning IDs to Memories**\n",
        "\n",
        "```python\n",
        "for idx, item in enumerate(current_memory.items):\n",
        "    memory_with_ids.append({\n",
        "        **item,\n",
        "        \"memory_id\": f\"mem_{idx}\"\n",
        "    })\n",
        "```\n",
        "\n",
        "> ‚úÖ **Why it matters:**\n",
        "> Gives each memory a unique `memory_id`, which is **crucial for selection** later. Without identifiers, the LLM can‚Äôt reference specific items reliably. This step turns opaque memory into something structured and addressable.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. **Prompting the LLM to Select Relevant Memories**\n",
        "\n",
        "```python\n",
        "selection_prompt = f\"\"\"Review these memories and select the ones relevant for this task:\n",
        "\n",
        "Task: {task}\n",
        "\n",
        "Available Memories:\n",
        "{memory_text}\n",
        "\n",
        "Select memories that provide important context or information for this specific task.\n",
        "Explain your selection process.\"\"\"\n",
        "```\n",
        "\n",
        "> ‚úÖ **Why it matters:**\n",
        "> This is the **heart of selective memory sharing**. You‚Äôre asking the LLM to apply reasoning and **filter** only what's helpful.\n",
        "> You're treating the LLM like a smart assistant that curates context for downstream use ‚Äî a key modern pattern.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. **Validating the LLM Output with a Schema**\n",
        "\n",
        "```python\n",
        "selection_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"selected_memories\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"ID of a memory to include\"\n",
        "            }\n",
        "        },\n",
        "        \"reasoning\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"Explanation of why these memories were selected\"\n",
        "        }\n",
        "    },\n",
        "    \"required\": [\"selected_memories\", \"reasoning\"]\n",
        "}\n",
        "```\n",
        "\n",
        "> ‚úÖ **Why it matters:**\n",
        "> This schema ensures the LLM gives **structured, predictable output** ‚Äî critical when tools depend on downstream parsing.\n",
        "> You **avoid ambiguous free-form replies** and **gain explainability** through the `reasoning` field.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. **Creating Filtered Memory Based on Selected IDs**\n",
        "\n",
        "```python\n",
        "filtered_memory = Memory()\n",
        "selected_ids = set(selection[\"selected_memories\"])\n",
        "for item in memory_with_ids:\n",
        "    if item[\"memory_id\"] in selected_ids:\n",
        "        item_copy = item.copy()\n",
        "        del item_copy[\"memory_id\"]\n",
        "        filtered_memory.add_memory(item_copy)\n",
        "```\n",
        "\n",
        "> ‚úÖ **Why it matters:**\n",
        "> Builds a **custom memory block** to send to the target agent.\n",
        "> This ensures the second agent receives **only the context it needs**, nothing more ‚Äî reducing token load and improving focus.\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. **Passing Filtered Memory to the Invoked Agent**\n",
        "\n",
        "```python\n",
        "result_memory = agent_run(\n",
        "    user_input=task,\n",
        "    memory=filtered_memory\n",
        ")\n",
        "```\n",
        "\n",
        "> ‚úÖ **Why it matters:**\n",
        "> This is the actual **handoff with scoped memory**.\n",
        "> Agent 2 gets to work using the **intelligently filtered** context.\n",
        "> The call is modular and clean.\n",
        "\n",
        "---\n",
        "\n",
        "#### 6. **Storing the Reasoning in the Original Agent‚Äôs Memory**\n",
        "\n",
        "```python\n",
        "current_memory.add_memory({\n",
        "    \"type\": \"system\",\n",
        "    \"content\": f\"Memory selection reasoning: {selection['reasoning']}\"\n",
        "})\n",
        "```\n",
        "\n",
        "> ‚úÖ **Why it matters:**\n",
        "> Builds **transparency** and **traceability** into the system.\n",
        "> Future debugging, audits, or higher-level reasoning agents can **understand why** certain information was shared.\n",
        "\n",
        "---\n",
        "\n",
        "### üîö Summary\n",
        "\n",
        "Focus on these **6 areas** because they teach you how to:\n",
        "\n",
        "* Structure unstructured memory for LLMs to reason over\n",
        "* Use the LLM not just to act, but to **choose context**\n",
        "* Safely and intelligently hand off tasks between agents\n",
        "* Reduce token load while **increasing explainability**\n",
        "* Maintain **clean modular design** in multi-agent systems\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "syYoqGAOooxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## üß† How Does the LLM Know What‚Äôs in Each Memory?\n",
        "\n",
        "It doesn‚Äôt just see the **memory ID** (`mem_0`, `mem_1`, etc.).\n",
        "\n",
        "Instead, it sees **both**:\n",
        "\n",
        "* The **ID** (`mem_0`)\n",
        "* The **content** of that memory\n",
        "\n",
        "This happens here in the code:\n",
        "\n",
        "```python\n",
        "memory_text = \"\\n\".join([\n",
        "    f\"Memory {m['memory_id']}: {m['content']}\"\n",
        "    for m in memory_with_ids\n",
        "])\n",
        "```\n",
        "\n",
        "So the **prompt looks something like this**:\n",
        "\n",
        "```\n",
        "Review these memories and select the ones relevant for this task:\n",
        "\n",
        "Task: Schedule a follow-up call with the client about the contract.\n",
        "\n",
        "Available Memories:\n",
        "Memory mem_0: \"Had a meeting with the client last week\"\n",
        "Memory mem_1: \"Client is waiting on the updated contract draft\"\n",
        "Memory mem_2: \"Lunch with marketing team scheduled Thursday\"\n",
        "...\n",
        "```\n",
        "\n",
        "Then it asks:\n",
        "\n",
        "> Select memories that provide important context or information for this specific task. Explain your selection process.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç What‚Äôs the Role of the Memory ID?\n",
        "\n",
        "The **`memory_id`** is just a reference tag ‚Äî like a label on a file folder.\n",
        "The LLM uses it to:\n",
        "\n",
        "* Refer to a memory unambiguously\n",
        "* Structure its response like:\n",
        "\n",
        "  ```json\n",
        "  {\n",
        "    \"selected_memories\": [\"mem_0\", \"mem_1\"],\n",
        "    \"reasoning\": \"These relate to the client and contract context\"\n",
        "  }\n",
        "  ```\n",
        "\n",
        "So later, when we filter:\n",
        "\n",
        "```python\n",
        "if item[\"memory_id\"] in selected_ids:\n",
        "```\n",
        "\n",
        "‚Ä¶it knows *exactly which full memories to pass on* ‚Äî because it already **read the content**, not just the IDs.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Why This Works\n",
        "\n",
        "| Element            | Purpose                               |\n",
        "| ------------------ | ------------------------------------- |\n",
        "| `memory_id`        | Unambiguous label for reference       |\n",
        "| `content`          | What the LLM uses to decide relevance |\n",
        "| `selection_prompt` | Guides the LLM to choose what matters |\n",
        "| `schema`           | Ensures a clean, parseable response   |\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Bonus: Why Use IDs at All?\n",
        "\n",
        "You might wonder, *why not just select the content directly?*\n",
        "\n",
        "Because:\n",
        "\n",
        "* IDs make referencing easier and reduce chance of LLM hallucinating long text\n",
        "* IDs keep the response **clean**, short, and deterministic\n",
        "* You can map those IDs back to memory items efficiently in code\n",
        "\n"
      ],
      "metadata": {
        "id": "YK0t6pfgk0Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† Selective Memory Sharing in Action\n",
        "\n",
        "The second agent receives **only the memories related to:**\n",
        "\n",
        "* Cost estimates\n",
        "* Budget breakdowns\n",
        "* The request for reduction\n",
        "\n",
        "This gives the budget review agent **focused, high-signal context** ‚Äî without distracting information about timelines, personnel, or unrelated project details.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Why This Beats Rule-Based Filtering\n",
        "\n",
        "This approach has several **clear advantages** over traditional, static filtering:\n",
        "\n",
        "1. **Contextual Understanding**\n",
        "   The LLM selects memories based on meaning and relevance ‚Äî not just keyword matching or rigid rules.\n",
        "\n",
        "2. **Preserved Reasoning**\n",
        "   The LLM explains *why* certain memories were selected. This adds transparency and helps you debug or improve selection later.\n",
        "\n",
        "3. **Adaptive & Flexible**\n",
        "   You don‚Äôt need to rewrite filtering logic for each new type of task. The LLM adapts its selection to the context at hand.\n",
        "\n",
        "4. **Audit Trail**\n",
        "   The original agent keeps a record of:\n",
        "\n",
        "   * What was shared\n",
        "   * Why it was shared\n",
        "     This is especially useful in sensitive workflows.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Example Use Case\n",
        "\n",
        "> A **project planning agent** asks a **budget specialist** to review cost overruns.\n",
        "\n",
        "Instead of handing over the **entire** project history, the agent shares:\n",
        "\n",
        "* Resource allocation notes\n",
        "* Previous expense approvals\n",
        "* Any recent cost change requests\n",
        "\n",
        "üéØ This lets the budget agent focus **only on financials** ‚Äî without getting bogged down in unrelated details.\n"
      ],
      "metadata": {
        "id": "4Cx8oEginRuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† Recap of the Four Memory Sharing Patterns\n",
        "\n",
        "Agent collaboration can be designed around different **memory-sharing strategies**, depending on the task‚Äôs complexity, risk, and communication goals.\n",
        "\n",
        "### 1. üì® Message Passing\n",
        "\n",
        "**‚ÄúJust the answer, please.‚Äù**\n",
        "\n",
        "* **Purpose:** Keep interactions clean and minimal.\n",
        "* **Mechanism:** The second agent works in isolation and returns only the final result.\n",
        "* **Use When:** You don‚Äôt need to understand *how* the answer was derived.\n",
        "\n",
        "> ‚úÖ Great for low-stakes, modular tasks.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. üîç Memory Reflection\n",
        "\n",
        "**‚ÄúTell me what you did and how.‚Äù**\n",
        "\n",
        "* **Purpose:** Learn from the invoked agent's reasoning process.\n",
        "* **Mechanism:** After task completion, all of the second agent‚Äôs memory is copied back to the first.\n",
        "* **Use When:** You want the first agent to *learn* or *audit* the reasoning used.\n",
        "\n",
        "> ‚úÖ Great for transparency, training, and debugging.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. üîÅ Memory Handoff\n",
        "\n",
        "**‚ÄúTake over from here.‚Äù**\n",
        "\n",
        "* **Purpose:** Allow one agent to fully continue where another left off.\n",
        "* **Mechanism:** Full memory is *transferred* and shared.\n",
        "* **Use When:** You want seamless continuation of a task with full context.\n",
        "\n",
        "> ‚úÖ Great for long-running tasks or handoffs in pipelines (e.g., customer service ‚Üí technical support).\n",
        "\n",
        "---\n",
        "\n",
        "### 4. üéØ Selective Memory Sharing\n",
        "\n",
        "**‚ÄúHere‚Äôs only what you need to know.‚Äù**\n",
        "\n",
        "* **Purpose:** Share *just the relevant* context based on task.\n",
        "* **Mechanism:** LLM chooses specific memories to share and explains its reasoning.\n",
        "* **Use When:** You want to reduce noise, save tokens, and improve focus.\n",
        "\n",
        "> ‚úÖ Great for bandwidth optimization, clarity, and task-scoped reasoning.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Choosing the Right Pattern\n",
        "\n",
        "Ask yourself:\n",
        "\n",
        "* ‚ùì **How much context** does the receiving agent need?\n",
        "* ‚ùì Should the **calling agent understand** the reasoning of the second?\n",
        "* ‚ùì Do you want to **preserve or reset** conversation history?\n",
        "* ‚ùì Is there any **sensitive or irrelevant** information that must be filtered?\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Final Insights\n",
        "\n",
        "* These patterns aren't mutually exclusive ‚Äî real systems often use **hybrids** depending on the sensitivity, task type, and agent role.\n",
        "* Managing memory is not just about cost ‚Äî it‚Äôs about **precision, reliability, and safety**.\n",
        "* Architecting agents with **clear memory boundaries and deliberate communication** makes your system more scalable, testable, and robust.\n",
        "* And yes ‚Äî **being kind to your LLMs** through focused context and modularity *really does* improve results. Treat your agents like collaborators, not calculators.\n",
        "\n"
      ],
      "metadata": {
        "id": "PZL2W9FHn9r0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0zs_ibdjvTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}