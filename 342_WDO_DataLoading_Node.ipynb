{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOOIhT20Oge6CG/ad5ggMD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/342_WDO_DataLoading_Node.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Workforce Development Orchestrator — Data Loading Node\n",
        "\n",
        "The `data_loading_node` is the **foundation node** of the Workforce Development Orchestrator. Its responsibility is simple but critical:\n",
        "\n",
        "> **Safely transform raw workforce data into a structured, reliable state the agent can trust.**\n",
        "\n",
        "Every downstream analysis — automation risk, skill gaps, learning paths, role evolution — depends on this step being correct, complete, and auditable.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Why This Node Exists\n",
        "\n",
        "Rather than allowing each analytical component to load data independently, this node centralizes **all data ingestion** into a single, controlled step.\n",
        "\n",
        "This design:\n",
        "\n",
        "* Eliminates duplication\n",
        "* Prevents inconsistent views of data\n",
        "* Creates a single source of truth for the entire run\n",
        "\n",
        "If something goes wrong here, the system fails early — before misleading insights are generated.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Configuration-Driven, Not Hard-Coded\n",
        "\n",
        "The node relies entirely on the `WorkforceDevelopmentOrchestratorConfig` for file locations and names.\n",
        "\n",
        "This ensures:\n",
        "\n",
        "* Environments can change without code changes\n",
        "* Data sources can be swapped safely\n",
        "* Executives can understand *where the data comes from*\n",
        "\n",
        "This is a small but powerful step toward operational trust.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Explicit Data Coverage\n",
        "\n",
        "The node loads **every dataset required by the agent** in one place:\n",
        "\n",
        "* Employees\n",
        "* Roles\n",
        "* Tasks\n",
        "* Skills\n",
        "* Automation signals\n",
        "* Skill gaps\n",
        "* Learning paths\n",
        "* Role evolution scenarios\n",
        "\n",
        "Nothing is implicit. Nothing is assumed.\n",
        "\n",
        "This makes it immediately clear:\n",
        "\n",
        "* What data the agent depends on\n",
        "* What would break if a dataset were missing\n",
        "* What needs to be updated as the organization evolves\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Performance and Determinism Through Lookups\n",
        "\n",
        "After loading raw data, the node builds **lookup and relationship maps**:\n",
        "\n",
        "* Direct ID lookups (roles, tasks, skills, employees)\n",
        "* Role-to-task mappings\n",
        "* Role-to-employee mappings\n",
        "\n",
        "These structures are deliberately created *once* and reused everywhere else.\n",
        "\n",
        "From a business standpoint, this ensures:\n",
        "\n",
        "* Predictable execution time\n",
        "* No hidden computation costs\n",
        "* No inconsistent joins during analysis\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Defensive Error Handling\n",
        "\n",
        "The node treats errors as first-class outputs.\n",
        "\n",
        "### Key behaviors:\n",
        "\n",
        "* Missing data directories are detected immediately\n",
        "* File and parsing errors are captured and contextualized\n",
        "* Unexpected failures are surfaced without crashing the agent\n",
        "\n",
        "Importantly, errors are **accumulated**, not overwritten. This allows:\n",
        "\n",
        "* Partial execution where appropriate\n",
        "* Clear diagnostics at the end of a run\n",
        "* Easier debugging and post-mortems\n",
        "\n",
        "This is critical for long-running or enterprise-facing agents.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Thin Node, Strong Utilities\n",
        "\n",
        "Notice what this node does *not* do:\n",
        "\n",
        "* It does not parse JSON directly\n",
        "* It does not build data structures inline\n",
        "* It does not embed business logic\n",
        "\n",
        "Instead, it delegates to utilities that are:\n",
        "\n",
        "* Independently tested\n",
        "* Reusable\n",
        "* Easier to reason about\n",
        "\n",
        "The fact that all utilities passed tests before this node was built is exactly the right workflow. This keeps orchestration clean and logic trustworthy.\n",
        "\n",
        "---\n",
        "\n",
        "## Why This Node Builds Confidence\n",
        "\n",
        "From an executive or stakeholder perspective, this node guarantees:\n",
        "\n",
        "* The agent reasons only over verified inputs\n",
        "* Failures are visible and explainable\n",
        "* Outputs are grounded in consistent data\n",
        "* Changes to data are controlled and auditable\n",
        "\n",
        "From a system design perspective, this node establishes a **stable base layer** that allows every other component to focus on *analysis*, not *data hygiene*.\n",
        "\n",
        "---\n",
        "\n",
        "## Architectural Takeaway\n",
        "\n",
        "This node does something deceptively important:\n",
        "\n",
        "It draws a clear line between **data reality** and **agent intelligence**.\n",
        "\n",
        "Everything beyond this point is interpretation and recommendation — but only because this node ensures the underlying facts are solid.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tp_DjU0x6uPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workforce Development Orchestrator — Data Loading Node Code"
      ],
      "metadata": {
        "id": "6Oy5dNgj6td5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfdZVYp65g-Y"
      },
      "outputs": [],
      "source": [
        "def data_loading_node(\n",
        "    state: WorkforceDevelopmentOrchestratorState,\n",
        "    config: WorkforceDevelopmentOrchestratorConfig\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Data Loading Node: Orchestrate loading all workforce data.\n",
        "\n",
        "    Loads employees, roles, tasks, skills, and related data from JSON files,\n",
        "    then builds lookup dictionaries for fast access.\n",
        "    \"\"\"\n",
        "    errors = state.get(\"errors\", [])\n",
        "    data_dir = Path(config.data_dir)\n",
        "\n",
        "    if not data_dir.exists():\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: Data directory not found: {data_dir}\"]\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        # Load all data files\n",
        "        employees = load_employees(data_dir, config.employees_file)\n",
        "        roles = load_roles(data_dir, config.roles_file)\n",
        "        tasks = load_tasks(data_dir, config.tasks_file)\n",
        "        skills = load_skills(data_dir, config.skills_file)\n",
        "        automation_signals = load_automation_signals(data_dir, config.automation_signals_file)\n",
        "        skill_gaps = load_skill_gaps(data_dir, config.skill_gaps_file)\n",
        "        learning_paths = load_learning_paths(data_dir, config.learning_paths_file)\n",
        "        role_evolution = load_role_evolution(data_dir, config.role_evolution_file)\n",
        "\n",
        "        # Build lookup dictionaries for fast access\n",
        "        roles_lookup = build_roles_lookup(roles)\n",
        "        tasks_lookup = build_tasks_lookup(tasks)\n",
        "        skills_lookup = build_skills_lookup(skills)\n",
        "        employees_lookup = build_employees_lookup(employees)\n",
        "        tasks_by_role = build_tasks_by_role(tasks)\n",
        "        employees_by_role = build_employees_by_role(employees)\n",
        "\n",
        "        return {\n",
        "            \"employees\": employees,\n",
        "            \"roles\": roles,\n",
        "            \"tasks\": tasks,\n",
        "            \"skills\": skills,\n",
        "            \"automation_signals\": automation_signals,\n",
        "            \"skill_gaps\": skill_gaps,\n",
        "            \"learning_paths\": learning_paths,\n",
        "            \"role_evolution\": role_evolution,\n",
        "            \"roles_lookup\": roles_lookup,\n",
        "            \"tasks_lookup\": tasks_lookup,\n",
        "            \"skills_lookup\": skills_lookup,\n",
        "            \"employees_lookup\": employees_lookup,\n",
        "            \"tasks_by_role\": tasks_by_role,\n",
        "            \"employees_by_role\": employees_by_role,\n",
        "            \"errors\": errors\n",
        "        }\n",
        "    except FileNotFoundError as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: {str(e)}\"]\n",
        "        }\n",
        "    except ValueError as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: {str(e)}\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"errors\": errors + [f\"data_loading_node: Unexpected error: {str(e)}\"]\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test data loading node for Workforce Development Orchestrator"
      ],
      "metadata": {
        "id": "iEk9GL1d6m61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Test data loading node for Workforce Development Orchestrator\n",
        "\n",
        "Testing Phase 2: Data Loading Node\n",
        "Following the pattern: Test node after utilities pass\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "from agents.workforce_development_orchestrator.nodes import data_loading_node\n",
        "from config import WorkforceDevelopmentOrchestratorState, WorkforceDevelopmentOrchestratorConfig\n",
        "\n",
        "\n",
        "def test_data_loading_node():\n",
        "    \"\"\"Test data loading node loads all data and builds lookups\"\"\"\n",
        "    state: WorkforceDevelopmentOrchestratorState = {\n",
        "        \"errors\": []\n",
        "    }\n",
        "    config = WorkforceDevelopmentOrchestratorConfig()\n",
        "\n",
        "    result = data_loading_node(state, config)\n",
        "\n",
        "    # Check that all data is loaded\n",
        "    assert \"employees\" in result\n",
        "    assert \"roles\" in result\n",
        "    assert \"tasks\" in result\n",
        "    assert \"skills\" in result\n",
        "    assert \"automation_signals\" in result\n",
        "    assert \"skill_gaps\" in result\n",
        "    assert \"learning_paths\" in result\n",
        "    assert \"role_evolution\" in result\n",
        "\n",
        "    # Check that lookups are built\n",
        "    assert \"roles_lookup\" in result\n",
        "    assert \"tasks_lookup\" in result\n",
        "    assert \"skills_lookup\" in result\n",
        "    assert \"employees_lookup\" in result\n",
        "    assert \"tasks_by_role\" in result\n",
        "    assert \"employees_by_role\" in result\n",
        "\n",
        "    # Verify data counts\n",
        "    assert len(result[\"employees\"]) == 10\n",
        "    assert len(result[\"roles\"]) == 5\n",
        "    assert len(result[\"tasks\"]) == 15\n",
        "    assert len(result[\"skills\"]) == 12\n",
        "\n",
        "    # Verify lookups work\n",
        "    assert \"R001\" in result[\"roles_lookup\"]\n",
        "    assert \"T001\" in result[\"tasks_lookup\"]\n",
        "    assert \"data_entry\" in result[\"skills_lookup\"]\n",
        "    assert \"E001\" in result[\"employees_lookup\"]\n",
        "    assert \"R001\" in result[\"tasks_by_role\"]\n",
        "    assert \"R001\" in result[\"employees_by_role\"]\n",
        "\n",
        "    # Verify no errors\n",
        "    assert len(result.get(\"errors\", [])) == 0\n",
        "\n",
        "    print(\"✅ test_data_loading_node: PASSED\")\n",
        "\n",
        "\n",
        "def test_data_loading_node_with_errors():\n",
        "    \"\"\"Test data loading node handles missing directory gracefully\"\"\"\n",
        "    state: WorkforceDevelopmentOrchestratorState = {\n",
        "        \"errors\": []\n",
        "    }\n",
        "    config = WorkforceDevelopmentOrchestratorConfig()\n",
        "    config.data_dir = \"nonexistent_directory\"\n",
        "\n",
        "    result = data_loading_node(state, config)\n",
        "\n",
        "    # Should have errors\n",
        "    assert \"errors\" in result\n",
        "    assert len(result[\"errors\"]) > 0\n",
        "    assert \"not found\" in result[\"errors\"][0].lower()\n",
        "\n",
        "    print(\"✅ test_data_loading_node_with_errors: PASSED\")\n",
        "\n",
        "\n",
        "def test_data_loading_node_integration():\n",
        "    \"\"\"Test data loading node with goal and planning nodes\"\"\"\n",
        "    state: WorkforceDevelopmentOrchestratorState = {\n",
        "        \"employee_id\": None,\n",
        "        \"errors\": []\n",
        "    }\n",
        "    config = WorkforceDevelopmentOrchestratorConfig()\n",
        "\n",
        "    # First goal node\n",
        "    from agents.workforce_development_orchestrator.nodes import goal_node, planning_node\n",
        "    state = goal_node(state)\n",
        "    assert \"goal\" in state\n",
        "\n",
        "    # Then planning node\n",
        "    state = planning_node(state)\n",
        "    assert \"plan\" in state\n",
        "\n",
        "    # Then data loading node\n",
        "    state = data_loading_node(state, config)\n",
        "\n",
        "    # Verify all data loaded\n",
        "    assert \"employees\" in state\n",
        "    assert \"roles_lookup\" in state\n",
        "    assert len(state.get(\"errors\", [])) == 0\n",
        "\n",
        "    print(\"✅ test_data_loading_node_integration: PASSED\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Testing Data Loading Node (Phase 2)\")\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "    test_data_loading_node()\n",
        "    test_data_loading_node_with_errors()\n",
        "    test_data_loading_node_integration()\n",
        "\n",
        "    print()\n",
        "    print(\"=\" * 60)\n",
        "    print(\"✅ All data loading node tests passed!\")\n",
        "    print(\"=\" * 60)\n",
        "\n"
      ],
      "metadata": {
        "id": "POp7XGii6nbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Results"
      ],
      "metadata": {
        "id": "3YB1BkR-7M2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_008_Workforce_Development_Orchestrator %  python3 test_data_loading_node.py\n",
        "============================================================\n",
        "Testing Data Loading Node (Phase 2)\n",
        "============================================================\n",
        "\n",
        "✅ test_data_loading_node: PASSED\n",
        "✅ test_data_loading_node_with_errors: PASSED\n",
        "✅ test_data_loading_node_integration: PASSED\n",
        "\n",
        "============================================================\n",
        "✅ All data loading node tests passed!\n",
        "============================================================\n"
      ],
      "metadata": {
        "id": "JHL3QyWJ7N2B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}