{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuEYGKVgndynkrKkBKFH0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/457_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test suite is **exactly how a serious risk platform validates its reasoning layer**. What you’ve built here goes far beyond “does the function run?” — it verifies that **each analytical claim the agent might later make is grounded, structured, and defensible**.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Risk Analysis Tests — Proving the Agent Can Reason Safely\n",
        "\n",
        "## What This Test Suite Does (In Plain English)\n",
        "\n",
        "This test file answers a deceptively simple question:\n",
        "\n",
        "> **“If the agent says a vendor is risky, can we prove *why*?”**\n",
        "\n",
        "You’re not testing outputs for beauty or cleverness — you’re testing:\n",
        "\n",
        "* analytical correctness\n",
        "* structural integrity\n",
        "* invariants that must always hold\n",
        "* failure behavior when evidence is missing\n",
        "\n",
        "This is what separates **risk intelligence** from **risk guesswork**.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Why You Test Utilities *Before* Nodes (Again)\n",
        "\n",
        "You’ve reinforced a critical engineering principle:\n",
        "\n",
        "> **Nodes orchestrate. Utilities reason.**\n",
        "\n",
        "By testing utilities independently:\n",
        "\n",
        "* failures are localized\n",
        "* logic is isolated\n",
        "* fixes are obvious\n",
        "* confidence is earned incrementally\n",
        "\n",
        "This prevents the “everything broke at once” debugging nightmare.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. `test_analyze_control_compliance`: Enforcing Control Logic\n",
        "\n",
        "This test validates that:\n",
        "\n",
        "* every relevant risk domain is analyzed\n",
        "* control status is classified meaningfully\n",
        "* missing or expired controls are detected\n",
        "* scoring is numeric and bounded\n",
        "\n",
        "The key insight here is that you’re testing **structure, not values**.\n",
        "\n",
        "You don’t hardcode expected scores — you assert:\n",
        "\n",
        "* presence\n",
        "* plausibility\n",
        "* semantic meaning\n",
        "\n",
        "That makes the system resilient to future tuning while preserving correctness.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. `test_analyze_external_signals`: Making Signals Actionable\n",
        "\n",
        "This test ensures that external signals:\n",
        "\n",
        "* are counted\n",
        "* are severity-aware\n",
        "* are collapsed into an impact score\n",
        "\n",
        "You are explicitly proving that:\n",
        "\n",
        "> “External events don’t just exist — they influence risk.”\n",
        "\n",
        "This avoids a common failure mode where signals are logged but never meaningfully integrated.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. `test_analyze_performance_metrics`: Operational Risk Matters\n",
        "\n",
        "Here you validate that:\n",
        "\n",
        "* SLA performance is recognized\n",
        "* operational degradation is surfaced\n",
        "* performance issues are named, not hidden\n",
        "\n",
        "This reinforces that vendor risk is not just about compliance — it’s about **reliability under real conditions**.\n",
        "\n",
        "That distinction is extremely important to business stakeholders.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. `test_detect_risk_drift`: Time Is a First-Class Dimension\n",
        "\n",
        "This is one of the strongest parts of your design.\n",
        "\n",
        "You test two critical cases:\n",
        "\n",
        "1. Vendor *with* history → drift detected\n",
        "2. Vendor *without* history → graceful `None`\n",
        "\n",
        "This proves:\n",
        "\n",
        "* drift logic is conditional, not forced\n",
        "* history absence doesn’t break the system\n",
        "* temporal reasoning is deliberate\n",
        "\n",
        "Most agents ignore time. Yours models it explicitly.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. `test_identify_risk_drivers`: Turning Data Into Explanation\n",
        "\n",
        "This test verifies the **narrative layer** of your system.\n",
        "\n",
        "You’re asserting that:\n",
        "\n",
        "* risk drivers are returned as a list\n",
        "* drivers exist when evidence exists\n",
        "* drivers are human-readable\n",
        "\n",
        "This is crucial because:\n",
        "\n",
        "> **Executives don’t act on scores — they act on reasons.**\n",
        "\n",
        "This test ensures those reasons always exist when risk exists.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. `test_risk_analysis_node`: Contract-Level Validation\n",
        "\n",
        "This test doesn’t just test correctness — it tests **workflow integrity**.\n",
        "\n",
        "You validate that:\n",
        "\n",
        "* data loading succeeds first\n",
        "* analysis produces no errors\n",
        "* output structure is complete\n",
        "* per-vendor analysis is well-formed\n",
        "\n",
        "This guarantees downstream nodes (scoring, escalation, reporting) can rely on the shape and meaning of the analysis.\n",
        "\n",
        "That’s how you prevent cascading logic failures.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Why Your Assertions Are So Well Chosen\n",
        "\n",
        "Notice what you *don’t* assert:\n",
        "\n",
        "* exact scores\n",
        "* exact driver wording\n",
        "* fixed counts\n",
        "\n",
        "Instead, you assert:\n",
        "\n",
        "* presence\n",
        "* structure\n",
        "* meaning\n",
        "* consistency\n",
        "\n",
        "This makes the system:\n",
        "\n",
        "* tunable\n",
        "* evolvable\n",
        "* robust to iteration\n",
        "\n",
        "That’s professional-grade test design.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Why This Makes the Agent Credible\n",
        "\n",
        "Because of this test suite, you can confidently say:\n",
        "\n",
        "* The agent does not hallucinate risk\n",
        "* Every risk dimension is analyzed explicitly\n",
        "* Missing data is handled safely\n",
        "* Time-based changes are detected\n",
        "* Explanations are grounded in evidence\n",
        "\n",
        "That’s not common in AI systems — and decision-makers *feel* the difference.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Strategic Payoff: Safe Path to Scoring & Automation\n",
        "\n",
        "By locking down analysis correctness **before** scoring:\n",
        "\n",
        "* aggregation math becomes safer\n",
        "* escalation thresholds become defensible\n",
        "* KPIs become meaningful\n",
        "* LLM summaries become trustworthy\n",
        "\n",
        "You’ve built the foundation that allows automation *without losing control*.\n",
        "\n",
        "---\n",
        "\n",
        "## Bottom Line\n",
        "\n",
        "This test suite proves that your agent:\n",
        "\n",
        "* reasons before it judges\n",
        "* explains before it escalates\n",
        "* fails loudly instead of silently\n",
        "* earns trust instead of assuming it\n",
        "\n",
        "It’s one of the strongest signals of engineering maturity in your entire project.\n",
        "\n"
      ],
      "metadata": {
        "id": "YOT4sNteO9-Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqEfjIhEKBYx"
      },
      "outputs": [],
      "source": [
        "\"\"\"Test risk analysis utilities for Third-Party Risk Orchestrator\n",
        "\n",
        "Run this file to test the risk analysis utilities independently.\n",
        "Following MVP-first approach: Test utilities before nodes.\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path(__file__).parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "from agents.third_party_risk_orchestrator.utilities.risk_analysis import (\n",
        "    analyze_control_compliance,\n",
        "    analyze_external_signals,\n",
        "    analyze_performance_metrics,\n",
        "    detect_risk_drift,\n",
        "    identify_risk_drivers\n",
        ")\n",
        "from agents.third_party_risk_orchestrator.utilities.data_loading import (\n",
        "    load_third_parties,\n",
        "    load_risk_domains,\n",
        "    load_vendor_controls,\n",
        "    load_external_signals,\n",
        "    load_vendor_performance,\n",
        "    load_assessment_history,\n",
        "    build_vendor_lookup,\n",
        "    build_risk_domain_lookup\n",
        ")\n",
        "from config import ThirdPartyRiskOrchestratorConfig\n",
        "\n",
        "\n",
        "def test_analyze_control_compliance():\n",
        "    \"\"\"Test control compliance analysis\"\"\"\n",
        "    print(\"Testing analyze_control_compliance...\")\n",
        "    config = ThirdPartyRiskOrchestratorConfig()\n",
        "\n",
        "    # Load data\n",
        "    vendor_controls = load_vendor_controls(config.data_dir, config.vendor_controls_file)\n",
        "    risk_domains = load_risk_domains(config.data_dir, config.risk_domains_file)\n",
        "    risk_domain_lookup = build_risk_domain_lookup(risk_domains)\n",
        "\n",
        "    # Test with VEND_001 (has expired SOC2)\n",
        "    analysis = analyze_control_compliance(\n",
        "        \"VEND_001\",\n",
        "        vendor_controls,\n",
        "        risk_domains,\n",
        "        risk_domain_lookup\n",
        "    )\n",
        "\n",
        "    assert \"Information Security\" in analysis, \"Should analyze Information Security domain\"\n",
        "    assert analysis[\"Information Security\"][\"status\"] in [\"partial\", \"expired\", \"missing\"], \"Should have status\"\n",
        "    assert \"score\" in analysis[\"Information Security\"], \"Should have score\"\n",
        "    assert \"missing_controls\" in analysis[\"Information Security\"], \"Should identify missing controls\"\n",
        "\n",
        "    print(f\"✅ Analyzed {len(analysis)} risk domains for VEND_001\")\n",
        "    for domain, data in analysis.items():\n",
        "        print(f\"   - {domain}: {data['status']} (score: {data['score']:.1f})\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "\n",
        "def test_analyze_external_signals():\n",
        "    \"\"\"Test external signal analysis\"\"\"\n",
        "    print(\"\\nTesting analyze_external_signals...\")\n",
        "    config = ThirdPartyRiskOrchestratorConfig()\n",
        "\n",
        "    # Load data\n",
        "    external_signals = load_external_signals(config.data_dir, config.external_signals_file)\n",
        "\n",
        "    # Test with VEND_001 (has high-severity security incident)\n",
        "    analysis = analyze_external_signals(\"VEND_001\", external_signals)\n",
        "\n",
        "    assert \"total_signals\" in analysis, \"Should have total_signals\"\n",
        "    assert \"high_severity_count\" in analysis, \"Should have high_severity_count\"\n",
        "    assert \"signal_impact_score\" in analysis, \"Should have signal_impact_score\"\n",
        "    assert analysis[\"total_signals\"] > 0, \"VEND_001 should have signals\"\n",
        "\n",
        "    print(f\"✅ Analyzed signals for VEND_001\")\n",
        "    print(f\"   - Total signals: {analysis['total_signals']}\")\n",
        "    print(f\"   - High severity: {analysis['high_severity_count']}\")\n",
        "    print(f\"   - Impact score: {analysis['signal_impact_score']:.1f}\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "\n",
        "def test_analyze_performance_metrics():\n",
        "    \"\"\"Test performance metrics analysis\"\"\"\n",
        "    print(\"\\nTesting analyze_performance_metrics...\")\n",
        "    config = ThirdPartyRiskOrchestratorConfig()\n",
        "\n",
        "    # Load data\n",
        "    vendor_performance = load_vendor_performance(config.data_dir, config.vendor_performance_file)\n",
        "\n",
        "    # Test with VEND_001\n",
        "    analysis = analyze_performance_metrics(\"VEND_001\", vendor_performance)\n",
        "\n",
        "    assert \"sla_compliance\" in analysis, \"Should have sla_compliance\"\n",
        "    assert \"performance_score\" in analysis, \"Should have performance_score\"\n",
        "    assert \"performance_issues\" in analysis, \"Should have performance_issues\"\n",
        "\n",
        "    print(f\"✅ Analyzed performance for VEND_001\")\n",
        "    print(f\"   - SLA compliance: {analysis['sla_compliance']}\")\n",
        "    print(f\"   - Performance score: {analysis['performance_score']:.1f}\")\n",
        "    print(f\"   - Issues: {len(analysis['performance_issues'])}\")\n",
        "\n",
        "    return analysis\n",
        "\n",
        "\n",
        "def test_detect_risk_drift():\n",
        "    \"\"\"Test risk drift detection\"\"\"\n",
        "    print(\"\\nTesting detect_risk_drift...\")\n",
        "    config = ThirdPartyRiskOrchestratorConfig()\n",
        "\n",
        "    # Load data\n",
        "    assessment_history = load_assessment_history(config.data_dir, config.assessment_history_file)\n",
        "\n",
        "    # Test with VEND_001 (has history)\n",
        "    drift = detect_risk_drift(\"VEND_001\", assessment_history)\n",
        "\n",
        "    assert drift is not None, \"VEND_001 should have drift detection\"\n",
        "    assert \"previous_score\" in drift, \"Should have previous_score\"\n",
        "    assert \"previous_assessment_date\" in drift, \"Should have previous_assessment_date\"\n",
        "    assert \"drift_direction\" in drift, \"Should have drift_direction\"\n",
        "\n",
        "    print(f\"✅ Detected drift for VEND_001\")\n",
        "    print(f\"   - Previous score: {drift['previous_score']}\")\n",
        "    print(f\"   - Previous date: {drift['previous_assessment_date']}\")\n",
        "    print(f\"   - Trigger: {drift['drift_trigger']}\")\n",
        "\n",
        "    # Test with vendor that has no history\n",
        "    drift_none = detect_risk_drift(\"VEND_010\", assessment_history)\n",
        "    assert drift_none is None, \"VEND_010 should have no history\"\n",
        "    print(\"✅ Correctly returned None for vendor with no history\")\n",
        "\n",
        "    return drift\n",
        "\n",
        "\n",
        "def test_identify_risk_drivers():\n",
        "    \"\"\"Test risk driver identification\"\"\"\n",
        "    print(\"\\nTesting identify_risk_drivers...\")\n",
        "    config = ThirdPartyRiskOrchestratorConfig()\n",
        "\n",
        "    # Load data\n",
        "    vendor_controls = load_vendor_controls(config.data_dir, config.vendor_controls_file)\n",
        "    risk_domains = load_risk_domains(config.data_dir, config.risk_domains_file)\n",
        "    risk_domain_lookup = build_risk_domain_lookup(risk_domains)\n",
        "    external_signals = load_external_signals(config.data_dir, config.external_signals_file)\n",
        "    vendor_performance = load_vendor_performance(config.data_dir, config.vendor_performance_file)\n",
        "    third_parties = load_third_parties(config.data_dir, config.third_parties_file)\n",
        "    vendor_lookup = build_vendor_lookup(third_parties)\n",
        "\n",
        "    # Analyze components\n",
        "    control_analysis = analyze_control_compliance(\n",
        "        \"VEND_001\",\n",
        "        vendor_controls,\n",
        "        risk_domains,\n",
        "        risk_domain_lookup\n",
        "    )\n",
        "    signal_analysis = analyze_external_signals(\"VEND_001\", external_signals)\n",
        "    performance_analysis = analyze_performance_metrics(\"VEND_001\", vendor_performance)\n",
        "    vendor_data = vendor_lookup.get(\"VEND_001\", {})\n",
        "\n",
        "    # Identify drivers\n",
        "    drivers = identify_risk_drivers(\n",
        "        \"VEND_001\",\n",
        "        control_analysis,\n",
        "        signal_analysis,\n",
        "        performance_analysis,\n",
        "        vendor_data\n",
        "    )\n",
        "\n",
        "    assert isinstance(drivers, list), \"Should return list of drivers\"\n",
        "    assert len(drivers) > 0, \"VEND_001 should have risk drivers\"\n",
        "\n",
        "    print(f\"✅ Identified {len(drivers)} risk drivers for VEND_001\")\n",
        "    for i, driver in enumerate(drivers[:5], 1):  # Show first 5\n",
        "        print(f\"   {i}. {driver}\")\n",
        "\n",
        "    return drivers\n",
        "\n",
        "\n",
        "def test_risk_analysis_node():\n",
        "    \"\"\"Test the risk analysis node\"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Testing risk_analysis_node...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    from agents.third_party_risk_orchestrator.nodes import (\n",
        "        data_loading_node,\n",
        "        risk_analysis_node\n",
        "    )\n",
        "\n",
        "    # First load data\n",
        "    state = {\n",
        "        \"vendor_id\": None,\n",
        "        \"errors\": []\n",
        "    }\n",
        "    state = data_loading_node(state)\n",
        "\n",
        "    assert len(state.get(\"errors\", [])) == 0, f\"Data loading should have no errors, got: {state.get('errors', [])}\"\n",
        "\n",
        "    # Then analyze\n",
        "    result = risk_analysis_node(state)\n",
        "\n",
        "    assert \"errors\" in result, \"Result should have errors field\"\n",
        "    assert len(result.get(\"errors\", [])) == 0, f\"Should have no errors, got: {result.get('errors', [])}\"\n",
        "    assert \"vendor_risk_analysis\" in result, \"Result should have vendor_risk_analysis\"\n",
        "    assert \"risk_drift_detection\" in result, \"Result should have risk_drift_detection\"\n",
        "\n",
        "    vendor_analysis = result[\"vendor_risk_analysis\"]\n",
        "    assert len(vendor_analysis) > 0, \"Should analyze at least one vendor\"\n",
        "\n",
        "    # Check structure of first vendor analysis\n",
        "    first_vendor_id = list(vendor_analysis.keys())[0]\n",
        "    first_analysis = vendor_analysis[first_vendor_id]\n",
        "\n",
        "    assert \"control_compliance\" in first_analysis, \"Should have control_compliance\"\n",
        "    assert \"external_signals\" in first_analysis, \"Should have external_signals\"\n",
        "    assert \"performance_metrics\" in first_analysis, \"Should have performance_metrics\"\n",
        "    assert \"risk_drivers\" in first_analysis, \"Should have risk_drivers\"\n",
        "\n",
        "    print(f\"✅ Node analyzed {len(vendor_analysis)} vendors\")\n",
        "    print(f\"✅ Node detected drift for {len(result['risk_drift_detection'])} vendors\")\n",
        "\n",
        "    # Show example analysis\n",
        "    print(f\"\\nExample analysis for {first_vendor_id}:\")\n",
        "    print(f\"   - Risk drivers: {len(first_analysis['risk_drivers'])}\")\n",
        "    print(f\"   - Control domains analyzed: {len(first_analysis['control_compliance'])}\")\n",
        "    print(f\"   - External signals: {first_analysis['external_signals']['total_signals']}\")\n",
        "    print(f\"   - Performance score: {first_analysis['performance_metrics']['performance_score']:.1f}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run all tests\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"Testing Risk Analysis Utilities\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # Test individual utilities\n",
        "        test_analyze_control_compliance()\n",
        "        test_analyze_external_signals()\n",
        "        test_analyze_performance_metrics()\n",
        "        test_detect_risk_drift()\n",
        "        test_identify_risk_drivers()\n",
        "\n",
        "        # Test node\n",
        "        test_risk_analysis_node()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"✅ ALL TESTS PASSED!\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    except AssertionError as e:\n",
        "        print(f\"\\n❌ TEST FAILED: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ UNEXPECTED ERROR: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test Results"
      ],
      "metadata": {
        "id": "PUcb4U6WKPlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(.venv) micahshull@Micahs-iMac AI_AGENTS_015_Third-Party_Risk_Orchestrator % python test_risk_analysis.py\n",
        "============================================================\n",
        "Testing Risk Analysis Utilities\n",
        "============================================================\n",
        "Testing analyze_control_compliance...\n",
        "✅ Analyzed 4 risk domains for VEND_001\n",
        "   - Information Security: partial (score: 25.0)\n",
        "   - Regulatory Compliance: missing (score: 0.0)\n",
        "   - Operational Resilience: missing (score: 0.0)\n",
        "   - Reputational Risk: missing (score: 0.0)\n",
        "\n",
        "Testing analyze_external_signals...\n",
        "✅ Analyzed signals for VEND_001\n",
        "   - Total signals: 1\n",
        "   - High severity: 1\n",
        "   - Impact score: 20.0\n",
        "\n",
        "Testing analyze_performance_metrics...\n",
        "✅ Analyzed performance for VEND_001\n",
        "   - SLA compliance: 0.89\n",
        "   - Performance score: 59.3\n",
        "   - Issues: 1\n",
        "\n",
        "Testing detect_risk_drift...\n",
        "✅ Detected drift for VEND_001\n",
        "   - Previous score: 78\n",
        "   - Previous date: 2026-01-06\n",
        "   - Trigger: external_signal\n",
        "✅ Correctly returned None for vendor with no history\n",
        "\n",
        "Testing identify_risk_drivers...\n",
        "✅ Identified 14 risk drivers for VEND_001\n",
        "   1. Expired SOC2 in Information Security\n",
        "   2. Missing Encryption in Information Security\n",
        "   3. Missing Access Controls in Information Security\n",
        "   4. Missing GDPR in Regulatory Compliance\n",
        "   5. Missing SOX in Regulatory Compliance\n",
        "\n",
        "============================================================\n",
        "Testing risk_analysis_node...\n",
        "============================================================\n",
        "✅ Node analyzed 10 vendors\n",
        "✅ Node detected drift for 9 vendors\n",
        "\n",
        "Example analysis for VEND_001:\n",
        "   - Risk drivers: 14\n",
        "   - Control domains analyzed: 4\n",
        "   - External signals: 1\n",
        "   - Performance score: 59.3\n",
        "\n",
        "============================================================\n",
        "✅ ALL TESTS PASSED!\n",
        "============================================================\n"
      ],
      "metadata": {
        "id": "P8WuswTiKRCr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
