{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9Wj24ihqZ3hAGkgpG67tc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/119_Error_Handling_Introduction_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13) Assertions vs exceptions\n",
        "\n",
        "* `assert condition, \"message\"` is for **internal invariants** while developing/testing.\n",
        "* Assertions can be disabled with optimizations, so **do not** rely on them for user-facing validation. Use `raise ValueError(...)` instead.\n",
        "\n",
        "\n",
        "This is one of those ‚Äúsubtle but important‚Äù distinctions. let‚Äôs slow it way down and compare **what they are**, **what they mean**, and **when to use each**.\n",
        "\n",
        "---\n",
        "\n",
        "# 1. what they are\n",
        "\n",
        "### **exception**\n",
        "\n",
        "* an **object** python raises to signal an error.\n",
        "* examples: `ValueError`, `TypeError`, `TimeoutError`.\n",
        "* meant for **real error handling** in production.\n",
        "* you (or your caller) can catch it with `try/except`.\n",
        "\n",
        "### **assertion**\n",
        "\n",
        "* a **debugging aid** built into python:\n",
        "\n",
        "  ```python\n",
        "  assert condition, \"message\"\n",
        "  ```\n",
        "* if `condition` is false ‚Üí raises `AssertionError`.\n",
        "* but python can be run with optimizations (`python -O`), and then **all asserts are stripped out**.\n",
        "\n",
        "---\n",
        "\n",
        "# 2. what they *mean*\n",
        "\n",
        "### exceptions\n",
        "\n",
        "> ‚ÄúSomething went wrong with the program‚Äôs **inputs, outputs, or environment**. The caller/user/system needs to know and decide what to do.‚Äù\n",
        "\n",
        "### assertions\n",
        "\n",
        "> ‚ÄúI, the developer, believe this should **always be true inside my code**. If not, it‚Äôs a bug in my program.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "# 3. when to use which\n",
        "\n",
        "### choose an **exception** when:\n",
        "\n",
        "* validating **user input** (e.g., `k must be between 1 and 50`).\n",
        "* checking **external data** (e.g., JSON missing a field).\n",
        "* handling **runtime failures** (timeouts, missing files).\n",
        "* you need the error to **always exist in production**.\n",
        "\n",
        "### choose an **assertion** when:\n",
        "\n",
        "* documenting assumptions about your own code logic.\n",
        "* catching **developer mistakes early**.\n",
        "* testing invariants (‚Äúthis should never happen if the code is correct‚Äù).\n",
        "* safe to remove in optimized runs.\n",
        "\n",
        "---\n",
        "\n",
        "# 4. analogy\n",
        "\n",
        "* **exception** = airport security scanner stopping you: *‚Äúyour passport is invalid ‚Äî you cannot board.‚Äù*\n",
        "* **assertion** = pilot‚Äôs checklist item: *‚Äúflaps should be down at takeoff ‚Äî if not, something is wrong with my plane.‚Äù*\n",
        "\n",
        "exceptions are for **external contracts**, assertions are for **internal sanity checks**.\n",
        "\n",
        "---\n",
        "\n",
        "# 5. example side by side\n",
        "\n",
        "```python\n",
        "# EXCEPTION: input validation\n",
        "def normalize_score(x):\n",
        "    if not isinstance(x, (int, float)):\n",
        "        raise TypeError(\"score must be a number\")    # input contract\n",
        "    if not (0 <= x <= 1):\n",
        "        raise ValueError(\"score must be between 0 and 1\")\n",
        "    return x\n",
        "\n",
        "# ASSERTION: internal invariant\n",
        "def compute_ratio(a, b):\n",
        "    result = a / b\n",
        "    assert 0 <= result <= 1, \"ratio out of expected range\"  # dev sanity\n",
        "    return result\n",
        "```\n",
        "\n",
        "* `normalize_score(\"oops\")` ‚Üí raises a **TypeError** (real validation).\n",
        "* `compute_ratio(10, 2)` ‚Üí would trigger an **AssertionError** only if your math/code is wrong.\n",
        "\n",
        "---\n",
        "\n",
        "# 6. in agent development\n",
        "\n",
        "* **exceptions** = guard rails at **boundaries** (tool inputs/outputs, API payloads). Keeps agent safe.\n",
        "* **assertions** = guard rails in your **own logic** (‚Äúa tool choice must always map to a callable‚Äù). Helps you debug agent code.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **summary**\n",
        "\n",
        "* exceptions = part of the *program‚Äôs contract* with the outside world.\n",
        "* assertions = part of the *developer‚Äôs contract* with themselves.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S9mvnqCqs-nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14) Testing error behavior\n",
        "\n",
        "With `pytest`:\n",
        "\n",
        "```py\n",
        "import pytest\n",
        "\n",
        "def test_normalize_score_bad_type():\n",
        "    with pytest.raises(TypeError):\n",
        "        normalize_score(\"oops\")\n",
        "```\n",
        "\n",
        "This ensures you raise the **right** error with the **right** message.\n",
        "üëå ‚Äî this is where error handling meets **testing**, and it‚Äôs super important for building reliable agents. let‚Äôs break it down.\n",
        "\n",
        "---\n",
        "\n",
        "# what you should learn here\n",
        "\n",
        "## 1. errors are **part of your contract**\n",
        "\n",
        "When you write functions, you‚Äôre not only defining *what they return on success* ‚Äî you‚Äôre also defining *what errors they raise on bad inputs or bad states*.\n",
        "\n",
        "Testing isn‚Äôt just about outputs, it‚Äôs also about making sure the **right errors** are raised for the **right reasons**.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. pytest has tools for testing errors\n",
        "\n",
        "```python\n",
        "import pytest\n",
        "\n",
        "def test_normalize_score_bad_type():\n",
        "    with pytest.raises(TypeError):\n",
        "        normalize_score(\"oops\")\n",
        "```\n",
        "\n",
        "* `with pytest.raises(TypeError):` ‚Üí test will **pass only if** the function raises exactly `TypeError`.\n",
        "* if no error, or wrong error type, the test fails.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. test **messages** too\n",
        "\n",
        "Sometimes the error type is not enough; you also want to check the message for clarity:\n",
        "\n",
        "```python\n",
        "def test_normalize_score_out_of_range():\n",
        "    with pytest.raises(ValueError, match=\"between 0 and 1\"):\n",
        "        normalize_score(42)\n",
        "```\n",
        "\n",
        "Now the test checks both:\n",
        "\n",
        "* correct error type (`ValueError`)\n",
        "* correct error message (must contain ‚Äúbetween 0 and 1‚Äù).\n",
        "\n",
        "---\n",
        "\n",
        "## 4. why this matters for agents\n",
        "\n",
        "* Agents often deal with **unreliable input/output** (LLMs, APIs, users).\n",
        "* Your tools and pipelines should **fail in predictable, testable ways**.\n",
        "* If you change validation logic later, tests will catch regressions (e.g., you forgot to check for empty strings).\n",
        "\n",
        "---\n",
        "\n",
        "## 5. a mini checklist for testing errors\n",
        "\n",
        "* Test **bad types** (e.g., str instead of int).\n",
        "* Test **bad values** (e.g., out of range).\n",
        "* Test **edge cases** (0, empty string, None).\n",
        "* Assert both **type of exception** and **message clarity**.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. quick example (tool boundary)\n",
        "\n",
        "```python\n",
        "def build_search_query(q: str, k: int):\n",
        "    if not isinstance(q, str) or not q.strip():\n",
        "        raise ValueError(\"q must be a non-empty string\")\n",
        "    if not isinstance(k, int) or not (1 <= k <= 50):\n",
        "        raise ValueError(\"k must be an int 1..50\")\n",
        "    return {\"q\": q.strip(), \"k\": k}\n",
        "\n",
        "def test_bad_query_empty():\n",
        "    with pytest.raises(ValueError, match=\"non-empty\"):\n",
        "        build_search_query(\"   \", 10)\n",
        "\n",
        "def test_bad_k_too_high():\n",
        "    with pytest.raises(ValueError, match=\"1..50\"):\n",
        "        build_search_query(\"cats\", 100)\n",
        "```\n",
        "\n",
        "These tests make sure your **tool adapter is safe**: the agent won‚Äôt accidentally build and send garbage requests downstream.\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **summary**\n",
        "\n",
        "* errors are **expected outcomes**, not just accidents.\n",
        "* test them like you test return values.\n",
        "* use `pytest.raises` (and `match=...`) to check both **error type** and **error message**.\n",
        "* for agents: this is your safety net ‚Äî tools break gracefully, not unpredictably.\n"
      ],
      "metadata": {
        "id": "uaAkiE7ctRxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 15) Concurrency & async quick notes\n",
        "\n",
        "* In `asyncio.gather`, set `return_exceptions=True` to collect failures without crashing all tasks:\n",
        "\n",
        "```py\n",
        "results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "for r in results:\n",
        "    if isinstance(r, Exception):\n",
        "        log(r)\n",
        "```\n",
        "\n",
        "* Always add **timeouts** around awaits (`asyncio.wait_for(coro, timeout)`).\n",
        "You‚Äôre now hitting the **concurrency angle** ‚Äî which is super relevant for agents since they often call multiple tools / APIs at once. here‚Äôs what you should be learning from this section:\n",
        "\n",
        "---\n",
        "\n",
        "# 1. async tasks fail independently\n",
        "\n",
        "When you launch multiple async tasks with `asyncio.gather`, the **default** is: if *any* task raises, the whole `gather` call raises and cancels the others.\n",
        "\n",
        "That‚Äôs bad for agents: you don‚Äôt want *one flaky API call* to kill *all* tool calls.\n",
        "\n",
        "### safer pattern:\n",
        "\n",
        "```python\n",
        "results = await asyncio.gather(*tasks, return_exceptions=True)\n",
        "for r in results:\n",
        "    if isinstance(r, Exception):\n",
        "        log(r)       # record failure\n",
        "    else:\n",
        "        use(r)       # process good result\n",
        "```\n",
        "\n",
        "‚Üí every task gets you *either* a value *or* an Exception object you can log/handle.\n",
        "\n",
        "---\n",
        "\n",
        "# 2. timeouts are critical\n",
        "\n",
        "Async code can hang forever (waiting for a slow API or socket). That‚Äôs poison for agents, since they run in loops and can deadlock.\n",
        "\n",
        "### fix:\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "\n",
        "result = await asyncio.wait_for(coro(), timeout=5.0)\n",
        "```\n",
        "\n",
        "* If the coroutine doesn‚Äôt finish in 5 seconds ‚Üí raises `asyncio.TimeoutError`.\n",
        "* Combine with your retry/backoff logic to make agents more resilient.\n",
        "\n",
        "---\n",
        "\n",
        "# 3. what this means for agent development\n",
        "\n",
        "* **Parallelism**: Your agent can call multiple tools / fetch multiple docs at once.\n",
        "* **Resilience**: With `return_exceptions=True`, one broken tool doesn‚Äôt take down the whole batch.\n",
        "* **Bounded latency**: With `asyncio.wait_for`, no step hangs forever ‚Äî every tool has a deadline.\n",
        "* **Integration with your error boundary (#11)**:\n",
        "\n",
        "  * Treat each result as a `StepResult` (`ok/error/retryable`).\n",
        "  * Log failures, retry if transient, fallback otherwise.\n",
        "\n",
        "---\n",
        "\n",
        "# 4. practical checklist\n",
        "\n",
        "* Use `asyncio.gather(..., return_exceptions=True)` any time you fan out multiple tool calls.\n",
        "* Always guard long awaits with `asyncio.wait_for`.\n",
        "* Classify timeouts as **retryable errors** in your boundary.\n",
        "* Log all exceptions before discarding or retrying.\n",
        "* If mixing sync + async tools, wrap sync ones in `loop.run_in_executor` (so they don‚Äôt block).\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **takeaway**\n",
        "\n",
        "* **without `return_exceptions`** ‚Üí one failure = all fail.\n",
        "* **with `return_exceptions=True`** ‚Üí you control error handling per task.\n",
        "* **with timeouts** ‚Üí you control how long the agent will wait.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0d2EJExrt13s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "you‚Äôre spot on üéØ ‚Äî a lot of ‚Äúno-code agent builders‚Äù emphasize *ease of assembly* (drag-and-drop flows, connect tools fast), but they often don‚Äôt expose or encourage the **defensive engineering practices** you‚Äôre learning (error boundaries, retries, validation, timeouts, logging, context).\n",
        "\n",
        "---\n",
        "\n",
        "## what‚Äôs usually missing in no-code systems\n",
        "\n",
        "* **error boundaries** ‚Üí one broken tool call can crash the whole run.\n",
        "* **timeouts** ‚Üí a stuck API call can freeze the entire agent.\n",
        "* **retry/backoff** ‚Üí transient errors (network hiccups, 5xxs) kill tasks instead of being retried.\n",
        "* **input validation** ‚Üí tools happily accept garbage until something fails downstream with a vague error.\n",
        "* **logging with context** ‚Üí you get ‚Äútool failed‚Äù but not *why* or *where*.\n",
        "* **classification (retryable vs fatal)** ‚Üí everything is treated the same, so the agent can‚Äôt make smart recovery choices.\n",
        "\n",
        "The result: flashy demos that work on **happy paths**, but brittle in real-world environments.\n",
        "\n",
        "---\n",
        "\n",
        "## why engineering-level error handling matters\n",
        "\n",
        "Agents are **control loops** sitting on top of unpredictable components:\n",
        "\n",
        "* users (messy input),\n",
        "* LLMs (hallucinate, mis-format),\n",
        "* tools/APIs (timeouts, throttling, schema drift).\n",
        "\n",
        "Without careful error handling, one bad piece propagates chaos. With the patterns you‚Äôre learning:\n",
        "\n",
        "* the agent stays **alive**,\n",
        "* failures become **data** the planner can reason about,\n",
        "* developers get **tracebacks/logs** for debugging.\n",
        "\n",
        "That‚Äôs the difference between a ‚Äútoy demo agent‚Äù and a **production-grade agent**.\n",
        "\n",
        "---\n",
        "\n",
        "## analogy\n",
        "\n",
        "no-code agents are like building with Lego blocks without glue: looks great, but the moment you bump it, pieces fall off. adding the engineering practices you‚Äôre learning is like **reinforcing the structure** so it survives stress in the wild.\n",
        "\n",
        "---\n",
        "\n",
        "## my take\n",
        "\n",
        "* no-code tools are fantastic for **exploration, prototyping, and learning**.\n",
        "* but for **real systems** (where uptime, reliability, and debugging matter), you need the Python-level skills you‚Äôre practicing:\n",
        "\n",
        "  * tight `try/except` boundaries,\n",
        "  * retries with backoff,\n",
        "  * timeouts,\n",
        "  * validation at boundaries,\n",
        "  * structured results (`ok/error`).\n",
        "\n",
        "---\n",
        "\n",
        "‚úÖ **so yes, you‚Äôre exactly right**: most no-code agent builders gloss over this, which makes them fragile. you‚Äôre putting yourself ahead by learning these fundamentals ‚Äî because you‚Äôll be able to take what they generate and **harden it** into something that actually works reliably.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "obfZVmCdu9nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 16) Small, realistic agent step example\n",
        "\n",
        "```py\n",
        "import json, time, logging\n",
        "\n",
        "class ToolHTTPError(NonRetryableToolError): pass\n",
        "class ToolTimeout(RetryableToolError): pass\n",
        "\n",
        "def call_tool_raw():\n",
        "    # imagine this actually calls an API and returns (status, text)\n",
        "    return 200, '{\"answer\": 42}'\n",
        "\n",
        "def call_tool():\n",
        "    t0 = time.time()\n",
        "    try:\n",
        "        status, text = call_tool_raw()\n",
        "        if status >= 500:\n",
        "            raise ToolTimeout(f\"server 5xx: {status}\")\n",
        "        if status >= 400:\n",
        "            raise ToolHTTPError(f\"client 4xx: {status}\")\n",
        "\n",
        "        try:\n",
        "            payload = json.loads(text)\n",
        "        except json.JSONDecodeError as e:\n",
        "            raise NonRetryableToolError(\"bad JSON from tool\") from e\n",
        "\n",
        "        if \"answer\" not in payload:\n",
        "            raise NonRetryableToolError(\"missing 'answer' field\")\n",
        "        return payload[\"answer\"]\n",
        "\n",
        "    except RetryableToolError as e:\n",
        "        logging.warning(\"Retryable tool failure: %s\", e, exc_info=True)\n",
        "        raise\n",
        "    except NonRetryableToolError as e:\n",
        "        logging.error(\"Non-retryable tool failure: %s\", e, exc_info=True)\n",
        "        raise\n",
        "    finally:\n",
        "        logging.info(\"tool call took %.3fs\", time.time() - t0)\n",
        "```\n",
        "\n",
        "Wrap with the `retry` helper from section 9 when you invoke it. This snippet is a mini ‚Äúall-in-one‚Äù of the patterns you‚Äôve been learning. Here‚Äôs what to focus on and why it matters for production-ish agents.\n",
        "\n",
        "# What to notice (and emulate)\n",
        "\n",
        "1. **Separate layers**\n",
        "\n",
        "* `call_tool_raw()` = thin I/O layer (status, raw text).\n",
        "* `call_tool()` = adapter/validator that turns raw stuff into **domain data** (an `int` answer) or raises meaningful exceptions.\n",
        "  ‚Üí Keep these separate so you can test/mockswap each independently.\n",
        "\n",
        "2. **Classify failures early**\n",
        "\n",
        "* `status >= 500` ‚Üí `ToolTimeout` (retryable).\n",
        "* `status >= 400` ‚Üí `ToolHTTPError` (non-retryable).\n",
        "  ‚Üí Turning HTTP categories into ‚Äúretry?‚Äù decisions is the essence of robust agents.\n",
        "\n",
        "3. **Validate outputs (schema)**\n",
        "\n",
        "* Parse JSON; if bad ‚Üí raise with `from e`.\n",
        "* Check required key `\"answer\"` exists.\n",
        "  ‚Üí Never trust tool outputs; make postconditions explicit.\n",
        "\n",
        "4. **Tight try/except scope**\n",
        "\n",
        "* Only the risky region is inside `try`.\n",
        "  ‚Üí Prevents catching unrelated bugs accidentally.\n",
        "\n",
        "5. **Right logging at the right place**\n",
        "\n",
        "* `logging.warning` for retryable, `logging.error` for non-retryable; `exc_info=True` attaches traceback.\n",
        "* `finally` logs latency.\n",
        "  ‚Üí You get observability without leaking internals to the agent/user.\n",
        "\n",
        "6. **Reraise after logging**\n",
        "\n",
        "* Boundary *logs* and *re-raises* domain exceptions; the caller (or your error boundary) decides retry/fallback.\n",
        "  ‚Üí Separation of concerns: this function doesn‚Äôt also implement the retry loop.\n",
        "\n",
        "7. **Small, actionable error messages**\n",
        "\n",
        "* ‚Äúserver 5xx: 503‚Äù, ‚Äúbad JSON from tool‚Äù, ‚Äúmissing 'answer' field‚Äù.\n",
        "  ‚Üí Fast to read; easy to classify and test with `pytest.raises(..., match=...)`.\n",
        "\n",
        "# How to use it (controller side)\n",
        "\n",
        "```python\n",
        "# combine with your backoff logic\n",
        "answer = retry(call_tool, attempts=5, base=0.2,\n",
        "               exceptions=(ToolTimeout,))\n",
        "```\n",
        "\n",
        "* Retry only **ToolTimeout** (transient).\n",
        "* Do **not** retry `ToolHTTPError` (client faults).\n",
        "* Wrap this call in your **error boundary** (StepResult) if you want pass/fail at the planner layer.\n",
        "\n",
        "# Common pitfalls to avoid\n",
        "\n",
        "* Catching `Exception` and returning None (hides bugs).\n",
        "* Skipping schema checks after JSON parse.\n",
        "* Retrying 4xxs (wastes time/money).\n",
        "* Huge `try` blocks (mask real failures).\n",
        "* No latency logging (you won‚Äôt see slow drifts).\n",
        "\n",
        "# Nice upgrades (optional)\n",
        "\n",
        "* Add a tool name to logs: `logging.error(\"[search] ...\")`.\n",
        "* Include `status` and a short `text[:200]` preview in error messages (redacts PII if needed).\n",
        "* Make `call_tool_raw()` actually set timeouts and raise on connection errors so they map to `ToolTimeout`.\n",
        "* Return structured data (e.g., `{\"answer\": int}`) not just a primitive, if you‚Äôll add fields later.\n",
        "\n",
        "# Tiny test sketch\n",
        "\n",
        "```python\n",
        "import pytest, json\n",
        "\n",
        "def test_5xx_retryable(monkeypatch):\n",
        "    def raw(): return 503, \"busy\"\n",
        "    monkeypatch.setattr(__name__, \"call_tool_raw\", raw)\n",
        "    with pytest.raises(ToolTimeout, match=\"5xx\"):\n",
        "        call_tool()\n",
        "\n",
        "def test_bad_json(monkeypatch):\n",
        "    def raw(): return 200, \"not-json\"\n",
        "    monkeypatch.setattr(__name__, \"call_tool_raw\", raw)\n",
        "    with pytest.raises(NonRetryableToolError, match=\"bad JSON\"):\n",
        "        call_tool()\n",
        "\n",
        "def test_ok(monkeypatch):\n",
        "    def raw(): return 200, json.dumps({\"answer\": 7})\n",
        "    monkeypatch.setattr(__name__, \"call_tool_raw\", raw)\n",
        "    assert call_tool() == 7\n",
        "```\n",
        "\n",
        "# Mental model to keep\n",
        "\n",
        "* **Raw I/O ‚Üí classify ‚Üí parse ‚Üí validate ‚Üí return**\n",
        "* Log + time every call; retry only transients; escalate others with clear messages.\n",
        "\n",
        "Master this shape and you can harden almost any tool call an agent makes.\n"
      ],
      "metadata": {
        "id": "FkR0ltxdvF8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 17) A tiny checklist (tape this near your keyboard)\n",
        "\n",
        "* Does my `try` only cover the **risky** lines?\n",
        "* Am I catching the **specific** exception type?\n",
        "* Did I provide a **useful message** or add context (`raise ... from e`)?\n",
        "* Are resources closed (`with ...`)?\n",
        "* For external calls: **timeout**, **retry** (transient only), **max attempts**, **backoff**.\n",
        "* Do I log exceptions with a **traceback** (`logging.exception`)?\n",
        "* At top-level agent steps: return a **structured error** `{ok, error, retryable}`.\n",
        "* **Validate at boundaries (inputs & outputs).** Normalize first (strip/lower), then `TypeError`/`ValueError` for bad inputs; after external calls, **schema-check** the response (required keys/ranges).\n",
        "* **Keep `try` blocks tiny.** Only wrap the line(s) that can fail; avoid hiding unrelated bugs.\n",
        "* **Never use bare `except:` or catch `BaseException`.** Catch concrete types; reserve a final `except Exception as e:` only at top-level boundaries.\n",
        "* **Always chain causes.** `raise Something(\"context\") from e` so you keep the original traceback.\n",
        "* **Prefer `with` over `finally` for resources.** Files, DB connections, HTTP sessions, locks, temp files.\n",
        "* **Structured logging.** Include tool name, request/correlation id, and key params; consider JSON logs; redact secrets/PII.\n",
        "* **Retry etiquette.** Exponential backoff **with jitter**; cap attempts and total time; honor `Retry-After` when present; **never** retry deterministic 4xx/validation errors.\n",
        "* **Deadlines & cancellation.** Wrap awaits/calls with timeouts; propagate cancellations; budget time across a whole step/run.\n",
        "* **Result contract at boundaries.** Convert exceptions to a small `{ok, value|error, retryable, took_s}` object; log full traceback before converting.\n",
        "* **Custom exception hierarchy.** Domain types like `RetryableToolError` vs `NonRetryableToolError` make policy simple.\n",
        "* **Concurrency safety.** For `asyncio.gather`, use `return_exceptions=True`; handle each result; protect critical sections with locks if needed.\n",
        "* **Testing errors.** Use `pytest.raises(..., match=\"...\")` for type + message; parametrize bad cases; include tests for timeouts/retries.\n",
        "* **Feature flags & fallbacks.** Have a ‚Äúplan B‚Äù tool or degraded mode when a step fails non-retryably.\n",
        "* **Metrics & alerts.** Count successes/retries/failures per tool; alert on spikes or rising latency.\n",
        "* **Assertions for invariants only.** Use `assert` for internal sanity (dev) and exceptions for user/input/contracts (prod).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CXG_nIWBrSM1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XsYMcZTErUXO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}