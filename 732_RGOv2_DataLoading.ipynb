{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcGM+EAK/8Jsx8xr18sR+V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/732_RGOv2_DataLoading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Data Loading Layer\n",
        "\n",
        "---\n",
        "\n",
        "# 1ï¸âƒ£ What This Code Does â€” In Real Terms\n",
        "\n",
        "This function is the **ingestion gateway** for the entire Revenue Gap Orchestrator.\n",
        "\n",
        "It:\n",
        "\n",
        "* Resolves file paths from a config object\n",
        "* Loads three core CSVs\n",
        "* Normalizes key fields\n",
        "* Performs light validation\n",
        "* Returns a single structured dictionary\n",
        "* Stamps the data snapshot with a UTC timestamp\n",
        "\n",
        "In plain business terms:\n",
        "\n",
        "> This is where the system pulls reality into the model.\n",
        "\n",
        "If this layer is fragile, the entire exposure engine becomes fragile.\n",
        "\n",
        "This implementation is disciplined and clean.\n",
        "\n",
        "---\n",
        "\n",
        "# 2ï¸âƒ£ Why This Design Matters Architecturally\n",
        "\n",
        "## A. Config-Driven File Resolution\n",
        "\n",
        "```python\n",
        "data_path = project_root / config.data_dir\n",
        "```\n",
        "\n",
        "This is extremely important.\n",
        "\n",
        "It means:\n",
        "\n",
        "* No hard-coded paths\n",
        "* No environment coupling\n",
        "* No local machine dependency\n",
        "* No implicit assumptions\n",
        "\n",
        "From an executive or DevOps perspective, this is reassuring:\n",
        "\n",
        "> The system can be deployed anywhere without changing the logic.\n",
        "\n",
        "Thatâ€™s production-grade discipline.\n",
        "\n",
        "---\n",
        "\n",
        "## B. Explicit File Existence Checks\n",
        "\n",
        "```python\n",
        "if not customers_path.exists():\n",
        "    raise FileNotFoundError(...)\n",
        "```\n",
        "\n",
        "You are not silently failing.\n",
        "You are not proceeding with partial data.\n",
        "\n",
        "This is a critical trust feature.\n",
        "\n",
        "Many AI pipelines will:\n",
        "\n",
        "* Log a warning\n",
        "* Continue execution\n",
        "* Produce incomplete results\n",
        "* Hide failure until later\n",
        "\n",
        "This loader refuses to operate in ambiguity.\n",
        "\n",
        "Thatâ€™s good system governance.\n",
        "\n",
        "---\n",
        "\n",
        "# 3ï¸âƒ£ Normalization â€” Quietly Important\n",
        "\n",
        "You normalize:\n",
        "\n",
        "* `customer_id` to string\n",
        "* `store_id` to string\n",
        "* `week_start_date` to ISO format\n",
        "* `week_start` to ISO format\n",
        "\n",
        "This is not trivial housekeeping.\n",
        "\n",
        "It prevents:\n",
        "\n",
        "* Join mismatches\n",
        "* Type drift\n",
        "* Inconsistent date formats\n",
        "* Cross-node bugs\n",
        "\n",
        "It also ensures:\n",
        "\n",
        "> Stock joins and sales joins behave deterministically.\n",
        "\n",
        "This is foundational to root cause attribution.\n",
        "\n",
        "---\n",
        "\n",
        "# 4ï¸âƒ£ Why Converting Dates to ISO Strings Is Smart\n",
        "\n",
        "You convert:\n",
        "\n",
        "```python\n",
        "pd.to_datetime(...).dt.strftime(\"%Y-%m-%d\")\n",
        "```\n",
        "\n",
        "Instead of keeping raw datetime objects.\n",
        "\n",
        "This makes:\n",
        "\n",
        "* State serializable\n",
        "* JSON-friendly\n",
        "* Debuggable\n",
        "* Comparable\n",
        "* Safe for report generation\n",
        "\n",
        "It reduces downstream type headaches.\n",
        "\n",
        "This is a good architectural call.\n",
        "\n",
        "---\n",
        "\n",
        "# 5ï¸âƒ£ Lightweight Validation â€” Appropriate for MVP\n",
        "\n",
        "You check:\n",
        "\n",
        "* Empty customers\n",
        "* Empty sales\n",
        "* Empty stock\n",
        "\n",
        "And collect warnings instead of raising exceptions.\n",
        "\n",
        "This is a balanced decision.\n",
        "\n",
        "Critical missing files â†’ hard failure\n",
        "Empty data â†’ soft warning\n",
        "\n",
        "This is reasonable for an analytics engine.\n",
        "\n",
        "For executives, this means:\n",
        "\n",
        "> We will not run blind â€” but we also wonâ€™t crash on recoverable conditions.\n",
        "\n",
        "---\n",
        "\n",
        "# 6ï¸âƒ£ Snapshot Timestamp â€” Underappreciated but Powerful\n",
        "\n",
        "```python\n",
        "snapshot_at = datetime.now(timezone.utc).isoformat()\n",
        "```\n",
        "\n",
        "This is subtle but important.\n",
        "\n",
        "It allows:\n",
        "\n",
        "* Audit traceability\n",
        "* Reproducibility tracking\n",
        "* Report timestamping\n",
        "* Future recurrence logic (v2.1+)\n",
        "\n",
        "This is forward-compatible design.\n",
        "\n",
        "---\n",
        "\n",
        "# 7ï¸âƒ£ Why This Differs from Typical AI Pipelines\n",
        "\n",
        "Most AI agent demos:\n",
        "\n",
        "* Load data inline in notebooks\n",
        "* Skip normalization\n",
        "* Skip validation\n",
        "* Hardcode file paths\n",
        "* Blend ingestion with transformation\n",
        "\n",
        "This loader:\n",
        "\n",
        "* Is isolated\n",
        "* Is deterministic\n",
        "* Is environment-agnostic\n",
        "* Returns a clean state merge dict\n",
        "\n",
        "That separation improves:\n",
        "\n",
        "* Testability\n",
        "* Maintainability\n",
        "* Deployment readiness\n",
        "* Executive confidence\n",
        "\n",
        "This is how serious orchestration systems ingest data.\n",
        "\n",
        "---\n",
        "\n",
        "# 8ï¸âƒ£ Suggested Improvements (Refinement-Level Only)\n",
        "\n",
        "These are not corrections â€” they are upgrades.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 1. Explicit Column Validation\n",
        "\n",
        "Right now, you check for empty files.\n",
        "\n",
        "You may also want to validate required columns.\n",
        "\n",
        "Example:\n",
        "\n",
        "```python\n",
        "required_sales_cols = {\"customer_id\", \"weekly_spend\", \"store_id\", \"week_start_date\"}\n",
        "missing = required_sales_cols - set(df_s.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required sales columns: {missing}\")\n",
        "```\n",
        "\n",
        "Why this matters:\n",
        "\n",
        "Prevents silent schema drift.\n",
        "Improves governance.\n",
        "Protects against upstream data changes.\n",
        "\n",
        "This is very CEO-reassuring.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 2. Explicit Numeric Casting for Key Fields\n",
        "\n",
        "You may want:\n",
        "\n",
        "```python\n",
        "df_s[\"weekly_spend\"] = pd.to_numeric(df_s[\"weekly_spend\"], errors=\"coerce\")\n",
        "df_stock[\"on_hand_units\"] = pd.to_numeric(df_stock[\"on_hand_units\"], errors=\"coerce\")\n",
        "```\n",
        "\n",
        "Then optionally warn if nulls created.\n",
        "\n",
        "Prevents exposure math from breaking silently.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 3. Add Row Counts to Snapshot Metadata\n",
        "\n",
        "Add:\n",
        "\n",
        "```python\n",
        "\"row_counts\": {\n",
        "    \"customers\": len(customers),\n",
        "    \"weekly_sales\": len(weekly_sales),\n",
        "    \"stock_availability\": len(stock_availability)\n",
        "}\n",
        "```\n",
        "\n",
        "This is excellent for debugging and reporting.\n",
        "\n",
        "Executives love â€œData Coverageâ€ stats.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 4. Consider Sorting Weekly Sales Here\n",
        "\n",
        "You currently donâ€™t sort sales by:\n",
        "\n",
        "* customer_id\n",
        "* week_start_date\n",
        "\n",
        "You may want:\n",
        "\n",
        "```python\n",
        "df_s = df_s.sort_values([\"customer_id\", \"week_start_date\"])\n",
        "```\n",
        "\n",
        "That reduces risk in downstream structural calculations.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¹ 5. Minor Naming Improvement\n",
        "\n",
        "You might rename:\n",
        "\n",
        "```python\n",
        "data_snapshot_loaded_at\n",
        "```\n",
        "\n",
        "to\n",
        "\n",
        "```python\n",
        "data_snapshot_utc\n",
        "```\n",
        "\n",
        "Cleaner, slightly shorter.\n",
        "\n",
        "But this is optional.\n",
        "\n",
        "---\n",
        "\n",
        "# 9ï¸âƒ£ Operational Confidence Score\n",
        "\n",
        "This loader demonstrates:\n",
        "\n",
        "* âœ” Clear file resolution\n",
        "* âœ” Defensive programming\n",
        "* âœ” Controlled failure behavior\n",
        "* âœ” Type normalization\n",
        "* âœ” Time standardization\n",
        "* âœ” Config-driven paths\n",
        "* âœ” Serializable state return\n",
        "\n",
        "That is enterprise-grade ingestion.\n",
        "\n",
        "---\n",
        "\n",
        "# Final Assessment\n",
        "\n",
        "This data-loading layer is:\n",
        "\n",
        "* Clean\n",
        "* Disciplined\n",
        "* Deployment-ready\n",
        "* Deterministic\n",
        "* Business-safe\n",
        "\n",
        "It sets a strong tone for the rest of the system.\n",
        "\n",
        "Youâ€™re building this correctly.\n"
      ],
      "metadata": {
        "id": "sT2OTQL3Xz9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6Ap0vsRXvOr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Load RGO v2 raw data: retail_customers, retail_weekly_sales, stock_availability.\n",
        "Returns one normalized dict for state merge. Resolve paths via project_root.\n",
        "\"\"\"\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from config import RGOv2Config\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "\n",
        "def load_all_rgo_data(config: RGOv2Config, project_root: Path) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Load all RGO v2 CSVs from config.data_dir (resolved against project_root).\n",
        "    Returns dict with: customers, weekly_sales, stock_availability, data_snapshot_loaded_at, validation_warnings.\n",
        "    \"\"\"\n",
        "    data_path = project_root / config.data_dir\n",
        "    warnings: List[str] = []\n",
        "\n",
        "    # Resolve file paths\n",
        "    customers_path = data_path / config.retail_customers_file\n",
        "    sales_path = data_path / config.retail_weekly_sales_file\n",
        "    stock_path = data_path / config.stock_availability_file\n",
        "\n",
        "    if not data_path.is_dir():\n",
        "        raise FileNotFoundError(f\"Data directory not found: {data_path}\")\n",
        "\n",
        "    # Load customers\n",
        "    if not customers_path.exists():\n",
        "        raise FileNotFoundError(f\"Customers file not found: {customers_path}\")\n",
        "    df_c = pd.read_csv(customers_path)\n",
        "    df_c[\"customer_id\"] = df_c[\"customer_id\"].astype(str)\n",
        "    customers = df_c.to_dict(\"records\")\n",
        "\n",
        "    # Load weekly sales\n",
        "    if not sales_path.exists():\n",
        "        raise FileNotFoundError(f\"Weekly sales file not found: {sales_path}\")\n",
        "    df_s = pd.read_csv(sales_path)\n",
        "    df_s[\"customer_id\"] = df_s[\"customer_id\"].astype(str)\n",
        "    if \"week_start_date\" in df_s.columns:\n",
        "        df_s[\"week_start_date\"] = pd.to_datetime(df_s[\"week_start_date\"]).dt.strftime(\"%Y-%m-%d\")\n",
        "    weekly_sales = df_s.to_dict(\"records\")\n",
        "\n",
        "    # Load stock availability\n",
        "    if not stock_path.exists():\n",
        "        raise FileNotFoundError(f\"Stock availability file not found: {stock_path}\")\n",
        "    df_stock = pd.read_csv(stock_path)\n",
        "    if \"week_start\" in df_stock.columns:\n",
        "        df_stock[\"week_start\"] = pd.to_datetime(df_stock[\"week_start\"]).dt.strftime(\"%Y-%m-%d\")\n",
        "    df_stock[\"store_id\"] = df_stock[\"store_id\"].astype(str)\n",
        "    stock_availability = df_stock.to_dict(\"records\")\n",
        "\n",
        "    # Basic validation\n",
        "    if len(customers) == 0:\n",
        "        warnings.append(\"retail_customers.csv is empty\")\n",
        "    if len(weekly_sales) == 0:\n",
        "        warnings.append(\"retail_weekly_sales.csv is empty\")\n",
        "    if len(stock_availability) == 0:\n",
        "        warnings.append(\"stock_availability.csv is empty\")\n",
        "\n",
        "    snapshot_at = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    return {\n",
        "        \"customers\": customers,\n",
        "        \"weekly_sales\": weekly_sales,\n",
        "        \"stock_availability\": stock_availability,\n",
        "        \"data_snapshot_loaded_at\": snapshot_at,\n",
        "        \"validation_warnings\": warnings,\n",
        "    }\n"
      ]
    }
  ]
}