{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODstwZ29gxkIaJxQ5Nyk/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/004_Agents_CustomerServiceTriage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **Customer Service Triage Agent** üéß  \n",
        "**Goal**: Build an agent that handles user support messages and routes them to the right department or tool (e.g., sales, refunds, tech).\n",
        "\n",
        "#### üîß Tools:\n",
        "- `route_to_sales()`\n",
        "- `initiate_refund()`\n",
        "- `log_support_ticket()`\n",
        "\n",
        "#### üß† New Concepts:\n",
        "- Tool delegation via natural language\n",
        "- Simulating a decision tree with an agent\n",
        "- Polite rejections and fallback handoffs\n",
        "\n",
        "---\n",
        "\n",
        "## üß† What Your Triage Agent Is Doing (Conceptually)\n",
        "\n",
        "### üéØ Goal:\n",
        "Interpret incoming user messages and **route them to the correct team or action**, based on the **intent** behind the message.\n",
        "\n",
        "This is a classic use case for AI agents: when messages are unpredictable, unstructured, and varied ‚Äî but decisions must be made consistently.\n",
        "\n",
        "---\n",
        "\n",
        "## üîÅ The Agent Loop (Step-by-Step)\n",
        "\n",
        "### 1. **Receives Input from a User**\n",
        "```python\n",
        "\"Can I get a refund on my last order?\"\n",
        "```\n",
        "\n",
        "### 2. **Uses an LLM to Decide What Kind of Message It Is**\n",
        "You provide the model with:\n",
        "- A list of possible **tool choices**\n",
        "- A very clear **instructional prompt**\n",
        "- **Few-shot examples** that show how to match message ‚Üí tool\n",
        "\n",
        "üß† So the model is acting as a **classifier**, but it‚Äôs doing it through **language understanding** rather than rules or keyword matching.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Selects the Right Tool (Action)**\n",
        "From your tool list:\n",
        "```python\n",
        "tools = {\n",
        "    \"route_to_sales\": ...,\n",
        "    \"initiate_refund\": ...,\n",
        "    \"log_tech_support\": ...,\n",
        "    \"log_unrecognized\": ...\n",
        "}\n",
        "```\n",
        "\n",
        "The agent maps each user input to one of these tools.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Executes the Tool**\n",
        "The tool receives the user‚Äôs original message and returns a response:\n",
        "\n",
        "```python\n",
        "tools[\"initiate_refund\"](\"Can I get a refund?\")\n",
        "‚Üí \"üí∏ Refund process started: 'Can I get a refund?'\"\n",
        "```\n",
        "\n",
        "Each tool simulates what would happen in a real business system:\n",
        "- Routing the ticket\n",
        "- Triggering automation\n",
        "- Saving to a queue\n",
        "- Escalating an issue\n",
        "\n"
      ],
      "metadata": {
        "id": "HRGLm6isBOld"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POaXsQMSBEBY"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß∞ Step 1: Setup & Tool Functions"
      ],
      "metadata": {
        "id": "kBn6yzWzB0UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers --quiet\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load instruction-following model\n",
        "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "# --- Tools ---\n",
        "def route_to_sales(message):\n",
        "    return f\"‚úÖ Routed to Sales: '{message}'\"\n",
        "\n",
        "def initiate_refund(message):\n",
        "    return f\"üí∏ Refund process started: '{message}'\"\n",
        "\n",
        "def log_tech_support(message):\n",
        "    return f\"üõ†Ô∏è Logged for Technical Support: '{message}'\"\n",
        "\n",
        "def log_unrecognized(message):\n",
        "    return f\"ü§ñ Could not categorize the message: '{message}'\"\n",
        "\n",
        "# Tool registry\n",
        "tools = {\n",
        "    \"route_to_sales\": route_to_sales,\n",
        "    \"initiate_refund\": initiate_refund,\n",
        "    \"log_tech_support\": log_tech_support,\n",
        "    \"log_unrecognized\": log_unrecognized\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452,
          "referenced_widgets": [
            "a2f96ceba38142938a26a5c32d693efe",
            "7cca698b5a8b4bbaaaf4c46c6e1a67bb",
            "55051665a1414078a51e4b8a137ca65d",
            "dc748ecdc1b9429eb765588c43bee7cf",
            "b91e77e2e1c74173b3f693a9120db018",
            "2581a8ba9f8e4fb6a6dcc7579691127f",
            "a6c06d1222654a929b569c1267c4f7d7",
            "d777b7f628254adf8ed57c1d26d52bc3",
            "e1ff6e3bd8554aed9ca56166f4d12324",
            "bd442425b3b44cdbb6f7ad59f441fd65",
            "228ecd2afa464614a2a0e885c5e17925",
            "ea5b0a08dfdf4a169c3b2d5edb3f5ed5",
            "dbe41669bed54acfa1e51f9b68a4889f",
            "1eb423cae2ed49e49e48b4649861f144",
            "fc118ea442634aca9e1ad6afd9827bcc",
            "9bd53f3c655d456eabad8abc67a4e5a9",
            "70b5cfdadc974159b1c779447adb3368",
            "97b80d3726354ee3938e30f51af35e82",
            "3b8525cf504b4fbdaa1ca4c309bef9a1",
            "4ec0eb5d917646fdacf702c148c47f67",
            "4805b99064f040f587b9dc2b06900326",
            "e65f9368ae7e43278441fb13980a8710",
            "2b11d842b3484c0fb5f44fe2e2ab95eb",
            "40c05e11a83b48b9869fb47dc0c5fe99",
            "3d268a879e0b48ada1ed89a2b3dd4f92",
            "292b5f1da0b847c8a3340024e1ef1525",
            "64bb28fee34340538e24ec2ede203c46",
            "a971b0011393465d9af783149abc4171",
            "a546b1924d7d43b99db59fb05ee66923",
            "f8c6273758d14c31925ae4ae92dc9f8f",
            "4be1b09ca60749c9bb693170f1010298",
            "7f6a03d50849454fb645e921e11a3785",
            "e4509d50d8e34abab91bda33a2d9d841",
            "fb449a85c5be4ec1ac0057e00228de3d",
            "94d5afd646ef45d4bf91167d90260d27",
            "0ba1dd9f12004bbca8b866434334d335",
            "56c2d78f3369480fbac0e9402f43d051",
            "6a7b8f921da441828537c278128152ba",
            "e6b9968ade94460189c2a452cc5450c9",
            "c7d5121ffa8b4111ac547daddb9251c5",
            "6d502a5231c44dd5ac34d66748640871",
            "34e390ff003048d9b035b62d3db48fa4",
            "a8cfa29cd4f94dd3b49e912b62342d52",
            "183a4c670803494f8314d011ba72db45",
            "05440154c8934787ac792984e21e2801",
            "b4068f15f86f4c4591ae318206516c25",
            "72bb10b8a9cb4ef48cb05a4b8a2074fa",
            "7fd9cdbc8062455784b8dec62b2026ce",
            "78d1fcb383bb45c188c718c1af73d086",
            "b6f07dae1f3f41139e55678ff43b0ac4",
            "02eaee59a37f442b8fb26b9aa009cba3",
            "d8d670a8b8f74c009ca821e839867a7c",
            "3440c096e0334a8bb9837c8c882b9c60",
            "474cdf562a534a44b96b3719898a0cfb",
            "8a5823912cbb4e7d9f8374b5f17ca207",
            "f9b511e760694a1989c9d1f1b2de267a",
            "173864ffa2004673ab3a802a24344a19",
            "ba7dfe1896f046ceb4e21d08ba1155ac",
            "50c956c9cb3c4103a5e23fb2e026f5f6",
            "7d6f728d69354515a605b2f55b8b2c1e",
            "f8e30f3e450c465887542b667c6d81be",
            "5811cb9e9ddb48a4910567250d3ba61f",
            "2a5f9bcceec54d83afa4f51d1da7e6dc",
            "0dbccf8f30284c5c920507008a594128",
            "a5d6f6ce31b64dffb8cbbd09e0c9008e",
            "3daf171183784003803b1c11bc8f3b12",
            "fc29b98c207748d2823b7dee30e04f53",
            "abdc7aa3098c4f0181a369c885d7204c",
            "e6f5bd6ca6534652807abfca26fd9754",
            "fef917993e264ddc9432640933f79d65",
            "eac304670c124a5b83cf67b42acc1e5f",
            "c0dde138e6b04afc9f515c52357ede0f",
            "574dcf53bdec486382f1e5e8d281370a",
            "32a08431b51f43a0b1d7eec332500627",
            "b0b7cce94b5744db8b5912cb97e473e3",
            "1dac9db892144017afafe1e44d8184d6",
            "90b8ed289af9444dadd887d60ae2ea97"
          ]
        },
        "id": "4LOETsj8BUum",
        "outputId": "55481a3e-3468-40c7-d2eb-80be4612222f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2f96ceba38142938a26a5c32d693efe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea5b0a08dfdf4a169c3b2d5edb3f5ed5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b11d842b3484c0fb5f44fe2e2ab95eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb449a85c5be4ec1ac0057e00228de3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05440154c8934787ac792984e21e2801"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9b511e760694a1989c9d1f1b2de267a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc29b98c207748d2823b7dee30e04f53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Step 2: Build the Triage Agent Loop\n",
        "\n",
        "This is where the LLM will:\n",
        "1. Read a customer message\n",
        "2. Choose the correct department (via tool name)\n",
        "3. Call the tool\n",
        "4. Return the routed response\n",
        "\n"
      ],
      "metadata": {
        "id": "0CtE_gpDB3ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def triage_agent(user_input):\n",
        "    # Prompt the model to classify the request\n",
        "    prompt = f\"\"\"\n",
        "You are a customer service triage agent. Your job is to route each message to the appropriate department by choosing one of these tools:\n",
        "\n",
        "- route_to_sales ‚Üí For questions about product pricing, availability, quotes, or upgrades.\n",
        "- initiate_refund ‚Üí For refund requests, cancellations, or billing issues.\n",
        "- log_tech_support ‚Üí For technical problems, broken features, or login issues.\n",
        "- log_unrecognized ‚Üí If the message doesn't fit any category.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- Respond with ONLY the tool name (e.g., route_to_sales).\n",
        "- Do NOT write full sentences.\n",
        "- If uncertain, default to: log_unrecognized.\n",
        "\n",
        "Examples:\n",
        "- \"I'd like a refund for my last order\" ‚Üí initiate_refund\n",
        "- \"Do you have bulk pricing for schools?\" ‚Üí route_to_sales\n",
        "- \"The login page won't load on my phone\" ‚Üí log_tech_support\n",
        "- \"What‚Äôs your favorite movie?\" ‚Üí log_unrecognized\n",
        "\n",
        "Now classify this message:\n",
        "\"{user_input}\"\n",
        "Response:\n",
        "\"\"\"\n",
        "\n",
        "    model_output = llm(prompt, max_new_tokens=20)[0][\"generated_text\"].strip().lower()\n",
        "\n",
        "    matched_tool = next((name for name in tools if name in model_output), None)\n",
        "    if not matched_tool:\n",
        "        matched_tool = \"log_unrecognized\"\n",
        "\n",
        "    return tools[matched_tool](user_input)\n"
      ],
      "metadata": {
        "id": "c_fnwfH_BUrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß™ Step 3: Test Cases"
      ],
      "metadata": {
        "id": "za7zN7h4B94P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(triage_agent(\"Can I get a refund on my last order?\"))\n",
        "print(triage_agent(\"Do you have a discount for small businesses?\"))\n",
        "print(triage_agent(\"My dashboard is just showing a white screen.\"))\n",
        "print(triage_agent(\"What's your favorite snack?\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HtpZeSnBUpZ",
        "outputId": "f8734f3f-75b6-4077-f9dd-97f49a2f1aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí∏ Refund process started: 'Can I get a refund on my last order?'\n",
            "‚úÖ Routed to Sales: 'Do you have a discount for small businesses?'\n",
            "üõ†Ô∏è Logged for Technical Support: 'My dashboard is just showing a white screen.'\n",
            "üõ†Ô∏è Logged for Technical Support: 'What's your favorite snack?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### üí° Breakdown of Your Test Results\n",
        "\n",
        "### ‚úÖ Refund request correctly routed\n",
        "```\n",
        "üí∏ Refund process started: 'Can I get a refund on my last order?'\n",
        "```\n",
        "Perfect match ‚Äî LLM understood the refund context and selected the right path.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Sales inquiry correctly routed\n",
        "```\n",
        "‚úÖ Routed to Sales: 'Do you have a discount for small businesses?'\n",
        "```\n",
        "Model recognized intent to discuss pricing/partnerships ‚Äî a job for Sales.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Technical issue correctly routed\n",
        "```\n",
        "üõ†Ô∏è Logged for Technical Support: 'My dashboard is just showing a white screen.'\n",
        "```\n",
        "‚úÖ LLM understands ‚Äúwhite screen‚Äù as a technical error. Excellent.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Model misrouted a personal question\n",
        "```\n",
        "üõ†Ô∏è Logged for Technical Support: 'What's your favorite snack?'\n",
        "```\n",
        "This should have triggered:\n",
        "```\n",
        "ü§ñ Could not categorize the message...\n",
        "```\n",
        "\n",
        "But instead, the model guessed **log_tech_support** ‚Äî likely because:\n",
        "- It had no good match and defaulted to the first ‚Äúlogical-sounding‚Äù tool.\n",
        "- The model didn‚Äôt return `log_unrecognized` because the prompt needs more examples or stronger emphasis.\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Want to Improve It?\n",
        "\n",
        "To make it more accurate:\n",
        "- Add more off-topic examples in the prompt\n",
        "- Reinforce the fallback option more strongly: *‚ÄúIf not sure, ALWAYS say log_unrecognized‚Äù*\n"
      ],
      "metadata": {
        "id": "QEoROHL3CwKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## ü§ñ What Are Multi-Agent Handoffs?\n",
        "\n",
        "It means one agent can **pass control** to another agent (or specialist) depending on the task.\n",
        "\n",
        "For example:\n",
        "- Your **triage agent** identifies a refund request\n",
        "- Instead of handling it directly, it **hands off** the task to a **refund agent**\n",
        "- The refund agent does the specialized work (e.g., validating the request, issuing a refund)\n",
        "\n",
        "---\n",
        "\n",
        "## üß† Why It Matters\n",
        "\n",
        "| Traditional Agent | Multi-Agent System |\n",
        "|-------------------|--------------------|\n",
        "| Single LLM handles everything | Tasks are **delegated** to the best-suited agent |\n",
        "| Monolithic, harder to scale | Modular and **composable** |\n",
        "| Flat logic | Can represent **real business workflows** |\n",
        "\n",
        "---\n",
        "\n",
        "## üõ†Ô∏è Step 1: Define Specialized Sub-Agents\n",
        "\n",
        "Let‚Äôs add 3 lightweight agents to your notebook:\n",
        "\n",
        "```python\n",
        "# Specialized refund agent\n",
        "def refund_agent(user_input):\n",
        "    return f\"üí∏ Refund Agent: Processing refund request ‚Äî '{user_input}'\"\n",
        "\n",
        "# Specialized sales agent\n",
        "def sales_agent(user_input):\n",
        "    return f\"üì¶ Sales Agent: Preparing quote or offer ‚Äî '{user_input}'\"\n",
        "\n",
        "# Specialized tech support agent\n",
        "def tech_agent(user_input):\n",
        "    return f\"üõ†Ô∏è Tech Support Agent: Logging issue and starting diagnosis ‚Äî '{user_input}'\"\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Step 2: Update Your Routing Tools to Handoff\n",
        "\n",
        "Now replace the tools in your original tool registry with these **handoffs**:\n",
        "\n",
        "```python\n",
        "tools = {\n",
        "    \"route_to_sales\": sales_agent,\n",
        "    \"initiate_refund\": refund_agent,\n",
        "    \"log_tech_support\": tech_agent,\n",
        "    \"log_unrecognized\": lambda msg: f\"ü§ñ General Agent: I couldn‚Äôt route this request ‚Äî '{msg}'\"\n",
        "}\n",
        "```\n",
        "\n",
        "## ‚úÖ What You‚Äôve Built\n",
        "\n",
        "| Component | What It Does |\n",
        "|----------|---------------|\n",
        "| **Triage agent** | Classifies the request and routes it |\n",
        "| **Sub-agents** | Handle specialized workflows |\n",
        "| **Agent handoff** | Simulates real customer support teams with specialized LLM agents |\n",
        "| **Composability** | You can now scale your system just by adding new agents |\n",
        "\n"
      ],
      "metadata": {
        "id": "hTwMwCBGDlu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load instruction-following model\n",
        "llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "# --- Tools ---\n",
        "def route_to_sales(message):\n",
        "    return f\"‚úÖ Routed to Sales: '{message}'\"\n",
        "\n",
        "def initiate_refund(message):\n",
        "    return f\"üí∏ Refund process started: '{message}'\"\n",
        "\n",
        "def log_tech_support(message):\n",
        "    return f\"üõ†Ô∏è Logged for Technical Support: '{message}'\"\n",
        "\n",
        "def log_unrecognized(message):\n",
        "    return f\"ü§ñ Could not categorize the message: '{message}'\"\n",
        "\n",
        "# Specialized refund agent\n",
        "def refund_agent(user_input):\n",
        "    return f\"üí∏ Refund Agent: Processing refund request ‚Äî '{user_input}'\"\n",
        "\n",
        "# Specialized sales agent\n",
        "def sales_agent(user_input):\n",
        "    return f\"üì¶ Sales Agent: Preparing quote or offer ‚Äî '{user_input}'\"\n",
        "\n",
        "# Specialized tech support agent\n",
        "def tech_agent(user_input):\n",
        "    return f\"üõ†Ô∏è Tech Support Agent: Logging issue and starting diagnosis ‚Äî '{user_input}'\"\n",
        "\n",
        "tools = {\n",
        "    \"route_to_sales\": sales_agent,\n",
        "    \"initiate_refund\": refund_agent,\n",
        "    \"log_tech_support\": tech_agent,\n",
        "    \"log_unrecognized\": lambda msg: f\"ü§ñ General Agent: I couldn‚Äôt route this request ‚Äî '{msg}'\"\n",
        "}\n",
        "\n",
        "def triage_agent(user_input):\n",
        "    # Prompt the model to classify the request\n",
        "    prompt = f\"\"\"\n",
        "You are a customer service triage agent. Your job is to route each message to the appropriate department by choosing one of these tools:\n",
        "\n",
        "- route_to_sales ‚Üí For questions about product pricing, availability, quotes, or upgrades.\n",
        "- initiate_refund ‚Üí For refund requests, cancellations, or billing issues.\n",
        "- log_tech_support ‚Üí For technical problems, broken features, or login issues.\n",
        "- log_unrecognized ‚Üí If the message doesn't fit any category.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- Respond with ONLY the tool name (e.g., route_to_sales).\n",
        "- Do NOT write full sentences.\n",
        "- If uncertain, default to: log_unrecognized.\n",
        "\n",
        "Examples:\n",
        "- \"I'd like a refund for my last order\" ‚Üí initiate_refund\n",
        "- \"Do you have bulk pricing for schools?\" ‚Üí route_to_sales\n",
        "- \"The login page won't load on my phone\" ‚Üí log_tech_support\n",
        "- \"What‚Äôs your favorite movie?\" ‚Üí log_unrecognized\n",
        "\n",
        "Now classify this message:\n",
        "\"{user_input}\"\n",
        "Response:\n",
        "\"\"\"\n",
        "\n",
        "    model_output = llm(prompt, max_new_tokens=20)[0][\"generated_text\"].strip().lower()\n",
        "\n",
        "    matched_tool = next((name for name in tools if name in model_output), None)\n",
        "    if not matched_tool:\n",
        "        matched_tool = \"log_unrecognized\"\n",
        "\n",
        "    return tools[matched_tool](user_input)\n",
        "\n",
        "print(triage_agent(\"Can I get a refund for my last order?\"))\n",
        "print(triage_agent(\"Do you offer a bundle discount?\"))\n",
        "print(triage_agent(\"My reports page is crashing.\"))\n",
        "print(triage_agent(\"What's your favorite Marvel movie?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH4_0WU_DliU",
        "outputId": "07b93e4d-764b-43cf-f824-fe994282c6c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí∏ Refund Agent: Processing refund request ‚Äî 'Can I get a refund for my last order?'\n",
            "üì¶ Sales Agent: Preparing quote or offer ‚Äî 'Do you offer a bundle discount?'\n",
            "üõ†Ô∏è Tech Support Agent: Logging issue and starting diagnosis ‚Äî 'My reports page is crashing.'\n",
            "üõ†Ô∏è Tech Support Agent: Logging issue and starting diagnosis ‚Äî 'What's your favorite Marvel movie?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load instruction-following model\n",
        "# llm = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "# --- Tools ---\n",
        "def route_to_sales(message):\n",
        "    return f\"‚úÖ Routed to Sales: '{message}'\"\n",
        "\n",
        "def initiate_refund(message):\n",
        "    return f\"üí∏ Refund process started: '{message}'\"\n",
        "\n",
        "def log_tech_support(message):\n",
        "    return f\"üõ†Ô∏è Logged for Technical Support: '{message}'\"\n",
        "\n",
        "def log_unrecognized(message):\n",
        "    return f\"ü§ñ Could not categorize the message: '{message}'\"\n",
        "\n",
        "# Specialized refund agent\n",
        "def refund_agent(user_input):\n",
        "    return f\"üí∏ Refund Agent: Processing refund request ‚Äî '{user_input}'\"\n",
        "\n",
        "# Specialized sales agent\n",
        "def sales_agent(user_input):\n",
        "    return f\"üì¶ Sales Agent: Preparing quote or offer ‚Äî '{user_input}'\"\n",
        "\n",
        "# Specialized tech support agent\n",
        "def tech_agent(user_input):\n",
        "    return f\"üõ†Ô∏è Tech Support Agent: Logging issue and starting diagnosis ‚Äî '{user_input}'\"\n",
        "\n",
        "tools = {\n",
        "    \"route_to_sales\": sales_agent,\n",
        "    \"initiate_refund\": refund_agent,\n",
        "    \"log_tech_support\": tech_agent,\n",
        "    \"log_unrecognized\": lambda msg: f\"ü§ñ General Agent: I couldn‚Äôt route this request ‚Äî '{msg}'\",\n",
        "    \"logunrecognized\": lambda msg: f\"ü§ñ (alternate case caught) ‚Äî '{msg}'\"  # just in case\n",
        "}\n",
        "\n",
        "\n",
        "def triage_agent(user_input):\n",
        "    # Prompt the model to classify the request\n",
        "    prompt = f\"\"\"\n",
        "You are a customer service triage agent. Your job is to route each message to the correct department by selecting one of the following tools:\n",
        "\n",
        "- route_to_sales ‚Üí Pricing, discounts, upgrades\n",
        "- initiate_refund ‚Üí Refunds, billing, cancellations\n",
        "- log_tech_support ‚Üí Bugs, app issues, access problems\n",
        "- LOG_UNRECOGNIZED ‚Üí Anything that doesn't belong in the above categories\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- Return ONLY one of these tool names\n",
        "- If unsure, always return LOG_UNRECOGNIZED\n",
        "\n",
        "Examples:\n",
        "- \"I'd like a refund for my last order\" ‚Üí initiate_refund\n",
        "- \"Do you have bulk pricing for schools?\" ‚Üí route_to_sales\n",
        "- \"The login page won't load on my phone\" ‚Üí log_tech_support\n",
        "- \"What‚Äôs your favorite Marvel movie?\" ‚Üí LOG_UNRECOGNIZED\n",
        "- \"How‚Äôs your day going?\" ‚Üí LOG_UNRECOGNIZED\n",
        "- \"Tell me a joke\" ‚Üí LOG_UNRECOGNIZED\n",
        "\n",
        "Now classify this message:\n",
        "\"{user_input}\"\n",
        "Response:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "    model_output = llm(prompt, max_new_tokens=20)[0][\"generated_text\"].strip().lower()\n",
        "\n",
        "    matched_tool = next((name for name in tools if name in model_output.replace(\"_\", \"\").lower()), None)\n",
        "    if not matched_tool:\n",
        "        matched_tool = \"log_unrecognized\"\n",
        "\n",
        "\n",
        "    return tools[matched_tool](user_input)\n",
        "\n",
        "print(triage_agent(\"Can I get a refund for my last order?\"))\n",
        "print(triage_agent(\"Do you offer a bundle discount?\"))\n",
        "print(triage_agent(\"My reports page is crashing.\"))\n",
        "print(triage_agent(\"What's your favorite Marvel movie?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2rgW-IrDlfv",
        "outputId": "87be3d8b-47dc-42b1-eac4-71cee00dd371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ General Agent: I couldn‚Äôt route this request ‚Äî 'Can I get a refund for my last order?'\n",
            "ü§ñ General Agent: I couldn‚Äôt route this request ‚Äî 'Do you offer a bundle discount?'\n",
            "ü§ñ General Agent: I couldn‚Äôt route this request ‚Äî 'My reports page is crashing.'\n",
            "ü§ñ General Agent: I couldn‚Äôt route this request ‚Äî 'What's your favorite Marvel movie?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "notebook_path = \"/content/drive/My Drive/AI AGENTS/004_Agents_CustomerServiceTriage.ipynb\"\n",
        "\n",
        "# Load the notebook JSON\n",
        "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "# 1. Remove widgets from notebook-level metadata\n",
        "if \"widgets\" in nb.get(\"metadata\", {}):\n",
        "    del nb[\"metadata\"][\"widgets\"]\n",
        "    print(\"‚úÖ Removed notebook-level 'widgets' metadata.\")\n",
        "\n",
        "# 2. Remove widgets from each cell's metadata\n",
        "for i, cell in enumerate(nb.get(\"cells\", [])):\n",
        "    if \"metadata\" in cell and \"widgets\" in cell[\"metadata\"]:\n",
        "        del cell[\"metadata\"][\"widgets\"]\n",
        "        print(f\"‚úÖ Removed 'widgets' from cell {i}\")\n",
        "\n",
        "# Save the cleaned notebook\n",
        "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(nb, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Notebook deeply cleaned. Try uploading to GitHub again.\")"
      ],
      "metadata": {
        "id": "tfIfRmdwDldX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd711833-59c7-4e53-8c87-c944b50d8095"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Notebook deeply cleaned. Try uploading to GitHub again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2eTl_yfDlaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QDCA2LFyDlYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nuXvmlrsBUmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxozSFAUBUj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Blog Research Agent** üîç  \n",
        "**Goal**: Create an agent that takes a blog topic and does lightweight research, saving summaries for key subtopics.\n",
        "\n",
        "#### üîß Tools:\n",
        "- `search_web(query)` (mocked)\n",
        "- `summarize_text(text)`\n",
        "- `save_summary(topic, summary)`\n",
        "\n",
        "#### üß† New Concepts:\n",
        "- Multi-step workflows\n",
        "- Agent-as-research-assistant\n",
        "- LLM chain of reasoning (search ‚Üí summarize ‚Üí store)"
      ],
      "metadata": {
        "id": "MonM2nrGBVFh"
      }
    }
  ]
}