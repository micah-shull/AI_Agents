{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIDtMlPW94yoWjLdnYoTk3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/327_EaaS_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Utilities for EaaS Orchestrator Agent"
      ],
      "metadata": {
        "id": "yMXKb4OaKgdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"LLM Utilities for EaaS Orchestrator Agent\n",
        "\n",
        "CEO-focused LLM enhancements for executive summaries and insights.\n",
        "Incorporates principles from CEO Trust & Value Creation Guide.\n",
        "\"\"\"\n",
        "\n",
        "from typing import Dict, List, Any, Optional\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "def generate_executive_insights(\n",
        "    summary: Dict[str, Any],\n",
        "    agent_summaries: List[Dict[str, Any]],\n",
        "    config: Any\n",
        ") -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Generate CEO-friendly executive insights using LLM.\n",
        "\n",
        "    Incorporates CEO Trust & Value Guide principles:\n",
        "    - Business value first\n",
        "    - Transparency and accountability\n",
        "    - Actionable recommendations\n",
        "    - CEO-friendly language\n",
        "\n",
        "    Returns None if LLM fails (graceful degradation).\n",
        "    \"\"\"\n",
        "    if not config.enable_llm_summaries:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Prepare data for LLM\n",
        "        business_metrics = {\n",
        "            \"total_revenue_impact\": summary.get('total_revenue_impact', 0.0),\n",
        "            \"total_cost\": summary.get('total_cost', 0.0),\n",
        "            \"net_roi\": summary.get('total_net_roi', 0.0),\n",
        "            \"roi_percent\": summary.get('overall_roi_percent', 0.0),\n",
        "            \"cost_per_evaluation\": summary.get('cost_per_evaluation', 0.0)\n",
        "        }\n",
        "\n",
        "        performance_metrics = {\n",
        "            \"overall_pass_rate\": summary.get('overall_pass_rate', 0.0),\n",
        "            \"average_score\": summary.get('average_score', 0.0),\n",
        "            \"healthy_agents\": summary.get('healthy_agents', 0),\n",
        "            \"degraded_agents\": summary.get('degraded_agents', 0),\n",
        "            \"critical_agents\": summary.get('critical_agents', 0)\n",
        "        }\n",
        "\n",
        "        # Top performing agents\n",
        "        top_agents = sorted(\n",
        "            agent_summaries,\n",
        "            key=lambda x: x.get('roi_percent', 0.0),\n",
        "            reverse=True\n",
        "        )[:3]\n",
        "\n",
        "        # Agents needing attention\n",
        "        agents_needing_attention = [\n",
        "            a for a in agent_summaries\n",
        "            if a.get('health_status') in ['degraded', 'critical'] or\n",
        "               a.get('roi_percent', 0.0) < 50.0\n",
        "        ]\n",
        "\n",
        "        # Build prompt based on CEO Trust Guide principles\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are an executive AI advisor specializing in AI agent evaluation and ROI analysis.\n",
        "Your role is to provide clear, transparent, and actionable insights to CEOs and executives.\n",
        "\n",
        "Core Principles (from CEO Trust & Value Creation Guide):\n",
        "1. **Transparency First** - All insights must be explainable and data-driven\n",
        "2. **Business Value Focus** - Every insight ties to revenue or cost\n",
        "3. **CEO-Friendly Language** - Use business terms, avoid technical jargon\n",
        "4. **Actionable Recommendations** - Every insight should lead to a clear action\n",
        "5. **Statistical Rigor** - Acknowledge uncertainty, show confidence levels\n",
        "\n",
        "Your communication style:\n",
        "- Direct and concise\n",
        "- Data-driven (cite specific numbers)\n",
        "- Business-focused (revenue, cost, ROI)\n",
        "- Action-oriented (what to do next)\n",
        "- Transparent (acknowledge limitations)\"\"\"),\n",
        "\n",
        "            (\"human\", \"\"\"Analyze this AI agent evaluation report and provide executive insights.\n",
        "\n",
        "**Business Metrics:**\n",
        "- Total Revenue Impact: ${total_revenue_impact:,.2f}\n",
        "- Total Cost: ${total_cost:,.2f}\n",
        "- Net ROI: ${net_roi:,.2f} ({roi_percent:.1f}% return)\n",
        "- Cost per Evaluation: ${cost_per_evaluation:.2f}\n",
        "\n",
        "**Performance Metrics:**\n",
        "- Overall Pass Rate: {overall_pass_rate:.1%}\n",
        "- Average Score: {average_score:.2f}\n",
        "- Healthy Agents: {healthy_agents}\n",
        "- Degraded Agents: {degraded_agents}\n",
        "- Critical Agents: {critical_agents}\n",
        "\n",
        "**Top Performing Agents:**\n",
        "{top_agents}\n",
        "\n",
        "**Agents Needing Attention:**\n",
        "{agents_needing_attention}\n",
        "\n",
        "Provide:\n",
        "1. **Executive Summary** (2-3 sentences): Key business value and ROI highlights\n",
        "2. **Key Insights** (3-4 bullet points): Most important findings for decision-making\n",
        "3. **Risk Assessment** (if any): Any concerns or areas needing attention\n",
        "4. **Strategic Recommendations** (2-3 actionable items): What should the CEO do next?\n",
        "\n",
        "Use CEO-friendly language. Focus on business value, ROI, and actionable insights.\n",
        "Be transparent about any limitations or uncertainties in the data.\"\"\")\n",
        "        ])\n",
        "\n",
        "        # Format agent summaries for prompt\n",
        "        top_agents_text = \"\\n\".join([\n",
        "            f\"- {a.get('agent_id', 'unknown')}: ROI {a.get('roi_percent', 0.0):.1f}%, \"\n",
        "            f\"Status: {a.get('health_status', 'unknown')}, \"\n",
        "            f\"Cost: ${a.get('total_cost', 0.0):.2f}, \"\n",
        "            f\"Revenue: ${a.get('revenue_impact', 0.0):.2f}\"\n",
        "            for a in top_agents\n",
        "        ])\n",
        "\n",
        "        agents_needing_attention_text = \"\\n\".join([\n",
        "            f\"- {a.get('agent_id', 'unknown')}: ROI {a.get('roi_percent', 0.0):.1f}%, \"\n",
        "            f\"Status: {a.get('health_status', 'unknown')}, \"\n",
        "            f\"Score: {a.get('average_score', 0.0):.2f}\"\n",
        "            for a in agents_needing_attention\n",
        "        ]) if agents_needing_attention else \"None\"\n",
        "\n",
        "        # Initialize LLM\n",
        "        llm = ChatOpenAI(\n",
        "            model=config.llm_model,\n",
        "            temperature=config.temperature,\n",
        "            max_tokens=config.llm_summary_max_tokens\n",
        "        )\n",
        "\n",
        "        # Generate insights\n",
        "        chain = prompt | llm\n",
        "        response = chain.invoke({\n",
        "            \"total_revenue_impact\": business_metrics[\"total_revenue_impact\"],\n",
        "            \"total_cost\": business_metrics[\"total_cost\"],\n",
        "            \"net_roi\": business_metrics[\"net_roi\"],\n",
        "            \"roi_percent\": business_metrics[\"roi_percent\"],\n",
        "            \"cost_per_evaluation\": business_metrics[\"cost_per_evaluation\"],\n",
        "            \"overall_pass_rate\": performance_metrics[\"overall_pass_rate\"],\n",
        "            \"average_score\": performance_metrics[\"average_score\"],\n",
        "            \"healthy_agents\": performance_metrics[\"healthy_agents\"],\n",
        "            \"degraded_agents\": performance_metrics[\"degraded_agents\"],\n",
        "            \"critical_agents\": performance_metrics[\"critical_agents\"],\n",
        "            \"top_agents\": top_agents_text,\n",
        "            \"agents_needing_attention\": agents_needing_attention_text\n",
        "        })\n",
        "\n",
        "        # Parse response (expecting structured sections)\n",
        "        insights_text = response.content.strip()\n",
        "\n",
        "        # Extract sections (improved parsing)\n",
        "        sections = {\n",
        "            \"executive_summary\": \"\",\n",
        "            \"key_insights\": [],\n",
        "            \"risk_assessment\": \"\",\n",
        "            \"strategic_recommendations\": []\n",
        "        }\n",
        "\n",
        "        # Split by numbered sections or headers\n",
        "        lines = insights_text.split('\\n')\n",
        "        current_section = None\n",
        "        current_content = []\n",
        "\n",
        "        for line in lines:\n",
        "            line_stripped = line.strip()\n",
        "            if not line_stripped:\n",
        "                continue\n",
        "\n",
        "            line_lower = line_stripped.lower()\n",
        "\n",
        "            # Detect section headers\n",
        "            if any(phrase in line_lower for phrase in ['executive summary', 'summary:', 'overview:']):\n",
        "                if current_section and current_content:\n",
        "                    _save_section(sections, current_section, current_content)\n",
        "                current_section = \"executive_summary\"\n",
        "                current_content = []\n",
        "            elif any(phrase in line_lower for phrase in ['key insight', 'insights:', 'takeaways:']):\n",
        "                if current_section and current_content:\n",
        "                    _save_section(sections, current_section, current_content)\n",
        "                current_section = \"key_insights\"\n",
        "                current_content = []\n",
        "            elif any(phrase in line_lower for phrase in ['risk assessment', 'risks:', 'risk:']):\n",
        "                if current_section and current_content:\n",
        "                    _save_section(sections, current_section, current_content)\n",
        "                current_section = \"risk_assessment\"\n",
        "                current_content = []\n",
        "            elif any(phrase in line_lower for phrase in ['recommendation', 'strategic recommendation', 'actions:', 'next steps:']):\n",
        "                if current_section and current_content:\n",
        "                    _save_section(sections, current_section, current_content)\n",
        "                current_section = \"strategic_recommendations\"\n",
        "                current_content = []\n",
        "            else:\n",
        "                # Skip markdown headers and limitations sections\n",
        "                if line_stripped.startswith('#') or 'limitation' in line_lower:\n",
        "                    continue\n",
        "                # Clean up numbered lists (remove duplicate numbering)\n",
        "                cleaned_line = _clean_numbered_line(line_stripped)\n",
        "                # Also clean up double dashes from bullet points\n",
        "                cleaned_line = cleaned_line.replace('- -', '-').replace('--', '-').strip()\n",
        "                if cleaned_line:\n",
        "                    current_content.append(cleaned_line)\n",
        "\n",
        "        # Save last section\n",
        "        if current_section and current_content:\n",
        "            _save_section(sections, current_section, current_content)\n",
        "\n",
        "        # Clean up recommendations - remove duplicates and format properly\n",
        "        if sections[\"strategic_recommendations\"]:\n",
        "            sections[\"strategic_recommendations\"] = _clean_recommendations(sections[\"strategic_recommendations\"])\n",
        "\n",
        "        # If parsing didn't work well, use full text as executive summary\n",
        "        if not sections[\"executive_summary\"]:\n",
        "            sections[\"executive_summary\"] = insights_text[:300] + \"...\" if len(insights_text) > 300 else insights_text\n",
        "\n",
        "        return {\n",
        "            \"raw_response\": insights_text,\n",
        "            \"executive_summary\": sections[\"executive_summary\"],\n",
        "            \"key_insights\": sections[\"key_insights\"] if isinstance(sections[\"key_insights\"], list) else ([sections[\"key_insights\"]] if sections[\"key_insights\"] else []),\n",
        "            \"risk_assessment\": sections[\"risk_assessment\"],\n",
        "            \"strategic_recommendations\": sections[\"strategic_recommendations\"] if isinstance(sections[\"strategic_recommendations\"], list) else ([sections[\"strategic_recommendations\"]] if sections[\"strategic_recommendations\"] else []),\n",
        "            \"source\": \"llm\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    Warning: LLM insights generation failed: {str(e)}\")\n",
        "        print(f\"    Falling back to rule-based summaries\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def _save_section(sections: Dict[str, Any], section_name: str, content: List[str]):\n",
        "    \"\"\"Helper to save section content properly.\"\"\"\n",
        "    if section_name in [\"key_insights\", \"strategic_recommendations\"]:\n",
        "        sections[section_name] = content\n",
        "    else:\n",
        "        sections[section_name] = '\\n'.join(content).strip()\n",
        "\n",
        "\n",
        "def _clean_numbered_line(line: str) -> str:\n",
        "    \"\"\"Clean up numbered list items (remove duplicate numbering like '1. 1.')\"\"\"\n",
        "    import re\n",
        "    # Remove patterns like \"1. 1.\" or \"2. 2.\" etc.\n",
        "    line = re.sub(r'^(\\d+)\\.\\s*\\1\\.\\s*', r'\\1. ', line)\n",
        "    # Remove standalone numbers at start\n",
        "    line = re.sub(r'^(\\d+)\\.\\s*$', '', line)\n",
        "    return line.strip()\n",
        "\n",
        "\n",
        "def _clean_recommendations(recommendations: List[str]) -> List[str]:\n",
        "    \"\"\"Clean and deduplicate recommendations.\"\"\"\n",
        "    cleaned = []\n",
        "    seen = set()\n",
        "\n",
        "    for rec in recommendations:\n",
        "        rec_clean = rec.strip()\n",
        "        if not rec_clean:\n",
        "            continue\n",
        "\n",
        "        # Remove duplicate numbering\n",
        "        import re\n",
        "        rec_clean = re.sub(r'^(\\d+)\\.\\s*', '', rec_clean)  # Remove leading \"1. \", \"2. \" etc.\n",
        "\n",
        "        # Skip if it's a header or limitation\n",
        "        if rec_clean.lower().startswith('#') or 'limitation' in rec_clean.lower():\n",
        "            continue\n",
        "\n",
        "        # Skip if it's a continuation sentence (starts with lowercase or \"While\", \"However\", etc.)\n",
        "        # These are usually explanations, not actionable recommendations\n",
        "        if rec_clean and rec_clean[0].islower() or rec_clean.startswith(('While ', 'However ', 'Although ', 'Since ', 'Given ')):\n",
        "            continue\n",
        "\n",
        "        # Deduplicate\n",
        "        rec_normalized = rec_clean.lower().strip()\n",
        "        if rec_normalized and rec_normalized not in seen:\n",
        "            seen.add(rec_normalized)\n",
        "            cleaned.append(rec_clean)\n",
        "\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def generate_agent_insights(\n",
        "    agent_summary: Dict[str, Any],\n",
        "    config: Any\n",
        ") -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Generate CEO-friendly insights for a specific agent.\n",
        "\n",
        "    Returns None if LLM fails (graceful degradation).\n",
        "    \"\"\"\n",
        "    if not config.enable_llm_summaries:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are an executive AI advisor. Provide concise, business-focused insights about AI agent performance.\n",
        "Focus on ROI, business value, and actionable recommendations. Use CEO-friendly language.\"\"\"),\n",
        "\n",
        "            (\"human\", \"\"\"Provide a 2-3 sentence executive insight for this agent:\n",
        "\n",
        "Agent: {agent_id}\n",
        "ROI: {roi_percent:.1f}%\n",
        "Status: {health_status}\n",
        "Cost: ${total_cost:.2f}\n",
        "Revenue Impact: ${revenue_impact:.2f}\n",
        "Average Score: {average_score:.2f}\n",
        "Total Evaluations: {total_evaluations}\n",
        "\n",
        "Focus on business value and what this means for the organization.\"\"\")\n",
        "        ])\n",
        "\n",
        "        llm = ChatOpenAI(\n",
        "            model=config.llm_model,\n",
        "            temperature=config.temperature,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        chain = prompt | llm\n",
        "        response = chain.invoke({\n",
        "            \"agent_id\": agent_summary.get('agent_id', 'unknown'),\n",
        "            \"roi_percent\": agent_summary.get('roi_percent', 0.0),\n",
        "            \"health_status\": agent_summary.get('health_status', 'unknown'),\n",
        "            \"total_cost\": agent_summary.get('total_cost', 0.0),\n",
        "            \"revenue_impact\": agent_summary.get('revenue_impact', 0.0),\n",
        "            \"average_score\": agent_summary.get('average_score', 0.0),\n",
        "            \"total_evaluations\": agent_summary.get('total_evaluations', 0)\n",
        "        })\n",
        "\n",
        "        return response.content.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    Warning: LLM agent insights failed: {str(e)}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "KcugppzGNQSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation-as-a-Service Report\n",
        "\n",
        "**Generated:** 2025-12-22 17:34:54\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "### ðŸ“Š Executive Overview\n",
        "\n",
        "The AI agent evaluation demonstrates exceptional business value, with a total revenue impact of \\$665 and an astonishing net ROI of 349,900%. All agents passed evaluation, indicating robust performance and no immediate concerns.\n",
        "\n",
        "### ðŸ’° Business Impact\n",
        "\n",
        "- **Total Revenue Impact:** \\$665.00\n",
        "- **Total Cost:** \\$0.19\n",
        "- **Net ROI:** \\$664.81 (349900.0% return)\n",
        "- **Cost per Evaluation:** \\$0.01\n",
        "- **Agents with Positive ROI:** 4/4\n",
        "- **Agents Needing Optimization:** 0\n",
        "\n",
        "### ðŸ“Š Performance Metrics\n",
        "\n",
        "- **Total Scenarios Evaluated:** 10\n",
        "- **Total Evaluations:** 19\n",
        "- **Overall Pass Rate:** 100.0% â†’ Stable\n",
        "- **Average Score:** 0.99 â†’ Stable\n",
        "- **Healthy Agents:** 4\n",
        "- **Degraded Agents:** 0\n",
        "- **Critical Agents:** 0\n",
        "\n",
        "### ðŸŽ¯ Key Takeaways\n",
        "\n",
        "- - **Outstanding ROI**: The overall net ROI of \\$664.81 reflects a highly efficient evaluation process, yielding a return of 349,900% on a minimal investment of \\$0.19.\n",
        "- - **Perfect Performance**: All agents achieved a 100% pass rate, with an average score of 0.99, indicating consistent high performance across the board.\n",
        "- - **Top Performers**: The escalation agent, refund agent, and shipping update agent are driving significant revenue, with ROIs exceeding 249,000%, showcasing their effectiveness in generating business value.\n",
        "- - **No Immediate Risks**: There are currently no agents requiring attention, suggesting a stable operational environment.\n",
        "\n",
        "### âš ï¸ Risk Assessment\n",
        "\n",
        "There are no immediate risks or areas needing attention based on the current evaluation. However, continuous monitoring is recommended to maintain performance standards.\n",
        "\n",
        "\n",
        "**Trends (vs. Previous Run):**\n",
        "- **Stable:** 4 agent(s) with stable performance\n",
        "\n",
        "### ðŸŽ¯ Recommended Actions\n",
        "\n",
        "1. **Leverage High-Performing Agents**: Consider scaling the use of the top-performing agents (escalation, refund, and shipping update) to maximize their revenue potential further.\n",
        "2. **Invest in Continuous Improvement**: While current performance is excellent, invest in ongoing training and development for agents to sustain high performance and adapt to changing business needs.\n",
        "3. **Monitor Performance Trends**: Establish a regular review process to track agent performance over time, ensuring any emerging issues are addressed promptly.\n",
        "4. While the data shows strong performance, it is essential to remain vigilant for any changes in market conditions or agent performance that could impact future evaluations. Regular assessments will help mitigate potential risks.\n",
        "\n",
        "## ðŸ’° ROI & Business Value Analysis\n",
        "\n",
        "### Overall Business Impact\n",
        "\n",
        "- **Total Revenue Impact:** \\$665.00\n",
        "- **Total Cost:** \\$0.19\n",
        "- **Net ROI:** \\$664.81\n",
        "- **ROI Percentage:** 349900.0%\n",
        "- **Cost per Evaluation:** \\$0.01\n",
        "\n",
        "### Agent-Level ROI\n",
        "\n",
        "| Agent | Cost | Revenue Impact | Net ROI | ROI % | ROI Ratio | Trend | Status |\n",
        "|-------|------|----------------|---------|-------|-----------|-------|--------|\n",
        "| refund_agent | \\$0.02 | \\$100.00 | \\$99.98 | 499899.8% | 5000.00x | â†’ | âœ… Excellent |\n",
        "| shipping_update_agent | \\$0.07 | \\$175.00 | \\$174.93 | 249899.9% | 2500.00x | â†’ | âœ… Excellent |\n",
        "| apology_message_agent | \\$0.06 | \\$90.00 | \\$89.94 | 149900.0% | 1500.00x | â†’ | âœ… Excellent |\n",
        "| escalation_agent | \\$0.04 | \\$300.00 | \\$299.96 | 749899.8% | 7500.00x | â†’ | âœ… Excellent |\n",
        "\n",
        "## ðŸ“Š Agent Performance Details\n",
        "\n",
        "### refund_agent\n",
        "\n",
        "**Executive Insight:** The refund_agent demonstrates an exceptional ROI of 499,899.8%, indicating an extraordinary efficiency in processing refunds at a minimal cost of just \\$0.02 per transaction. With a perfect average score of 1.00 from evaluations, this agent not only enhances customer satisfaction but also drives revenue impact, making it a critical asset for optimizing operational efficiency. To capitalize on this success, consider scaling its deployment across additional customer service functions to further amplify business value.\n",
        "\n",
        "**Performance:**\n",
        "- **Status:** healthy\n",
        "- **Total Evaluations:** 2\n",
        "- **Passed:** 2\n",
        "- **Failed:** 0\n",
        "- **Average Score:** 1.00 â†’ Stable\n",
        "- **Average Response Time:** 0.00s\n",
        "\n",
        "**Business Value:**\n",
        "- **Total Cost:** \\$0.02\n",
        "- **Revenue Impact:** \\$100.00\n",
        "- **Net ROI:** \\$99.98 â†’ Stable\n",
        "- **ROI Percentage:** 499899.8% â†’\n",
        "- **ROI Category:** exceptional\n",
        "- **Cost per Evaluation:** \\$0.01 â†’ Stable\n",
        "\n",
        "**Statistical Assessment:**\n",
        "- *Historical comparison data not yet available*\n",
        "- *KPI significance testing will be available after multiple evaluation runs*\n",
        "- *ROI significance testing will be available after multiple evaluation runs*\n",
        "\n",
        "### shipping_update_agent\n",
        "\n",
        "**Executive Insight:** The shipping_update_agent demonstrates exceptional performance with an astonishing ROI of 249,899.9%, indicating that every dollar spent yields significant revenue impact. With a cost of just \\$0.07 and an average score of 1.00 across evaluations, this agent is a highly efficient asset that can enhance customer satisfaction and operational efficiency. To maximize its value, consider scaling its deployment across additional customer touchpoints.\n",
        "\n",
        "**Performance:**\n",
        "- **Status:** healthy\n",
        "- **Total Evaluations:** 7\n",
        "- **Passed:** 7\n",
        "- **Failed:** 0\n",
        "- **Average Score:** 1.00 â†’ Stable\n",
        "- **Average Response Time:** 0.00s\n",
        "\n",
        "**Business Value:**\n",
        "- **Total Cost:** \\$0.07\n",
        "- **Revenue Impact:** \\$175.00\n",
        "- **Net ROI:** \\$174.93 â†’ Stable\n",
        "- **ROI Percentage:** 249899.9% â†’\n",
        "- **ROI Category:** exceptional\n",
        "- **Cost per Evaluation:** \\$0.01 â†’ Stable\n",
        "\n",
        "**Statistical Assessment:**\n",
        "- *Historical comparison data not yet available*\n",
        "- *KPI significance testing will be available after multiple evaluation runs*\n",
        "- *ROI significance testing will be available after multiple evaluation runs*\n",
        "\n",
        "### apology_message_agent\n",
        "\n",
        "**Executive Insight:** The apology_message_agent demonstrates exceptional ROI at 149,900%, indicating a highly efficient use of resources with minimal cost of \\$0.06 per interaction. With a strong average score of 0.97 from six evaluations, this agent not only enhances customer satisfaction but also drives a significant revenue impact of \\$90.00, underscoring its value in maintaining brand reputation and customer loyalty. Prioritize scaling this agent to maximize its positive influence on customer relations and overall profitability.\n",
        "\n",
        "**Performance:**\n",
        "- **Status:** healthy\n",
        "- **Total Evaluations:** 6\n",
        "- **Passed:** 6\n",
        "- **Failed:** 0\n",
        "- **Average Score:** 0.97 â†’ Stable\n",
        "- **Average Response Time:** 0.00s\n",
        "\n",
        "**Business Value:**\n",
        "- **Total Cost:** \\$0.06\n",
        "- **Revenue Impact:** \\$90.00\n",
        "- **Net ROI:** \\$89.94 â†’ Stable\n",
        "- **ROI Percentage:** 149900.0% â†’\n",
        "- **ROI Category:** exceptional\n",
        "- **Cost per Evaluation:** \\$0.01 â†’ Stable\n",
        "\n",
        "**Statistical Assessment:**\n",
        "**KPI Significance:**\n",
        "- âž¡ï¸ Change not statistically significant: 0.0% change (p=1.0) | Target met: 0.97 >= 0.85\n",
        "- **P-value:** 1.0000\n",
        "- **Statistically Significant:** No\n",
        "- **Percent Change:** 0.0%\n",
        "- **95% Confidence Interval:** [0.850, 1.100]\n",
        "\n",
        "**ROI Significance:**\n",
        "- âœ… ROI \\$89.94 is positive but not statistically significant | ROI Ratio: 1499.00x | 95% CI: \\$89.94 to \\$89.94\n",
        "- **P-value:** nan\n",
        "- **Statistically Significant:** No\n",
        "- **ROI Ratio:** 1499.00x\n",
        "- **95% Confidence Interval:** [89.94, 89.94]\n",
        "\n",
        "### escalation_agent\n",
        "\n",
        "**Executive Insight:** The escalation agent demonstrates exceptional performance with an ROI of 749,899.8%, indicating a highly efficient use of resources that translates into significant revenue impact for the organization. With a minimal cost of just \\$0.04 per evaluation and a perfect average score, this agent is a prime candidate for scaling and further investment, ensuring continued enhancement of customer satisfaction and operational efficiency.\n",
        "\n",
        "**Performance:**\n",
        "- **Status:** healthy\n",
        "- **Total Evaluations:** 4\n",
        "- **Passed:** 4\n",
        "- **Failed:** 0\n",
        "- **Average Score:** 1.00 â†’ Stable\n",
        "- **Average Response Time:** 0.00s\n",
        "\n",
        "**Business Value:**\n",
        "- **Total Cost:** \\$0.04\n",
        "- **Revenue Impact:** \\$300.00\n",
        "- **Net ROI:** \\$299.96 â†’ Stable\n",
        "- **ROI Percentage:** 749899.8% â†’\n",
        "- **ROI Category:** exceptional\n",
        "- **Cost per Evaluation:** \\$0.01 â†’ Stable\n",
        "\n",
        "**Statistical Assessment:**\n",
        "- *Historical comparison data not yet available*\n",
        "- *KPI significance testing will be available after multiple evaluation runs*\n",
        "- *ROI significance testing will be available after multiple evaluation runs*\n",
        "\n",
        "## Evaluation Results\n",
        "\n",
        "| Scenario | Agent | Score | Passed | Issues |\n",
        "|----------|-------|-------|--------|--------|\n",
        "| S001 | shipping_update_agent | 1.00 | âœ“ |  |\n",
        "| S002 | shipping_update_agent | 1.00 | âœ“ |  |\n",
        "| S002 | apology_message_agent | 1.00 | âœ“ |  |\n",
        "| S003 | refund_agent | 1.00 | âœ“ |  |\n",
        "| S003 | apology_message_agent | 0.85 | âœ“ | Output status doesn't match expected outcome type |\n",
        "| S004 | shipping_update_agent | 1.00 | âœ“ |  |\n",
        "| S004 | apology_message_agent | 1.00 | âœ“ |  |\n",
        "| S005 | escalation_agent | 1.00 | âœ“ |  |\n",
        "| S005 | apology_message_agent | 1.00 | âœ“ |  |\n",
        "| S006 | shipping_update_agent | 1.00 | âœ“ |  |\n",
        "| S006 | apology_message_agent | 1.00 | âœ“ |  |\n",
        "| S006 | escalation_agent | 1.00 | âœ“ |  |\n",
        "| S007 | shipping_update_agent | 1.00 | âœ“ |  |\n",
        "| S008 | shipping_update_agent | 1.00 | âœ“ |  |\n",
        "| S008 | apology_message_agent | 1.00 | âœ“ |  |\n",
        "| S008 | escalation_agent | 1.00 | âœ“ |  |\n",
        "| S009 | escalation_agent | 1.00 | âœ“ |  |\n",
        "| S009 | refund_agent | 1.00 | âœ“ |  |\n",
        "| S010 | shipping_update_agent | 1.00 | âœ“ |  |\n"
      ],
      "metadata": {
        "id": "u2pwMg-4ML6t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8LTTGzCyMPUv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}