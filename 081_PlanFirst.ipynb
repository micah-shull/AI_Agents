{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNYXPoHcuTWRNxe2Ho9OMa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micah-shull/AI_Agents/blob/main/081_PlanFirst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook introduces a new capability pattern — “Plan First” — that changes *how* an agent approaches a task before doing anything else.**\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Ideas**\n",
        "\n",
        "1. **Strategic Thinking Before Action**\n",
        "\n",
        "   * Instead of immediately running tools, the agent is *forced* to produce a detailed plan first.\n",
        "   * This mirrors how humans often work best — think, plan, then act — rather than jumping in blind.\n",
        "\n",
        "2. **Memory-Driven Planning**\n",
        "\n",
        "   * The plan is stored in the agent’s memory as a *system message*.\n",
        "   * This means it becomes part of the agent’s ongoing decision-making context for every subsequent step.\n",
        "\n",
        "3. **Plan Generation Logic**\n",
        "\n",
        "   * The `create_plan` tool builds a structured prompt that:\n",
        "\n",
        "     * Pulls in *available tools* and their descriptions.\n",
        "     * Retrieves *task-relevant memory*.\n",
        "     * Guides the LLM through a structured, step-by-step reasoning format.\n",
        "   * This ensures the plan is specific, actionable, and tied to available capabilities.\n",
        "\n",
        "4. **Capability Hook — `init()`**\n",
        "\n",
        "   * The `PlanFirstCapability` runs its planning step in the **initialization phase** of the agent loop (`init` method).\n",
        "   * This happens before *any* action execution starts.\n",
        "\n",
        "5. **Keeps the Agent On Track**\n",
        "\n",
        "   * Once the plan is in memory, the agent can refer back to it to avoid scope creep or tool misuse.\n",
        "   * In longer tasks, this helps the agent “stay strategic” instead of drifting.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why It’s Important**\n",
        "\n",
        "* Adds **strategic discipline** to agent workflows.\n",
        "* Improves **task consistency** by making the agent commit to a structure.\n",
        "* Enhances **transparency** — humans can see and approve the plan before the agent starts executing.\n",
        "* Makes agents **more explainable**, because you can trace decisions back to the original plan.\n",
        "\n"
      ],
      "metadata": {
        "id": "a0ArVa0X_XAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 1) The planning tool, returns a plan string\n",
        "\n",
        "```python\n",
        "@register_tool(tags=[\"planning\"])\n",
        "def create_plan(action_context: ActionContext,\n",
        "                memory: Memory,\n",
        "                action_registry: ActionRegistry) -> str:\n",
        "    \"\"\"Create a detailed execution plan based on the task and available tools.\"\"\"\n",
        "\n",
        "    # Get tool descriptions for the prompt\n",
        "    tool_descriptions = \"\\n\".join(\n",
        "        f\"- {action.name}: {action.description}\"\n",
        "        for action in action_registry.get_actions()\n",
        "    )\n",
        "\n",
        "    # Get relevant memory content (user + system only)\n",
        "    memory_content = \"\\n\".join(\n",
        "        f\"{m['type']}: {m['content']}\"\n",
        "        for m in memory.items          # <-- fixed: was _memory\n",
        "        if m.get('type') in ['user', 'system']\n",
        "    )\n",
        "\n",
        "    # Construct the prompt\n",
        "    prompt = f\"\"\"Given the task in memory and the available tools, create a detailed plan.\n",
        "Think through this step by step:\n",
        "\n",
        "1. First, identify the key components of the task\n",
        "2. Consider what tools you have available\n",
        "3. Break down the task into logical steps\n",
        "4. For each step, specify:\n",
        "   - What needs to be done\n",
        "   - What tool(s) will be used\n",
        "   - What information is needed\n",
        "   - What the expected outcome is\n",
        "\n",
        "Write your plan in clear, numbered steps. Each step should be specific and actionable.\n",
        "\n",
        "Available tools:\n",
        "{tool_descriptions}\n",
        "\n",
        "Task context from memory:\n",
        "{memory_content}\n",
        "\n",
        "Create a plan that accomplishes this task effectively.\"\"\"\n",
        "\n",
        "    return prompt_llm(action_context=action_context, prompt=prompt)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "OXiZZkXpEEfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Example of the **plan text** the tool might return\n",
        "\n",
        "*(This is just sample output, not code that runs.)*\n",
        "\n",
        "```text\n",
        "Plan for Sales Data Analysis:\n",
        "\n",
        "1. Data Validation\n",
        "   - Tool: validate_data()\n",
        "   - Check data completeness and format\n",
        "   - Ensure all required fields are present\n",
        "   - Expected: Confirmation of valid dataset\n",
        "\n",
        "2. Initial Analysis\n",
        "   - Tool: analyze_data()\n",
        "   - Calculate key metrics (revenue, growth)\n",
        "   - Generate summary statistics\n",
        "   - Expected: Basic statistical overview\n",
        "\n",
        "3. Trend Identification\n",
        "   - Tool: find_patterns()\n",
        "   - Look for seasonal patterns\n",
        "   - Identify sales trends\n",
        "   - Expected: List of significant trends\n",
        "\n",
        "4. Visualization\n",
        "   - Tool: create_visualization()\n",
        "   - Create relevant charts\n",
        "   - Highlight key findings\n",
        "   - Expected: Clear visual representations\n",
        "\n",
        "5. Report Generation\n",
        "   - Tool: generate_report()\n",
        "   - Compile findings\n",
        "   - Include visualizations\n",
        "   - Expected: Comprehensive report\n",
        "\n",
        "I'll begin with step 1: Data Validation...\n",
        "```\n",
        "\n",
        "# 3) What the capability does with that plan\n",
        "\n",
        "*(Your earlier `PlanFirstCapability` calls `create_plan(...)` in `init()` and writes the plan into memory as a system directive.)*\n",
        "No change needed here unless you want to add a review/revision loop.\n",
        "\n",
        "# 4) Agent usage: enable the capability and run\n",
        "\n",
        "```python\n",
        "agent = Agent(\n",
        "    goals=[\n",
        "        Goal(name=\"analysis\", description=\"Analyze sales data and create a report\")\n",
        "    ],\n",
        "    capabilities=[\n",
        "        PlanFirstCapability(track_progress=True)\n",
        "    ],\n",
        "    # ... other agent configuration: language, registry, env, llm, etc.\n",
        ")\n",
        "\n",
        "result = agent.run(\"Analyze our Q4 sales data and create a report\")\n",
        "```\n",
        "\n",
        "# Notes / gotchas to focus on\n",
        "\n",
        "* **Bug fix:** use `memory.items` (not `_memory.items`).\n",
        "* **Scope control:** the planning tool only pulls **user/system** memories so the plan isn’t polluted by random assistant chatter.\n",
        "* **Tool awareness:** `tool_descriptions` is injected so the plan explicitly maps steps → tools (great for traceability and later automation).\n",
        "* **Separation of concerns:** the *tool* returns a string plan; the *capability* decides how/where to store and enforce it.\n",
        "* **Extend later:** you can drop in the review/revise loop we discussed to harden plans before execution.\n"
      ],
      "metadata": {
        "id": "tKos-jWxEOtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan First: A New Capability\n",
        "\n",
        "One key to making agents more effective is getting them to think strategically before taking action.  \n",
        "Instead of jumping straight into executing tools, we want our agent to first develop a comprehensive plan.  \n",
        "Let’s build a capability that enforces this “plan first” approach.\n",
        "\n",
        "---\n",
        "\n",
        "## The Plan First Pattern\n",
        "\n",
        "Here’s how we’ll make our agent plan before acting:\n",
        "\n",
        "1. When the agent first starts, we’ll prompt it to create a detailed plan\n",
        "2. We’ll store this plan in the agent’s memory\n",
        "3. The agent will refer back to this plan throughout its execution\n",
        "\n",
        "---\n",
        "\n",
        "## Implementation\n",
        "\n",
        "```python\n",
        "class PlanFirstCapability(Capability):\n",
        "    def __init__(self, plan_memory_type=\"system\", track_progress=False):\n",
        "        super().__init__(\n",
        "            name=\"Plan First Capability\",\n",
        "            description=\"The Agent will always create a plan and add it to memory\"\n",
        "        )\n",
        "        self.plan_memory_type = plan_memory_type\n",
        "        self.first_call = True\n",
        "        self.track_progress = track_progress\n",
        "\n",
        "    def init(self, agent, action_context):\n",
        "        if self.first_call:\n",
        "            self.first_call = False\n",
        "            plan = create_plan(\n",
        "                action_context=action_context,\n",
        "                memory=action_context.get_memory(),\n",
        "                action_registry=action_context.get_action_registry()\n",
        "            )\n",
        "\n",
        "            action_context.get_memory().add_memory({\n",
        "                \"type\": self.plan_memory_type,\n",
        "                \"content\": \"You must follow these instructions carefully to complete the task:\\n\" + plan\n",
        "            })\n"
      ],
      "metadata": {
        "id": "WnpjLQ8b_SNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this level of abstraction, building agents is really about:\n",
        "\n",
        "1. **Defining intent in plain language**\n",
        "\n",
        "   * The plan prompts, goal descriptions, and capability instructions are just highly structured English.\n",
        "   * You’re telling the model *what to do* and *how to think about it*, not how to code it line-by-line.\n",
        "\n",
        "2. **Structuring the workflow**\n",
        "\n",
        "   * Instead of dumping everything in one mega-prompt, you break the process into **capabilities** (plan, revise, act) and **tools** (data fetch, transform, visualize).\n",
        "   * Each piece is reusable, swappable, and easy to test.\n",
        "\n",
        "3. **Controlling context & dependencies**\n",
        "\n",
        "   * ActionContext and the Environment give the agent just the right “stuff” for the job — not too much, not too little.\n",
        "   * This is how you keep it safe, modular, and predictable.\n",
        "\n",
        "It’s a bit like working with a very talented assistant:\n",
        "\n",
        "* You don’t tell them every keystroke; you give them the plan, the resources, and the rules of engagement.\n",
        "* The system handles *how* the steps get executed, and you just decide *what* the steps should be.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P0ABK3sCEzPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two pieces play different roles:\n",
        "\n",
        "## Big picture\n",
        "\n",
        "* **`create_plan` (tool)** = *What to produce.*\n",
        "  A stateless, single-purpose function that **generates** a plan (plain text) using the LLM, given the current memory + available tools.\n",
        "\n",
        "* **`PlanFirstCapability` (capability)** = *When and how to use it.*\n",
        "  A lifecycle hook that **enforces planning behavior** in the agent loop: it **calls** `create_plan` at the right time (once at startup), **stores** the plan into memory, and (optionally) **tracks progress** or can later **gate** actions based on the plan.\n",
        "\n",
        "---\n",
        "\n",
        "## What to focus on\n",
        "\n",
        "### 1) Separation of concerns (When/How vs What)\n",
        "\n",
        "* **Tool (`create_plan`)** focuses on *content generation* only. It’s easy to test, reuse, and swap out.\n",
        "* **Capability (`PlanFirstCapability`)** focuses on *policy and orchestration*: ensuring a plan exists, where it’s stored, and how it’s used.\n",
        "\n",
        "### 2) Lifecycle integration\n",
        "\n",
        "* `PlanFirstCapability.init(...)` runs **once** at the start of the agent run. That’s where it:\n",
        "\n",
        "  * Calls `create_plan(...)`\n",
        "  * Writes the plan into memory (type = `\"system\"` by default via `plan_memory_type`)\n",
        "  * Can set flags for later enforcement (e.g., `track_progress`)\n",
        "* Later, the capability could use other hooks (`process_prompt`, `process_action`, `should_terminate`, etc.) to:\n",
        "\n",
        "  * Remind the agent to follow the plan\n",
        "  * Prevent off-plan actions or trigger **re-planning** if context changes\n",
        "\n",
        "### 3) Dependency injection & context access\n",
        "\n",
        "* **Tool** signature explicitly asks for `action_context`, `memory`, and `action_registry`, making it **pure** and **testable**.\n",
        "  It builds the plan from:\n",
        "\n",
        "  * **`action_registry.get_actions()`** → list available tools\n",
        "  * **`memory.items`** → pull relevant user/system context\n",
        "* **Capability** uses `action_context.get_memory()` and `action_context.get_action_registry()` to fetch what it needs, without hard-coding any globals.\n",
        "\n",
        "### 4) Reusability & portability\n",
        "\n",
        "* You can reuse `create_plan` in other agents (or even call it manually in a script).\n",
        "* You can attach `PlanFirstCapability` to any agent that should **always** plan first—no changes to the agent core.\n",
        "\n",
        "### 5) Configuration points\n",
        "\n",
        "* `plan_memory_type=\"system\"` lets you control where the plan is saved (e.g., `\"system\"` vs `\"assistant\"`).\n",
        "* `track_progress=True/False` gives you a hook for future extensions (progress ticks, plan adherence checks, re-plan triggers).\n",
        "\n",
        "---\n",
        "\n",
        "## Mental model (flow)\n",
        "\n",
        "1. **Agent starts** → `PlanFirstCapability.init(...)` fires.\n",
        "2. Capability **calls** `create_plan(...)`.\n",
        "3. Capability **stores** the returned plan in memory (as a system instruction like “You must follow these instructions carefully…”).\n",
        "4. Agent continues; capability can **enforce** adherence across the loop.\n",
        "\n",
        "---\n",
        "\n",
        "## Practical tips\n",
        "\n",
        "* **Test `create_plan`** in isolation with fake memory/tool lists; it should return a well-structured plan string.\n",
        "* **Evolve the capability** to:\n",
        "\n",
        "  * Add a `process_action` check: block actions that aren’t in plan scope.\n",
        "  * Add a `process_result` hook: mark plan steps as complete.\n",
        "  * Add a `should_terminate` rule: stop when all planned steps are done.\n",
        "\n",
        "In short: **`create_plan`** is the **planner**; **`PlanFirstCapability`** is the **project manager** making sure the planner’s output is created, saved, and followed.\n"
      ],
      "metadata": {
        "id": "IXVVn7SxHiir"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co50EWXs-k1E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can turn “Plan First” into “Plan → Review → Revise → Execute.” Two easy ways to add this:\n",
        "\n",
        "# Option A: Extend the existing capability\n",
        "\n",
        "Add a lightweight review loop inside `PlanFirstCapability.init()` before committing the plan to memory.\n",
        "\n",
        "```python\n",
        "class PlanFirstCapability(Capability):\n",
        "    def __init__(self, track_progress=False, max_plan_revisions=2, reviewer=\"ai\"):\n",
        "        super().__init__(\"Plan First Capability\", \"Draft, review, and finalize a plan before acting\")\n",
        "        self.track_progress = track_progress\n",
        "        self.max_plan_revisions = max_plan_revisions\n",
        "        self.reviewer = reviewer  # \"ai\" or \"human\"\n",
        "\n",
        "    def init(self, agent, action_context):\n",
        "        memory = action_context.get_memory()\n",
        "        registry = action_context.get_action_registry()\n",
        "\n",
        "        plan = create_plan(action_context=action_context, memory=memory, action_registry=registry)\n",
        "\n",
        "        # --- review loop ---\n",
        "        for i in range(self.max_plan_revisions):\n",
        "            critique = critique_plan(action_context, plan)  # tool below\n",
        "            if critique[\"approved\"]:\n",
        "                break\n",
        "            plan = revise_plan(action_context, plan, critique[\"issues\"])  # tool below\n",
        "\n",
        "        # Store final plan\n",
        "        memory.add_memory({\n",
        "            \"type\": \"system\",\n",
        "            \"content\": \"You must follow these instructions carefully:\\n\" + plan\n",
        "        })\n",
        "```\n",
        "\n",
        "Two tiny tools to support it:\n",
        "\n",
        "```python\n",
        "@register_tool(tags=[\"planning\"])\n",
        "def critique_plan(action_context: ActionContext, plan: str) -> dict:\n",
        "    \"\"\"Return {'approved': bool, 'issues': [..], 'risk': 'low/med/high'}.\"\"\"\n",
        "    schema = {\"type\":\"object\",\"properties\":{\"approved\":{\"type\":\"boolean\"},\"issues\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\"risk\":{\"type\":\"string\"}},\"required\":[\"approved\",\"issues\"]}\n",
        "    prompt = f\"Critique this execution plan for clarity, feasibility, risks:\\n\\n{plan}\\n\\nDecide if it's executable as-is.\"\n",
        "    return prompt_llm_for_json(action_context, schema, prompt)\n",
        "\n",
        "@register_tool(tags=[\"planning\"])\n",
        "def revise_plan(action_context: ActionContext, plan: str, issues: list[str]) -> str:\n",
        "    \"\"\"Return an improved plan addressing issues.\"\"\"\n",
        "    prompt = f\"Revise the plan below to address these issues {issues}. Keep numbered, actionable steps.\\n\\n{plan}\"\n",
        "    return action_context.get('llm')(prompt)\n",
        "```\n",
        "\n",
        "# Option B: Separate “PlanReviewCapability”\n",
        "\n",
        "Keep concerns clean: one capability drafts; another reviews/revises (and can be toggled off in low-risk contexts).\n",
        "\n",
        "```python\n",
        "class PlanReviewCapability(Capability):\n",
        "    def __init__(self, max_revisions=2): ...\n",
        "    def init(self, agent, action_context):\n",
        "        mem = action_context.get_memory()\n",
        "        plan_msg = next((m for m in reversed(mem.items) if \"You must follow these instructions carefully:\" in m[\"content\"]), None)\n",
        "        if not plan_msg: return\n",
        "        plan = plan_msg[\"content\"].split(\"carefully:\\n\",1)[1]\n",
        "\n",
        "        for _ in range(self.max_revisions):\n",
        "            crit = critique_plan(action_context, plan)\n",
        "            if crit[\"approved\"]: break\n",
        "            plan = revise_plan(action_context, plan, crit[\"issues\"])\n",
        "\n",
        "        plan_msg[\"content\"] = \"You must follow these instructions carefully:\\n\" + plan\n",
        "```\n",
        "\n",
        "# Nice refinements\n",
        "\n",
        "* **Checklist-based review:** encode explicit criteria (scope, inputs, outputs, safety, tool fit, acceptance tests).\n",
        "* **Risk gates:** auto-approve when risk = low; require human approval if risk = high.\n",
        "* **Versioning:** store `plan_v1`, `plan_v2`, … in memory for traceability.\n",
        "* **Staged execution:** pair with your staged-execution pattern—plan is approved, then actions are staged and reviewed before execution.\n",
        "* **Iteration guardrails:** `max_plan_revisions`, time budget, and a fallback (“execute with caution” or escalate to human).\n",
        "\n",
        "# Why this helps\n",
        "\n",
        "* Better **quality** (forces structure and tool-awareness).\n",
        "* Higher **safety** (explicit risks and acceptance checks).\n",
        "* Stronger **explainability** (plan + critique trail).\n",
        "* Still **modular** (can turn review on/off per task, or swap the reviewer persona).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oncqNWInCPri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making agents **capability-driven**\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Avoid modifying core agent logic**\n",
        "\n",
        "If you want an agent to gain time-awareness, planning, logging, or any other behavior:\n",
        "\n",
        "* In a *non-capability* setup → you’d open `Agent` and hardcode that new logic.\n",
        "* In this setup → you write a **new capability** and pass it into the `Agent` constructor.\n",
        "\n",
        "The Agent loop stays **exactly the same** — it just calls each capability hook at the right time.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Mix and match behaviors like LEGO pieces**\n",
        "\n",
        "Capabilities are **modular units**:\n",
        "\n",
        "* `TimeAwareCapability()`\n",
        "* `PlanFirstCapability()`\n",
        "* `LoggingCapability()`\n",
        "\n",
        "Want an agent that logs and plans? Just include both in the list:\n",
        "\n",
        "```python\n",
        "capabilities=[LoggingCapability(), PlanFirstCapability()]\n",
        "```\n",
        "\n",
        "Want one that plans first but doesn’t log? Remove the logging piece — nothing else breaks.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Promote reusability across agents**\n",
        "\n",
        "Because a capability doesn’t depend on *a specific agent*, you can plug it into **any** agent that follows the same lifecycle:\n",
        "\n",
        "* Your \"data analysis\" agent\n",
        "* Your \"customer support\" agent\n",
        "* Your \"marketing copywriter\" agent\n",
        "  All can use `PlanFirstCapability()` without rewriting it.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Reduce bugs and side effects**\n",
        "\n",
        "When you change a capability, you’re only touching *that one behavior*.\n",
        "Since it’s not woven deep into the Agent code, you don’t risk breaking the Agent’s orchestration loop.\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Scale with less pain**\n",
        "\n",
        "As your system grows:\n",
        "\n",
        "* You’ll have dozens of agents.\n",
        "* Each needs slightly different “addons.”\n",
        "* Instead of cloning agents or branching code, you just build a library of capabilities and snap them together.\n",
        "\n",
        "---\n",
        "\n",
        "It’s the same reason big web frameworks (like Flask/Django or Express.js) use **middleware** — each layer is independent, but together they form the complete request/response cycle.\n",
        "\n"
      ],
      "metadata": {
        "id": "BtXAHrLFWZTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are Hooks?\n",
        "\n",
        "In this context, **hooks** are *predefined points in the agent’s lifecycle* where you can “hook” in extra behavior without modifying the core code.\n",
        "\n",
        "Think of them as **event listeners** or **extension points** — they’re places where the agent says:\n",
        "\n",
        "> “Hey, I just finished this step — does any capability want to do something now?”\n",
        "\n",
        "---\n",
        "\n",
        "### In our agent lifecycle, hooks look like this:\n",
        "\n",
        "Each method in `Capability` **is a hook**:\n",
        "\n",
        "| Hook (Method)            | When it runs                  | Example use                       |\n",
        "| ------------------------ | ----------------------------- | --------------------------------- |\n",
        "| `init()`                 | Once when the agent starts    | Add initial memory, set time zone |\n",
        "| `start_agent_loop()`     | Start of each loop            | Check progress, reset variables   |\n",
        "| `process_prompt()`       | Before sending prompt to LLM  | Add current time, insert plan     |\n",
        "| `process_response()`     | After LLM responds            | Sanitize or validate response     |\n",
        "| `process_action()`       | Before executing a tool       | Add metadata, enforce rules       |\n",
        "| `process_result()`       | After executing a tool        | Transform output, log results     |\n",
        "| `process_new_memories()` | When new memories are created | Filter or enrich memory           |\n",
        "| `end_agent_loop()`       | After each loop finishes      | Log summary, cleanup              |\n",
        "| `should_terminate()`     | Before next loop starts       | Decide to stop                    |\n",
        "| `terminate()`            | When agent stops              | Final cleanup                     |\n",
        "\n",
        "---\n",
        "\n",
        "### Why hooks are powerful\n",
        "\n",
        "* **Separation of concerns** → The Agent doesn’t care *what* happens in each hook, it just calls them in order.\n",
        "* **Plug-and-play** → You can add or remove behaviors just by adding/removing capabilities.\n",
        "* **No core changes** → Hooks are always there, even if no capability uses them.\n",
        "\n",
        "---\n",
        "\n",
        "💡 **Analogy:**\n",
        "Imagine the Agent is a cooking robot.\n",
        "Hooks are like “pauses” where you can step in and do something:\n",
        "\n",
        "* After it chops vegetables → you could taste-test.\n",
        "* Before it plates the dish → you could sprinkle garnish.\n",
        "* After it serves → you could take a photo.\n",
        "\n",
        "You’re not rewriting the robot — you’re just hooking in at the right spots.\n",
        "\n"
      ],
      "metadata": {
        "id": "vWl8I2SnXADv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zwb5X47sCSpf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}